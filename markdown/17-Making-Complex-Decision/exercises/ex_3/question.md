

Select a specific member of the set of policies that are optimal for
$R(s)>0$ as shown in
Figure <a class="insideBookFigRef" target="_blank" href="https://aimacode.github.io/aima-exercises/figures/sequential-decision-policies-figure.png">sequential-decision-policies-figure</a>(b), and
calculate the fraction of time the agent spends in each state, in the
limit, if the policy is executed forever. (<i>Hint</i>:
Construct the state-to-state transition probability matrix corresponding
to the policy and see
Exercise <a class="exerciseRef" href="{{ site.baseurl }}/dbn-exercises/ex_2/">markov-convergence-exercise</a>.)
