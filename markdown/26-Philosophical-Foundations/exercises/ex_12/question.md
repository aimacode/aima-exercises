

Some critics object that AI is impossible, while others object that it
is *too* possible and that ultraintelligent machines pose a
threat. Which of these objections do you think is more likely? Would it
be a contradiction for someone to hold both positions?
