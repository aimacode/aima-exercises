

Some linguists have argued as follows:<br>
<br>
 Children learning a language hear only <i>positive
 examples</i> of the language and no <i>negative
 examples</i>. Therefore, the hypothesis that “every possible
 sentence is in the language” is consistent with all the observed
 examples. Moreover, this is the simplest consistent hypothesis.
 Furthermore, all grammars for languages that are supersets of the true
 language are also consistent with the observed data. Yet children do
 induce (more or less) the right grammar. It follows that they begin
 with very strong innate grammatical constraints that rule out all of
 these more general hypotheses <i>a priori</i>.<br>

Comment on the weak point(s) in this argument from a statistical
learning viewpoint.
