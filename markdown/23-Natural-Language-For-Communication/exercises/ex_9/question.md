[Exercise 23.9](ex_9/)

Some linguists have argued as follows:

> Children learning a language hear only *positive
> examples* of the language and no *negative
> examples*. Therefore, the hypothesis that “every possible
> sentence is in the language” is consistent with all the observed
> examples. Moreover, this is the simplest consistent hypothesis.
> Furthermore, all grammars for languages that are supersets of the true
> language are also consistent with the observed data. Yet children do
> induce (more or less) the right grammar. It follows that they begin
> with very strong innate grammatical constraints that rule out all of
> these more general hypotheses *a priori*.

Comment on the weak point(s) in this argument from a statistical
learning viewpoint.
