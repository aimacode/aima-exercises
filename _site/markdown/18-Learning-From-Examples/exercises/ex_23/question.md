

Consider an ensemble learning algorithm that
uses simple majority voting among $K$ learned hypotheses.
Suppose that each hypothesis has error $\epsilon$ and that the errors
made by each hypothesis are independent of the othersâ€™. Calculate a
formula for the error of the ensemble algorithm in terms of $K$
and $\epsilon$, and evaluate it for the cases where
$K=5$, 10, and 20 and $\epsilon={0.1}$, 0.2,
and 0.4. If the independence assumption is removed, is it possible for
the ensemble error to be <i>worse</i> than $\epsilon$?
