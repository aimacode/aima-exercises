

Consider the following set of examples, each with six inputs and one
target output:<br>

|    |  |   |   |  |  |  |   |   |  |  |  |   |  |  |
| --- | --- | --- | --- | --- | --- |
| $\textbf{x}_1$  | 1 | 1  | 1  | 1 | 1 | 1 | 1  | 0  | 0 | 0 | 0 | 0  | 0  | 0 |
| $\textbf{x}_2$  | 0 | 0  | 0  | 1 | 1 | 0 | 0  | 1  | 1 | 0 | 1 | 0  | 1  | 1 |
| $\textbf{x}_3$  | 1 | 1  | 1  | 0 | 1 | 0 | 0  | 1  | 1 | 0 | 0 | 0  | 1  | 1 |
| $\textbf{x}_4$  | 0 | 1  | 0  | 0 | 1 | 0 | 0  | 1  | 0 | 1 | 1 | 1  | 0  | 1 |
| $\textbf{x}_5$  | 0 | 0  | 1  | 1 | 0 | 1 | 1  | 0  | 1 | 1 | 0 | 0  | 1  | 0 |
| $\textbf{x}_6$  | 0 | 0  | 0  | 1 | 0 | 1 | 0  | 1  | 1 | 0 | 1 | 1  | 1  | 0 |
| $\textbf{T}$  | 1 | 1  | 1  | 1 | 1 | 1 | 0  | 1  | 0 | 0 | 0 | 0  | 0  | 0 |


1.  Run the perceptron learning rule on these data and show the
    final weights.<br>

2.  Run the decision tree learning rule, and show the resulting
    decision tree.<br>

3.  Comment on your results.<br>
