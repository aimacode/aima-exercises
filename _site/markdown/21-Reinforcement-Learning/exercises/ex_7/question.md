Implement an exploring reinforcement learning
agent that uses direct utility estimation. Make two versions—one with a
tabular representation and one using the function approximator in
Equation (<a class="equationRef" title="" href="#">4x3-linear-approx-equation</a>). Compare their
performance in three environments:<br>

1.  The $4\times 3$ world described in the chapter.<br>

2.  A ${10}\times {10}$ world with no obstacles and a +1 reward
    at (10,10).<br>

3.  A ${10}\times {10}$ world with no obstacles and a +1 reward
    at (5,5).
