[Exercise 21.6](ex_6/)

Adapt the vacuum world (ChapterÂ [agents-chapter](#/)) for
reinforcement learning by including rewards for squares being clean.
Make the world observable by providing suitable percepts. Now experiment
with different reinforcement learning agents. Is function approximation
necessary for success? What sort of approximator works for this
application?

