<!DOCTYPE html>
<html>
  <head>
    <title>Main –  – </title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    
    <meta name="author" content="" />

    
    <meta property="og:title" content="Main" />
    <meta property="twitter:title" content="Main" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="https://code.jquery.com/jquery-3.3.1.js"></script>
    <script src="//www.gstatic.com/firebasejs/5.0.4/firebase.js"></script>
    <script type="text/javascript" src="//aima-exercises.firebaseapp.com/config.js"></script>
<!--     <script src="//http://www.gstatic.com/firebasejs/5.0.4/firebase-firestore.js"></script>
 -->
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title=" - " href="/feed.xml" />
<!--     <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
 -->
    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <input type="checkbox" id="toggleheader">
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <center>
            <h1>Aritificial Intelligence: A Modern Approach</h1>
            <h3>Stuart J. Russell and Peter Norvig</h3>
          </center>
        </header>
      </div>
    </div>
    <input type="checkbox" id="toggletoc">
    <div class="toc">
      <div>Table of Contents</div>
      <ul>
	<li>
		<span>Part &#x2160; Artificial Intelligence</span>
		<ol>
			<li><a href="/intro-exercises">1. Introduction</a></li>
			<li><a href="/agents-exercises">2. Intelligent Agent</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2161; Problem-solving</span>
		<ol>
			<li><a href="/search-exercises">3. Solving Problems By Searching</a></li>
			<li><a href="/advanced-search-exercises">4. Beyond Classical Search</a></li>
			<li><a href="/game-playing-exercises">5. Adversarial Search</a></li>
			<li><a href="/csp-exercises">6. Constraint Satisfaction Problems</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2162; Knowledge, reasoning, and planning</span>
		<ol>
			<li><a href="/knowledge-logic-exercises">7. Logical Agents</a></li>
			<li><a href="/fol-exercises">8. First Order Logic</a></li>
			<li><a href="/logical-inference-exercises">9. Inference In First Order Logic</a></li>
			<li><a href="/planning-exercises">10. Classical Planning</a></li>
			<li><a href="/advanced-planning-exercises">11. Planning And Acting In The Real World</a></li>
			<li><a href="/kr-exercises">12. Knowledge Representation</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2163; Uncertain knowledge and reasoning</span>
		<ol>
			<li><a href="/probability-exercises">13. Quantifying Uncertainity</a></li>
			<li><a href="/bayes-nets-exercises">14. Probabilistic Reasoning</a></li>
			<li><a href="/dbn-exercises">15. Probabilistic Reasoning Over Time</a></li>
			<li><a href="/decision-theory-exercises">16. Making Simple Decisions</a></li>
			<li><a href="/complex-decisions-exercises">17. Making Complex Decision</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2164; Learning</span>
		<ol>
			<li><a href="/concept-learning-exercises">18. Learning From Examples</a></li>
			<li><a href="/ilp-exercises">19. Knowledge In Learning</a></li>
			<li><a href="/bayesian-learning-exercises">20. Learning Probabilistic Models</a></li>
			<li><a href="/reinforcement-learning-exercises">21. Reinforcement Learning</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2165; Communicating, perceiving, and acting</span>
		<ol>
			<li><a href="/nlp-communicating-exercises">22. Natural Language Processing</a></li>
			<li><a href="/nlp-english-exercises">23. Natural Language For Communication</a></li>
			<li><a href="/perception-exercises">24. Perception</a></li>
			<li><a href="/robotics-exercises">25. Robotics</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2166; Conclusions</span>
		<ol>
			<li><a href="/philosophy-exercises">26. Philosophical Foundations</a></li>
			<li><a href="/#/"> Future Exercises</a></li>
		</ol>
	</li>
</ul>
    </div>
    <div id="main" role="main" class="container">
      



<ul class="breadcrumb">

  <label for="toggletoc" class="toc-icon">
    <span></span>
    <span></span>
    <span></span>
  </label>

   
    <li><a class="breadcrumb-text" href="/">home</a> &nbsp; </li>
   

<label for="toggleheader" class="toggleheader" title="Toggle Header">
    &#9167;
</label>
</ul>

      <article class="post">

  <div class="entry">
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    },
    "HTML-CSS": { 
      preferredFont: "TeX", 
      availableFonts: ["STIX","TeX"], 
      styles: {".MathJax": {}} 
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h1 id="10-classical-planning">10. Classical Planning</h1>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_1" data-rating="0"></i></div>
<p><a href="ex_1/">Exercise 10.1</a></p>

<p>Consider a robot whose operation is described by the following PDDL
operators:</p>

<p><script type="math/tex">Op({Go(x,y)},{At(Robot,x)},{\lnot At(Robot,x) \land At(Robot,y)})</script>
<script type="math/tex">Op({Pick(o)},{At(Robot,x)\land At(o,x)},{\lnot At(o,x) \land Holding(o)})</script>
<script type="math/tex">Op({Drop(o)},{At(Robot,x)\land Holding(o)},{At(o,x) \land \lnot Holding(o)}</script></p>

<ol>
  <li>
    <p>The operators allow the robot to hold more than one object. Show how
to modify them with an $EmptyHand$ predicate for a robot that can
hold only one object.</p>
  </li>
  <li>
    <p>Assuming that these are the only actions in the world, write a
successor-state axiom for $EmptyHand$.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_2" data-rating="0"></i></div>
<p><a href="ex_2/">Exercise 10.2</a></p>

<p>Describe the differences and similarities between problem solving and
planning.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_3" data-rating="0"></i></div>
<p><a href="ex_3/">Exercise 10.3</a></p>

<p>[strips-airport-exercise]Given the action schemas and initial state
from Figure <a href="#/">airport-pddl-algorithm</a>, what are all the
applicable concrete instances of ${Fly}(p,{from},{to})$ in the
state described by</p>

<script type="math/tex; mode=display">At(P_1,JFK) \land At(P_2,SFO) \land Plane(P_1) \land Plane(P_2) \land Airport(JFK) \land Airport(SFO)?</script>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_4" data-rating="0"></i></div>
<p><a href="ex_4/">Exercise 10.4</a></p>

<p>The monkey-and-bananas problem is faced by a monkey in a laboratory with
some bananas hanging out of reach from the ceiling. A box is available
that will enable the monkey to reach the bananas if he climbs on it.
Initially, the monkey is at $A$, the bananas at $B$, and the box at $C$.
The monkey and box have height ${Low}$, but if the monkey climbs onto
the box he will have height ${High}$, the same as the bananas. The
actions available to the monkey include ${Go}$ from one place to
another, ${Push}$ an object from one place to another, ${ClimbUp}$
onto or ${ClimbDown}$ from an object, and ${Grasp}$ or ${Ungrasp}$
an object. The result of a ${Grasp}$ is that the monkey holds the
object if the monkey and object are in the same place at the same
height.</p>

<ol>
  <li>
    <p>Write down the initial state description.</p>
  </li>
  <li>
    <p>Write the six action schemas.</p>
  </li>
  <li>
    <p>Suppose the monkey wants to fool the scientists, who are off to tea,
by grabbing the bananas, but leaving the box in its original place.
Write this as a general goal (i.e., not assuming that the box is
necessarily at C) in the language of situation calculus. Can this
goal be solved by a classical planning system?</p>
  </li>
  <li>
    <p>Your schema for pushing is probably incorrect, because if the object
is too heavy, its position will remain the same when the ${Push}$
schema is applied. Fix your action schema to account for
heavy objects.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_5" data-rating="0"></i></div>
<p><a href="ex_5/">Exercise 10.5</a></p>

<p>The original {Strips} planner was designed to control Shakey the robot.
Figure <a href="#shakey-figure">shakey-figure</a> shows a version of Shakey’s world
consisting of four rooms lined up along a corridor, where each room has
a door and a light switch. The actions in Shakey’s world include moving from place to place,
pushing movable objects (such as boxes), climbing onto and down from
rigid objects (such as boxes), and turning light switches on and off.
The robot itself could not climb on a box or toggle a switch, but the
planner was capable of finding and printing out plans that were beyond
the robot’s abilities. Shakey’s six actions are the following:</p>

<ul>
  <li>
    <p>${Go}(x,y,r)$, which requires that Shakey be ${At}$ $x$ and that
$x$ and $y$ are locations ${In}$ the same room $r$. By convention
a door between two rooms is in both of them.</p>
  </li>
  <li>
    <p>Push a box $b$ from location $x$ to location $y$ within the same
room: ${Push}(b,x,y,r)$. You will need the predicate ${Box}$ and
constants for the boxes.</p>
  </li>
  <li>
    <p>Climb onto a box from position $x$: ${ClimbUp}(x, b)$; climb down
from a box to position $x$: ${ClimbDown}(b, x)$. We will need the
predicate ${On}$ and the constant ${Floor}$.</p>
  </li>
  <li>
    <p>Turn a light switch on or off: ${TurnOn}(s,b)$;
${TurnOff}(s,b)$. To turn a light on or off, Shakey must be on top
of a box at the light switch’s location.</p>
  </li>
</ul>

<p>Write PDDL sentences for Shakey’s six actions and the initial state from
Figure <a href="#shakey-figure">shakey-figure</a>. Construct a plan for Shakey to
get ${Box}{}_2$ into ${Room}{}_2$.</p>
<center>
<b id="shakey-figure">Figure [shakey-figure]</b> Shakey's world. Shakey can move between landmarks within a room, can pass through the door between rooms, can climb climbable objects and push pushable objects, and can flip light switches.
</center>
<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/shakey2.svg" alt="shakey-figure" /></p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_6" data-rating="0"></i></div>
<p><a href="ex_6/">Exercise 10.6</a></p>

<p>A finite Turing machine has a finite one-dimensional tape of cells, each
cell containing one of a finite number of symbols. One cell has a read
and write head above it. There is a finite set of states the machine can
be in, one of which is the accept state. At each time step, depending on
the symbol on the cell under the head and the machine’s current state,
there are a set of actions we can choose from. Each action involves
writing a symbol to the cell under the head, transitioning the machine
to a state, and optionally moving the head left or right. The mapping
that determines which actions are allowed is the Turing machine’s
program. Your goal is to control the machine into the accept state.</p>

<p>Represent the Turing machine acceptance problem as a planning problem.
If you can do this, it demonstrates that determining whether a planning
problem has a solution is at least as hard as the Turing acceptance
problem, which is PSPACE-hard.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_7" data-rating="0"></i></div>
<p><a href="ex_7/">Exercise 10.7 [negative-effects-exercise]</a></p>

<p>Explain why dropping negative effects from
every action schema results in a relaxed problem, provided that
preconditions and goals contain only positive literals.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_8" data-rating="0"></i></div>
<p><a href="ex_8/">Exercise 10.8 [sussman-anomaly-exercise]</a></p>

<p>Figure <a href="#/">sussman-anomaly-figure</a>
(page <a href="#/">sussman-anomaly-figure</a>) shows a blocks-world problem that is known as the {Sussman anomaly}.
The problem was considered anomalous because the noninterleaved planners
of the early 1970s could not solve it. Write a definition of the problem
and solve it, either by hand or with a planning program. A
noninterleaved planner is a planner that, when given two subgoals
$G_{1}$ and $G_{2}$, produces either a plan for $G_{1}$ concatenated
with a plan for $G_{2}$, or vice versa. Can a noninterleaved planner
solve this problem? How, or why not?</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_9" data-rating="0"></i></div>
<p><a href="ex_9/">Exercise 10.9</a></p>

<p>Prove that backward search with PDDL problems is complete.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_10" data-rating="0"></i></div>
<p><a href="ex_10/">Exercise 10.10</a></p>

<p>Construct levels 0, 1, and 2 of the planning graph for the problem in
Figure <a href="#/">airport-pddl-algorithm</a>.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_11" data-rating="0"></i></div>
<p><a href="ex_11/">Exercise 10.11 [graphplan-proof-exercise]</a></p>

<p>Prove the following assertions about
planning graphs:</p>

<ol>
  <li>
    <p>A literal that does not appear in the final level of the graph
cannot be achieved.</p>
  </li>
  <li>
    <p>The level cost of a literal in a serial graph is no greater than the
actual cost of an optimal plan for achieving it.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_12" data-rating="0"></i></div>
<p><a href="ex_12/">Exercise 10.12</a></p>

<p>We saw that planning graphs can handle only propositional actions. What
if we want to use planning graphs for a problem with variables in the
goal, such as ${At}(P_{1}, x) 
    \land {At}(P_{2}, x)$, where $x$ is assumed to be bound by an
existential quantifier that ranges over a finite domain of locations?
How could you encode such a problem to work with planning graphs?</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_13" data-rating="0"></i></div>
<p><a href="ex_13/">Exercise 10.13</a></p>

<p>The set-level heuristic (see page <a href="#/">set-level-page</a>) uses a planning graph
to estimate the cost of achieving a conjunctive goal from the current
state. What relaxed problem is the set-level heuristic the solution to?</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_14" data-rating="0"></i></div>
<p><a href="ex_14/">Exercise 10.14</a></p>

<p>Examine the definition of <strong>bidirectional
search</strong> in Chapter <a href="#/">search-chapter</a>.</p>

<ol>
  <li>
    <p>Would bidirectional state-space search be a good idea for planning?</p>
  </li>
  <li>
    <p>What about bidirectional search in the space of partial-order plans?</p>
  </li>
  <li>
    <p>Devise a version of partial-order planning in which an action can be
added to a plan if its preconditions can be achieved by the effects
of actions already in the plan. Explain how to deal with conflicts
and ordering constraints. Is the algorithm essentially identical to
forward state-space search?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_15" data-rating="0"></i></div>
<p><a href="ex_15/">Exercise 10.15</a></p>

<p>We contrasted forward and backward state-space searchers with
partial-order planners, saying that the latter is a plan-space searcher.
Explain how forward and backward state-space search can also be
considered plan-space searchers, and say what the plan refinement
operators are.</p>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_16" data-rating="0"></i></div>
<p><a href="ex_16/">Exercise 10.16 [satplan-preconditions-exercise]</a></p>

<p>Up to now we have assumed that the
plans we create always make sure that an action’s preconditions are
satisfied. Let us now investigate what propositional successor-state
axioms such as ${HaveArrow}^{t+1} {\;\;{\Leftrightarrow}\;\;}{}$
$({HaveArrow}^t
\land \lnot {Shoot}^t)$ have to say about actions whose preconditions
are not satisfied.</p>

<ol>
  <li>
    <p>Show that the axioms predict that nothing will happen when an action
is executed in a state where its preconditions are not satisfied.</p>
  </li>
  <li>
    <p>Consider a plan $p$ that contains the actions required to achieve a
goal but also includes illegal actions. Is it the case that
<script type="math/tex">initial state \land successor-state axioms \land
p {\models} goal ?</script></p>
  </li>
  <li>
    <p>With first-order successor-state axioms in situation calculus, is it
possible to prove that a plan containing illegal actions will
achieve the goal?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_17" data-rating="0"></i></div>
<p><a href="ex_17/">Exercise 10.17 [strips-translation-exercise]</a></p>

<p>Consider how to translate a set of action
schemas into the successor-state axioms of situation calculus.</p>

<ol>
  <li>
    <p>Consider the schema for ${Fly}(p,{from},{to})$. Write a
logical definition for the predicate
${Poss}({Fly}(p,{from},{to}),s)$, which is true if the
preconditions for ${Fly}(p,{from},{to})$ are satisfied in
situation $s$.</p>
  </li>
  <li>
    <p>Next, assuming that ${Fly}(p,{from},{to})$ is the only action
schema available to the agent, write down a successor-state axiom
for ${At}(p,x,s)$ that captures the same information as the
action schema.</p>
  </li>
  <li>
    <p>Now suppose there is an additional method of travel:
${Teleport}(p,{from},{to})$. It has the additional
precondition $\lnot {Warped}(p)$ and the additional effect
${Warped}(p)$. Explain how the situation calculus knowledge base
must be modified.</p>
  </li>
  <li>
    <p>Finally, develop a general and precisely specified procedure for
carrying out the translation from a set of action schemas to a set
of successor-state axioms.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="planning-exercises" data-exercise="ex_18" data-rating="0"></i></div>
<p><a href="ex_18/">Exercise 10.18 [disjunctive-satplan-exercise]</a></p>

<p>In the $SATPlan$ algorithm in
Figure <a href="#/">satplan-agent-algorithm</a> (page <a href="#/">satplan-agent-algorithm</a>),
each call to the satisfiability algorithm asserts a goal $g^T$, where
$T$ ranges from 0 to $T_{max}$. Suppose instead that the
satisfiability algorithm is called only once, with the goal
$g^0 \vee g^1 \vee \cdots \vee g^{T_{max}}$.</p>

<ol>
  <li>
    <p>Will this always return a plan if one exists with length less than
or equal to $T_{max}$?</p>
  </li>
  <li>
    <p>Does this approach introduce any new spurious “solutions”?</p>
  </li>
  <li>
    <p>Discuss how one might modify a satisfiability algorithm such as $WalkSAT$ so
that it finds short solutions (if they exist) when given a
disjunctive goal of this form.</p>
  </li>
</ol>


  </div>

<!--   <div class="date">
    Written on 
  </div>
 -->
  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'nalinc';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>


</article>

<script type="text/javascript">
var chapter  = String('/planning-exercises/')
var chapterName = chapter.match(/\/([^\/]*)\//, "")[1]
$.get( "https://aima-exercises.firebaseapp.com/rating/"+chapterName, function( data ) {
  console.log(data)
  $("i[data-chapter='"+chapterName+"']").each(function(index,element){
  	ex = $(element).data("exercise")
  	if(ex in data){
  		console.log(data[ex])
  		$(element).attr("data-rating",data[ex])
  	}
    $(".arrow-up").removeClass("loader")
  })
});

$(document).on('click',"i[data-chapter]",function(e){
	ele = $(e.target)
  ele.addClass("loader")
	exerciseName = ele.data("exercise")
	$.post( "https://aima-exercises.firebaseapp.com/rating/"+chapterName+"/"+exerciseName, function( data ) {
	  console.log(data)
	  ele.attr("data-rating",data["rating"])
    ele.removeClass("loader")
	});	
})


</script>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!--            Designed by <a href="http://nalinc.github.io" style="color:#2196F3">Nalin</a> &#9889; 
           Written in <a href="#/" style="color: #2a932a">Markdown</a> &#9889; 
           Powered by <a href="http://jekyllrb.com" style="color: #d73838">Jekyll</a>    -->
          <!-- 











 -->
        </footer>
      </div>
    </div>

    


    <script type="text/javascript">
      // firestore =firebase.firestore();
      // function rateExercise(e){
      //   console.log(e.target)
      //   chapterLabel = $(e.target).data("chapter")
      //   exerciseLabel = $(e.target).data("exercise")
      //   docRef = firestore.collection("rating").doc(chapterLabel)
      //   score = 0
      //   docRef.get().then(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //      // score = myData
      //       console.log(myData)
      //       if(exerciseLabel in myData){
      //         myData[exerciseLabel] += 1
      //       }else{
      //         myData[exerciseLabel] = 1
      //       }
      //      // $(e.target).data("rating",score);
      //       docRef.set(myData).then(function(){
      //         console.log("status saved")
      //         console.log(myData[exerciseLabel])
      //         $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       })
      //     }
      //   })
      // }
      // getRealTimeUpdates = function(){
      //   docRef = firestore.collection("rating").doc("intro-exercises");
      //   docRef.onSnapshot(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //       for(key in myData){
      //         console.log(key)  
      //         // $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       }
      //     }
      //   })
      // }

      // getRealTimeUpdates()
      // $(document).on("click",".arrow-up", rateExercise)
    </script>
  </body>
</html>
