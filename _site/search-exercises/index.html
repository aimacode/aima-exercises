<!DOCTYPE html>
<html>
  <head>
    <title>Main –  – </title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    
    <meta name="author" content="" />

    
    <meta property="og:title" content="Main" />
    <meta property="twitter:title" content="Main" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="https://code.jquery.com/jquery-3.3.1.js"></script>
    <script src="//www.gstatic.com/firebasejs/5.0.4/firebase.js"></script>
    <script type="text/javascript" src="//aima-exercises.firebaseapp.com/config.js"></script>
<!--     <script src="//http://www.gstatic.com/firebasejs/5.0.4/firebase-firestore.js"></script>
 -->
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title=" - " href="/feed.xml" />
<!--     <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
 -->
    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <input type="checkbox" id="toggleheader">
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <center>
            <h1>Aritificial Intelligence: A Modern Approach</h1>
            <h3>Stuart J. Russell and Peter Norvig</h3>
          </center>
        </header>
      </div>
    </div>
    <input type="checkbox" id="toggletoc">
    <div class="toc">
      <div>Table of Contents</div>
      <form action="/search" id="site_search" autocomplete="off" method="GET">
        <input type="text" name="query" class="toc_search" placeholder="Search within AIMA Exercises">
      </form>
      <ul>
	<li>
		<span>Part &#x2160; Artificial Intelligence</span>
		<ol>
			<li><a href="/intro-exercises">1. Introduction</a></li>
			<li><a href="/agents-exercises">2. Intelligent Agent</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2161; Problem-solving</span>
		<ol>
			<li><a href="/search-exercises">3. Solving Problems By Searching</a></li>
			<li><a href="/advanced-search-exercises">4. Beyond Classical Search</a></li>
			<li><a href="/game-playing-exercises">5. Adversarial Search</a></li>
			<li><a href="/csp-exercises">6. Constraint Satisfaction Problems</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2162; Knowledge, reasoning, and planning</span>
		<ol>
			<li><a href="/knowledge-logic-exercises">7. Logical Agents</a></li>
			<li><a href="/fol-exercises">8. First Order Logic</a></li>
			<li><a href="/logical-inference-exercises">9. Inference In First Order Logic</a></li>
			<li><a href="/planning-exercises">10. Classical Planning</a></li>
			<li><a href="/advanced-planning-exercises">11. Planning And Acting In The Real World</a></li>
			<li><a href="/kr-exercises">12. Knowledge Representation</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2163; Uncertain knowledge and reasoning</span>
		<ol>
			<li><a href="/probability-exercises">13. Quantifying Uncertainity</a></li>
			<li><a href="/bayes-nets-exercises">14. Probabilistic Reasoning</a></li>
			<li><a href="/dbn-exercises">15. Probabilistic Reasoning Over Time</a></li>
			<li><a href="/decision-theory-exercises">16. Making Simple Decisions</a></li>
			<li><a href="/complex-decisions-exercises">17. Making Complex Decision</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2164; Learning</span>
		<ol>
			<li><a href="/concept-learning-exercises">18. Learning From Examples</a></li>
			<li><a href="/ilp-exercises">19. Knowledge In Learning</a></li>
			<li><a href="/bayesian-learning-exercises">20. Learning Probabilistic Models</a></li>
			<li><a href="/reinforcement-learning-exercises">21. Reinforcement Learning</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2165; Communicating, perceiving, and acting</span>
		<ol>
			<li><a href="/nlp-communicating-exercises">22. Natural Language Processing</a></li>
			<li><a href="/nlp-english-exercises">23. Natural Language For Communication</a></li>
			<li><a href="/perception-exercises">24. Perception</a></li>
			<li><a href="/robotics-exercises">25. Robotics</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2166; Conclusions</span>
		<ol>
			<li><a href="/philosophy-exercises">26. Philosophical Foundations</a></li>
			<li><a href="/#/"> Future Exercises</a></li>
		</ol>
	</li>
</ul>
    </div>
    <div id="main" role="main" class="container">
      



<ul class="breadcrumb">

  <label for="toggletoc" class="toc-icon">
    <span></span>
    <span></span>
    <span></span>
  </label>

   
    <li><a class="breadcrumb-text" href="/">home</a> &nbsp; </li>
   

<label for="toggleheader" class="toggleheader" title="Toggle Header">
    &#9167;
</label>
</ul>

      <article class="post">

  <div class="entry">
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    },
    "HTML-CSS": { 
      preferredFont: "TeX", 
      availableFonts: ["STIX","TeX"], 
      styles: {".MathJax": {}} 
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h1 id="3-solving-problems-by-searching">3. Solving Problems By Searching</h1>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_1" data-rating="0"></i></div>
<p><a href="ex_1/">Exercise 3.1</a></p>

<p>Explain why problem formulation must follow goal formulation.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_2" data-rating="0"></i></div>
<p><a href="ex_2/">Exercise 3.2</a></p>

<p>Give a complete problem formulation for each of the following problems.
Choose a formulation that is precise enough to be implemented.</p>

<ol>
  <li>
    <p>There are six glass boxes in a row, each with a lock. Each of the
first five boxes holds a key unlocking the next box in line; the
last box holds a banana. You have the key to the first box, and you
want the banana.</p>
  </li>
  <li>
    <p>You start with the sequence ABABAECCEC, or in general any sequence
made from A, B, C, and E. You can transform this sequence using the
following equalities: AC = E, AB = BC, BB = E, and E$x$ = $x$ for
any $x$. For example, ABBC can be transformed into AEC, and then AC,
and then E. Your goal is to produce the sequence E.</p>
  </li>
  <li>
    <p>There is an $n \times n$ grid of squares, each square initially
being either unpainted floor or a bottomless pit. You start standing
on an unpainted floor square, and can either paint the square under
you or move onto an adjacent unpainted floor square. You want the
whole floor painted.</p>
  </li>
  <li>
    <p>A container ship is in port, loaded high with containers. There 13
rows of containers, each 13 containers wide and 5 containers tall.
You control a crane that can move to any location above the ship,
pick up the container under it, and move it onto the dock. You want
the ship unloaded.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_3" data-rating="0"></i></div>
<p><a href="ex_3/">Exercise 3.3</a></p>

<p>Your goal is to navigate a robot out of a maze. The robot starts in the
center of the maze facing north. You can turn the robot to face north,
east, south, or west. You can direct the robot to move forward a certain
distance, although it will stop before hitting a wall.</p>

<ol>
  <li>
    <p>Formulate this problem. How large is the state space?</p>
  </li>
  <li>
    <p>In navigating a maze, the only place we need to turn is at the
intersection of two or more corridors. Reformulate this problem
using this observation. How large is the state space now?</p>
  </li>
  <li>
    <p>From each point in the maze, we can move in any of the four
directions until we reach a turning point, and this is the only
action we need to do. Reformulate the problem using these actions.
Do we need to keep track of the robot’s orientation now?</p>
  </li>
  <li>
    <p>In our initial description of the problem we already abstracted from
the real world, restricting actions and removing details. List three
such simplifications we made.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_4" data-rating="0"></i></div>
<p><a href="ex_4/">Exercise 3.4</a></p>

<p>You have a $9 \times 9$ grid of squares, each of which can be colored
red or blue. The grid is initially colored all blue, but you can change
the color of any square any number of times. Imagining the grid divided
into nine $3 \times 3$ sub-squares, you want each sub-square to be all
one color but neighboring sub-squares to be different colors.</p>

<ol>
  <li>
    <p>Formulate this problem in the straightforward way. Compute the size
of the state space.</p>
  </li>
  <li>
    <p>You need color a square only once. Reformulate, and compute the size
of the state space. Would breadth-first graph search perform faster
on this problem than on the one in (a)? How about iterative
deepening tree search?</p>
  </li>
  <li>
    <p>Given the goal, we need consider only colorings where each
sub-square is uniformly colored. Reformulate the problem and compute
the size of the state space.</p>
  </li>
  <li>
    <p>How many solutions does this problem have?</p>
  </li>
  <li>
    <p>Parts (b) and (c) successively abstracted the original problem (a).
Can you give a translation from solutions in problem (c) into
solutions in problem (b), and from solutions in problem (b) into
solutions for problem (a)?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_5" data-rating="0"></i></div>
<p><a href="ex_5/">Exercise 3.5 [two-friends-exercise]</a></p>

<p>Suppose two friends live in different cities on
a map, such as the Romania map shown in . On every turn, we can
simultaneously move each friend to a neighboring city on the map. The
amount of time needed to move from city $i$ to neighbor $j$ is equal to
the road distance $d(i,j)$ between the cities, but on each turn the
friend that arrives first must wait until the other one arrives (and
calls the first on his/her cell phone) before the next turn can begin.
We want the two friends to meet as quickly as possible.</p>

<ol>
  <li>
    <p>Write a detailed formulation for this search problem. (You will find
it helpful to define some formal notation here.)</p>
  </li>
  <li>
    <p>Let $D(i,j)$ be the straight-line distance between cities $i$ and
$j$. Which of the following heuristic functions are admissible? (i)
$D(i,j)$; (ii) $2\cdot D(i,j)$; (iii) $D(i,j)/2$.</p>
  </li>
  <li>
    <p>Are there completely connected maps for which no solution exists?</p>
  </li>
  <li>
    <p>Are there maps in which all solutions require one friend to visit
the same city twice?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_6" data-rating="0"></i></div>
<p><a href="ex_6/">Exercise 3.6 [8puzzle-parity-exercise]</a></p>

<p>Show that the 8-puzzle states are divided
into two disjoint sets, such that any state is reachable from any other
state in the same set, while no state is reachable from any state in the
other set. (<em>Hint:</em> See @Berlekamp+al:1982.) Devise a procedure to decide
which set a given state is in, and explain why this is useful for
generating random states.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_7" data-rating="0"></i></div>
<p><a href="ex_7/">Exercise 3.7 [nqueens-size-exercise]</a></p>

<p>Consider the $n$-queens problem using the
“efficient” incremental formulation given on page <a href="#/">nqueens-page</a>. Explain why the state
space has at least $\sqrt[3]{n!}$ states and estimate the largest $n$
for which exhaustive exploration is feasible. (<em>Hint</em>:
Derive a lower bound on the branching factor by considering the maximum
number of squares that a queen can attack in any column.)</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_8" data-rating="0"></i></div>
<p><a href="ex_8/">Exercise 3.8</a></p>

<p>Give a complete problem formulation for each of the following. Choose a
formulation that is precise enough to be implemented.</p>

<ol>
  <li>
    <p>Using only four colors, you have to color a planar map in such a way
that no two adjacent regions have the same color.</p>
  </li>
  <li>
    <p>A 3-foot-tall monkey is in a room where some bananas are suspended
from the 8-foot ceiling. He would like to get the bananas. The room
contains two stackable, movable, climbable 3-foot-high crates.</p>
  </li>
  <li>
    <p>You have a program that outputs the message “illegal input record”
when fed a certain file of input records. You know that processing
of each record is independent of the other records. You want to
discover what record is illegal.</p>
  </li>
  <li>
    <p>You have three jugs, measuring 12 gallons, 8 gallons, and 3 gallons,
and a water faucet. You can fill the jugs up or empty them out from
one to another or onto the ground. You need to measure out exactly
one gallon.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_9" data-rating="0"></i></div>
<p><a href="ex_9/">Exercise 3.9 [path-planning-exercise]</a></p>

<p>Consider the problem of finding the shortest
path between two points on a plane that has convex polygonal obstacles
as shown in . This is an idealization of the problem that a robot has to
solve to navigate in a crowded environment.</p>

<ol>
  <li>
    <p>Suppose the state space consists of all positions $(x,y)$ in
the plane. How many states are there? How many paths are there to
the goal?</p>
  </li>
  <li>
    <p>Explain briefly why the shortest path from one polygon vertex to any
other in the scene must consist of straight-line segments joining
some of the vertices of the polygons. Define a good state space now.
How large is this state space?</p>
  </li>
  <li>
    <p>Define the necessary functions to implement the search problem,
including an function that takes a vertex as input and returns a set
of vectors, each of which maps the current vertex to one of the
vertices that can be reached in a straight line. (Do not forget the
neighbors on the same polygon.) Use the straight-line distance for
the heuristic function.</p>
  </li>
  <li>
    <p>Apply one or more of the algorithms in this chapter to solve a range
of problems in the domain, and comment on their performance.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_10" data-rating="0"></i></div>
<p><a href="ex_10/">Exercise 3.10 [negative-g-exercise]</a></p>

<p>On page <a href="#/">non-negative-g</a>, we said that we would not consider problems
with negative path costs. In this exercise, we explore this decision in
more depth.</p>

<ol>
  <li>
    <p>Suppose that actions can have arbitrarily large negative costs;
explain why this possibility would force any optimal algorithm to
explore the entire state space.</p>
  </li>
  <li>
    <p>Does it help if we insist that step costs must be greater than or
equal to some negative constant $c$? Consider both trees and graphs.</p>
  </li>
  <li>
    <p>Suppose that a set of actions forms a loop in the state space such
that executing the set in some order results in no net change to
the state. If all of these actions have negative cost, what does
this imply about the optimal behavior for an agent in such an
environment?</p>
  </li>
  <li>
    <p>One can easily imagine actions with high negative cost, even in
domains such as route finding. For example, some stretches of road
might have such beautiful scenery as to far outweigh the normal
costs in terms of time and fuel. Explain, in precise terms, within
the context of state-space search, why humans do not drive around
scenic loops indefinitely, and explain how to define the state space
and actions for route finding so that artificial agents can also
avoid looping.</p>
  </li>
  <li>
    <p>Can you think of a real domain in which step costs are such as to
cause looping?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_11" data-rating="0"></i></div>
<p><a href="ex_11/">Exercise 3.11 [mc-problem]</a></p>

<p>The problem is usually stated as follows. Three
missionaries and three cannibals are on one side of a river, along with
a boat that can hold one or two people. Find a way to get everyone to
the other side without ever leaving a group of missionaries in one place
outnumbered by the cannibals in that place. This problem is famous in AI
because it was the subject of the first paper that approached problem
formulation from an analytical viewpoint @Amarel:1968.</p>

<ol>
  <li>
    <p>Formulate the problem precisely, making only those distinctions
necessary to ensure a valid solution. Draw a diagram of the complete
state space.</p>
  </li>
  <li>
    <p>Implement and solve the problem optimally using an appropriate
search algorithm. Is it a good idea to check for repeated states?</p>
  </li>
  <li>
    <p>Why do you think people have a hard time solving this puzzle, given
that the state space is so simple?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_12" data-rating="0"></i></div>
<p><a href="ex_12/">Exercise 3.12</a></p>

<p>Define in your own words the following terms: state, state space, search
tree, search node, goal, action, transition model, and branching factor.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_13" data-rating="0"></i></div>
<p><a href="ex_13/">Exercise 3.13</a></p>

<p>What’s the difference between a world state, a state description, and a
search node? Why is this distinction useful?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_14" data-rating="0"></i></div>
<p><a href="ex_14/">Exercise 3.14</a></p>

<p>An action such as really consists of a long sequence of finer-grained
actions: turn on the car, release the brake, accelerate forward, etc.
Having composite actions of this kind reduces the number of steps in a
solution sequence, thereby reducing the search time. Suppose we take
this to the logical extreme, by making super-composite actions out of
every possible sequence of actions. Then every problem instance is
solved by a single super-composite action, such as . Explain how search
would work in this formulation. Is this a practical approach for
speeding up problem solving?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_15" data-rating="0"></i></div>
<p><a href="ex_15/">Exercise 3.15</a></p>

<p>Does a finite state space always lead to a finite search tree? How about
a finite state space that is a tree? Can you be more precise about what
types of state spaces always lead to finite search trees? (Adapted from
, 1996.)</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_16" data-rating="0"></i></div>
<p><a href="ex_16/">Exercise 3.16 [graph-separation-property-exercise]</a></p>

<p>Prove that satisfies the graph
separation property illustrated in . (<em>Hint</em>: Begin by
showing that the property holds at the start, then show that if it holds
before an iteration of the algorithm, it holds afterwards.) Describe a
search algorithm that violates the property.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_17" data-rating="0"></i></div>
<p><a href="ex_17/">Exercise 3.17</a></p>

<p>Which of the following are true and which are false? Explain your
answers.</p>

<ol>
  <li>
    <p>Depth-first search always expands at least as many nodes as A search
with an admissible heuristic.</p>
  </li>
  <li>
    <p>$h(n)=0$ is an admissible heuristic for the 8-puzzle.</p>
  </li>
  <li>
    <p>A is of no use in robotics because percepts, states, and actions
are continuous.</p>
  </li>
  <li>
    <p>Breadth-first search is complete even if zero step costs
are allowed.</p>
  </li>
  <li>
    <p>Assume that a rook can move on a chessboard any number of squares in
a straight line, vertically or horizontally, but cannot jump over
other pieces. Manhattan distance is an admissible heuristic for the
problem of moving the rook from square A to square B in the smallest
number of moves.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_18" data-rating="0"></i></div>
<p><a href="ex_18/">Exercise 3.18</a></p>

<p>Consider a state space where the start state is number 1 and each state
$k$ has two successors: numbers $2k$ and $2k+1$.</p>

<ol>
  <li>
    <p>Draw the portion of the state space for states 1 to 15.</p>
  </li>
  <li>
    <p>Suppose the goal state is 11. List the order in which nodes will be
visited for breadth-first search, depth-limited search with limit 3,
and iterative deepening search.</p>
  </li>
  <li>
    <p>How well would bidirectional search work on this problem? What is
the branching factor in each direction of the bidirectional search?</p>
  </li>
  <li>
    <p>Does the answer to (c) suggest a reformulation of the problem that
would allow you to solve the problem of getting from state 1 to a
given goal state with almost no search?</p>
  </li>
  <li>
    <p>Call the action going from $k$ to $2k$ Left, and the action going to
$2k+1$ Right. Can you find an algorithm that outputs the solution to
this problem without any search at all?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_19" data-rating="0"></i></div>
<p><a href="ex_19/">Exercise 3.19 [brio-exercise]</a></p>

<p>A basic wooden railway set contains the pieces shown in
. The task is to connect these pieces into a railway that has no
overlapping tracks and no loose ends where a train could run off onto
the floor.</p>

<ol>
  <li>
    <p>Suppose that the pieces fit together <em>exactly</em> with no
slack. Give a precise formulation of the task as a search problem.</p>
  </li>
  <li>
    <p>Identify a suitable uninformed search algorithm for this task and
explain your choice.</p>
  </li>
  <li>
    <p>Explain why removing any one of the “fork” pieces makes the
problem unsolvable.</p>
  </li>
  <li>
    <p>Give an upper bound on the total size of the state space defined by
your formulation. (<em>Hint</em>: think about the maximum
branching factor for the construction process and the maximum depth,
ignoring the problem of overlapping pieces and loose ends. Begin by
pretending that every piece is unique.)</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_20" data-rating="0"></i></div>
<p><a href="ex_20/">Exercise 3.20</a></p>

<p>Implement two versions of the function for the 8-puzzle: one that copies
and edits the data structure for the parent node $s$ and one that
modifies the parent state directly (undoing the modifications as
needed). Write versions of iterative deepening depth-first search that
use these functions and compare their performance.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_21" data-rating="0"></i></div>
<p><a href="ex_21/">Exercise 3.21 [iterative-lengthening-exercise]</a></p>

<p>On page <a href="#/">iterative-lengthening-page</a>,
we mentioned <strong>iterative lengthening search</strong>,
an iterative analog of uniform cost search. The idea is to use increasing limits on
path cost. If a node is generated whose path cost exceeds the current
limit, it is immediately discarded. For each new iteration, the limit is
set to the lowest path cost of any node discarded in the previous
iteration.</p>

<ol>
  <li>
    <p>Show that this algorithm is optimal for general path costs.</p>
  </li>
  <li>
    <p>Consider a uniform tree with branching factor $b$, solution depth
$d$, and unit step costs. How many iterations will iterative
lengthening require?</p>
  </li>
  <li>
    <p>Now consider step costs drawn from the continuous range
$[\epsilon,1]$, where $0 &lt; \epsilon &lt; 1$. How many iterations are
required in the worst case?</p>
  </li>
  <li>
    <p>Implement the algorithm and apply it to instances of the 8-puzzle
and traveling salesperson problems. Compare the algorithm’s
performance to that of uniform-cost search, and comment on
your results.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_22" data-rating="0"></i></div>
<p><a href="ex_22/">Exercise 3.22</a></p>

<p>Describe a state space in which iterative deepening search performs much
worse than depth-first search (for example, $O(n^{2})$ vs. $O(n)$).</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_23" data-rating="0"></i></div>
<p><a href="ex_23/">Exercise 3.23</a></p>

<p>Write a program that will take as input two Web page URLs and find a
path of links from one to the other. What is an appropriate search
strategy? Is bidirectional search a good idea? Could a search engine be
used to implement a predecessor function?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_24" data-rating="0"></i></div>
<p><a href="ex_24/">Exercise 3.24 [vacuum-search-exercise]</a></p>

<p>Consider the vacuum-world problem defined in .</p>

<ol>
  <li>
    <p>Which of the algorithms defined in this chapter would be appropriate
for this problem? Should the algorithm use tree search or graph
search?</p>
  </li>
  <li>
    <p>Apply your chosen algorithm to compute an optimal sequence of
actions for a $3\times 3$ world whose initial state has dirt in the
three top squares and the agent in the center.</p>
  </li>
  <li>
    <p>Construct a search agent for the vacuum world, and evaluate its
performance in a set of $3\times 3$ worlds with probability 0.2 of
dirt in each square. Include the search cost as well as path cost in
the performance measure, using a reasonable exchange rate.</p>
  </li>
  <li>
    <p>Compare your best search agent with a simple randomized reflex agent
that sucks if there is dirt and otherwise moves randomly.</p>
  </li>
  <li>
    <p>Consider what would happen if the world were enlarged to
$n \times n$. How does the performance of the search agent and of
the reflex agent vary with $n$?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_25" data-rating="0"></i></div>
<p><a href="ex_25/">Exercise 3.25 [search-special-case-exercise]</a></p>

<p>Prove each of the following statements,
or give a counterexample:</p>

<ol>
  <li>
    <p>Breadth-first search is a special case of uniform-cost search.</p>
  </li>
  <li>
    <p>Depth-first search is a special case of best-first tree search.</p>
  </li>
  <li>
    <p>Uniform-cost search is a special case of A search.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_26" data-rating="0"></i></div>
<p><a href="ex_26/">Exercise 3.26</a></p>

<p>Compare the performance of A and RBFS on a set of randomly generated
problems in the 8-puzzle (with Manhattan distance) and TSP (with MST—see
) domains. Discuss your results. What happens to the performance of RBFS
when a small random number is added to the heuristic values in the
8-puzzle domain?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_27" data-rating="0"></i></div>
<p><a href="ex_27/">Exercise 3.27</a></p>

<p>Trace the operation of A search applied to the problem of getting to
Bucharest from Lugoj using the straight-line distance heuristic. That
is, show the sequence of nodes that the algorithm will consider and the
$f$, $g$, and $h$ score for each node.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_28" data-rating="0"></i></div>
<p><a href="ex_28/">Exercise 3.28</a></p>

<p>Sometimes there is no good evaluation function for a problem but there
is a good comparison method: a way to tell whether one node is better
than another without assigning numerical values to either. Show that
this is enough to do a best-first search. Is there an analog of A for
this setting?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_29" data-rating="0"></i></div>
<p><a href="ex_29/">Exercise 3.29 [a*-failure-exercise]</a></p>

<p>Devise a state space in which A using returns a
suboptimal solution with an $h(n)$ function that is admissible but
inconsistent.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_30" data-rating="0"></i></div>
<p><a href="ex_30/">Exercise 3.30</a></p>

<p>Accurate heuristics don’t necessarily reduce search time in the worst
case. Given any depth $d$, define a search problem with a goal node at
depth $d$, and write a heuristic function such that $|h(n) - h^*(n)|  \le O(\log h^*(n))$ but $A^*$ expands all nodes of depth less
than $d$.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_31" data-rating="0"></i></div>
<p><a href="ex_31/">Exercise 3.31</a></p>

<p>The <strong>heuristic path algorithm</strong> @Pohl:1977 is a best-first search in which the evaluation function
is $f(n) =
(2-w)g(n) + wh(n)$. For what values of $w$ is this complete? For what
values is it optimal, assuming that $h$ is admissible? What kind of
search does this perform for $w=0$, $w=1$, and $w=2$?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_32" data-rating="0"></i></div>
<p><a href="ex_32/">Exercise 3.32</a></p>

<p>Consider the unbounded version of the regular 2D grid shown in . The
start state is at the origin, (0,0), and the goal state is at $(x,y)$.</p>

<ol>
  <li>
    <p>What is the branching factor $b$ in this state space?</p>
  </li>
  <li>
    <p>How many distinct states are there at depth $k$ (for $k&gt;0$)?</p>
  </li>
  <li>
    <p>What is the maximum number of nodes expanded by breadth-first tree
search?</p>
  </li>
  <li>
    <p>What is the maximum number of nodes expanded by breadth-first graph
search?</p>
  </li>
  <li>
    <p>Is $h = |u-x| + |v-y|$ an admissible heuristic for a state at
$(u,v)$? Explain.</p>
  </li>
  <li>
    <p>How many nodes are expanded by A graph search using $h$?</p>
  </li>
  <li>
    <p>Does $h$ remain admissible if some links are removed?</p>
  </li>
  <li>
    <p>Does $h$ remain admissible if some links are added between
nonadjacent states?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_33" data-rating="0"></i></div>
<p><a href="ex_33/">Exercise 3.33</a></p>

<p>$n$ vehicles occupy squares $(1,1)$ through $(n,1)$ (i.e., the bottom
row) of an $n\times n$ grid. The vehicles must be moved to the top row
but in reverse order; so the vehicle $i$ that starts in $(i,1)$ must end
up in $(n-i+1,n)$. On each time step, every one of the $n$ vehicles can
move one square up, down, left, or right, or stay put; but if a vehicle
stays put, one other adjacent vehicle (but not more than one) can hop
over it. Two vehicles cannot occupy the same square.</p>

<ol>
  <li>
    <p>Calculate the size of the state space as a function of $n$.</p>
  </li>
  <li>
    <p>Calculate the branching factor as a function of $n$.</p>
  </li>
  <li>
    <p>Suppose that vehicle $i$ is at $(x_i,y_i)$; write a nontrivial
admissible heuristic $h_i$ for the number of moves it will require
to get to its goal location $(n-i+1,n)$, assuming no other vehicles
are on the grid.</p>
  </li>
  <li>
    <p>Which of the following heuristics are admissible for the problem of
moving all $n$ vehicles to their destinations? Explain.</p>

    <ol>
      <li>
        <p>$\sum_{i= 1}^{n} h_i$.</p>
      </li>
      <li>
        <p>$\max{h_1,\ldots,h_n}$.</p>
      </li>
      <li>
        <p>$\min{h_1,\ldots,h_n}$.</p>
      </li>
    </ol>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_34" data-rating="0"></i></div>
<p><a href="ex_34/">Exercise 3.34</a></p>

<p>Consider the problem of moving $k$ knights from $k$ starting squares
$s_1,\ldots,s_k$ to $k$ goal squares $g_1,\ldots,g_k$, on an unbounded
chessboard, subject to the rule that no two knights can land on the same
square at the same time. Each action consists of moving <em>up
to</em> $k$ knights simultaneously. We would like to complete the
maneuver in the smallest number of actions.</p>

<ol>
  <li>
    <p>What is the maximum branching factor in this state space, expressed
as a function of $k$?</p>
  </li>
  <li>
    <p>Suppose $h_i$ is an admissible heuristic for the problem of moving
knight $i$ to goal $g_i$ by itself. Which of the following
heuristics are admissible for the $k$-knight problem? Of those,
which is the best?</p>

    <ol>
      <li>
        <p>$\min{h_1,\ldots,h_k}$.</p>
      </li>
      <li>
        <p>$\max{h_1,\ldots,h_k}$.</p>
      </li>
      <li>
        <p>$\sum_{i= 1}^{k} h_i$.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Repeat (b) for the case where you are allowed to move only one
knight at a time.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_35" data-rating="0"></i></div>
<p><a href="ex_35/">Exercise 3.35</a></p>

<p>We saw on page <a href="#/">I-to-F</a> that the straight-line distance heuristic leads greedy
best-first search astray on the problem of going from Iasi to Fagaras.
However, the heuristic is perfect on the opposite problem: going from
Fagaras to Iasi. Are there problems for which the heuristic is
misleading in both directions?</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_36" data-rating="0"></i></div>
<p><a href="ex_36/">Exercise 3.36</a></p>

<p>Invent a heuristic function for the 8-puzzle that sometimes
overestimates, and show how it can lead to a suboptimal solution on a
particular problem. (You can use a computer to help if you want.) Prove
that if $h$ never overestimates by more than $c$, A using $h$ returns a
solution whose cost exceeds that of the optimal solution by no more than
$c$.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_37" data-rating="0"></i></div>
<p><a href="ex_37/">Exercise 3.37</a></p>

<p>[consistent-heuristic-exercise]Prove that if a heuristic is
consistent, it must be admissible. Construct an admissible heuristic
that is not consistent.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_38" data-rating="0"></i></div>
<p><a href="ex_38/">Exercise 3.38</a></p>

<p>[tsp-mst-exercise]The traveling salesperson problem (TSP) can be
solved with the minimum-spanning-tree (MST) heuristic, which estimates
the cost of completing a tour, given that a partial tour has already
been constructed. The MST cost of a set of cities is the smallest sum of
the link costs of any tree that connects all the cities.</p>

<ol>
  <li>
    <p>Show how this heuristic can be derived from a relaxed version of
the TSP.</p>
  </li>
  <li>
    <p>Show that the MST heuristic dominates straight-line distance.</p>
  </li>
  <li>
    <p>Write a problem generator for instances of the TSP where cities are
represented by random points in the unit square.</p>
  </li>
  <li>
    <p>Find an efficient algorithm in the literature for constructing the
MST, and use it with A graph search to solve instances of the TSP.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_39" data-rating="0"></i></div>
<p><a href="ex_39/">Exercise 3.39 [Gaschnig-h-exercise]</a></p>

<p>On page <a href="#/">Gaschnig-h-page</a> , we defined the relaxation of the 8-puzzle in
which a tile can move from square A to square B if B is blank. The exact
solution of this problem defines <strong>Gaschnig’s heuristic</strong> @Gaschnig:1979. Explain why Gaschnig’s
heuristic is at least as accurate as $h_1$ (misplaced tiles), and show
cases where it is more accurate than both $h_1$ and $h_2$ (Manhattan
distance). Explain how to calculate Gaschnig’s heuristic efficiently.</p>

<div><i class="arrow-up loader" data-chapter="search-exercises" data-exercise="ex_40" data-rating="0"></i></div>
<p><a href="ex_40/">Exercise 3.40</a></p>

<p>We gave two simple heuristics for the 8-puzzle: Manhattan distance and
misplaced tiles. Several heuristics in the literature purport to improve
on this—see, for example, @Nilsson:1971,
@Mostow+Prieditis:1989, and @Hansson+al:1992. Test these claims by implementing
the heuristics and comparing the performance of the resulting
algorithms.</p>


  </div>

<!--   <div class="date">
    Written on 
  </div>
 -->
  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'nalinc';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>


</article>

<script type="text/javascript">
var chapter  = String('/search-exercises/')
var chapterName = chapter.match(/\/([^\/]*)\//, "")[1]
$.get( "https://aima-exercises.firebaseapp.com/rating/"+chapterName, function( data ) {
  console.log(data)
  $("i[data-chapter='"+chapterName+"']").each(function(index,element){
  	ex = $(element).data("exercise")
  	if(ex in data){
  		console.log(data[ex])
  		$(element).attr("data-rating",data[ex])
  	}
    $(".arrow-up").removeClass("loader")
  })
});

$(document).on('click',"i[data-chapter]",function(e){
	ele = $(e.target)
  ele.addClass("loader")
	exerciseName = ele.data("exercise")
	$.post( "https://aima-exercises.firebaseapp.com/rating/"+chapterName+"/"+exerciseName, function( data ) {
	  console.log(data)
	  ele.attr("data-rating",data["rating"])
    ele.removeClass("loader")
	});	
})


</script>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!--            Designed by <a href="http://nalinc.github.io" style="color:#2196F3">Nalin</a> &#9889; 
           Written in <a href="#/" style="color: #2a932a">Markdown</a> &#9889; 
           Powered by <a href="http://jekyllrb.com" style="color: #d73838">Jekyll</a>    -->
          <!-- 











 -->
        </footer>
      </div>
    </div>

    


    <script type="text/javascript">
      // firestore =firebase.firestore();
      // function rateExercise(e){
      //   console.log(e.target)
      //   chapterLabel = $(e.target).data("chapter")
      //   exerciseLabel = $(e.target).data("exercise")
      //   docRef = firestore.collection("rating").doc(chapterLabel)
      //   score = 0
      //   docRef.get().then(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //      // score = myData
      //       console.log(myData)
      //       if(exerciseLabel in myData){
      //         myData[exerciseLabel] += 1
      //       }else{
      //         myData[exerciseLabel] = 1
      //       }
      //      // $(e.target).data("rating",score);
      //       docRef.set(myData).then(function(){
      //         console.log("status saved")
      //         console.log(myData[exerciseLabel])
      //         $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       })
      //     }
      //   })
      // }
      // getRealTimeUpdates = function(){
      //   docRef = firestore.collection("rating").doc("intro-exercises");
      //   docRef.onSnapshot(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //       for(key in myData){
      //         console.log(key)  
      //         // $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       }
      //     }
      //   })
      // }

      // getRealTimeUpdates()
      // $(document).on("click",".arrow-up", rateExercise)
    </script>
  </body>
</html>
