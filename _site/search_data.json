{
  "_":{
	"title":"",
	"content":"",
	"url":""  	
  }	
  
    
  
    
  
    
  
    
  
    
  
    
  
    ,
      "dbn-exercises-ex-10":  {
        "title": "Exercise 15.10",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .8 on each step; the robot switches to arandomly selected new heading with probability .2 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?",
        "url": " /dbn-exercises/ex_10/"
      }
    
  
    ,
      "dbn-exercises-ex-3":  {
        "title": "Exercise 15.3",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "This exercise develops a space-efficient variant ofthe forward–backward algorithm described inFigure forward-backward-algorithm (page forward-backward-algorithm).We wish to compute $textbf{P} (textbf{X}_k|textbf{e}_{1:t})$ for$k=1,ldots ,t$. This will be done with a divide-and-conquerapproach.1.  Suppose, for simplicity, that $t$ is odd, and let the halfway point    be $h=(t+1)/2$. Show that $textbf{P} (textbf{X}_k|textbf{e}_{1:t}) $     can be computed for    $k=1,ldots ,h$ given just the initial forward message    $textbf{f}_{1:0}$, the backward message $textbf{b}_{h+1:t}$, and the evidence    $textbf{e}_{1:h}$.2.  Show a similar result for the second half of the sequence.3.  Given the results of (a) and (b), a recursive divide-and-conquer    algorithm can be constructed by first running forward along the    sequence and then backward from the end, storing just the required    messages at the middle and the ends. Then the algorithm is called on    each half. Write out the algorithm in detail.4.  Compute the time and space complexity of the algorithm as a function    of $t$, the length of the sequence. How does this change if we    divide the input into more than two pieces?",
        "url": " /dbn-exercises/ex_3/"
      }
    
  
    ,
      "dbn-exercises-ex-4":  {
        "title": "Exercise 15.4",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "On page flawed-viterbi-page, we outlined a flawedprocedure for finding the most likely state sequence, given anobservation sequence. The procedure involves finding the most likelystate at each time step, using smoothing, and returning the sequencecomposed of these states. Show that, for some temporal probabilitymodels and observation sequences, this procedure returns an impossiblestate sequence (i.e., the posterior probability of the sequence iszero).",
        "url": " /dbn-exercises/ex_4/"
      }
    
  
    ,
      "dbn-exercises-ex-5":  {
        "title": "Exercise 15.5",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Equation (matrix-filtering-equation) describes thefiltering process for the matrix formulation of HMMs. Give a similarequation for the calculation of likelihoods, which was describedgenerically in Equation (forward-likelihood-equation).",
        "url": " /dbn-exercises/ex_5/"
      }
    
  
    ,
      "dbn-exercises-ex-2":  {
        "title": "Exercise 15.2",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "In this exercise, we examine whathappens to the probabilities in the umbrella world in the limit of longtime sequences.1.  Suppose we observe an unending sequence of days on which the    umbrella appears. Show that, as the days go by, the probability of    rain on the current day increases monotonically toward a    fixed point. Calculate this fixed point.2.  Now consider forecasting further and further into the    future, given just the first two umbrella observations. First,    compute the probability $P(r_{2+k}|u_1,u_2)$ for    $k=1 ldots 20$ and plot the results. You should see that    the probability converges towards a fixed point. Prove that the    exact value of this fixed point is 0.5.",
        "url": " /dbn-exercises/ex_2/"
      }
    
  
    ,
      "dbn-exercises-ex-15":  {
        "title": "Exercise 15.15",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:-   The prior probability of getting enough sleep, with no observations,    is 0.7.-   The probability of getting enough sleep on night $t$ is 0.8 given    that the student got enough sleep the previous night, and 0.3    if not.-   The probability of having red eyes is 0.2 if the student got enough    sleep, and 0.7 if not.-   The probability of sleeping in class is 0.1 if the student got    enough sleep, and 0.3 if not.Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.",
        "url": " /dbn-exercises/ex_15/"
      }
    
  
    ,
      "dbn-exercises-ex-12":  {
        "title": "Exercise 15.12",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Often, we wish to monitor a continuous-statesystem whose behavior switches unpredictably among a set of $k$ distinct“modes.” For example, an aircraft trying to evade a missile can executea series of distinct maneuvers that the missile may attempt to track. ABayesian network representation of such a switching Kalmanfilter model is shown inFigure switching-kf-figure.1.  Suppose that the discrete state $S_t$ has $k$ possible values and    that the prior continuous state estimate    ${textbf{P}}(textbf{X}_0)$ is a multivariate    Gaussian distribution. Show that the prediction    ${textbf{P}}(textbf{X}_1)$ is a mixture of    Gaussians—that is, a weighted sum of Gaussians such    that the weights sum to 1.2.  Show that if the current continuous state estimate    ${textbf{P}}(textbf{X}_t|textbf{e}_{1:t})$ is a mixture of $m$ Gaussians,    then in the general case the updated state estimate    ${textbf{P}}(textbf{X}_{t+1}|textbf{e}_{1:t+1})$ will be a mixture of    $km$ Gaussians.3.  What aspect of the temporal process do the weights in the Gaussian    mixture represent?The results in (a) and (b) show that the representation of the posteriorgrows without limit even for switching Kalman filters, which are amongthe simplest hybrid dynamic models.",
        "url": " /dbn-exercises/ex_12/"
      }
    
  
    ,
      "dbn-exercises-ex-13":  {
        "title": "Exercise 15.13",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Complete the missing step in the derivationof Equation (kalman-one-step-equation) onpage kalman-one-step-equation, the first update step for the one-dimensional Kalmanfilter.",
        "url": " /dbn-exercises/ex_13/"
      }
    
  
    ,
      "dbn-exercises-ex-14":  {
        "title": "Exercise 15.14",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Let us examine the behavior of the varianceupdate in Equation (kalman-univariate-equation)(page kalman-univariate-equation).1.  Plot the value of $sigma_t^2$ as a function of $t$, given various    values for $sigma_x^2$ and $sigma_z^2$.2.  Show that the update has a fixed point $sigma^2$ such that    $sigma_t^2 rightarrow sigma^2$ as $t rightarrow infty$, and    calculate the value of $sigma^2$.3.  Give a qualitative explanation for what happens as    $sigma_x^2rightarrow 0$ and as $sigma_z^2rightarrow 0$.",
        "url": " /dbn-exercises/ex_14/"
      }
    
  
    ,
      "dbn-exercises-ex-9":  {
        "title": "Exercise 15.9",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "We have described three policies for the vacuum robot: (1) a uniformrandom walk, (2) a bias for wandering southeast, as described inExercise hmm-robust-exercise, and (3) the policydescribed in Exercise roomba-viterbi-exercise. Supposean observer is given the observation sequence from a vacuum robot, butis not sure which of the three policies the robot is following. Whatapproach should the observer use to find the most likely path, given theobservations? Implement the approach and test it. How much does thelocalization accuracy suffer, compared to the case in which the observerknows which policy the robot is following?",
        "url": " /dbn-exercises/ex_9/"
      }
    
  
    ,
      "dbn-exercises-ex-7":  {
        "title": "Exercise 15.7",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "In Section hmm-localization-section, the priordistribution over locations is uniform and the transition model assumesan equal probability of moving to any neighboring square. What if thoseassumptions are wrong? Suppose that the initial location is actuallychosen uniformly from the northwest quadrant of the room and the actionactually tends to move southeast. Keepingthe HMM model fixed, explore the effect on localization and pathaccuracy as the southeasterly tendency increases, for different valuesof $epsilon$.",
        "url": " /dbn-exercises/ex_7/"
      }
    
  
    ,
      "dbn-exercises-ex-1":  {
        "title": "Exercise 15.1",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Show that any second-order Markovprocess can be rewritten as a first-order Markov process with anaugmented set of state variables. Can this always be doneparsimoniously, i.e., without increasing the number ofparameters needed to specify the transition model?",
        "url": " /dbn-exercises/ex_1/"
      }
    
  
    ,
      "dbn-exercises-ex-6":  {
        "title": "Exercise 15.6",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Consider the vacuum worlds ofFigure vacuum-maze-ch4-figure (perfect sensing) andFigure vacuum-maze-hmm2-figure (noisy sensing). Supposethat the robot receives an observation sequence such that, with perfectsensing, there is exactly one possible location it could be in. Is thislocation necessarily the most probable location under noisy sensing forsufficiently small noise probability $epsilon$? Prove your claim orfind a counterexample.",
        "url": " /dbn-exercises/ex_6/"
      }
    
  
    ,
      "dbn-exercises-ex-8":  {
        "title": "Exercise 15.8",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Consider a version of the vacuum robot(page vacuum-maze-hmm2-figure) that has the policy of going straight for as longas it can; only when it encounters an obstacle does it change to a new(randomly selected) heading. To model this robot, each state in themodel consists of a (location, heading) pair. Implementthis model and see how well the Viterbi algorithm can track a robot withthis model. The robot’s policy is more constrained than the random-walkrobot; does that mean that predictions of the most likely path are moreaccurate?",
        "url": " /dbn-exercises/ex_8/"
      }
    
  
    
  
    ,
      "philosophy-exercises-ex-11":  {
        "title": "Exercise 26.11",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "How do the potential threats from AI technology compare with those fromother computer science technologies, and to bio-, nano-, and nucleartechnologies?",
        "url": " /philosophy-exercises/ex_11/"
      }
    
  
    ,
      "philosophy-exercises-ex-10":  {
        "title": "Exercise 26.10",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Analyze the potential threats from AI technology to society. Whatthreats are most serious, and how might they be combated? How do theycompare to the potential benefits?",
        "url": " /philosophy-exercises/ex_10/"
      }
    
  
    ,
      "philosophy-exercises-ex-3":  {
        "title": "Exercise 26.3",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Attempt to write definitions of the terms “intelligence,” “thinking,”and “consciousness.” Suggest some possible objections to yourdefinitions.",
        "url": " /philosophy-exercises/ex_3/"
      }
    
  
    ,
      "philosophy-exercises-ex-4":  {
        "title": "Exercise 26.4",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Does a refutation of the Chinese room argument necessarily prove thatappropriately programmed computers have mental states? Does anacceptance of the argument necessarily mean that computers cannot havemental states?",
        "url": " /philosophy-exercises/ex_4/"
      }
    
  
    ,
      "philosophy-exercises-ex-5":  {
        "title": "Exercise 26.5",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "In the brain replacement argument, it isimportant to be able to restore the subject’s brain to normal, such thatits external behavior is as it would have been if the operation had nottaken place. Can the skeptic reasonably object that this would requireupdating those neurophysiological properties of the neurons relating toconscious experience, as distinct from those involved in the functionalbehavior of the neurons?",
        "url": " /philosophy-exercises/ex_5/"
      }
    
  
    ,
      "philosophy-exercises-ex-2":  {
        "title": "Exercise 26.2",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Find and analyze an account in the popular media of one or more of thearguments to the effect that AI is impossible.",
        "url": " /philosophy-exercises/ex_2/"
      }
    
  
    ,
      "philosophy-exercises-ex-12":  {
        "title": "Exercise 26.12",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Some critics object that AI is impossible, while others object that itis too possible and that ultraintelligent machines pose athreat. Which of these objections do you think is more likely? Would itbe a contradiction for someone to hold both positions?",
        "url": " /philosophy-exercises/ex_12/"
      }
    
  
    ,
      "philosophy-exercises-ex-9":  {
        "title": "Exercise 26.9",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "I. J. Good claims that intelligence is the most important quality, andthat building ultraintelligent machines will change everything. Asentient cheetah counters that “Actually speed is more important; if wecould build ultrafast machines, that would change everything,” and asentient elephant claims “You’re both wrong; what we need is ultrastrongmachines.” What do you think of these arguments?",
        "url": " /philosophy-exercises/ex_9/"
      }
    
  
    ,
      "philosophy-exercises-ex-7":  {
        "title": "Exercise 26.7",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Alan Perlis [Perlis:1982] wrote, “A year spent in artificialintelligence is enough to make one believe in God”. He also wrote, in aletter to Philip Davis, that one of the central dreams of computerscience is that “through the performance of computers and their programswe will remove all doubt that there is only a chemical distinctionbetween the living and nonliving world.” To what extent does theprogress made so far in artificial intelligence shed light on theseissues? Suppose that at some future date, the AI endeavor has beencompletely successful; that is, we have build intelligent agents capableof carrying out any human cognitive task at human levels of ability. Towhat extent would that shed light on these issues?",
        "url": " /philosophy-exercises/ex_7/"
      }
    
  
    ,
      "philosophy-exercises-ex-1":  {
        "title": "Exercise 26.1",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Go through Turing’s list of alleged“disabilities” of machines, identifying which have been achieved, whichare achievable in principle by a program, and which are stillproblematic because they require conscious mental states.",
        "url": " /philosophy-exercises/ex_1/"
      }
    
  
    ,
      "philosophy-exercises-ex-6":  {
        "title": "Exercise 26.6",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Suppose that a Prolog program containing many clauses about the rules ofBritish citizenship is compiled and run on an ordinary computer. Analyzethe “brain states” of the computer under wide and narrow content.",
        "url": " /philosophy-exercises/ex_6/"
      }
    
  
    ,
      "philosophy-exercises-ex-8":  {
        "title": "Exercise 26.8",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Compare the social impact of artificial intelligence in the last fiftyyears with the social impact of the introduction of electric appliancesand the internal combustion engine in the fifty years between 1890 and1940.",
        "url": " /philosophy-exercises/ex_8/"
      }
    
  
    
  
    ,
      "concept-learning-exercises-ex-11":  {
        "title": "Exercise 18.11",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "This exercise considers $chi^2$ pruning ofdecision trees (Section chi-squared-section.1.  Create a data set with two input attributes, such that the    information gain at the root of the tree for both attributes is    zero, but there is a decision tree of depth 2 that is consistent    with all the data. What would $chi^2$ pruning do on this data set    if applied bottom up? If applied top down?2.  Modify DECISION-TREE-LEARNING to include $chi^2$-pruning. You might wish to consult    Quinlan [Quinlan:1986] or [Kearns+Mansour:1998] for details.",
        "url": " /concept-learning-exercises/ex_11/"
      }
    
  
    ,
      "concept-learning-exercises-ex-16":  {
        "title": "Exercise 18.16",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Construct a decision list to classify the data below.Select tests to be as small as possible (in terms of attributes),breaking ties among tests with the same number of attributes byselecting the one that classifies the greatest number of examplescorrectly. If multiple tests have the same number of attributes andclassify the same number of examples, then break the tie usingattributes with lower index numbers (e.g., select $A_1$ over $A_2$).$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; A_4 &amp;amp; y  	hline textbf{x}_1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1  	textbf{x}_2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_3 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1  	 textbf{x}_4 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	 textbf{x}_5 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_6 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  	 textbf{x}_7 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_8 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	hline  end{array}$$",
        "url": " /concept-learning-exercises/ex_16/"
      }
    
  
    ,
      "concept-learning-exercises-ex-29":  {
        "title": "Exercise 18.29",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose you had a neural network with linearactivation functions. That is, for each unit the output is some constant$c$ times the weighted sum of the inputs.1.  Assume that the network has one hidden layer. For a given assignment    to the weights $textbf{w}$, write down equations for the value of the    units in the output layer as a function of $textbf{w}$ and the input layer    $textbf{x}$, without any explicit mention of the output of the    hidden layer. Show that there is a network with no hidden units that    computes the same function.2.  Repeat the calculation in part (a), but this time do it for a    network with any number of hidden layers.3.  Suppose a network with one hidden layer and linear activation    functions has $n$ input and output nodes and $h$ hidden nodes. What    effect does the transformation in part (a) to a network with no    hidden layers have on the total number of weights? Discuss in    particular the case $h ll n$.",
        "url": " /concept-learning-exercises/ex_29/"
      }
    
  
    ,
      "concept-learning-exercises-ex-20":  {
        "title": "Exercise 18.20",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose a $7$-nearest-neighbors regression searchreturns $ {4, 2, 8, 4, 9, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.",
        "url": " /concept-learning-exercises/ex_20/"
      }
    
  
    ,
      "concept-learning-exercises-ex-27":  {
        "title": "Exercise 18.27",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Consider the following set of examples, each with six inputs and onetarget output:$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; A_4 &amp;amp; A_5 &amp;amp; A_6 &amp;amp; A_7 &amp;amp; A_8 &amp;amp; A_9 &amp;amp; A_{10} &amp;amp; A_{11} &amp;amp; A_{12} &amp;amp; A_{13} &amp;amp; A_{14}  	hline 	textbf{x}_1  &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 0 	textbf{x}_2  &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 	textbf{x}_3  &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 	textbf{x}_4  &amp;amp; 0 &amp;amp; 1  &amp;amp; 0  &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 1 	textbf{x}_5  &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 	textbf{x}_6  &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 0 	textbf{T}   &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 0 	hline  end{array}$$1.  Run the perceptron learning rule on these data and show the    final weights.2.  Run the decision tree learning rule, and show the resulting    decision tree.3.  Comment on your results.",
        "url": " /concept-learning-exercises/ex_27/"
      }
    
  
    ,
      "concept-learning-exercises-ex-18":  {
        "title": "Exercise 18.18",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "This exercise concerns the expressiveness ofdecision lists (Section learning-theory-section).1.  Show that decision lists can represent any Boolean function, if the    size of the tests is not limited.2.  Show that if the tests can contain at most $k$ literals each, then    decision lists can represent any function that can be represented by    a decision tree of depth $k$.",
        "url": " /concept-learning-exercises/ex_18/"
      }
    
  
    ,
      "concept-learning-exercises-ex-26":  {
        "title": "Exercise 18.26",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Recall fromChapter concept-learning-chapter that there are$2^{2^n}$ distinct Boolean functions of $n$ inputs. How many ofthese are representable by a threshold perceptron?",
        "url": " /concept-learning-exercises/ex_26/"
      }
    
  
    ,
      "concept-learning-exercises-ex-19":  {
        "title": "Exercise 18.19",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose a $7$-nearest-neighbors regression searchreturns $ {7, 6, 8, 4, 7, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.",
        "url": " /concept-learning-exercises/ex_19/"
      }
    
  
    ,
      "concept-learning-exercises-ex-21":  {
        "title": "Exercise 18.21",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Figure kernel-machine-figureshowed how a circle at the origin can be linearly separated by mappingfrom the features $(x_1, x_2)$ to the two dimensions $(x_1^2, x_2^2)$.But what if the circle is not located at the origin? What if it is anellipse, not a circle? The general equation for a circle (and hence thedecision boundary) is $(x_1-a)^2 +(x_2-b)^2 - r^20$, and the general equation for an ellipse is$c(x_1-a)^2 + d(x_2-b)^2 - 1 0$.1.  Expand out the equation for the circle and show what the weights    $w_i$ would be for the decision boundary in the four-dimensional    feature space $(x_1, x_2, x_1^2, x_2^2)$. Explain why this means    that any circle is linearly separable in this space.2.  Do the same for ellipses in the five-dimensional feature space    $(x_1, x_2, x_1^2, x_2^2, x_1 x_2)$.",
        "url": " /concept-learning-exercises/ex_21/"
      }
    
  
    ,
      "concept-learning-exercises-ex-17":  {
        "title": "Exercise 18.17",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Prove that a decision list can represent the same function as a decisiontree while using at most as many rules as there are leaves in thedecision tree for that function. Give an example of a functionrepresented by a decision list using strictly fewer rules than thenumber of leaves in a minimal-sized decision tree for that samefunction.",
        "url": " /concept-learning-exercises/ex_17/"
      }
    
  
    ,
      "concept-learning-exercises-ex-28":  {
        "title": "Exercise 18.28",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Section logistic-regression-section(page logistic-regression-section) noted that the output of the logistic functioncould be interpreted as a probability $p$ assigned by themodel to the proposition that $f(textbf{x})1$; the probability that$f(textbf{x})0$ is therefore $1-p$. Write down the probability $p$as a function of $textbf{x}$ and calculate the derivative of $log p$ withrespect to each weight $w_i$. Repeat the process for $log (1-p)$. Thesecalculations give a learning rule for minimizing thenegative-log-likelihood loss function for a probabilistic hypothesis.Comment on any resemblance to other learning rules in the chapter.",
        "url": " /concept-learning-exercises/ex_28/"
      }
    
  
    ,
      "concept-learning-exercises-ex-10":  {
        "title": "Exercise 18.10",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "A decision graph is a generalization of a decision treethat allows nodes (i.e., attributes used for splits) to have multipleparents, rather than just a single parent. The resulting graph muststill be acyclic. Now, consider the XOR function of threebinary input attributes, which produces the value 1 if and only if anodd number of the three input attributes has value 1.1.  Draw a minimal-sized decision tree for the    three-input XOR function.2.  Draw a minimal-sized decision graph for the    three-input XOR function.",
        "url": " /concept-learning-exercises/ex_10/"
      }
    
  
    ,
      "concept-learning-exercises-ex-32":  {
        "title": "Exercise 18.32",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "The neural network whose learning performance is measured inFigure restaurant-back-prop-figure has four hiddennodes. This number was chosen somewhat arbitrarily. Use across-validation method to find the best number of hidden nodes.",
        "url": " /concept-learning-exercises/ex_32/"
      }
    
  
    ,
      "concept-learning-exercises-ex-3":  {
        "title": "Exercise 18.3",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Draw a decision tree for the problem of deciding whether to move forwardat a road intersection, given that the light has just turned green.",
        "url": " /concept-learning-exercises/ex_3/"
      }
    
  
    ,
      "concept-learning-exercises-ex-4":  {
        "title": "Exercise 18.4",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "We never test the same attribute twice along one path in a decisiontree. Why not?",
        "url": " /concept-learning-exercises/ex_4/"
      }
    
  
    ,
      "concept-learning-exercises-ex-33":  {
        "title": "Exercise 18.33",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Consider the problem of separating$N$ data points into positive and negative examples using a linearseparator. Clearly, this can always be done for $N2$ pointson a line of dimension $d1$, regardless of how the points arelabeled or where they are located (unless the points are in the sameplace).1.  Show that it can always be done for $N3$ points on a    plane of dimension $d2$, unless they are collinear.2.  Show that it cannot always be done for $N4$ points on a    plane of dimension $d2$.3.  Show that it can always be done for $N4$ points in a    space of dimension $d3$, unless they are coplanar.4.  Show that it cannot always be done for $N5$ points in a    space of dimension $d3$.5.  The ambitious student may wish to prove that $N$ points in general    position (but not $N+1$) are linearly separable in a space of    dimension $N-1$.",
        "url": " /concept-learning-exercises/ex_33/"
      }
    
  
    ,
      "concept-learning-exercises-ex-5":  {
        "title": "Exercise 18.5",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose we generate a training set from a decision tree and then applydecision-tree learning to that training set. Is it the case that thelearning algorithm will eventually return the correct tree as thetraining-set size goes to infinity? Why or why not?",
        "url": " /concept-learning-exercises/ex_5/"
      }
    
  
    ,
      "concept-learning-exercises-ex-2":  {
        "title": "Exercise 18.2",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Repeat Exercise infant-language-exercise for the caseof learning to play tennis (or some other sport with which you arefamiliar). Is this supervised learning or reinforcement learning?",
        "url": " /concept-learning-exercises/ex_2/"
      }
    
  
    ,
      "concept-learning-exercises-ex-15":  {
        "title": "Exercise 18.15",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose that a learning algorithm is trying to find a consistenthypothesis when the classifications of examples are actually random.There are $n$ Boolean attributes, and examples are drawn uniformly fromthe set of $2^n$ possible examples. Calculate the number of examplesrequired before the probability of finding a contradiction in the datareaches 0.5.",
        "url": " /concept-learning-exercises/ex_15/"
      }
    
  
    ,
      "concept-learning-exercises-ex-12":  {
        "title": "Exercise 18.12",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "The standard DECISION-TREE-LEARNING algorithm described in thechapter does not handle cases in which some examples have missingattribute values.1.  First, we need to find a way to classify such examples, given a    decision tree that includes tests on the attributes for which values    can be missing. Suppose that an example $textbf{x}$ has a missing value for    attribute $A$ and that the decision tree tests for $A$ at a node    that $textbf{x}$ reaches. One way to handle this case is to pretend that    the example has all possible values for the    attribute, but to weight each value according to its frequency among    all of the examples that reach that node in the decision tree. The    classification algorithm should follow all branches at any node for    which a value is missing and should multiply the weights along each    path. Write a modified classification algorithm for decision trees    that has this behavior.2.  Now modify the information-gain calculation so that in any given    collection of examples $C$ at a given node in the tree during the    construction process, the examples with missing values for any of    the remaining attributes are given “as-if” values according to the    frequencies of those values in the set $C$.",
        "url": " /concept-learning-exercises/ex_12/"
      }
    
  
    ,
      "concept-learning-exercises-ex-24":  {
        "title": "Exercise 18.24",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Construct by hand a neural network that computes the xorfunction of two inputs. Make sure to specify what sort of units you areusing.",
        "url": " /concept-learning-exercises/ex_24/"
      }
    
  
    ,
      "concept-learning-exercises-ex-23":  {
        "title": "Exercise 18.23",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Consider an ensemble learning algorithm thatuses simple majority voting among $K$ learned hypotheses.Suppose that each hypothesis has error $epsilon$ and that the errorsmade by each hypothesis are independent of the others’. Calculate aformula for the error of the ensemble algorithm in terms of $K$and $epsilon$, and evaluate it for the cases where$K=5$, 10, and 20 and $epsilon={0.1}$, 0.2,and 0.4. If the independence assumption is removed, is it possible forthe ensemble error to be worse than $epsilon$?",
        "url": " /concept-learning-exercises/ex_23/"
      }
    
  
    ,
      "concept-learning-exercises-ex-22":  {
        "title": "Exercise 18.22",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Construct a support vector machine that computes thexor function. Use values of +1 and –1 (instead of 1 and 0)for both inputs and outputs, so that an example looks like $([-1, 1],1)$ or $([-1, -1], -1)$. Map the input $[x_1,x_2]$ into a spaceconsisting of $x_1$ and $x_1,x_2$. Draw the four input points in thisspace, and the maximal margin separator. What is the margin? Now drawthe separating line back in the original Euclidean input space.",
        "url": " /concept-learning-exercises/ex_22/"
      }
    
  
    ,
      "concept-learning-exercises-ex-25":  {
        "title": "Exercise 18.25",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "A simple perceptron cannot represent xor (or, generally,the parity function of its inputs). Describe what happens to the weightsof a four-input, hard-threshold perceptron, beginning with all weightsset to 0.1, as examples of the parity function arrive.",
        "url": " /concept-learning-exercises/ex_25/"
      }
    
  
    ,
      "concept-learning-exercises-ex-13":  {
        "title": "Exercise 18.13",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "InSection broadening-decision-tree-section, we noted thatattributes with many different possible values can cause problems withthe gain measure. Such attributes tend to split the examples intonumerous small classes or even singleton classes, thereby appearing tobe highly relevant according to the gain measure. Thegain-ratio criterion selects attributesaccording to the ratio between their gain and their intrinsicinformation content—that is, the amount of information contained in theanswer to the question, “What is the value of this attribute?” Thegain-ratio criterion therefore tries to measure how efficiently anattribute provides information on the correct classification of anexample. Write a mathematical expression for the information content ofan attribute, and implement the gain ratio criterion in DECISION-TREE-LEARNING.",
        "url": " /concept-learning-exercises/ex_13/"
      }
    
  
    ,
      "concept-learning-exercises-ex-14":  {
        "title": "Exercise 18.14",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose you are running a learning experiment on a new algorithm forBoolean classification. You have a data set consisting of 100 positiveand 100 negative examples. You plan to use leave-one-outcross-validation and compare your algorithm to a baseline function, asimple majority classifier. (A majority classifier is given a set oftraining data and then always outputs the class that is in the majorityin the training set, regardless of the input.) You expect the majorityclassifier to score about 50% on leave-one-out cross-validation, but toyour surprise, it scores zero every time. Can you explain why?",
        "url": " /concept-learning-exercises/ex_14/"
      }
    
  
    ,
      "concept-learning-exercises-ex-9":  {
        "title": "Exercise 18.9",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Construct a data set (set of examples with attributes andclassifications) that would cause the decision-tree learning algorithmto find a non-minimal-sized tree. Show the tree constructed by thealgorithm and the minimal-sized tree that you can generate by hand.",
        "url": " /concept-learning-exercises/ex_9/"
      }
    
  
    ,
      "concept-learning-exercises-ex-7":  {
        "title": "Exercise 18.7",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose that an attribute splits the set ofexamples $E$ into subsets $E_k$ and that each subset has $p_k$positive examples and $n_k$ negative examples. Show that theattribute has strictly positive information gain unless the ratio$p_k/(p_k+n_k)$ is the same for all $k$.",
        "url": " /concept-learning-exercises/ex_7/"
      }
    
  
    ,
      "concept-learning-exercises-ex-31":  {
        "title": "Exercise 18.31",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Suppose that a training set contains only a single example, repeated 100times. In 80 of the 100 cases, the single output value is 1; in theother 20, it is 0. What will a back-propagation network predict for thisexample, assuming that it has been trained and reaches a global optimum?(Hint: to find the global optimum, differentiate theerror function and set it to zero.)",
        "url": " /concept-learning-exercises/ex_31/"
      }
    
  
    ,
      "concept-learning-exercises-ex-1":  {
        "title": "Exercise 18.1",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Consider the problem faced by an infantlearning to speak and understand a language. Explain how this processfits into the general learning model. Describe the percepts and actionsof the infant, and the types of learning the infant must do. Describethe subfunctions the infant is trying to learn in terms of inputs andoutputs, and available example data.",
        "url": " /concept-learning-exercises/ex_1/"
      }
    
  
    ,
      "concept-learning-exercises-ex-6":  {
        "title": "Exercise 18.6",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "In the recursive construction ofdecision trees, it sometimes happens that a mixed set of positive andnegative examples remains at a leaf node, even after all the attributeshave been used. Suppose that we have $p$ positive examples and $n$negative examples.1.  Show that the solution used by DECISION-TREE-LEARNING, which picks the majority    classification, minimizes the absolute error over the set of    examples at the leaf.2.  Show that the class probability $p/(p+n)$ minimizes the sum of squared errors.",
        "url": " /concept-learning-exercises/ex_6/"
      }
    
  
    ,
      "concept-learning-exercises-ex-8":  {
        "title": "Exercise 18.8",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Consider the following data set comprised of three binary inputattributes ($A_1, A_2$, and $A_3$) and one binary output:$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; Outputspace y  	hline textbf{x}_1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  	textbf{x}_2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  	 textbf{x}_3 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	 textbf{x}_4 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_5 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1  	hline  end{array}$$Use the algorithm in Figure DTL-algorithm(page DTL-algorithm) to learn a decision tree for these data. Show thecomputations made to determine the attribute to split at each node.",
        "url": " /concept-learning-exercises/ex_8/"
      }
    
  
    ,
      "concept-learning-exercises-ex-30":  {
        "title": "Exercise 18.30",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Implement a data structure for layered, feed-forward neural networks,remembering to provide the information needed for both forwardevaluation and backward propagation. Using this data structure, write afunction NEURAL-NETWORK-OUTPUT that takes an example and a network and computes theappropriate output values.",
        "url": " /concept-learning-exercises/ex_30/"
      }
    
  
    
  
    ,
      "ilp-exercises-ex-3":  {
        "title": "Exercise 19.3",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):1.  Zip code determines the state (U.S.).2.  Design and denomination determine the mass of a coin.3.  Climate, food intake, exercise, and metabolism determine weight gain    and loss.4.  Baldness is determined by the baldness (or lack thereof) of one’s    maternal grandfather.",
        "url": " /ilp-exercises/ex_3/"
      }
    
  
    ,
      "ilp-exercises-ex-4":  {
        "title": "Exercise 19.4",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Would a probabilistic version of determinations be useful? Suggest adefinition.",
        "url": " /ilp-exercises/ex_4/"
      }
    
  
    ,
      "ilp-exercises-ex-5":  {
        "title": "Exercise 19.5",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Fill in the missing values for the clauses $C_1$ or$C_2$ (or both) in the following sets of clauses, given that $C$ is theresolvent of $C_1$ and $C_2$:1.  $C = {True} Rightarrow P(A,B)$,    $C_1 = P(x,y) Rightarrow Q(x,y)$, $C_2    = ??$.2.  $C = {True} Rightarrow P(A,B)$, $C_1 = ??$,    $C_2 = ??$.3.  $C = P(x,y) Rightarrow P(x,f(y))$, $C_1 = ??$,    $C_2 = ??$.If there is more than one possible solution, provide one example of eachdifferent kind.",
        "url": " /ilp-exercises/ex_5/"
      }
    
  
    ,
      "ilp-exercises-ex-2":  {
        "title": "Exercise 19.2",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):1.  Design and denomination determine the mass of a coin.2.  For a given program, input determines output.3.  Climate, food intake, exercise, and metabolism determine weight gain    and loss.4.  Baldness is determined by the baldness (or lack thereof) of one’s    maternal grandfather. ",
        "url": " /ilp-exercises/ex_2/"
      }
    
  
    ,
      "ilp-exercises-ex-7":  {
        "title": "Exercise 19.7",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Suppose that is considering adding a literalto a clause using a binary predicate $P$ and that previous literals(including the head of the clause) contain five different variables.1.  How many functionally different literals can be generated? Two    literals are functionally identical if they differ only in the names    of the *new* variables that they contain.2.  Can you find a general formula for the number of different literals    with a predicate of arity $r$ when there are $n$ variables    previously used?3.  Why does not allow literals that contain no previously used    variables?",
        "url": " /ilp-exercises/ex_7/"
      }
    
  
    ,
      "ilp-exercises-ex-1":  {
        "title": "Exercise 19.1",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Show, by translating into conjunctive normal form andapplying resolution, that the conclusion drawn on page dbsig-pageconcerning Brazilians is sound.",
        "url": " /ilp-exercises/ex_1/"
      }
    
  
    ,
      "ilp-exercises-ex-6":  {
        "title": "Exercise 19.6",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Suppose one writes a logic program that carriesout a resolution inference step. That is, let ${Resolve}(c_1,c_2,c)$succeed if $c$ is the result of resolving $c_1$ and $c_2$. Normally,${Resolve}$ would be used as part of a theorem prover by calling itwith $c_1$ and $c_2$ instantiated to particular clauses, therebygenerating the resolvent $c$. Now suppose instead that we call it with$c$ instantiated and $c_1$ and $c_2$ uninstantiated. Will this succeedin generating the appropriate results of an inverse resolution step?Would you need any special modifications to the logic programming systemfor this to work?",
        "url": " /ilp-exercises/ex_6/"
      }
    
  
    ,
      "ilp-exercises-ex-8":  {
        "title": "Exercise 19.8",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Using the data from the family tree inFigure family2-figure, or a subset thereof, apply thealgorithm to learn a definition for the ${Ancestor}$ predicate.",
        "url": " /ilp-exercises/ex_8/"
      }
    
  
    
  
    ,
      "nlp-english-exercises-ex-11":  {
        "title": "Exercise 23.11",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the following toy grammar:&amp;gt; $S rightarrow NPspace VP$&amp;gt; $NP rightarrow Noun$&amp;gt; $NP rightarrow NPspace andspace NP$&amp;gt; $NP rightarrow NPspace PP$&amp;gt; $VP rightarrow Verb$&amp;gt; $VP rightarrow VPspace and space VP$&amp;gt; $VP rightarrow VPspace PP$&amp;gt; $PP rightarrow Prepspace NP$&amp;gt; $Noun rightarrow Sallyspace; poolsspace; streamsspace; swims$&amp;gt; $Prep rightarrow in$&amp;gt; $Verb rightarrow poolsspace; streamsspace; swims$1.  Show all the parse trees in this grammar for the sentence “Sally    swims in streams and pools.”2.  Show all the table entries that would be made by    a (non-probabalistic) CYK parser on this sentence.",
        "url": " /nlp-english-exercises/ex_11/"
      }
    
  
    ,
      "nlp-english-exercises-ex-16":  {
        "title": "Exercise 23.16",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the following sentence (from The New York Times,July 28, 2008):&amp;gt; Banks struggling to recover from multibillion-dollar loans on real&amp;gt; estate are curtailing loans to American businesses, depriving even&amp;gt; healthy companies of money for expansion and hiring.1.  Which of the words in this sentence are lexically ambiguous?2.  Find two cases of syntactic ambiguity in this sentence (there are    more than two.)3.  Give an instance of metaphor in this sentence.4.  Can you find semantic ambiguity?",
        "url": " /nlp-english-exercises/ex_16/"
      }
    
  
    ,
      "nlp-english-exercises-ex-20":  {
        "title": "Exercise 23.20",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "(Adapted from [Knight:1999].) Our translation model assumes that, after the phrasetranslation model selects phrases and the distortion model permutesthem, the language model can unscramble the permutation. This exerciseinvestigates how sensible that assumption is. Try to unscramble theseproposed lists of phrases into the correct order:1.  have, programming, a, seen, never, I, language, better2.  loves, john, mary3.  is the, communication, exchange of, intentional, information    brought, by, about, the production, perception of, and signs, from,    drawn, a, of, system, signs, conventional, shared4.  created, that, we hold these, to be, all men, truths, are, equal,    self-evidentWhich ones could you do? What type of knowledge did you draw upon? Traina bigram model from a training corpus, and use it to find thehighest-probability permutation of some sentences from a test corpus.Report on the accuracy of this model.",
        "url": " /nlp-english-exercises/ex_20/"
      }
    
  
    ,
      "nlp-english-exercises-ex-18":  {
        "title": "Exercise 23.18",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Select five sentences and submit them to an online translation service.Translate them from English to another language and back to English.Rate the resulting sentences for grammaticality and preservation ofmeaning. Repeat the process; does the second round of iteration giveworse results or the same results? Does the choice of intermediatelanguage make a difference to the quality of the results? If you know aforeign language, look at the translation of one paragraph into thatlanguage. Count and describe the errors made, and conjecture why theseerrors were made.",
        "url": " /nlp-english-exercises/ex_18/"
      }
    
  
    ,
      "nlp-english-exercises-ex-19":  {
        "title": "Exercise 23.19",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "The $D_i$ values for the sentence inFigure mt-alignment-figure sum to 0. Will that be trueof every translation pair? Prove it or give a counterexample.",
        "url": " /nlp-english-exercises/ex_19/"
      }
    
  
    ,
      "nlp-english-exercises-ex-21":  {
        "title": "Exercise 23.21",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Calculate the most probable path through the HMM inFigure sr-hmm-figure for the output sequence$[C_1,C_2,C_3,C_4,C_4,C_6,C_7]$. Also give its probability.",
        "url": " /nlp-english-exercises/ex_21/"
      }
    
  
    ,
      "nlp-english-exercises-ex-17":  {
        "title": "Exercise 23.17",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Without looking back atExercise washing-clothes-exercise, answer the followingquestions:1.  What are the four steps that are mentioned?2.  What step is left out?3.  What is “the material” that is mentioned in the text?4.  What kind of mistake would be expensive?5.  Is it better to do too few things or too many? Why?",
        "url": " /nlp-english-exercises/ex_17/"
      }
    
  
    ,
      "nlp-english-exercises-ex-10":  {
        "title": "Exercise 23.10",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "In this exercise you will transform $large varepsilon_0$  intoChomsky Normal Form (CNF). There are five steps: (a) Add a new startsymbol, (b) Eliminate $epsilon$ rules, (c) Eliminate multiple words onright-hand sides, (d) Eliminate rules of the form(${it X} rightarrow$${it Y}$),(e) Convert long right-hand sides into binary rules.1.  The start symbol, $S$, can occur only on the left-hand side in CNF.    Replace ${it S}$ everywhere by a new symbol    ${it S&#39;}$ and add a rule of the form    ${it S}$    $rightarrow$${it S&#39;}$.2.  The empty string, $epsilon$ cannot appear on the right-hand side    in CNF. $large varepsilon_0$ does not have any rules with $epsilon$, so this is not    an issue.3.  A word can appear on the right-hand side in a rule only of the form    (${it X}$    $rightarrow$word).    Replace each rule of the form (${it X}$    $rightarrow$…word …)    with (${it X}$    $rightarrow$…${it W&#39;}$ …)    and (${it W&#39;}$    $rightarrow$word),    using a new symbol ${it W&#39;}$.4.  A rule (${it X}$    $rightarrow$${it Y}$)    is not allowed in CNF; it must be (${it X}$    $rightarrow$${it Y}$    ${it Z}$) or (${it X}$    $rightarrow$word).    Replace each rule of the form (${it X}$    $rightarrow$${it Y}$)    with a set of rules of the form (${it X}$    $rightarrow$…), one    for each rule (${it Y}$    $rightarrow$…),    where (…) indicates one or more symbols.5.  Replace each rule of the form (${it X}$    $rightarrow$${it Y}$    ${it Z}$ …) with two rules, (${it X}$    $rightarrow$${it Y}$    ${it Z&#39;}$) and (${it Z&#39;}$    $rightarrow$${it Z}$    …), where ${it Z&#39;}$ is a new symbol.Show each step of the process and the final set of rules.",
        "url": " /nlp-english-exercises/ex_10/"
      }
    
  
    ,
      "nlp-english-exercises-ex-3":  {
        "title": "Exercise 23.3",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the following PCFG for simple verb phrases:&amp;gt; 0.1: VP $rightarrow$ Verb&amp;gt; 0.2: VP $rightarrow$ Copula Adjective&amp;gt; 0.5: VP $rightarrow$ Verb the Noun&amp;gt; 0.2: VP $rightarrow$ VP Adverb&amp;gt; 0.5: Verb $rightarrow$ is&amp;gt; 0.5: Verb $rightarrow$ shoots&amp;gt; 0.8: Copula $rightarrow$ is&amp;gt; 0.2: Copula $rightarrow$ seems&amp;gt; 0.5: Adjective $rightarrow$ unwell&amp;gt; 0.5: Adjective $rightarrow$ well&amp;gt; 0.5: Adverb $rightarrow$ well&amp;gt; 0.5: Adverb $rightarrow$ badly&amp;gt; 0.6: Noun $rightarrow$ duck&amp;gt; 0.4: Noun $rightarrow$ well1.  Which of the following have a nonzero probability as a VP? (i)    shoots the duck well well well(ii) seems the well well(iii) shoots    the unwell well badly2.  What is the probability of generating “is well well”?3.  What types of ambiguity are exhibited by the phrase in (b)?4.  Given any PCFG, is it possible to calculate the probability that the    PCFG generates a string of exactly 10 words?",
        "url": " /nlp-english-exercises/ex_3/"
      }
    
  
    ,
      "nlp-english-exercises-ex-4":  {
        "title": "Exercise 23.4",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the following simple PCFG for noun phrases:&amp;gt; 0.6: NP $rightarrow$ Det AdjString Noun&amp;gt; 0.4: NP $rightarrow$ Det NounNounCompound&amp;gt; 0.5: AdjString $rightarrow$ Adj AdjString&amp;gt; 0.5: AdjString $rightarrow$ $Lambda$&amp;gt; 1.0: NounNounCompound $rightarrow$ Noun&amp;gt; 0.8: Det $rightarrow$ the&amp;gt; 0.2: Det $rightarrow$ a&amp;gt; 0.5: Adj $rightarrow$ small&amp;gt; 0.5: Adj $rightarrow$ green&amp;gt; 0.6: Noun $rightarrow$ village&amp;gt; 0.4: Noun $rightarrow$ greenwhere $Lambda$ denotes the empty string.1.  What is the longest NP that can be generated by this grammar? (i)    three words(ii) four words(iii) infinitely many words2.  Which of the following have a nonzero probability of being generated    as complete NPs? (i) a small green village(ii) a green    green green(iii) a small village green3.  What is the probability of generating “the green green”?4.  What types of ambiguity are exhibited by the phrase in (c)?5.  Given any PCFG and any finite word sequence, is it possible to    calculate the probability that the sequence was generated by the    PCFG?",
        "url": " /nlp-english-exercises/ex_4/"
      }
    
  
    ,
      "nlp-english-exercises-ex-5":  {
        "title": "Exercise 23.5",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Outline the major differences between Java (or any other computerlanguage with which you are familiar) and English, commenting on the“understanding” problem in each case. Think about such things asgrammar, syntax, semantics, pragmatics, compositionality,context-dependence, lexical ambiguity, syntactic ambiguity, referencefinding (including pronouns), background knowledge, and what it means to“understand” in the first place.",
        "url": " /nlp-english-exercises/ex_5/"
      }
    
  
    ,
      "nlp-english-exercises-ex-2":  {
        "title": "Exercise 23.2",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "An HMM grammar is essentially a standard HMM whose statevariable is $N$ (nonterminal, with values such as $Det$, $Adjective$,$Noun$ and so on) and whose evidence variable is $W$ (word, with valuessuch as $is$, $duck$, and so on). The HMM model includes a prior${textbf{P}}(N_0)$, a transition model${textbf{P}}(N_{t+1}|N_t)$, and a sensor model${textbf{P}}(W_t|N_t)$. Show that every HMM grammar can bewritten as a PCFG. [Hint: start by thinking about how the HMM prior canbe represented by PCFG rules for the sentence symbol. You may find ithelpful to illustrate for the particular HMM with values $A$, $B$ for$N$ and values $x$, $y$ for $W$.]",
        "url": " /nlp-english-exercises/ex_2/"
      }
    
  
    ,
      "nlp-english-exercises-ex-15":  {
        "title": "Exercise 23.15",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Augment the $large varepsilon_1$ grammar so that it handles article–noun agreement. That is,make sure that “agents” and “an agent” are ${it NP}$s, but“agent” and “an agents” are not.",
        "url": " /nlp-english-exercises/ex_15/"
      }
    
  
    ,
      "nlp-english-exercises-ex-12":  {
        "title": "Exercise 23.12",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Using DCG notation, write a grammar for alanguage that is just like $large varepsilon_1$, except that it enforces agreement betweenthe subject and verb of a sentence and thus does not generateungrammatical sentences such as “I smells the wumpus.”",
        "url": " /nlp-english-exercises/ex_12/"
      }
    
  
    ,
      "nlp-english-exercises-ex-22":  {
        "title": "Exercise 23.22",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "We forgot to mention that the text inExercise washing-clothes-exercise is entitled “WashingClothes.” Reread the text and answer the questions inExercise washing-clothes2-exercise. Did you do betterthis time? Bransford and Johnson [Bransford+Johnson:1973] used thistext in a controlled experiment and found that the title helpedsignificantly. What does this tell you about how language and memoryworks?",
        "url": " /nlp-english-exercises/ex_22/"
      }
    
  
    ,
      "nlp-english-exercises-ex-13":  {
        "title": "Exercise 23.13",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the following PCFG:&amp;gt; $S rightarrow NP space VP[1.0] $&amp;gt; $NP rightarrow textit{Noun}[0.6] space|space textit{Pronoun}[0.4] $&amp;gt; $VP rightarrow textit{Verb} space NP[0.8] space|space textit{Modal}space textit{Verb}[0.2]$&amp;gt; $textit{Noun} rightarrow textbf{can}[0.1] space|space textbf{fish}[0.3] space|space ...$&amp;gt; $textit{Pronoun} rightarrow textbf{I}[0.4] space|space ...$&amp;gt; $textit{Verb} rightarrow textbf{can}[0.01] space|space textbf{fish}[0.1] space|space ...$&amp;gt; $textit{Modal} rightarrow textbf{can}[0.3] space|space ...$The sentence “I can fish” has two parse trees with this grammar. Showthe two trees, their prior probabilities, and their conditionalprobabilities, given the sentence.",
        "url": " /nlp-english-exercises/ex_13/"
      }
    
  
    ,
      "nlp-english-exercises-ex-14":  {
        "title": "Exercise 23.14",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "An augmented context-free grammar can represent languages that a regularcontext-free grammar cannot. Show an augmented context-free grammar forthe language $a^nb^nc^n$. The allowable values for augmentationvariables are 1 and $SUCCESSOR(n)$, where $n$ is a value. The rule for a sentencein this language is$$S(n) rightarrow A(n) B(n) C(n)  .$$Show the rule(s) for each of ${it A}$,${it B}$, and ${it C}$.",
        "url": " /nlp-english-exercises/ex_14/"
      }
    
  
    ,
      "nlp-english-exercises-ex-9":  {
        "title": "Exercise 23.9",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Some linguists have argued as follows: Children learning a language hear only positive examples of the language and no negative examples. Therefore, the hypothesis that “every possible sentence is in the language” is consistent with all the observed examples. Moreover, this is the simplest consistent hypothesis. Furthermore, all grammars for languages that are supersets of the true language are also consistent with the observed data. Yet children do induce (more or less) the right grammar. It follows that they begin with very strong innate grammatical constraints that rule out all of these more general hypotheses a priori.Comment on the weak point(s) in this argument from a statisticallearning viewpoint.",
        "url": " /nlp-english-exercises/ex_9/"
      }
    
  
    ,
      "nlp-english-exercises-ex-7":  {
        "title": "Exercise 23.7",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Consider the sentence “Someone walked slowly to the supermarket” and alexicon consisting of the following words:$Pronoun rightarrow textbf{someone} quad Verb rightarrow textbf{walked}$$Adv rightarrow textbf{slowly} quad Prep rightarrow textbf{to}$$Article rightarrow textbf{the} quad Noun rightarrow textbf{supermarket}$Which of the following three grammars, combined with the lexicon,generates the given sentence? Show the corresponding parse tree(s).$$quadquadquadquad (A):quadquadquadquad  quadquadquadquad(B):quadquadquadquad  quadquadquadquad(C):quadquadquadquad S rightarrow NP space VP quadquadquadquad quadquadquadquad Srightarrow NPspace VP quadquadquadquad Srightarrow NPspace VPquadquadquadquad NPrightarrow Pronoun quadquadquadquad  NPrightarrow Pronoun quadquadquadquad  NPrightarrow Pronounquadquadquadquad NPrightarrow Articlespace Noun quadquadquadquad  NPrightarrow Noun quadquadquadquad  NPrightarrow Articlespace NPquadquadquadquad VPrightarrow VPspace PP quadquadquadquad NPrightarrow Articlespace NP quadquadquadquad  VPrightarrow Verbspace Advquadquadquadquad  VPrightarrow VPspace Advspace Adv quadquadquadquad  VPrightarrow Verbspace Vmod quadquadquadquad  Advrightarrow Advspace Advquadquadquadquad  VPrightarrow Verb quadquadquadquad  Vmodrightarrow Advspace Vmod quadquadquadquad   Advrightarrow PPquadquadquadquad PPrightarrow Prepspace NP quadquadquadquad Vmodrightarrow Adv quadquadquadquad PPrightarrow Prepspace NPquadquadquadquad NPrightarrow Noun quadquadquadquad Advrightarrow PP quadquadquadquad NPrightarrow Nounquadquadquadquadquad quadquadquadquad PPrightarrow Prepspace NP quadquadquadquad quadquadquadquad$$For each of the preceding three grammars, write down three sentences ofEnglish and three sentences of non-English generated by the grammar.Each sentence should be significantly different, should be at least sixwords long, and should include some new lexical entries (which youshould define). Suggest ways to improve each grammar to avoid generatingthe non-English sentences.",
        "url": " /nlp-english-exercises/ex_7/"
      }
    
  
    ,
      "nlp-english-exercises-ex-1":  {
        "title": "Exercise 23.1",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Read the following text once forunderstanding, and remember as much of it as you can. There will be atest later.&amp;gt; The procedure is actually quite simple. First you arrange things intodifferent groups. Of course, one pile may be sufficient depending on howmuch there is to do. If you have to go somewhere else due to lack offacilities that is the next step, otherwise you are pretty well set. Itis important not to overdo things. That is, it is better to do too fewthings at once than too many. In the short run this may not seemimportant but complications can easily arise. A mistake is expensive aswell. At first the whole procedure will seem complicated. Soon, however,it will become just another facet of life. It is difficult to foreseeany end to the necessity for this task in the immediate future, but thenone can never tell. After the procedure is completed one arranges thematerial into different groups again. Then they can be put into theirappropriate places. Eventually they will be used once more and the wholecycle will have to be repeated. However, this is part of life.",
        "url": " /nlp-english-exercises/ex_1/"
      }
    
  
    ,
      "nlp-english-exercises-ex-6":  {
        "title": "Exercise 23.6",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "This exercise concerns grammars for very simple languages.1.  Write a context-free grammar for the language $a^n b^n$.2.  Write a context-free grammar for the palindrome language: the set of    all strings whose second half is the reverse of the first half.3.  Write a context-sensitive grammar for the duplicate language: the    set of all strings whose second half is the same as the first half.",
        "url": " /nlp-english-exercises/ex_6/"
      }
    
  
    ,
      "nlp-english-exercises-ex-8":  {
        "title": "Exercise 23.8",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Collect some examples of time expressions, such as “two o’clock,”“midnight,” and “12:46.” Also think up some examples that areungrammatical, such as “thirteen o’clock” or “half past two fifteen.”Write a grammar for the time language.",
        "url": " /nlp-english-exercises/ex_8/"
      }
    
  
    
  
    ,
      "probability-exercises-ex-11":  {
        "title": "Exercise 13.11",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Deciding to put probability theory to good use, we encounter a slotmachine with three independent wheels, each producing one of the foursymbols bar, bell, lemon, orcherry with equal probability. The slot machine has thefollowing payout scheme for a bet of 1 coin (where “?” denotes that wedon’t care what comes up for that wheel): &amp;gt; bar/bar/bar pays 20 coins&amp;gt; bell/bell/bell pays 15 coins&amp;gt; lemon/lemon/lemon pays 5 coins&amp;gt; cherry/cherry/cherry pays 3 coins&amp;gt; cherry/cherry/? pays 2 coins&amp;gt; cherry/?/? pays 1 coin1.  Compute the expected “payback” percentage of the machine. In other    words, for each coin played, what is the expected coin return?2.  Compute the probability that playing the slot machine once will    result in a win.3.  Estimate the mean and median number of plays you can expect to make    until you go broke, if you start with 10 coins. You can run a    simulation to estimate this, rather than trying to compute an    exact answer.",
        "url": " /probability-exercises/ex_11/"
      }
    
  
    ,
      "probability-exercises-ex-16":  {
        "title": "Exercise 13.16",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Consider two medical tests, A and B, for a virus. Test A is 95%effective at recognizing the virus when it is present, but has a 10%false positive rate (indicating that the virus is present, when it isnot). Test B is 90% effective at recognizing the virus, but has a 5%false positive rate. The two tests use independent methods ofidentifying the virus. The virus is carried by 1% of all people. Saythat a person is tested for the virus using only one of the tests, andthat test comes back positive for carrying the virus. Which testreturning positive is more indicative of someone really carrying thevirus? Justify your answer mathematically.",
        "url": " /probability-exercises/ex_16/"
      }
    
  
    ,
      "probability-exercises-ex-29":  {
        "title": "Exercise 13.29",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "In our analysis of the wumpus world, we used the fact thateach square contains a pit with probability 0.2, independently of thecontents of the other squares. Suppose instead that exactly $N/5$ pitsare scattered at random among the $N$ squares other than [1,1]. Arethe variables $P_{i,j}$ and $P_{k,l}$ still independent? What is thejoint distribution ${textbf{P}}(P_{1,1},ldots,P_{4,4})$ now?Redo the calculation for the probabilities of pits in [1,3] and[2,2].",
        "url": " /probability-exercises/ex_29/"
      }
    
  
    ,
      "probability-exercises-ex-20":  {
        "title": "Exercise 13.20",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "It is quite often useful to consider theeffect of some specific propositions in the context of some generalbackground evidence that remains fixed, rather than in the completeabsence of information. The following questions ask you to prove moregeneral versions of the product rule and Bayes’ rule, with respect tosome background evidence $textbf{e}$: 1.  Prove the conditionalized version of the general product rule:    $${textbf{P}}(X,Y textbf{e}) = {textbf{P}}(XY,textbf{e}) {textbf{P}}(Ytextbf{e}) .$$ 2.  Prove the conditionalized version of Bayes’ rule in    Equation (conditional-bayes-equation). ",
        "url": " /probability-exercises/ex_20/"
      }
    
  
    ,
      "probability-exercises-ex-27":  {
        "title": "Exercise 13.27",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Write out a general algorithm for answering queries of the form${textbf{P}}({Cause}textbf{e})$, using a naive Bayesdistribution. Assume that the evidence $textbf{e}$ may assign values toany subset of the effect variables.",
        "url": " /probability-exercises/ex_27/"
      }
    
  
    ,
      "probability-exercises-ex-18":  {
        "title": "Exercise 13.18",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 10,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?",
        "url": " /probability-exercises/ex_18/"
      }
    
  
    ,
      "probability-exercises-ex-26":  {
        "title": "Exercise 13.26",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "(Adapted from Pearl [Pearl:1988].) Suppose you are a witness to anighttime hit-and-run accident involving a taxi in Athens. All taxis inAthens are blue or green. You swear, under oath, that the taxi was blue.Extensive testing shows that, under the dim lighting conditions,discrimination between blue and green is 75% reliable. 1.  Is it possible to calculate the most likely color for the taxi?    (*Hint:* distinguish carefully between the proposition    that the taxi *is* blue and the proposition that it    *appears* blue.) 2.  What if you know that 9 out of 10 Athenian taxis are green?",
        "url": " /probability-exercises/ex_26/"
      }
    
  
    ,
      "probability-exercises-ex-19":  {
        "title": "Exercise 13.19",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 100,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?",
        "url": " /probability-exercises/ex_19/"
      }
    
  
    ,
      "probability-exercises-ex-21":  {
        "title": "Exercise 13.21",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Show that the statement of conditional independence$${textbf{P}}(X,Y  | Z) = {textbf{P}}(X | Z) {textbf{P}}(Y | Z)$$is equivalent to each of the statements$${textbf{P}}(X | Y,Z) = {textbf{P}}(X | Z) quadmbox{and}quad {textbf{P}}(Y | X,Z) = {textbf{P}}(Y | Z) .$$",
        "url": " /probability-exercises/ex_21/"
      }
    
  
    ,
      "probability-exercises-ex-17":  {
        "title": "Exercise 13.17",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Suppose you are given a coin that lands ${heads}$ with probability $x$and ${tails}$ with probability $1 - x$. Are the outcomes of successiveflips of the coin independent of each other given that you know thevalue of $x$? Are the outcomes of successive flips of the coinindependent of each other if you do not know the value of$x$? Justify your answer.",
        "url": " /probability-exercises/ex_17/"
      }
    
  
    ,
      "probability-exercises-ex-28":  {
        "title": "Exercise 13.28",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Text categorization is the task ofassigning a given document to one of a fixed set of categories on thebasis of the text it contains. Naive Bayes models are often used forthis task. In these models, the query variable is the document category,and the “effect” variables are the presence or absence of each word inthe language; the assumption is that words occur independently indocuments, with frequencies determined by the document category.1.  Explain precisely how such a model can be constructed, given as    “training data” a set of documents that have been assigned    to categories.2.  Explain precisely how to categorize a new document.3.  Is the conditional independence assumption reasonable? Discuss.",
        "url": " /probability-exercises/ex_28/"
      }
    
  
    ,
      "probability-exercises-ex-10":  {
        "title": "Exercise 13.10",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "In his letter of August 24, 1654, Pascalwas trying to show how a pot of money should be allocated when agambling game must end prematurely. Imagine a game where each turnconsists of the roll of a die, player E gets a point whenthe die is even, and player  O gets a point when the dieis odd. The first player to get 7 points wins the pot. Suppose the gameis interrupted with E leading 4–2. How should the moneybe fairly split in this case? What is the general formula? (Fermat andPascal made several errors before solving the problem, but you should beable to get it right the first time.)",
        "url": " /probability-exercises/ex_10/"
      }
    
  
    ,
      "probability-exercises-ex-3":  {
        "title": "Exercise 13.3",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "For each of the following statements, either prove it is true or give acounterexample.1.  If $P(a b, c) = P(b a, c)$, then    $P(a c) = P(b c)$ 2.  If $P(a b, c) = P(a)$, then $P(b c) = P(b)$ 3.  If $P(a b) = P(a)$, then    $P(a b, c) = P(a c)$",
        "url": " /probability-exercises/ex_3/"
      }
    
  
    ,
      "probability-exercises-ex-4":  {
        "title": "Exercise 13.4",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Would it be rational for an agent to hold the three beliefs$P(A) = 0.4$, $P(B) = 0.3$, and$P(A lor B) = 0.5$? If so, what range of probabilities wouldbe rational for the agent to hold for $A land B$? Make up a table likethe one in Figure de-finetti-table, and show how itsupports your argument about rationality. Then draw another version ofthe table where $P(A lor B)= 0.7$. Explain why it is rational to have this probability,even though the table shows one case that is a loss and three that justbreak even. (Hint: what is Agent 1 committed to about theprobability of each of the four cases, especially the case that is aloss?)",
        "url": " /probability-exercises/ex_4/"
      }
    
  
    ,
      "probability-exercises-ex-5":  {
        "title": "Exercise 13.5",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "This question deals with the propertiesof possible worlds, defined on page possible-worlds-page as assignments to allrandom variables. We will work with propositions that correspond toexactly one possible world because they pin down the assignments of allthe variables. In probability theory, such propositions are called atomic event. Forexample, with Boolean variables $X_1$, $X_2$, $X_3$, the proposition$x_1land lnot x_2 land lnot x_3$ fixes the assignment of thevariables; in the language of propositional logic, we would say it hasexactly one model.1.  Prove, for the case of $n$ Boolean variables, that any two distinct    atomic events are mutually exclusive; that is, their conjunction is    equivalent to ${false}$.2.  Prove that the disjunction of all possible atomic events is    logically equivalent to ${true}$.3.  Prove that any proposition is logically equivalent to the    disjunction of the atomic events that entail its truth.",
        "url": " /probability-exercises/ex_5/"
      }
    
  
    ,
      "probability-exercises-ex-2":  {
        "title": "Exercise 13.2",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Using the axioms of probability, prove that anyprobability distribution on a discrete random variable must sum to 1.",
        "url": " /probability-exercises/ex_2/"
      }
    
  
    ,
      "probability-exercises-ex-15":  {
        "title": "Exercise 13.15",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Show that the three forms of independence inEquation (independence-equation) are equivalent.",
        "url": " /probability-exercises/ex_15/"
      }
    
  
    ,
      "probability-exercises-ex-12":  {
        "title": "Exercise 13.12",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Deciding to put probability theory to good use, we encounter a slotmachine with three independent wheels, each producing one of the foursymbols bar, bell, lemon, orcherry with equal probability. The slot machine has thefollowing payout scheme for a bet of 1 coin (where “?” denotes that wedon’t care what comes up for that wheel): &amp;gt; bar/bar/bar pays 20 coins&amp;gt; bell/bell/bell pays 15 coins&amp;gt; lemon/lemon/lemon pays 5 coins&amp;gt; cherry/cherry/cherry pays 3 coins&amp;gt; cherry/cherry/? pays 2 coins&amp;gt; cherry/?/? pays 1 coin1.  Compute the expected “payback” percentage of the machine. In other    words, for each coin played, what is the expected coin return?2.  Compute the probability that playing the slot machine once will    result in a win.3.  Estimate the mean and median number of plays you can expect to make    until you go broke, if you start with 10 coins. You can run a    simulation to estimate this, rather than trying to compute an    exact answer.",
        "url": " /probability-exercises/ex_12/"
      }
    
  
    ,
      "probability-exercises-ex-24":  {
        "title": "Exercise 13.24",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "This exercise investigates the way in which conditional independencerelationships affect the amount of information needed for probabilisticcalculations.1.  Suppose we wish to calculate $P(he_1,e_2)$ and we have no    conditional independence information. Which of the following sets of    numbers are sufficient for the calculation?    1.  ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,        ${textbf{P}}(E_1H)$,        ${textbf{P}}(E_2H)$    2.  ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,        ${textbf{P}}(E_1,E_2H)$    3.  ${textbf{P}}(H)$,        ${textbf{P}}(E_1H)$,        ${textbf{P}}(E_2H)$2.  Suppose we know that    ${textbf{P}}(E_1H,E_2)={textbf{P}}(E_1H)$    for all values of $H$, $E_1$, $E_2$. Now which of the three sets are    sufficient?",
        "url": " /probability-exercises/ex_24/"
      }
    
  
    ,
      "probability-exercises-ex-23":  {
        "title": "Exercise 13.23",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "In this exercise, you will complete thenormalization calculation for the meningitis example. First, make up asuitable value for $P(slnot m)$, and use it to calculateunnormalized values for $P(ms)$ and $P(lnot m s)$(i.e., ignoring the $P(s)$ term in the Bayes’ rule expression,Equation (meningitis-bayes-equation). Now normalizethese values so that they add to 1.",
        "url": " /probability-exercises/ex_23/"
      }
    
  
    ,
      "probability-exercises-ex-22":  {
        "title": "Exercise 13.22",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Suppose you are given a bag containing $n$ unbiased coins. You are toldthat $n-1$ of these coins are normal, with heads on one side and tailson the other, whereas one coin is a fake, with heads on both sides. 1.  Suppose you reach into the bag, pick out a coin at random, flip it,    and get a head. What is the (conditional) probability that the coin    you chose is the fake coin? 2.  Suppose you continue flipping the coin for a total of $k$ times    after picking it and see $k$ heads. Now what is the conditional    probability that you picked the fake coin? 3.  Suppose you wanted to decide whether the chosen coin was fake by    flipping it $k$ times. The decision procedure returns ${fake}$ if    all $k$ flips come up heads; otherwise it returns ${normal}$. What    is the (unconditional) probability that this procedure makes an    error?",
        "url": " /probability-exercises/ex_22/"
      }
    
  
    ,
      "probability-exercises-ex-25":  {
        "title": "Exercise 13.25",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Let $X$, $Y$, $Z$ be Boolean random variables. Label the eight entriesin the joint distribution ${textbf{P}}(X,Y,Z)$ as $a$ through$h$. Express the statement that $X$ and $Y$ are conditionallyindependent given $Z$, as a set of equations relating $a$ through $h$.How many nonredundantequations are there?",
        "url": " /probability-exercises/ex_25/"
      }
    
  
    ,
      "probability-exercises-ex-13":  {
        "title": "Exercise 13.13",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon = 0.001$, $delta = 0.01$.",
        "url": " /probability-exercises/ex_13/"
      }
    
  
    ,
      "probability-exercises-ex-14":  {
        "title": "Exercise 13.14",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon0.002$, $delta0.01$.",
        "url": " /probability-exercises/ex_14/"
      }
    
  
    ,
      "probability-exercises-ex-9":  {
        "title": "Exercise 13.9",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:1.  $textbf{P}({toothache})$.2.  $textbf{P}({Catch})$.3.  $textbf{P}({Cavity}{catch})$.4.  $textbf{P}({Cavity}{toothache}lor {catch})$.",
        "url": " /probability-exercises/ex_9/"
      }
    
  
    ,
      "probability-exercises-ex-7":  {
        "title": "Exercise 13.7",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Consider the set of all possible five-card poker hands dealt fairly froma standard deck of fifty-two cards.1.  How many atomic events are there in the joint probability    distribution (i.e., how many five-card hands are there)?2.  What is the probability of each atomic event?3.  What is the probability of being dealt a royal straight flush? Four    of a kind?",
        "url": " /probability-exercises/ex_7/"
      }
    
  
    ,
      "probability-exercises-ex-31":  {
        "title": "Exercise 13.31",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "",
        "url": " /probability-exercises/ex_31/"
      }
    
  
    ,
      "probability-exercises-ex-1":  {
        "title": "Exercise 13.1",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Show from first principles that $P(abland a) = 1$.",
        "url": " /probability-exercises/ex_1/"
      }
    
  
    ,
      "probability-exercises-ex-6":  {
        "title": "Exercise 13.6",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "ProveEquation (kolmogorov-disjunction-equation) fromEquations basic-probability-axiom-equationand (proposition-probability-equation.",
        "url": " /probability-exercises/ex_6/"
      }
    
  
    ,
      "probability-exercises-ex-8":  {
        "title": "Exercise 13.8",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:1.  $textbf{P}({toothache})$.2.  $textbf{P}({Cavity})$.3.  $textbf{P}({Toothache}{cavity})$.4.  $textbf{P}({Cavity}{toothache}lor {catch})$.",
        "url": " /probability-exercises/ex_8/"
      }
    
  
    ,
      "probability-exercises-ex-30":  {
        "title": "Exercise 13.30",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Redo the probability calculation for pits in [1,3] and [2,2],assuming that each square contains a pit with probability 0.01,independent of the other squares. What can you say about the relativeperformance of a logical versus a probabilistic agent in this case?",
        "url": " /probability-exercises/ex_30/"
      }
    
  
    
  
    ,
      "kr-exercises-ex-11":  {
        "title": "Exercise 12.11",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "An alternative scheme for representing measuresinvolves applying the units function to an abstract length object. Insuch a scheme, one would write ${Inches}({Length}(L_1)) = {1.5}$.How does this scheme compare with the one in the chapter? Issues includeconversion axioms, names for abstract quantities (such as “50 dollars”),and comparisons of abstract measures in different units (50 inches ismore than 50 centimeters).",
        "url": " /kr-exercises/ex_11/"
      }
    
  
    ,
      "kr-exercises-ex-16":  {
        "title": "Exercise 12.16",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "This exercise concerns the problem of planning a route for a robot totake from one city to another. The basic action taken by the robot is${Go}(x,y)$, which takes it from city $x$ to city $y$ if there is aroute between those cities. ${Road}(x, y)$ is true if and only ifthere is a road connecting cities $x$ and $y$; if there is, then${Distance}(x, y)$ gives the length of the road. See the map onpage romania-distances-figure for an example. The robot begins in Arad and mustreach Bucharest.1.  Write a suitable logical description of the initial situation of    the robot.2.  Write a suitable logical query whose solutions provide possible    paths to the goal.3.  Write a sentence describing the ${Go}$ action.4.  Now suppose that the robot consumes fuel at the rate of .02 gallons    per mile. The robot starts with 20 gallons of fuel. Augment your    representation to include these considerations.5.  Now suppose some of the cities have gas stations at which the robot    can fill its tank. Extend your representation and write all the    rules needed to describe gas stations, including the    ${Fillup}$ action.",
        "url": " /kr-exercises/ex_16/"
      }
    
  
    ,
      "kr-exercises-ex-29":  {
        "title": "Exercise 12.29",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "A complete solution to the problem ofinexact matches to the buyer’s description in shopping is very difficultand requires a full array of natural language processing and informationretrieval techniques. (See Chapters nlp1-chapterand nlp-english-chapter.) One small step is to allow the user tospecify minimum and maximum values for various attributes. The buyermust use the following grammar for product descriptions:$$Description rightarrow Category space [Connector space Modifier]*$$$$Connector rightarrow &quot;with&quot; space | &quot;and&quot; | &quot;,&quot;$$$$Modifier rightarrow Attribute space |space Attribute space Op space Value$$$$Op rightarrow &quot;=&quot; | &quot;gt&quot; | &quot;lt&quot;$$Here, ${Category}$ names a product category, ${Attribute}$ is somefeature such as “CPU” or “price,” and ${Value}$ is the target valuefor the attribute. So the query “computer with at least a 2.5 GHz CPUfor under 500” must be re-expressed as “computer with CPU $&amp;gt;$ 2.5 GHzand price $&amp;lt;$ 500.” Implement a shopping agent that accepts descriptionsin this language.",
        "url": " /kr-exercises/ex_29/"
      }
    
  
    ,
      "kr-exercises-ex-20":  {
        "title": "Exercise 12.20",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Describe the event of trading something for something else. Describebuying as a kind of trading in which one of the objects traded is a sumof money.",
        "url": " /kr-exercises/ex_20/"
      }
    
  
    ,
      "kr-exercises-ex-27":  {
        "title": "Exercise 12.27",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "One might suppose that the syntacticdistinction between unboxed links and singly boxed links in semanticnetworks is unnecessary, because singly boxed links are always attachedto categories; an inheritance algorithm could simply assume that anunboxed link attached to a category is intended to apply to all membersof that category. Show that this argument is fallacious, giving examplesof errors that would arise.",
        "url": " /kr-exercises/ex_27/"
      }
    
  
    ,
      "kr-exercises-ex-18":  {
        "title": "Exercise 12.18",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Construct a representation for exchange ratesbetween currencies that allows for daily fluctuations.",
        "url": " /kr-exercises/ex_18/"
      }
    
  
    ,
      "kr-exercises-ex-26":  {
        "title": "Exercise 12.26",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Recall that inheritance information in semantic networks can be capturedlogically by suitable implication sentences. This exercise investigatesthe efficiency of using such sentences for inheritance.1.  Consider the information in a used-car catalog such as Kelly’s Blue    Book—for example, that 1973 Dodge vans are (or perhaps were once)    worth 575. Suppose all this information (for 11,000 models) is    encoded as logical sentences, as suggested in the chapter. Write    down three such sentences, including that for 1973 Dodge vans. How    would you use the sentences to find the value of a    particular car, given a backward-chaining theorem    prover such as Prolog?2.  Compare the time efficiency of the backward-chaining method for    solving this problem with the inheritance method used in    semantic nets.3.  Explain how forward chaining allows a logic-based system to solve    the same problem efficiently, assuming that the KB contains only the    11,000 sentences about prices.4.  Describe a situation in which neither forward nor backward chaining    on the sentences will allow the price query for an individual car to    be handled efficiently.5.  Can you suggest a solution enabling this type of query to be solved    efficiently in all cases in logic systems? Hint:    Remember that two cars of the same year and model have the    same price.)",
        "url": " /kr-exercises/ex_26/"
      }
    
  
    ,
      "kr-exercises-ex-19":  {
        "title": "Exercise 12.19",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Define the predicate ${Fixed}$, where${Fixed}({Location}(x))$ means that the location of object $x$ isfixed over time.",
        "url": " /kr-exercises/ex_19/"
      }
    
  
    ,
      "kr-exercises-ex-21":  {
        "title": "Exercise 12.21",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "The two preceding exercises assume a fairly primitive notion ofownership. For example, the buyer starts by owning thedollar bills. This picture begins to break down when, for example, one’smoney is in the bank, because there is no longer any specific collectionof dollar bills that one owns. The picture is complicated still furtherby borrowing, leasing, renting, and bailment. Investigate the variouscommonsense and legal concepts of ownership, and propose a scheme bywhich they can be represented formally.",
        "url": " /kr-exercises/ex_21/"
      }
    
  
    ,
      "kr-exercises-ex-17":  {
        "title": "Exercise 12.17",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Investigate ways to extend the event calculus to handlesimultaneous events. Is it possible to avoid acombinatorial explosion of axioms?",
        "url": " /kr-exercises/ex_17/"
      }
    
  
    ,
      "kr-exercises-ex-28":  {
        "title": "Exercise 12.28",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "One part of the shopping process that was not covered in this chapter ischecking for compatibility between items. For example, if a digitalcamera is ordered, what accessory batteries, memory cards, and cases arecompatible with the camera? Write a knowledge base that can determinethe compatibility of a set of items and suggest replacements oradditional items if the shopper makes a choice that is not compatible.The knowledge base should works with at least one line of products andextend easily to other lines.",
        "url": " /kr-exercises/ex_28/"
      }
    
  
    ,
      "kr-exercises-ex-10":  {
        "title": "Exercise 12.10",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Write definitions for the following:1.  ${ExhaustivePartDecomposition}$2.  ${PartPartition}$3.  ${PartwiseDisjoint}$These should be analogous to the definitions for${ExhaustiveDecomposition}$, ${Partition}$, and ${Disjoint}$. Isit the case that ${PartPartition}(s,{BunchOf}(s))$? If so, prove it;if not, give a counterexample and define sufficient conditions underwhich it does hold.",
        "url": " /kr-exercises/ex_10/"
      }
    
  
    ,
      "kr-exercises-ex-3":  {
        "title": "Exercise 12.3",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Figure ontology-figure shows the top levels of ahierarchy for everything. Extend it to include as many real categoriesas possible. A good way to do this is to cover all the things in youreveryday life. This includes objects and events. Start with waking up,and proceed in an orderly fashion noting everything that you see, touch,do, and think about. For example, a random sampling produces music,news, milk, walking, driving, gas, Soda Hall, carpet, talking, ProfessorFateman, chicken curry, tongue, $ 7, sun, the daily newspaper, and so on.You should produce both a single hierarchy chart (on a large sheet ofpaper) and a listing of objects and categories with the relationssatisfied by members of each category. Every object should be in acategory, and every category should be in the hierarchy.",
        "url": " /kr-exercises/ex_3/"
      }
    
  
    ,
      "kr-exercises-ex-4":  {
        "title": "Exercise 12.4",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Develop a representational system for reasoningabout windows in a window-based computer interface. In particular, yourrepresentation should be able to describe:-   The state of a window: minimized, displayed, or nonexistent.-   Which window (if any) is the active window.-   The position of every window at a given time.-   The order (front to back) of overlapping windows.-   The actions of creating, destroying, resizing, and moving windows;    changing the state of a window; and bringing a window to the front.    Treat these actions as atomic; that is, do not deal with the issue    of relating them to mouse actions. Give axioms describing the    effects of actions on fluents. You may use either event or    situation calculus.Assume an ontology containing situations,actions, integers (for $x$ and $y$coordinates) and windows. Define a language over thisontology; that is, a list of constants, function symbols, and predicateswith an English description of each. If you need to add more categoriesto the ontology (e.g., pixels), you may do so, but be sure to specifythese in your write-up. You may (and should) use symbols defined in thetext, but be sure to list these explicitly.",
        "url": " /kr-exercises/ex_4/"
      }
    
  
    ,
      "kr-exercises-ex-5":  {
        "title": "Exercise 12.5",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "State the following in the language you developed for the previousexercise:1.  In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out on    the top and bottom. Do not state exact coordinates    for these; describe the general situation.2.  If a window is displayed, then its top edge is higher than its    bottom edge.3.  After you create a window $w$, it is displayed.4.  A window can be minimized only if it is displayed.",
        "url": " /kr-exercises/ex_5/"
      }
    
  
    ,
      "kr-exercises-ex-2":  {
        "title": "Exercise 12.2",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "You are to create a system for advising computer science undergraduateson what courses to take over an extended period in order to satisfy theprogram requirements. (Use whatever requirements are appropriate foryour institution.) First, decide on a vocabulary for representing allthe information, and then represent it; then formulate a query to thesystem that will return a legal program of study as a solution. Youshould allow for some tailoring to individual students, in that yoursystem should ask what courses or equivalents the student has alreadytaken, and not generate programs that repeat those courses.Suggest ways in which your system could be improved—for example to takeinto account knowledge about student preferences, the workload, good andbad instructors, and so on. For each kind of knowledge, explain how itcould be expressed logically. Could your system easily incorporate thisinformation to find all feasible programs of study for a student? Couldit find the best program?",
        "url": " /kr-exercises/ex_2/"
      }
    
  
    ,
      "kr-exercises-ex-15":  {
        "title": "Exercise 12.15",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "State the interval-algebra relation that holds between every pair of thefollowing real-world events:&amp;gt; $LK$: The life of President Kennedy.&amp;gt; $IK$: The infancy of President Kennedy.&amp;gt; $PK$: The presidency of President Kennedy.&amp;gt; $LJ$: The life of President Johnson.&amp;gt; $PJ$: The presidency of President Johnson.&amp;gt; $LO$: The life of President Obama.",
        "url": " /kr-exercises/ex_15/"
      }
    
  
    ,
      "kr-exercises-ex-12":  {
        "title": "Exercise 12.12",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Write a set of sentences that allows one to calculate the price of anindividual tomato (or other object), given the price per pound. Extendthe theory to allow the price of a bag of tomatoes to be calculated.",
        "url": " /kr-exercises/ex_12/"
      }
    
  
    ,
      "kr-exercises-ex-24":  {
        "title": "Exercise 12.24",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:1.  Partial knowledge adversary games, such as card games. Here one    player wants to reason about what his opponent knows about the state    of the game.2.  Chess with a clock. Here the player may wish to reason about the    limits of his opponent’s or his own ability to find the best move in    the time available. For instance, if player A has much more time    left than player B, then A will sometimes make a move that greatly    complicates the situation, in the hopes of gaining an advantage    because he has more time to work out the proper strategy.3.  A shopping agent in an environment in which there are costs of    gathering information.4.  Reasoning about public key cryptography, which rests on the    intractability of certain computational problems.",
        "url": " /kr-exercises/ex_24/"
      }
    
  
    ,
      "kr-exercises-ex-23":  {
        "title": "Exercise 12.23",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:1.  Partial knowledge adversary games, such as card games. Here one    player wants to reason about what his opponent knows about the state    of the game.2.  Chess with a clock. Here the player may wish to reason about the    limits of his opponent’s or his own ability to find the best move in    the time available. For instance, if player A has much more time    left than player B, then A will sometimes make a move that greatly    complicates the situation, in the hopes of gaining an advantage    because he has more time to work out the proper strategy.3.  A shopping agent in an environment in which there are costs of    gathering information.4.  Reasoning about public key cryptography, which rests on the    intractability of certain computational problems.",
        "url": " /kr-exercises/ex_23/"
      }
    
  
    ,
      "kr-exercises-ex-22":  {
        "title": "Exercise 12.22",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "(Adapted from Fagin+al:1995.) Consider a game playedwith a deck of just 8 cards, 4 aces and 4 kings. The three players,Alice, Bob, and Carlos, are dealt two cards each. Without looking atthem, they place the cards on their foreheads so that the other playerscan see them. Then the players take turns either announcing that theyknow what cards are on their own forehead, thereby winning the game, orsaying “I don’t know.” Everyone knows the players are truthful and areperfect at reasoning about beliefs.1.  Game 1. Alice and Bob have both said “I don’t know.” Carlos sees    that Alice has two aces (A-A) and Bob has two kings (K-K). What    should Carlos say? (Hint: consider all three possible    cases for Carlos: A-A, K-K, A-K.)2.  Describe each step of Game 1 using the notation of modal logic.3.  Game 2. Carlos, Alice, and Bob all said “I don’t know” on their    first turn. Alice holds K-K and Bob holds A-K. What should Carlos    say on his second turn?4.  Game 3. Alice, Carlos, and Bob all say “I don’t know” on their first    turn, as does Alice on her second turn. Alice and Bob both hold A-K.    What should Carlos say?5.  Prove that there will always be a winner to this game.",
        "url": " /kr-exercises/ex_22/"
      }
    
  
    ,
      "kr-exercises-ex-25":  {
        "title": "Exercise 12.25",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Translate the following description logic expression (frompage description-logic-ex) into first-order logic, and comment on the result:$$And(Man, AtLeast(3,Son), AtMost(2,Daughter), All(Son,And(Unemployed,Married, All(Spouse,Doctor ))), All(Daughter,And(Professor, Fills(Department ,Physics,Math))))$$",
        "url": " /kr-exercises/ex_25/"
      }
    
  
    ,
      "kr-exercises-ex-13":  {
        "title": "Exercise 12.13",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Add sentences to extend the definition of thepredicate ${Name}(s, c)$ so that a string such as “laptop computer”matches the appropriate category names from a variety of stores. Try tomake your definition general. Test it by looking at ten online stores,and at the category names they give for three different categories. Forexample, for the category of laptops, we found the names “Notebooks,”“Laptops,” “Notebook Computers,” “Notebook,” “Laptops and Notebooks,”and “Notebook PCs.” Some of these can be covered by explicit ${Name}$facts, while others could be covered by sentences for handling plurals,conjunctions, etc.",
        "url": " /kr-exercises/ex_13/"
      }
    
  
    ,
      "kr-exercises-ex-14":  {
        "title": "Exercise 12.14",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Write event calculus axioms to describe the actions in the wumpus world.",
        "url": " /kr-exercises/ex_14/"
      }
    
  
    ,
      "kr-exercises-ex-9":  {
        "title": "Exercise 12.9",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Represent the following seven sentences using and extending therepresentations developed in the chapter: 1.  Water is a liquid between 0 and 100 degrees.2.  Water boils at 100 degrees.3.  The water in John’s water bottle is frozen.4.  Perrier is a kind of water.5.  John has Perrier in his water bottle.6.  All liquids have a freezing point.7.  A liter of water weighs more than a liter of alcohol.",
        "url": " /kr-exercises/ex_9/"
      }
    
  
    ,
      "kr-exercises-ex-7":  {
        "title": "Exercise 12.7",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "(Adapted from an example by Doug Lenat.) Your mission is to capture, inlogical form, enough knowledge to answer a series of questions about thefollowing simple scenario: Yesterday John went to the North Berkeley Safeway supermarket and bought two pounds of tomatoes and a pound of ground beef.Start by trying to represent the content of the sentence as a series ofassertions. You should write sentences that have straightforward logicalstructure (e.g., statements that objects have certain properties, thatobjects are related in certain ways, that all objects satisfying oneproperty satisfy another). The following might help you get started:-   Which classes, objects, and relations would you need? What are their    parents, siblings and so on? (You will need events and temporal    ordering, among other things.)-   Where would they fit in a more general hierarchy?-   What are the constraints and interrelationships among them?-   How detailed must you be about each of the various concepts?To answer the questions below, your knowledge base must includebackground knowledge. You’ll have to deal with what kind of things areat a supermarket, what is involved with purchasing the things oneselects, what the purchases will be used for, and so on. Try to makeyour representation as general as possible. To give a trivial example:don’t say “People buy food from Safeway,” because that won’t help youwith those who shop at another supermarket. Also, don’t turn thequestions into answers; for example, question (c) asks “Did John buy anymeat?”—not “Did John buy a pound of ground beef?”Sketch the chains of reasoning that would answer the questions. Ifpossible, use a logical reasoning system to demonstrate the sufficiencyof your knowledge base. Many of the things you write might be onlyapproximately correct in reality, but don’t worry too much; the idea isto extract the common sense that lets you answer these questions at all.A truly complete answer to this question is extremelydifficult, probably beyond the state of the art of current knowledgerepresentation. But you should be able to put together a consistent setof axioms for the limited questions posed here.1.  Is John a child or an adult? [Adult]2.  Does John now have at least two tomatoes? [Yes]3.  Did John buy any meat? [Yes]4.  If Mary was buying tomatoes at the same time as John, did he see    her? [Yes]5.  Are the tomatoes made in the supermarket? [No]6.  What is John going to do with the tomatoes? [Eat them]7.  Does Safeway sell deodorant? [Yes]8.  Did John bring some money or a credit card to the supermarket?    [Yes]9.  Does John have less money after going to the supermarket? [Yes]",
        "url": " /kr-exercises/ex_7/"
      }
    
  
    ,
      "kr-exercises-ex-1":  {
        "title": "Exercise 12.1",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Define an ontology in first-order logic for tic-tac-toe. The ontologyshould contain situations, actions, squares, players, marks (X, O, orblank), and the notion of winning, losing, or drawing a game. Alsodefine the notion of a forced win (or draw): a position from which aplayer can force a win (or draw) with the right sequence of actions.Write axioms for the domain. (Note: The axioms that enumerate thedifferent squares and that characterize the winning positions are ratherlong. You need not write these out in full, but indicate clearly whatthey look like.)",
        "url": " /kr-exercises/ex_1/"
      }
    
  
    ,
      "kr-exercises-ex-6":  {
        "title": "Exercise 12.6",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "State the following in the language you developed for the previousexercise:1.  In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out on    the top and bottom. Do not state exact coordinates    for these; describe the general situation.2.  If a window is displayed, then its top edge is higher than its    bottom edge.3.  After you create a window $w$, it is displayed.4.  A window can be minimized only if it is displayed.",
        "url": " /kr-exercises/ex_6/"
      }
    
  
    ,
      "kr-exercises-ex-8":  {
        "title": "Exercise 12.8",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Make the necessary additions or changes to your knowledge base from theprevious exercise so that the questions that follow can be answered.Include in your report a discussion of your changes, explaining why theywere needed, whether they were minor or major, and what kinds ofquestions would necessitate further changes.1.  Are there other people in Safeway while John is there?    [Yes—staff!]2.  Is John a vegetarian? [No]3.  Who owns the deodorant in Safeway? [Safeway Corporation]4.  Did John have an ounce of ground beef? [Yes]5.  Does the Shell station next door have any gas? [Yes]6.  Do the tomatoes fit in John’s car trunk? [Yes]",
        "url": " /kr-exercises/ex_8/"
      }
    
  
    ,
      "kr-exercises-ex-30":  {
        "title": "Exercise 12.30",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Our description of Internet shopping omitted theall-important step of actually buying the product.Provide a formal logical description of buying, using event calculus.That is, define the sequence of events that occurs when a buyer submitsa credit-card purchase and then eventually gets billed and receives theproduct.",
        "url": " /kr-exercises/ex_30/"
      }
    
  
    
  
    ,
      "complex-decisions-exercises-ex-11":  {
        "title": "Exercise 17.11",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Consider the $101 times 3$ world shown inFigure grid-mdp-figure(b). In the start state the agenthas a choice of two deterministic actions, Up orDown, but in the other states the agent has onedeterministic action, Right. Assuming a discounted rewardfunction, for what values of the discount $gamma$ should the agentchoose Up and for which Down? Compute theutility of each action as a function of $gamma$. (Note that this simpleexample actually reflects many real-world situations in which one mustweigh the value of an immediate action versus the potential continuallong-term consequences, such as choosing to dump pollutants into alake.)",
        "url": " /complex-decisions-exercises/ex_11/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-16":  {
        "title": "Exercise 17.16",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "What is the time complexity of $d$ steps of POMDP value iteration for asensorless environment?",
        "url": " /complex-decisions-exercises/ex_16/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-20":  {
        "title": "Exercise 17.20",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Solve the game of three-finger Morra.",
        "url": " /complex-decisions-exercises/ex_20/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-18":  {
        "title": "Exercise 17.18",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Show that a dominant strategyequilibrium is a Nash equilibrium, but not vice versa.",
        "url": " /complex-decisions-exercises/ex_18/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-19":  {
        "title": "Exercise 17.19",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "In the children’s game of rock–paper–scissors each player reveals at thesame time a choice of rock, paper, or scissors. Paper wraps rock, rockblunts scissors, and scissors cut paper. In the extended versionrock–paper–scissors–fire–water, fire beats rock, paper, and scissors;rock, paper, and scissors beat water; and water beats fire. Write outthe payoff matrix and find a mixed-strategy solution to this game.",
        "url": " /complex-decisions-exercises/ex_19/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-21":  {
        "title": "Exercise 17.21",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "In the Prisoner’s Dilemma, consider the case where aftereach round, Alice and Bob have probability $X$ meeting again. Supposeboth players choose the perpetual punishment strategy (where each willchoose ${refuse}$ unless the other player has ever played${testify}$). Assume neither player has played ${testify}$ thus far.What is the expected future total payoff for choosing to ${testify}$versus ${refuse}$ when $X = .2$? How about when $X = .05$? For whatvalue of $X$ is the expected future total payoff the same whether onechooses to ${testify}$ or ${refuse}$ in the current round?",
        "url": " /complex-decisions-exercises/ex_21/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-17":  {
        "title": "Exercise 17.17",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Consider a version of the two-state POMDP onpage 2state-pomdp-page in which the sensor is 90% reliable in state 0 butprovides no information in state 1 (that is, it reports 0 or 1 withequal probability). Analyze, either qualitatively or quantitatively, theutility function and the optimal policy for this problem.",
        "url": " /complex-decisions-exercises/ex_17/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-10":  {
        "title": "Exercise 17.10",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Consider the $3 times 3$ world shown inFigure grid-mdp-figure(a). The transition model is thesame as in the $4times 3$Figure sequential-decision-world-figure: 80% of thetime the agent goes in the direction it selects; the rest of the time itmoves at right angles to the intended direction.Implement value iteration for this world for each value of $r$ below.Use discounted rewards with a discount factor of 0.99. Show the policyobtained in each case. Explain intuitively why the value of $r$ leads toeach policy.1.  $r = -100$2.  $r = -3$3.  $r = 0$4.  $r = +3$",
        "url": " /complex-decisions-exercises/ex_10/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-3":  {
        "title": "Exercise 17.3",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Select a specific member of the set of policies that are optimal for$R(s)&amp;gt;0$ as shown inFigure sequential-decision-policies-figure(b), andcalculate the fraction of time the agent spends in each state, in thelimit, if the policy is executed forever. (Hint:Construct the state-to-state transition probability matrix correspondingto the policy and seeExercise markov-convergence-exercise.)",
        "url": " /complex-decisions-exercises/ex_3/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-4":  {
        "title": "Exercise 17.4",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Suppose that we define the utility of a statesequence to be the maximum reward obtained in any statein the sequence. Show that this utility function does not result instationary preferences between state sequences. Is it still possible todefine a utility function on states such that MEU decision making givesoptimal behavior?",
        "url": " /complex-decisions-exercises/ex_4/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-5":  {
        "title": "Exercise 17.5",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Can any finite search problem be translated exactly into a Markovdecision problem such that an optimal solution of the latter is also anoptimal solution of the former? If so, explain preciselyhow to translate the problem and how to translate the solution back; ifnot, explain precisely why not (i.e., give acounterexample).",
        "url": " /complex-decisions-exercises/ex_5/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-2":  {
        "title": "Exercise 17.2",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "For the $4times 3$ world shown inFigure sequential-decision-world-figure, calculatewhich squares can be reached from (1,1) by the action sequence$[{Right},{Right},{Right},{Up},{Up}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section) for ahidden Markov model.",
        "url": " /complex-decisions-exercises/ex_2/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-15":  {
        "title": "Exercise 17.1",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Let the initial belief state $b_0$ for the$4times 3$ POMDP on page 4x3-pomdp-page be the uniform distributionover the nonterminal states, i.e.,$&amp;lt; frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},0,0 &amp;gt;$.Calculate the exact belief state $b_1$ after the agent moves and itssensor reports 1 adjacent wall. Also calculate $b_2$ assuming that thesame thing happens again.",
        "url": " /complex-decisions-exercises/ex_15/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-12":  {
        "title": "Exercise 17.12",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Consider an undiscounted MDP having three states, (1, 2, 3), withrewards $-1$, $-2$, $0$, respectively. State 3 is a terminal state. Instates 1 and 2 there are two possible actions: $a$ and $b$. Thetransition model is as follows:-   In state 1, action $a$ moves the agent to state 2 with probability    0.8 and makes the agent stay put with probability 0.2.-   In state 2, action $a$ moves the agent to state 1 with probability    0.8 and makes the agent stay put with probability 0.2.-   In either state 1 or state 2, action $b$ moves the agent to state 3    with probability 0.1 and makes the agent stay put with    probability 0.9.Answer the following questions:1.  What can be determined qualitatively about the    optimal policy in states 1 and 2?2.  Apply policy iteration, showing each step in full, to determine the    optimal policy and the values of states 1 and 2. Assume that the    initial policy has action $b$ in both states.3.  What happens to policy iteration if the initial policy has action    $a$ in both states? Does discounting help? Does the optimal policy    depend on the discount factor?",
        "url": " /complex-decisions-exercises/ex_12/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-24":  {
        "title": "Exercise 17.24",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Imagine an auction mechanism that is just like an ascending-bid auction,except that at the end, the winning bidder, the one who bid $b_{max}$,pays only $b_{max}/2$ rather than $b_{max}$. Assuming all agents arerational, what is the expected revenue to the auctioneer for thismechanism, compared with a standard ascending-bid auction?",
        "url": " /complex-decisions-exercises/ex_24/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-23":  {
        "title": "Exercise 17.23",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "A Dutch auction is similar in an English auction, but rather thanstarting the bidding at a low price and increasing, in a Dutch auctionthe seller starts at a high price and gradually lowers the price untilsome buyer is willing to accept that price. (If multiple bidders acceptthe price, one is arbitrarily chosen as the winner.) More formally, theseller begins with a price $p$ and gradually lowers $p$ by increments of$d$ until at least one buyer accepts the price. Assuming all bidders actrationally, is it true that for arbitrarily small $d$, a Dutch auctionwill always result in the bidder with the highest value for the itemobtaining the item? If so, show mathematically why. If not, explain howit may be possible for the bidder with highest value for the item not toobtain it.",
        "url": " /complex-decisions-exercises/ex_23/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-22":  {
        "title": "Exercise 17.22",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "The following payoff matrix, from @Blinder:1983 by way of Bernstein:1996, shows a game betweenpoliticians and the Federal Reserve.$$begin{array} 	{|r|r|}hline  &amp;amp; Fed: contract &amp;amp; Fed: do nothing &amp;amp; Fed: expand  	hline		Pol: contract &amp;amp; F=7, P=1 &amp;amp; F=9, P=4 &amp;amp; F=6, P=6  		Pol: do nothing &amp;amp; F=8, P=2 &amp;amp; F=5, P=5 &amp;amp; F=4, P=9  		Pol: expand &amp;amp; F=3, P=3 &amp;amp; F=2, P=7 &amp;amp; F=1, P=8 	hline  end{array}$$Politicians can expand or contract fiscal policy, while the Fed canexpand or contract monetary policy. (And of course either side canchoose to do nothing.) Each side also has preferences for who should dowhat—neither side wants to look like the bad guys. The payoffs shown aresimply the rank orderings: 9 for first choice through 1 for last choice.Find the Nash equilibrium of the game in pure strategies. Is this aPareto-optimal solution? You might wish to analyze the policies ofrecent administrations in this light.",
        "url": " /complex-decisions-exercises/ex_22/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-25":  {
        "title": "Exercise 17.25",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Teams in the National Hockey League historically received 2 points forwinning a game and 0 for losing. If the game is tied, an overtime periodis played; if nobody wins in overtime, the game is a tie and each teamgets 1 point. But league officials felt that teams were playing tooconservatively in overtime (to avoid a loss), and it would be moreexciting if overtime produced a winner. So in 1999 the officialsexperimented in mechanism design: the rules were changed, giving a teamthat loses in overtime 1 point, not 0. It is still 2 points for a winand 1 for a tie. 1.  Was hockey a zero-sum game before the rule change? After?2.  Suppose that at a certain time $t$ in a game, the home team has    probability $p$ of winning in regulation time, probability $0.78-p$    of losing, and probability 0.22 of going into overtime, where they    have probability $q$ of winning, $.9-q$ of losing, and .1 of tying.    Give equations for the expected value for the home and    visiting teams.3.  Imagine that it were legal and ethical for the two teams to enter    into a pact where they agree that they will skate to a tie in    regulation time, and then both try in earnest to win in overtime.    Under what conditions, in terms of $p$ and $q$, would it be rational    for both teams to agree to this pact?4.  Longley+Sankaran:2005 report that since the rule change, the percentage of games with a    winner in overtime went up 18.2%, as desired, but the percentage of    overtime games also went up 3.6%. What does that suggest about    possible collusion or conservative play after the rule change?",
        "url": " /complex-decisions-exercises/ex_25/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-13":  {
        "title": "Exercise 17.13",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Consider the $4times 3$ world shown inFigure sequential-decision-world-figure.1.  Implement an environment simulator for this environment, such that    the specific geography of the environment is easily altered. Some    code for doing this is already in the online code repository.2.  Create an agent that uses policy iteration, and measure its    performance in the environment simulator from various    starting states. Perform several experiments from each starting    state, and compare the average total reward received per run with    the utility of the state, as determined by your algorithm.3.  Experiment with increasing the size of the environment. How does the    run time for policy iteration vary with the size of the environment?",
        "url": " /complex-decisions-exercises/ex_13/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-14":  {
        "title": "Exercise 17.14",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "How can the value determination algorithm beused to calculate the expected loss experienced by an agent using agiven set of utility estimates ${U}$ and an estimatedmodel ${P}$, compared with an agent using correct values?",
        "url": " /complex-decisions-exercises/ex_14/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-9":  {
        "title": "Exercise 17.9",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "This exercise considers two-player MDPs that correspond to zero-sum,turn-taking games like those inChapter game-playing-chapter. Let the players be $A$and $B$, and let $R(s)$ be the reward for player $A$ in state $s$. (Thereward for $B$ is always equal and opposite.)1.  Let $U_A(s)$ be the utility of state $s$ when it is $A$’s turn to    move in $s$, and let $U_B(s)$ be the utility of state $s$ when it is    $B$’s turn to move in $s$. All rewards and utilities are calculated    from $A$’s point of view (just as in a minimax game tree). Write    down Bellman equations defining $U_A(s)$ and $U_B(s)$.2.  Explain how to do two-player value iteration with these equations,    and define a suitable termination criterion.3.  Consider the game described in    Figure line-game4-figure on page line-game4-figure.    Draw the state space (rather than the game tree), showing the moves    by $A$ as solid lines and moves by $B$ as dashed lines. Mark each    state with $R(s)$. You will find it helpful to arrange the states    $(s_A,s_B)$ on a two-dimensional grid, using $s_A$ and $s_B$ as    “coordinates.”4.  Now apply two-player value iteration to solve this game, and derive    the optimal policy.                (a) $3 times 3$ world for Exercise 3x3-mdp-exercise. The reward for each state is indicated. The upper right square is a terminal state. (b) $101 times 3$ world for Exercise 101x3-mdp-exercise (omitting 93 identical columns in the middle).      The start state has reward 0.    ",
        "url": " /complex-decisions-exercises/ex_9/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-7":  {
        "title": "Exercise 17.7",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "For the environment shown inFigure sequential-decision-world-figure, find all thethreshold values for $R(s)$ such that the optimal policy changes whenthe threshold is crossed. You will need a way to calculate the optimalpolicy and its value for fixed $R(s)$. (Hint: Prove thatthe value of any fixed policy varies linearly with $R(s)$.)",
        "url": " /complex-decisions-exercises/ex_7/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-1":  {
        "title": "Exercise 17.1",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "For the $4times 3$ world shown inFigure sequential-decision-world-figure., calculatewhich squares can be reached from (1,1) by the action sequence$[{Up},{Up},{Right},{Right},{Right}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section for ahidden Markov model.",
        "url": " /complex-decisions-exercises/ex_1/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-6":  {
        "title": "Exercise 17.6",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Sometimes MDPs are formulated with areward function $R(s,a)$ that depends on the action taken or with areward function $R(s,a,s&#39;)$ that also depends on the outcome state.1.  Write the Bellman equations for these formulations.2.  Show how an MDP with reward function $R(s,a,s&#39;)$ can be transformed    into a different MDP with reward function $R(s,a)$, such that    optimal policies in the new MDP correspond exactly to optimal    policies in the original MDP.3.  Now do the same to convert MDPs with $R(s,a)$ into MDPs with $R(s)$.",
        "url": " /complex-decisions-exercises/ex_6/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-8":  {
        "title": "Exercise 17.8",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Equation (vi-contraction-equation) onpage vi-contraction-equation states that the Bellman operator is a contraction.1.  Show that, for any functions $f$ and $g$,    $$|max_a f(a) - max_a g(a)| leq max_a |f(a) - g(a)| .$$2.  Write out an expression for $$|(B,U_i - B,U&#39;_i)(s)|$$ and then apply    the result from (1) to complete the proof that the Bellman operator    is a contraction.",
        "url": " /complex-decisions-exercises/ex_8/"
      }
    
  
    
  
    ,
      "planning-exercises-ex-11":  {
        "title": "Exercise 10.11",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Prove the following assertions aboutplanning graphs:1.  A literal that does not appear in the final level of the graph    cannot be achieved.2.  The level cost of a literal in a serial graph is no greater than the    actual cost of an optimal plan for achieving it.",
        "url": " /planning-exercises/ex_11/"
      }
    
  
    ,
      "planning-exercises-ex-16":  {
        "title": "Exercise 10.16",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Up to now we have assumed that theplans we create always make sure that an action’s preconditions aresatisfied. Let us now investigate what propositional successor-stateaxioms such as ${HaveArrow}^{t+1} {;;{Leftrightarrow};;}{}$$({HaveArrow}^tland lnot {Shoot}^t)$ have to say about actions whose preconditionsare not satisfied.1.  Show that the axioms predict that nothing will happen when an action    is executed in a state where its preconditions are not satisfied.2.  Consider a plan $p$ that contains the actions required to achieve a    goal but also includes illegal actions. Is it the case that$$initial state land successor-state axioms landp {models} goal ?$$3.  With first-order successor-state axioms in situation calculus, is it    possible to prove that a plan containing illegal actions will    achieve the goal?",
        "url": " /planning-exercises/ex_16/"
      }
    
  
    ,
      "planning-exercises-ex-18":  {
        "title": "Exercise 10.18",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "In the $SATPlan$ algorithm inFigure satplan-agent-algorithm (page satplan-agent-algorithm,each call to the satisfiability algorithm asserts a goal $g^T$, where$T$ ranges from 0 to $T_{max}$. Suppose instead that thesatisfiability algorithm is called only once, with the goal$g^0 vee g^1 vee cdots vee g^{T_{max}}$. 1.  Will this always return a plan if one exists with length less than    or equal to $T_{max}$? 2.  Does this approach introduce any new spurious “solutions”?3.  Discuss how one might modify a satisfiability algorithm such as $WalkSAT$ so    that it finds short solutions (if they exist) when given a    disjunctive goal of this form.",
        "url": " /planning-exercises/ex_18/"
      }
    
  
    ,
      "planning-exercises-ex-17":  {
        "title": "Exercise 10.17",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Consider how to translate a set of actionschemas into the successor-state axioms of situation calculus.1.  Consider the schema for ${Fly}(p,{from},{to})$. Write a    logical definition for the predicate    ${Poss}({Fly}(p,{from},{to}),s)$, which is true if the    preconditions for ${Fly}(p,{from},{to})$ are satisfied in    situation $s$.2.  Next, assuming that ${Fly}(p,{from},{to})$ is the only action    schema available to the agent, write down a successor-state axiom    for ${At}(p,x,s)$ that captures the same information as the    action schema.3.  Now suppose there is an additional method of travel:    ${Teleport}(p,{from},{to})$. It has the additional    precondition $lnot {Warped}(p)$ and the additional effect    ${Warped}(p)$. Explain how the situation calculus knowledge base    must be modified.4.  Finally, develop a general and precisely specified procedure for    carrying out the translation from a set of action schemas to a set    of successor-state axioms.",
        "url": " /planning-exercises/ex_17/"
      }
    
  
    ,
      "planning-exercises-ex-10":  {
        "title": "Exercise 10.10",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Construct levels 0, 1, and 2 of the planning graph for the problem inFigure airport-pddl-algorithm",
        "url": " /planning-exercises/ex_10/"
      }
    
  
    ,
      "planning-exercises-ex-3":  {
        "title": "Exercise 10.3",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Given the action schemas and initial statefrom Figure airport-pddl-algorithm, what are all theapplicable concrete instances of ${Fly}(p,{from},{to})$ in thestate described by$$At(P_1,JFK) land At(P_2,SFO) land Plane(P_1) land Plane(P_2) land Airport(JFK) land Airport(SFO)?$$",
        "url": " /planning-exercises/ex_3/"
      }
    
  
    ,
      "planning-exercises-ex-4":  {
        "title": "Exercise 10.4",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "The monkey-and-bananas problem is faced by a monkey in a laboratory withsome bananas hanging out of reach from the ceiling. A box is availablethat will enable the monkey to reach the bananas if he climbs on it.Initially, the monkey is at $A$, the bananas at $B$, and the box at $C$.The monkey and box have height ${Low}$, but if the monkey climbs ontothe box he will have height ${High}$, the same as the bananas. Theactions available to the monkey include ${Go}$ from one place toanother, ${Push}$ an object from one place to another, ${ClimbUp}$onto or ${ClimbDown}$ from an object, and ${Grasp}$ or ${Ungrasp}$an object. The result of a ${Grasp}$ is that the monkey holds theobject if the monkey and object are in the same place at the sameheight.1.  Write down the initial state description.2.  Write the six action schemas.3.  Suppose the monkey wants to fool the scientists, who are off to tea,    by grabbing the bananas, but leaving the box in its original place.    Write this as a general goal (i.e., not assuming that the box is    necessarily at C) in the language of situation calculus. Can this    goal be solved by a classical planning system?4.  Your schema for pushing is probably incorrect, because if the object    is too heavy, its position will remain the same when the ${Push}$    schema is applied. Fix your action schema to account for    heavy objects.",
        "url": " /planning-exercises/ex_4/"
      }
    
  
    ,
      "planning-exercises-ex-5":  {
        "title": "Exercise 10.5",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "The original {Strips} planner was designed to control Shakey the robot.Figure shakey-figure shows a version of Shakey’s worldconsisting of four rooms lined up along a corridor, where each room hasa door and a light switch. The actions in Shakey’s world include moving from place to place,pushing movable objects (such as boxes), climbing onto and down fromrigid objects (such as boxes), and turning light switches on and off.The robot itself could not climb on a box or toggle a switch, but theplanner was capable of finding and printing out plans that were beyondthe robot’s abilities. Shakey’s six actions are the following:-   ${Go}(x,y,r)$, which requires that Shakey be ${At}$ $x$ and that    $x$ and $y$ are locations ${In}$ the same room $r$. By convention    a door between two rooms is in both of them.-   Push a box $b$ from location $x$ to location $y$ within the same    room: ${Push}(b,x,y,r)$. You will need the predicate ${Box}$ and    constants for the boxes.-   Climb onto a box from position $x$: ${ClimbUp}(x, b)$; climb down    from a box to position $x$: ${ClimbDown}(b, x)$. We will need the    predicate ${On}$ and the constant ${Floor}$.-   Turn a light switch on or off: ${TurnOn}(s,b)$;    ${TurnOff}(s,b)$. To turn a light on or off, Shakey must be on top    of a box at the light switch’s location.Write PDDL sentences for Shakey’s six actions and the initial state fromConstruct a plan for Shakey toget ${Box}{}_2$ into ${Room}{}_2$.          Shakey&#39;s world. Shakey can move between landmarks within a room, can pass through the door between rooms, can climb climbable objects and push pushable objects, and can flip light switches.  ",
        "url": " /planning-exercises/ex_5/"
      }
    
  
    ,
      "planning-exercises-ex-2":  {
        "title": "Exercise 10.2",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Describe the differences and similarities between problem solving andplanning.",
        "url": " /planning-exercises/ex_2/"
      }
    
  
    ,
      "planning-exercises-ex-15":  {
        "title": "Exercise 10.15",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "We contrasted forward and backward state-space searchers withpartial-order planners, saying that the latter is a plan-space searcher.Explain how forward and backward state-space search can also beconsidered plan-space searchers, and say what the plan refinementoperators are.",
        "url": " /planning-exercises/ex_15/"
      }
    
  
    ,
      "planning-exercises-ex-12":  {
        "title": "Exercise 10.12",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "We saw that planning graphs can handle only propositional actions. Whatif we want to use planning graphs for a problem with variables in thegoal, such as ${At}(P_{1}, x)    land {At}(P_{2}, x)$, where $x$ is assumed to be bound by anexistential quantifier that ranges over a finite domain of locations?How could you encode such a problem to work with planning graphs?",
        "url": " /planning-exercises/ex_12/"
      }
    
  
    ,
      "planning-exercises-ex-13":  {
        "title": "Exercise 10.13",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "The set-level heuristic (see page set-level-page uses a planning graphto estimate the cost of achieving a conjunctive goal from the currentstate. What relaxed problem is the set-level heuristic the solution to?",
        "url": " /planning-exercises/ex_13/"
      }
    
  
    ,
      "planning-exercises-ex-14":  {
        "title": "Exercise 10.14",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Examine the definition of bidirectional search in Chapter search-chapter.1.  Would bidirectional state-space search be a good idea for planning?2.  What about bidirectional search in the space of partial-order plans?3.  Devise a version of partial-order planning in which an action can be    added to a plan if its preconditions can be achieved by the effects    of actions already in the plan. Explain how to deal with conflicts    and ordering constraints. Is the algorithm essentially identical to    forward state-space search?",
        "url": " /planning-exercises/ex_14/"
      }
    
  
    ,
      "planning-exercises-ex-9":  {
        "title": "Exercise 10.9",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Prove that backward search with PDDL problems is complete.",
        "url": " /planning-exercises/ex_9/"
      }
    
  
    ,
      "planning-exercises-ex-7":  {
        "title": "Exercise 10.7",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Explain why dropping negative effects fromevery action schema results in a relaxed problem, provided thatpreconditions and goals contain only positive literals.",
        "url": " /planning-exercises/ex_7/"
      }
    
  
    ,
      "planning-exercises-ex-1":  {
        "title": "Exercise 10.1",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Consider a robot whose operation is described by the following PDDLoperators:$$Op({Go(x,y)},{At(Robot,x)},{lnot At(Robot,x) land At(Robot,y)})$$$$Op({Pick(o)},{At(Robot,x)land At(o,x)},{lnot At(o,x) land Holding(o)})$$$$Op({Drop(o)},{At(Robot,x)land Holding(o)},{At(o,x) land lnot Holding(o)}$$1.  The operators allow the robot to hold more than one object. Show how    to modify them with an $EmptyHand$ predicate for a robot that can    hold only one object.2.  Assuming that these are the only actions in the world, write a    successor-state axiom for $EmptyHand$.",
        "url": " /planning-exercises/ex_1/"
      }
    
  
    ,
      "planning-exercises-ex-6":  {
        "title": "Exercise 10.6",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "A finite Turing machine has a finite one-dimensional tape of cells, eachcell containing one of a finite number of symbols. One cell has a readand write head above it. There is a finite set of states the machine canbe in, one of which is the accept state. At each time step, depending onthe symbol on the cell under the head and the machine’s current state,there are a set of actions we can choose from. Each action involveswriting a symbol to the cell under the head, transitioning the machineto a state, and optionally moving the head left or right. The mappingthat determines which actions are allowed is the Turing machine’sprogram. Your goal is to control the machine into the accept state.Represent the Turing machine acceptance problem as a planning problem.If you can do this, it demonstrates that determining whether a planningproblem has a solution is at least as hard as the Turing acceptanceproblem, which is PSPACE-hard.",
        "url": " /planning-exercises/ex_6/"
      }
    
  
    ,
      "planning-exercises-ex-8":  {
        "title": "Exercise 10.8",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Figure sussman-anomaly-figure(page sussman-anomaly-figure) shows a blocks-world problem that is known as the {Sussman anomaly}.The problem was considered anomalous because the noninterleaved plannersof the early 1970s could not solve it. Write a definition of the problemand solve it, either by hand or with a planning program. Anoninterleaved planner is a planner that, when given two subgoals$G_{1}$ and $G_{2}$, produces either a plan for $G_{1}$ concatenatedwith a plan for $G_{2}$, or vice versa. Can a noninterleaved plannersolve this problem? How, or why not?",
        "url": " /planning-exercises/ex_8/"
      }
    
  
    
  
    ,
      "robotics-exercises-ex-11":  {
        "title": "Exercise 25.11",
        "breadcrumb": "25-Robotics",
      	"content"  : "In Figure Fig5(b) onpage Fig5, we encountered an augmented finite state machine forthe control of a single leg of a hexapod robot. In this exercise, theaim is to design an AFSM that, when combined with six copies of theindividual leg controllers, results in efficient, stable locomotion. Forthis purpose, you have to augment the individual leg controller to passmessages to your new AFSM and to wait until other messages arrive. Arguewhy your controller is efficient, in that it does not unnecessarilywaste energy (e.g., by sliding legs), and in that it propels the robotat reasonably high speeds. Prove that your controller satisfies thedynamic stability condition given on page polygon-stability-condition-page.",
        "url": " /robotics-exercises/ex_11/"
      }
    
  
    ,
      "robotics-exercises-ex-10":  {
        "title": "Exercise 25.10",
        "breadcrumb": "25-Robotics",
      	"content"  : "Consider the simplified robot shown inFigure FigEx3. Suppose the robot’s Cartesiancoordinates are known at all times, as are those of its goal location.However, the locations of the obstacles are unknown. The robot can senseobstacles in its immediate proximity, as illustrated in this figure. Forsimplicity, let us assume the robot’s motion is noise-free, and thestate space is discrete. Figure FigEx3 is only oneexample; in this exercise you are required to address all possible gridworlds with a valid path from the start to the goal location.1.  Design a deliberate controller that guarantees that the robot always    reaches its goal location if at all possible. The deliberate    controller can memorize measurements in the form of a map that is    being acquired as the robot moves. Between individual moves, it may    spend arbitrary time deliberating.2.  Now design a reactive controller for the same task.    This controller may not memorize past sensor measurements. (It may    not build a map!) Instead, it has to make all decisions based on the    current measurement, which includes knowledge of its own location    and that of the goal. The time to make a decision must be    independent of the environment size or the number of past    time steps. What is the maximum number of steps that it may take for    your robot to arrive at the goal?3.  How will your controllers from (a) and (b) perform if any of the    following six conditions apply: continuous state space, noise in    perception, noise in motion, noise in both perception and motion,    unknown location of the goal (the goal can be detected only when    within sensor range), or moving obstacles. For each condition and    each controller, give an example of a situation where the robot    fails (or explain why it cannot fail).",
        "url": " /robotics-exercises/ex_10/"
      }
    
  
    ,
      "robotics-exercises-ex-3":  {
        "title": "Exercise 25.3",
        "breadcrumb": "25-Robotics",
      	"content"  : "Consider a robot with two simple manipulators, asshown in figure figRobot2. Manipulator A is a square block of side 2which can slide back and on a rod that runs along the x-axis fromx=$-$10 to x=10. Manipulator B is a square block of side 2 which canslide back and on a rod that runs along the y-axis from y=-10 to y=10.The rods lie outside the plane of manipulation, so the rods do notinterfere with the movement of the blocks. A configuration is then apair ${langle}x,y{rangle}$ where $x$ is the x-coordinate of the centerof manipulator A and where $y$ is the y-coordinate of the center ofmanipulator B. Draw the configuration space for this robot, indicatingthe permitted and excluded zones.",
        "url": " /robotics-exercises/ex_3/"
      }
    
  
    ,
      "robotics-exercises-ex-4":  {
        "title": "Exercise 25.4",
        "breadcrumb": "25-Robotics",
      	"content"  : "Suppose that you are working with the robot inExercise AB-manipulator-ex and you are given theproblem of finding a path from the starting configuration offigure figRobot2 to the ending configuration. Consider a potentialfunction $$D(A, {Goal})^2 + D(B, {Goal})^2 + frac{1}{D(A, B)^2}$$where $D(A,B)$ is the distance between the closest points of A and B.1.  Show that hill climbing in this potential field will get stuck in a    local minimum.2.  Describe a potential field where hill climbing will solve this    particular problem. You need not work out the exact numerical    coefficients needed, just the general form of the solution. (Hint:    Add a term that “rewards&quot; the hill climber for moving A out of B’s    way, even in a case like this where this does not reduce the    distance from A to B in the above sense.)",
        "url": " /robotics-exercises/ex_4/"
      }
    
  
    ,
      "robotics-exercises-ex-5":  {
        "title": "Exercise 25.5",
        "breadcrumb": "25-Robotics",
      	"content"  : "Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is60cm long and that its upper arm and forearm are each 40cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?",
        "url": " /robotics-exercises/ex_5/"
      }
    
  
    ,
      "robotics-exercises-ex-2":  {
        "title": "Exercise 25.2",
        "breadcrumb": "25-Robotics",
      	"content"  : "Implement Monte Carlo localization for asimulated robot with range sensors. A grid map and range data areavailable from the code repository ataima.cs.berkeley.edu. You should demonstratesuccessful global localization of the robot.    A Robot manipulator in two of its possible configurations.",
        "url": " /robotics-exercises/ex_2/"
      }
    
  
    ,
      "robotics-exercises-ex-12":  {
        "title": "Exercise 25.12",
        "breadcrumb": "25-Robotics",
      	"content"  : "(This exercise was first devised by MichaelGenesereth and Nils Nilsson. It works for first graders through graduatestudents.) Humans are so adept at basic household tasks that they oftenforget how complex these tasks are. In this exercise you will discoverthe complexity and recapitulate the last 30 years of developments inrobotics. Consider the task of building an arch out of three blocks.Simulate a robot with four humans as follows:Brain. The Brain direct the hands in the execution of aplan to achieve the goal. The Brain receives input from the Eyes, butcannot see the scene directly. The brain is the only onewho knows what the goal is.Eyes. The Eyes report a brief description of the sceneto the Brain: “There is a red box standing on top of a green box, whichis on its side” Eyes can also answer questions from the Brain such as,“Is there a gap between the Left Hand and the red box?” If you have avideo camera, point it at the scene and allow the eyes to look at theviewfinder of the video camera, but not directly at the scene.Left hand and right hand. One personplays each Hand. The two Hands stand next to each other, each wearing anoven mitt on one hand, Hands execute only simple commands from theBrain—for example, “Left Hand, move two inches forward.” They cannotexecute commands other than motions; for example, they cannot becommanded to “Pick up the box.” The Hands must beblindfolded. The only sensory capability they have is theability to tell when their path is blocked by an immovable obstacle suchas a table or the other Hand. In such cases, they can beep to inform theBrain of the difficulty.",
        "url": " /robotics-exercises/ex_12/"
      }
    
  
    ,
      "robotics-exercises-ex-9":  {
        "title": "Exercise 25.9",
        "breadcrumb": "25-Robotics",
      	"content"  : "Consider a mobile robot moving on a horizontal surface. Suppose that therobot can execute two kinds of motions:-   Rolling forward a specified distance.-   Rotating in place through a specified angle.The state of such a robot can be characterized in terms of threeparameters ${langle}x,y,phi$, the x-coordinate and y-coordinate of therobot (more precisely, of its center of rotation) and the robot’sorientation expressed as the angle from the positive x direction. Theaction “$Roll(D)$” has the effect of changing state ${langle}x,y,phi$to ${langle}x+D cos(phi), y+D sin(phi), phi {rangle}$, and theaction $Rotate(theta)$ has the effect of changing state${langle}x,y,phi {rangle}$ to${langle}x,y, phi + theta {rangle}$.1.  Suppose that the robot is initially at ${langle}0,0,0 {rangle}$    and then executes the actions $Rotate(60^{circ})$, $Roll(1)$,    $Rotate(25^{circ})$, $Roll(2)$. What is the final state of the    robot?2.  Now suppose that the robot has imperfect control of its own    rotation, and that, if it attempts to rotate by $theta$, it may    actually rotate by any angle between $theta-10^{circ}$ and    $theta+10^{circ}$. In that case, if the robot attempts to carry    out the sequence of actions in (A), there is a range of possible    ending states. What are the minimal and maximal values of the    x-coordinate, the y-coordinate and the orientation in the final    state?3.  Let us modify the model in (B) to a probabilistic model in which,    when the robot attempts to rotate by $theta$, its actual angle of    rotation follows a Gaussian distribution with mean $theta$ and    standard deviation $10^{circ}$. Suppose that the robot executes the    actions $Rotate(90^{circ})$, $Roll(1)$. Give a simple argument    that (a) the expected value of the location at the end is not equal    to the result of rotating exactly $90^{circ}$ and then rolling    forward 1 unit, and (b) that the distribution of locations at the    end does not follow a Gaussian. (Do not attempt to calculate the    true mean or the true distribution.)    The point of this exercise is that rotational uncertainty quickly    gives rise to a lot of positional uncertainty and that dealing with    rotational uncertainty is painful, whether uncertainty is treated in    terms of hard intervals or probabilistically, due to the fact that    the relation between orientation and position is both non-linear    and non-monotonic.      Simplified robot in a maze. See Exercise robot-exploration-exercise",
        "url": " /robotics-exercises/ex_9/"
      }
    
  
    ,
      "robotics-exercises-ex-7":  {
        "title": "Exercise 25.7",
        "breadcrumb": "25-Robotics",
      	"content"  : "Implement an algorithm for calculating the Voronoidiagram of an arbitrary 2D environment, described by an $ntimes n$Boolean array. Illustrate your algorithm by plotting the Voronoi diagramfor 10 interesting maps. What is the complexity of your algorithm?",
        "url": " /robotics-exercises/ex_7/"
      }
    
  
    ,
      "robotics-exercises-ex-1":  {
        "title": "Exercise 25.1",
        "breadcrumb": "25-Robotics",
      	"content"  : "Monte Carlo localization isbiased for any finite sample size—i.e., the expectedvalue of the location computed by the algorithm differs from the trueexpected value—because of the way particle filtering works. In thisquestion, you are asked to quantify this bias.To simplify, consider a world with four possible robot locations:$X={x_1,x_2,x_3,x_4}$. Initially, wedraw $Ngeq $ samples uniformly from among those locations. Asusual, it is perfectly acceptable if more than one sample is generatedfor any of the locations $X$. Let $Z$ be a Boolean sensor variablecharacterized by the following conditional probabilities:$$begin{aligned}P(z | x_1) = 0.8 qquadqquad P(z | x_1) = 0.2  P(z | x_2) = 0.4 qquadqquad P(z | x_2) = 0.6  P(z | x_3) = 0.1 qquadqquad P(z | x_3) = 0.9  P(z | x_4) = 0.1 qquadqquad P(z | x_4) = 0.9 end{aligned}$$MCL uses these probabilities to generate particle weights, which aresubsequently normalized and used in the resampling process. Forsimplicity, let us assume we generate only one new sample in theresampling process, regardless of $N$. This sample might correspond toany of the four locations in $X$. Thus, the sampling process defines aprobability distribution over $X$.1.  What is the resulting probability distribution over $X$ for this new    sample? Answer this question separately for    $N=1,ldots,10$, and for $N=infty$.2.  The difference between two probability distributions $P$ and $Q$ can    be measured by the KL divergence, which is defined as    $${KL}(P,Q) = sum_i P(x_i)logfrac{P(x_i)}{Q(x_i)} .$$ What are    the KL divergences between the distributions in (a) and the true    posterior?3.  What modification of the problem formulation (not the algorithm!)    would guarantee that the specific estimator above is unbiased even    for finite values of $N$? Provide at least two such modifications    (each of which should be sufficient).",
        "url": " /robotics-exercises/ex_1/"
      }
    
  
    ,
      "robotics-exercises-ex-6":  {
        "title": "Exercise 25.6",
        "breadcrumb": "25-Robotics",
      	"content"  : "Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is70cm long and that its upper arm and forearm are each 50cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?",
        "url": " /robotics-exercises/ex_6/"
      }
    
  
    ,
      "robotics-exercises-ex-8":  {
        "title": "Exercise 25.8",
        "breadcrumb": "25-Robotics",
      	"content"  : "This exercise explores the relationship betweenworkspace and configuration space using the examples shown inFigure FigEx2.1.  Consider the robot configurations shown in    Figure FigEx2(a) through (c), ignoring the obstacle    shown in each of the diagrams. Draw the corresponding arm    configurations in configuration space. (Hint: Each    arm configuration maps to a single point in configuration space, as    illustrated in Figure FigArm1(b).)2.  Draw the configuration space for each of the workspace diagrams in    Figure FigEx2(a)–(c). (Hint: The    configuration spaces share with the one shown in    Figure FigEx2(a) the region that corresponds to    self-collision, but differences arise from the lack of enclosing    obstacles and the different locations of the obstacles in these    individual figures.)3.  For each of the black dots in Figure FigEx2(e)–(f),    draw the corresponding configurations of the robot arm in workspace.    Please ignore the shaded regions in this exercise.4.  The configuration spaces shown in    Figure FigEx2(e)–(f) have all been generated by a    single workspace obstacle (dark shading), plus the constraints    arising from the self-collision constraint (light shading). Draw,    for each diagram, the workspace obstacle that corresponds to the    darkly shaded area.5.  Figure FigEx2(d) illustrates that a single planar    obstacle can decompose the workspace into two disconnected regions.    What is the maximum number of disconnected regions that can be    created by inserting a planar obstacle into an obstacle-free,    connected workspace, for a 2DOF robot? Give an example, and argue    why no larger number of disconnected regions can be created. How    about a non-planar obstacle?                (a)                    (b)                    (c)                    (d)                    (e)                    (f)    ",
        "url": " /robotics-exercises/ex_8/"
      }
    
  
    
  
    ,
      "intro-exercises-ex-11":  {
        "title": "Exercise 1.11",
        "breadcrumb": "1-Introduction",
      	"content"  : "Many of the computational models of cognitive activities that have beenproposed involve quite complex mathematical operations, such asconvolving an image with a Gaussian or finding a minimum of the entropyfunction. Most humans (and certainly all animals) never learn this kindof mathematics at all, almost no one learns it before college, andalmost no one can compute the convolution of a function with a Gaussianin their head. What sense does it make to say that the “vision system”is doing this kind of mathematics, whereas the actual person has no ideahow to do it?",
        "url": " /intro-exercises/ex_11/"
      }
    
  
    ,
      "intro-exercises-ex-16":  {
        "title": "Exercise 1.16",
        "breadcrumb": "1-Introduction",
      	"content"  : "“Surely animals cannot be intelligent—they can do only what their genestell them.” Is the latter statement true, and does it imply the former?",
        "url": " /intro-exercises/ex_16/"
      }
    
  
    ,
      "intro-exercises-ex-20":  {
        "title": "Exercise 1.20",
        "breadcrumb": "1-Introduction",
      	"content"  : "Various subfields of AI have held contests by defining a standard taskand inviting researchers to do their best. Examples include the DARPAGrand Challenge for robotic cars, the International PlanningCompetition, the Robocup robotic soccer league, the TREC informationretrieval event, and contests in machine translation and speechrecognition. Investigate five of these contests and describe theprogress made over the years. To what degree have the contests advancedthe state of the art in AI? To what degree do they hurt the field bydrawing energy away from new ideas?",
        "url": " /intro-exercises/ex_20/"
      }
    
  
    ,
      "intro-exercises-ex-18":  {
        "title": "Exercise 1.18",
        "breadcrumb": "1-Introduction",
      	"content"  : "Examine the AI literature to discover whether the following tasks cancurrently be solved by computers:- Playing a decent game of table tennis (Ping-Pong).- Driving in the center of Cairo, Egypt.- Driving in Victorville, California.- Buying a week’s worth of groceries at the market.- Buying a week’s worth of groceries on the Web.- Playing a decent game of bridge at a competitive level.- Discovering and proving new mathematical theorems.- Writing an intentionally funny story.- Giving competent legal advice in a specialized area of law.- Translating spoken English into spoken Swedish in real time.- Performing a complex surgical operation.",
        "url": " /intro-exercises/ex_18/"
      }
    
  
    ,
      "intro-exercises-ex-19":  {
        "title": "Exercise 1.19",
        "breadcrumb": "1-Introduction",
      	"content"  : "For the currently infeasible tasks, try to find out what thedifficulties are and predict when, if ever, they will be overcome.",
        "url": " /intro-exercises/ex_19/"
      }
    
  
    ,
      "intro-exercises-ex-17":  {
        "title": "Exercise 1.17",
        "breadcrumb": "1-Introduction",
      	"content"  : "“Surely animals, humans, and computers cannot be intelligent—they can doonly what their constituent atoms are told to do by the laws ofphysics.” Is the latter statement true, and does it imply the former?",
        "url": " /intro-exercises/ex_17/"
      }
    
  
    ,
      "intro-exercises-ex-10":  {
        "title": "Exercise 1.10",
        "breadcrumb": "1-Introduction",
      	"content"  : "To what extent are the following computer systems instances ofartificial intelligence:- Supermarket bar code scanners.- Voice-activated telephone menus.- Spelling and grammar correction features in Microsoft Word.- Internet routing algorithms that respond dynamically to the state of the network.",
        "url": " /intro-exercises/ex_10/"
      }
    
  
    ,
      "intro-exercises-ex-3":  {
        "title": "Exercise 1.3",
        "breadcrumb": "1-Introduction",
      	"content"  : "Every year the Loebner Prize is awarded to the program that comesclosest to passing a version of the Turing Test. Research and report onthe latest winner of the Loebner prize. What techniques does it use? Howdoes it advance the state of the art in AI?",
        "url": " /intro-exercises/ex_3/"
      }
    
  
    ,
      "intro-exercises-ex-4":  {
        "title": "Exercise 1.4",
        "breadcrumb": "1-Introduction",
      	"content"  : "Are reflex actions (such as flinching from a hot stove) rational? Arethey intelligent?",
        "url": " /intro-exercises/ex_4/"
      }
    
  
    ,
      "intro-exercises-ex-5":  {
        "title": "Exercise 1.5",
        "breadcrumb": "1-Introduction",
      	"content"  : "There are well-known classes of problems that are intractably difficultfor computers, and other classes that are provably undecidable. Doesthis mean that AI is impossible?",
        "url": " /intro-exercises/ex_5/"
      }
    
  
    ,
      "intro-exercises-ex-2":  {
        "title": "Exercise 1.2",
        "breadcrumb": "1-Introduction",
      	"content"  : "Read Turing’s original paper on AI Turing:1950 .In the paper, he discusses several objections to his proposed enterprise and his test forintelligence. Which objections still carry weight? Are his refutationsvalid? Can you think of new objections arising from developments sincehe wrote the paper? In the paper, he predicts that, by the year 2000, acomputer will have a 30% chance of passing a five-minute Turing Testwith an unskilled interrogator. What chance do you think a computerwould have today? In another 50 years?",
        "url": " /intro-exercises/ex_2/"
      }
    
  
    ,
      "intro-exercises-ex-15":  {
        "title": "Exercise 1.15",
        "breadcrumb": "1-Introduction",
      	"content"  : "“Surely computers cannot be intelligent—they can do only what theirprogrammers tell them.” Is the latter statement true, and does it implythe former?",
        "url": " /intro-exercises/ex_15/"
      }
    
  
    ,
      "intro-exercises-ex-12":  {
        "title": "Exercise 1.12",
        "breadcrumb": "1-Introduction",
      	"content"  : "Some authors have claimed that perception and motor skills are the mostimportant part of intelligence, and that “higher level” capacities arenecessarily parasitic—simple add-ons to these underlying facilities.Certainly, most of evolution and a large part of the brain have beendevoted to perception and motor skills, whereas AI has found tasks suchas game playing and logical inference to be easier, in many ways, thanperceiving and acting in the real world. Do you think that AI’straditional focus on higher-level cognitive abilities is misplaced?",
        "url": " /intro-exercises/ex_12/"
      }
    
  
    ,
      "intro-exercises-ex-13":  {
        "title": "Exercise 1.13",
        "breadcrumb": "1-Introduction",
      	"content"  : "Why would evolution tend to result in systems that act rationally? Whatgoals are such systems designed to achieve?",
        "url": " /intro-exercises/ex_13/"
      }
    
  
    ,
      "intro-exercises-ex-14":  {
        "title": "Exercise 1.14",
        "breadcrumb": "1-Introduction",
      	"content"  : "Is AI a science, or is it engineering? Or neither or both? Explain.",
        "url": " /intro-exercises/ex_14/"
      }
    
  
    ,
      "intro-exercises-ex-9":  {
        "title": "Exercise 1.9",
        "breadcrumb": "1-Introduction",
      	"content"  : "To what extent are the following computer systems instances ofartificial intelligence:-   Supermarket bar code scanners.-   Web search engines.-   Voice-activated telephone menus.-   Internet routing algorithms that respond dynamically to the state of    the network.",
        "url": " /intro-exercises/ex_9/"
      }
    
  
    ,
      "intro-exercises-ex-7":  {
        "title": "Exercise 1.7",
        "breadcrumb": "1-Introduction",
      	"content"  : "The neural structure of the sea slug Aplysis has beenwidely studied (first by Nobel Laureate Eric Kandel) because it has onlyabout 20,000 neurons, most of them large and easily manipulated.Assuming that the cycle time for an Aplysis neuron isroughly the same as for a human neuron, how does the computationalpower, in terms of memory updates per second, compare with the high-endcomputer described in (Figure computer-brain-table)?",
        "url": " /intro-exercises/ex_7/"
      }
    
  
    ,
      "intro-exercises-ex-1":  {
        "title": "Exercise 1.1",
        "breadcrumb": "1-Introduction",
      	"content"  : "Define in your own words: (a) intelligence, (b) artificial intelligence,(c) agent, (d) rationality, (e) logical reasoning.",
        "url": " /intro-exercises/ex_1/"
      }
    
  
    ,
      "intro-exercises-ex-6":  {
        "title": "Exercise 1.6",
        "breadcrumb": "1-Introduction",
      	"content"  : "Suppose we extend Evans’s SYSTEM program so that it can score 200 on a standardIQ test. Would we then have a program more intelligent than a human?Explain.",
        "url": " /intro-exercises/ex_6/"
      }
    
  
    ,
      "intro-exercises-ex-8":  {
        "title": "Exercise 1.8",
        "breadcrumb": "1-Introduction",
      	"content"  : "How could introspection—reporting on one’s inner thoughts—be inaccurate?Could I be wrong about what I’m thinking? Discuss.",
        "url": " /intro-exercises/ex_8/"
      }
    
  
    ,
      "intro-exercises":  {
        "title": "Introduction",
        "breadcrumb": "Introduction",
      	"content"  : "1. IntroductionThese exercises are intended to stimulate discussion, and some might beset as term projects. Alternatively, preliminary attempts can be madenow, and these attempts can be reviewed after the completion of thebook.            Exercise 1                                Define in your own words: (a) intelligence, (b) artificial intelligence,(c) agent, (d) rationality, (e) logical reasoning.                Exercise 2                                Read Turing’s original paper on AI Turing:1950 .In the paper, he discusses several objections to his proposed enterprise and his test forintelligence. Which objections still carry weight? Are his refutationsvalid? Can you think of new objections arising from developments sincehe wrote the paper? In the paper, he predicts that, by the year 2000, acomputer will have a 30% chance of passing a five-minute Turing Testwith an unskilled interrogator. What chance do you think a computerwould have today? In another 50 years?                Exercise 3                                Every year the Loebner Prize is awarded to the program that comesclosest to passing a version of the Turing Test. Research and report onthe latest winner of the Loebner prize. What techniques does it use? Howdoes it advance the state of the art in AI?                Exercise 4                                Are reflex actions (such as flinching from a hot stove) rational? Arethey intelligent?                Exercise 5                                There are well-known classes of problems that are intractably difficultfor computers, and other classes that are provably undecidable. Doesthis mean that AI is impossible?                Exercise 6                                Suppose we extend Evans’s SYSTEM program so that it can score 200 on a standardIQ test. Would we then have a program more intelligent than a human?Explain.                Exercise 7                                The neural structure of the sea slug Aplysis has beenwidely studied (first by Nobel Laureate Eric Kandel) because it has onlyabout 20,000 neurons, most of them large and easily manipulated.Assuming that the cycle time for an Aplysis neuron isroughly the same as for a human neuron, how does the computationalpower, in terms of memory updates per second, compare with the high-endcomputer described in (Figure computer-brain-table)?                Exercise 8                                How could introspection—reporting on one’s inner thoughts—be inaccurate?Could I be wrong about what I’m thinking? Discuss.                Exercise 9                                To what extent are the following computer systems instances ofartificial intelligence:-   Supermarket bar code scanners.-   Web search engines.-   Voice-activated telephone menus.-   Internet routing algorithms that respond dynamically to the state of    the network.                Exercise 10                                To what extent are the following computer systems instances ofartificial intelligence:- Supermarket bar code scanners.- Voice-activated telephone menus.- Spelling and grammar correction features in Microsoft Word.- Internet routing algorithms that respond dynamically to the state of the network.                Exercise 11                                Many of the computational models of cognitive activities that have beenproposed involve quite complex mathematical operations, such asconvolving an image with a Gaussian or finding a minimum of the entropyfunction. Most humans (and certainly all animals) never learn this kindof mathematics at all, almost no one learns it before college, andalmost no one can compute the convolution of a function with a Gaussianin their head. What sense does it make to say that the “vision system”is doing this kind of mathematics, whereas the actual person has no ideahow to do it?                Exercise 12                                Some authors have claimed that perception and motor skills are the mostimportant part of intelligence, and that “higher level” capacities arenecessarily parasitic—simple add-ons to these underlying facilities.Certainly, most of evolution and a large part of the brain have beendevoted to perception and motor skills, whereas AI has found tasks suchas game playing and logical inference to be easier, in many ways, thanperceiving and acting in the real world. Do you think that AI’straditional focus on higher-level cognitive abilities is misplaced?                Exercise 13                                Why would evolution tend to result in systems that act rationally? Whatgoals are such systems designed to achieve?                Exercise 14                                Is AI a science, or is it engineering? Or neither or both? Explain.                Exercise 15                                “Surely computers cannot be intelligent—they can do only what theirprogrammers tell them.” Is the latter statement true, and does it implythe former?                Exercise 16                                “Surely animals cannot be intelligent—they can do only what their genestell them.” Is the latter statement true, and does it imply the former?                Exercise 17                                “Surely animals, humans, and computers cannot be intelligent—they can doonly what their constituent atoms are told to do by the laws ofphysics.” Is the latter statement true, and does it imply the former?                Exercise 18                                Examine the AI literature to discover whether the following tasks cancurrently be solved by computers:- Playing a decent game of table tennis (Ping-Pong).- Driving in the center of Cairo, Egypt.- Driving in Victorville, California.- Buying a week’s worth of groceries at the market.- Buying a week’s worth of groceries on the Web.- Playing a decent game of bridge at a competitive level.- Discovering and proving new mathematical theorems.- Writing an intentionally funny story.- Giving competent legal advice in a specialized area of law.- Translating spoken English into spoken Swedish in real time.- Performing a complex surgical operation.                Exercise 19                                For the currently infeasible tasks, try to find out what thedifficulties are and predict when, if ever, they will be overcome.                Exercise 20                                Various subfields of AI have held contests by defining a standard taskand inviting researchers to do their best. Examples include the DARPAGrand Challenge for robotic cars, the International PlanningCompetition, the Robocup robotic soccer league, the TREC informationretrieval event, and contests in machine translation and speechrecognition. Investigate five of these contests and describe theprogress made over the years. To what degree have the contests advancedthe state of the art in AI? To what degree do they hurt the field bydrawing energy away from new ideas?    ",
        "url": " /intro-exercises/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-11":  {
        "title": "Exercise 7.11",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Using a method of your choice, verifyeach of the equivalences inTable logical-equivalence-table (page logical-equivalence-table).",
        "url": " /knowledge-logic-exercises/ex_11/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-16":  {
        "title": "Exercise 7.16",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "This exercise looks into the relationship betweenclauses and implication sentences.1.  Show that the clause $(lnot P_1 lor cdots lor lnot P_m lor Q)$    is logically equivalent to the implication sentence    $(P_1 land cdots land P_m) {;{Rightarrow};}Q$.2.  Show that every clause (regardless of the number of    positive literals) can be written in the form    $(P_1 land cdots land P_m) {;{Rightarrow};}(Q_1 lor cdots lor Q_n)$,    where the $P$s and $Q$s are proposition symbols. A knowledge base    consisting of such sentences is in implicative normal form or Kowalski    form Kowalski:1979.3.  Write down the full resolution rule for sentences in implicative    normal form.",
        "url": " /knowledge-logic-exercises/ex_16/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-29":  {
        "title": "Exercise 7.29",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "How long does it take to prove${KB}{models}alpha$ using {DPLL} when $alpha$ is a literal alreadycontained in ${KB}$? Explain.",
        "url": " /knowledge-logic-exercises/ex_29/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-20":  {
        "title": "Exercise 7.20",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Explain why every nonempty propositional clause, by itself, issatisfiable. Prove rigorously that every set of five 3-SAT clauses issatisfiable, provided that each clause mentions exactly three distinctvariables. What is the smallest set of such clauses that isunsatisfiable? Construct such a set.",
        "url": " /knowledge-logic-exercises/ex_20/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-27":  {
        "title": "Exercise 7.27",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Is a randomly generated 4-CNF sentence with $n$ symbols and $m$ clausesmore or less likely to be solvable than a randomly generated 3-CNFsentence with $n$ symbols and $m$ clauses? Explain.",
        "url": " /knowledge-logic-exercises/ex_27/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-18":  {
        "title": "Exercise 7.18",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "This question considers representing satisfiability (SAT) problems asCSPs.1.  Draw the constraint graph corresponding to the SAT problem    $$(lnot X_1 lor X_2) land (lnot X_2 lor X_3) land ldots land (lnot X_{n-1} lor X_n)$$    for the particular case $n5$.2.  How many solutions are there for this general SAT problem as a    function of $n$?3.  Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find all    solutions to a SAT CSP of the type given in (a). (To find    all solutions to a CSP, we simply modify the basic    algorithm so it continues searching after each solution is found.)    Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$    is ordered before ${true}$. How much time will the algorithm take    to terminate? (Write an $O(cdot)$ expression as a function of $n$.)4.  We know that SAT problems in Horn form can be solved in linear time    by forward chaining (unit propagation). We also know that every    tree-structured binary CSP with discrete, finite domains can be    solved in time linear in the number of variables    (Section csp-structure-section). Are these two    facts connected? Discuss.",
        "url": " /knowledge-logic-exercises/ex_18/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-26":  {
        "title": "Exercise 7.26",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Convert the following set of sentences toclausal form.1.  S1: $A {;;{Leftrightarrow};;}(B lor E)$.2.  S2: $E {:;{Rightarrow}:;}D$.3.  S3: $C land F {:;{Rightarrow}:;}lnot B$.4.  S4: $E {:;{Rightarrow}:;}B$.5.  S5: $B {:;{Rightarrow}:;}F$.6.  S6: $B {:;{Rightarrow}:;}C$Give a trace of the execution of DPLL on the conjunction of theseclauses.",
        "url": " /knowledge-logic-exercises/ex_26/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-19":  {
        "title": "Exercise 7.19",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "This question considers representing satisfiability (SAT) problems asCSPs.1.  Draw the constraint graph corresponding to the SAT problem    $$(lnot X_1 lor X_2) land (lnot X_2 lor X_3) land ldots land (lnot X_{n-1} lor X_n)$$    for the particular case $n4$.2.  How many solutions are there for this general SAT problem as a    function of $n$?3.  Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find all    solutions to a SAT CSP of the type given in (a). (To find    all solutions to a CSP, we simply modify the basic    algorithm so it continues searching after each solution is found.)    Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$    is ordered before ${true}$. How much time will the algorithm take    to terminate? (Write an $O(cdot)$ expression as a function of $n$.)4.  We know that SAT problems in Horn form can be solved in linear time    by forward chaining (unit propagation). We also know that every    tree-structured binary CSP with discrete, finite domains can be    solved in time linear in the number of variables    (Section csp-structure-section). Are these two    facts connected? Discuss.",
        "url": " /knowledge-logic-exercises/ex_19/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-21":  {
        "title": "Exercise 7.21",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "A propositional 2-CNF expression is a conjunction ofclauses, each containing exactly 2 literals, e.g.,$$(Alor B) land (lnot A lor C) land (lnot B lor D) land (lnot  C lor G) land (lnot D lor G) .$$1.  Prove using resolution that the above sentence entails $G$.2.  Two clauses are semantically distinct if they are not    logically equivalent. How many semantically distinct 2-CNF clauses    can be constructed from $n$ proposition symbols?3.  Using your answer to (b), prove that propositional resolution always    terminates in time polynomial in $n$ given a 2-CNF sentence    containing no more than $n$ distinct symbols.4.  Explain why your argument in (c) does not apply to 3-CNF.",
        "url": " /knowledge-logic-exercises/ex_21/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-17":  {
        "title": "Exercise 7.17",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "According to some political pundits, a person who is radical ($R$) iselectable ($E$) if he/she is conservative ($C$), but otherwise is notelectable.1.  Which of the following are correct representations of this    assertion?    1.  $(Rland E)iff C$    2.  $R{:;{Rightarrow}:;}(Eiff C)$    3.  $R{:;{Rightarrow}:;}((C{:;{Rightarrow}:;}E) lor lnot E)$2.  Which of the sentences in (a) can be expressed in Horn form?",
        "url": " /knowledge-logic-exercises/ex_17/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-28":  {
        "title": "Exercise 7.28",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Minesweeper, the well-known computer game, isclosely related to the wumpus world. A minesweeper world isa rectangular grid of $N$ squares with $M$ invisible mines scatteredamong them. Any square may be probed by the agent; instant death followsif a mine is probed. Minesweeper indicates the presence of mines byrevealing, in each probed square, the number of minesthat are directly or diagonally adjacent. The goal is to probe everyunmined square.1.  Let $X_{i,j}$ be true iff square $[i,j]$ contains a mine. Write down    the assertion that exactly two mines are adjacent to [1,1] as a    sentence involving some logical combination of    $X_{i,j}$ propositions.2.  Generalize your assertion from (a) by explaining how to construct a    CNF sentence asserting that $k$ of $n$ neighbors contain mines.3.  Explain precisely how an agent can use {DPLL} to prove that a given square    does (or does not) contain a mine, ignoring the global constraint    that there are exactly $M$ mines in all.4.  Suppose that the global constraint is constructed from your method    from part (b). How does the number of clauses depend on $M$ and $N$?    Suggest a way to modify {DPLL} so that the global constraint does not need    to be represented explicitly.5.  Are any conclusions derived by the method in part (c) invalidated    when the global constraint is taken into account?6.  Give examples of configurations of probe values that induce    long-range dependencies such that the contents of a    given unprobed square would give information about the contents of a    far-distant square. (Hint: consider an    $Ntimes 1$ board.)",
        "url": " /knowledge-logic-exercises/ex_28/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-10":  {
        "title": "Exercise 7.10",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "We have defined four binary logical connectives.1.  Are there any others that might be useful?2.  How many binary connectives can there be?3.  Why are some of them not very useful?",
        "url": " /knowledge-logic-exercises/ex_10/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-32":  {
        "title": "Exercise 7.32",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Discuss what is meant by optimal behavior in the wumpusworld. Show that the {Hybrid-Wumpus-Agent} is not optimal, and suggest ways to improve it.",
        "url": " /knowledge-logic-exercises/ex_32/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-35":  {
        "title": "Exercise 7.35",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Modify the {Hybrid-Wumpus-Agent} to use the 1-CNF logical stateestimation method described on page 1cnf-belief-state-page. We noted on that pagethat such an agent will not be able to acquire, maintain, and use morecomplex beliefs such as the disjunction $P_{3,1}lor P_{2,2}$. Suggest amethod for overcoming this problem by defining additional propositionsymbols, and try it out in the wumpus world. Does it improve theperformance of the agent?",
        "url": " /knowledge-logic-exercises/ex_35/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-3":  {
        "title": "Exercise 7.3",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Consider the problem of deciding whether apropositional logic sentence is true in a given model.1.  Write a recursive algorithm PL-True?$ (s, m )$ that returns ${true}$ if and    only if the sentence $s$ is true in the model $m$ (where $m$ assigns    a truth value for every symbol in $s$). The algorithm should run in    time linear in the size of the sentence. (Alternatively, use a    version of this function from the online code repository.)2.  Give three examples of sentences that can be determined to be true    or false in a partial model that does not specify a    truth value for some of the symbols.3.  Show that the truth value (if any) of a sentence in a partial model    cannot be determined efficiently in general.4.  Modify your algorithm so that it can sometimes judge truth from    partial models, while retaining its recursive structure and linear    run time. Give three examples of sentences whose truth in a partial    model is not detected by your algorithm.5.  Investigate whether the modified algorithm makes $TT-Entails?$ more efficient.",
        "url": " /knowledge-logic-exercises/ex_3/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-4":  {
        "title": "Exercise 7.4",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Which of the following are correct?1.  ${False} models {True}$.2.  ${True} models {False}$.3.  $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.4.  $A{;;{Leftrightarrow};;}B models A lor B$.5.  $A{;;{Leftrightarrow};;}B models lnot A lor B$.6.  $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.7.  $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.8.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B)$.9.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.10. $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.11. $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$    is satisfiable.12. $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ has    the same number of models as $(A{;;{Leftrightarrow};;}B)$ for    any fixed set of proposition symbols that includes $A$, $B$, $C$.",
        "url": " /knowledge-logic-exercises/ex_4/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-34":  {
        "title": "Exercise 7.34",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Section successor-state-sectionprovides some of the successor-state axioms required for the wumpusworld. Write down axioms for all remaining fluent symbols.",
        "url": " /knowledge-logic-exercises/ex_34/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-33":  {
        "title": "Exercise 7.33",
        "breadcrumb": "7-logical-Agents",
      	"content"  : "Suppose an agent inhabits a world with two states, $S$ and $lnot S$,and can do exactly one of two actions, $a$ and $b$. Action $a$ doesnothing and action $b$ flips from one state to the other. Let $S^t$ bethe proposition that the agent is in state $S$ at time $t$, and let$a^t$ be the proposition that the agent does action $a$ at time $t$(similarly for $b^t$).1.  Write a successor-state axiom for $S^{t+1}$.2.  Convert the sentence in (a) into CNF.3.  Show a resolution refutation proof that if the agent is in $lnot S$    at time $t$ and does $a$, it will still be in $lnot S$ at time    $t+1$.",
        "url": " /knowledge-logic-exercises/ex_33/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-5":  {
        "title": "Exercise 7.5",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Which of the following are correct?1.  ${False} models {True}$.2.  ${True} models {False}$.3.  $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.4.  $A{;;{Leftrightarrow};;}B models A lor B$.5.  $A{;;{Leftrightarrow};;}B models lnot A lor B$.6.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor Blor C) land (Bland Cland D{:;{Rightarrow}:;}E)$.7.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.8.  $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.9.  $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.10. $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.11. $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$    is satisfiable.12. $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ has    the same number of models as $(A{;;{Leftrightarrow};;}B)$ for    any fixed set of proposition symbols that includes $A$, $B$, $C$.",
        "url": " /knowledge-logic-exercises/ex_5/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-2":  {
        "title": "Exercise 7.2",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "(Adapted from Barwise+Etchemendy:1993 .) Given the following, can you prove that the unicorn ismythical? How about magical? Horned?Note: If the unicorn is mythical, then it is immortal, but if it is not mythical, then it is a mortal mammal. If the unicorn is either immortal or a mammal, then it is horned. The unicorn is magical if it is horned.",
        "url": " /knowledge-logic-exercises/ex_2/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-15":  {
        "title": "Exercise 7.15",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Use resolution to prove the sentence $lnot A land lnot B$ from theclauses in Exercise convert-clausal-exercise.",
        "url": " /knowledge-logic-exercises/ex_15/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-12":  {
        "title": "Exercise 7.12",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable logical-equivalence-table (page logical-equivalence-table).1.  ${Smoke} {:;{Rightarrow}:;}{Smoke}$2.  ${Smoke} {:;{Rightarrow}:;}{Fire}$3.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$4.  ${Smoke} lor {Fire} lor lnot {Fire}$5.  $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})            {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$6.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire}) $7.  ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$",
        "url": " /knowledge-logic-exercises/ex_12/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-24":  {
        "title": "Exercise 7.24",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "A sentence is in disjunctive normal form(DNF) if it is the disjunction ofconjunctions of literals. For example, the sentence$(A land B land lnot C) lor (lnot A land C) lor (B land lnot C)$is in DNF.1.  Any propositional logic sentence is logically equivalent to the    assertion that some possible world in which it would be true is in    fact the case. From this observation, prove that any sentence can be    written in DNF.2.  Construct an algorithm that converts any sentence in propositional    logic into DNF. (Hint: The algorithm is similar to    the algorithm for conversion to CNF iven in    Sectio pl-resolution-section.)3.  Construct a simple algorithm that takes as input a sentence in DNF    and returns a satisfying assignment if one exists, or reports that    no satisfying assignment exists.4.  Apply the algorithms in (b) and (c) to the following set of    sentences: $A {Rightarrow} B$ $B {Rightarrow} C$ $C {Rightarrow} A$5.  Since the algorithm in (b) is very similar to the algorithm for    conversion to CNF, and since the algorithm in (c) is much simpler    than any algorithm for solving a set of sentences in CNF, why is    this technique not used in automated reasoning?",
        "url": " /knowledge-logic-exercises/ex_24/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-23":  {
        "title": "Exercise 7.23",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Consider the following sentence:$$[ ({Food} {:;{Rightarrow}:;}{Party}) lor ({Drinks} {:;{Rightarrow}:;}{Party}) ] {:;{Rightarrow}:;}[ ( {Food} land {Drinks} )  {:;{Rightarrow}:;}{Party}] .$$1.  Determine, using enumeration, whether this sentence is valid,    satisfiable (but not valid), or unsatisfiable.2.  Convert the left-hand and right-hand sides of the main implication    into CNF, showing each step, and explain how the results confirm    your answer to (a).3.  Prove your answer to (a) using resolution.",
        "url": " /knowledge-logic-exercises/ex_23/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-22":  {
        "title": "Exercise 7.22",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Prove each of the following assertions:1.  Every pair of propositional clauses either has no resolvents, or all    their resolvents are logically equivalent.2.  There is no clause that, when resolved with itself, yields    (after factoring) the clause $(lnot P lor lnot Q)$.3.  If a propositional clause $C$ can be resolved with a copy of itself,    it must be logically equivalent to $ True $.",
        "url": " /knowledge-logic-exercises/ex_22/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-25":  {
        "title": "Exercise 7.25",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Convert the following set of sentences toclausal form.1.  S1: $A {;;{Leftrightarrow};;}(B lor E)$.2.  S2: $E {:;{Rightarrow}:;}D$.3.  S3: $C land F {:;{Rightarrow}:;}lnot B$.4.  S4: $E {:;{Rightarrow}:;}B$.5.  S5: $B {:;{Rightarrow}:;}F$.6.  S6: $B {:;{Rightarrow}:;}C$Give a trace of the execution of DPLL on the conjunction of theseclauses.",
        "url": " /knowledge-logic-exercises/ex_25/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-13":  {
        "title": "Exercise 7.13",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable logical-equivalence-table (page logical-equivalence-table).1.  ${Smoke} {:;{Rightarrow}:;}{Smoke}$2.  ${Smoke} {:;{Rightarrow}:;}{Fire}$3.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$4.  ${Smoke} lor {Fire} lor lnot {Fire}$5.  $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})            {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$6.  ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$7.  $({Big} land {Dumb}) lor lnot {Dumb}$",
        "url": " /knowledge-logic-exercises/ex_13/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-14":  {
        "title": "Exercise 7.14",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Any propositional logic sentence is logicallyequivalent to the assertion that each possible world in which it wouldbe false is not the case. From this observation, prove that any sentencecan be written in CNF.",
        "url": " /knowledge-logic-exercises/ex_14/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-9":  {
        "title": "Exercise 7.9",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Consider a vocabulary with only four propositions, $A$, $B$, $C$, and$D$. How many models are there for the following sentences?1.  $Blor C$.2.  $lnot Alor lnot B lor lnot C lor lnot D$.3.  $(A{:;{Rightarrow}:;}B) land A land lnot B land C land D$.",
        "url": " /knowledge-logic-exercises/ex_9/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-7":  {
        "title": "Exercise 7.7",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Prove, or find a counterexample to, each of the following assertions:1.  If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then    $(alphaland beta)modelsgamma$2.  If $(alphaland beta)modelsgamma$ then $alphamodelsgamma$ or    $betamodelsgamma$ (or both).3.  If $alphamodels (beta lor gamma)$ then $alpha models beta$    or $alpha models gamma$ (or both).",
        "url": " /knowledge-logic-exercises/ex_7/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-31":  {
        "title": "Exercise 7.31",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Write a successor-state axiom for the ${Locked}$ predicate, whichapplies to doors, assuming the only actions available are ${Lock}$ and${Unlock}$.",
        "url": " /knowledge-logic-exercises/ex_31/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-1":  {
        "title": "Exercise 7.1",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Suppose the agent has progressed to the point shown inFigure wumpus-seq35-figure(a), page wumpus-seq35-figure,having perceived nothing in [1,1], a breeze in [2,1], and a stenchin [1,2], and is now concerned with the contents of [1,3], [2,2],and [3,1]. Each of these can contain a pit, and at most one cancontain a wumpus. Following the example ofFigure wumpus-entailment-figure, construct the set ofpossible worlds. (You should find 32 of them.) Mark the worlds in whichthe KB is true and those in which each of the following sentences istrue:$alpha_2$ = “There is no pit in [2,2].”$alpha_3$ = “There is a wumpus in [1,3].”Hence show that ${KB} {models}alpha_2$ and${KB} {models}alpha_3$.",
        "url": " /knowledge-logic-exercises/ex_1/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-6":  {
        "title": "Exercise 7.6",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Prove each of the following assertions:1.  $alpha$ is valid if and only if ${True}{models}alpha$.2.  For any $alpha$, ${False}{models}alpha$.3.  $alpha{models}beta$ if and only if the sentence    $(alpha {:;{Rightarrow}:;}beta)$ is valid.4.  $alpha equiv beta$ if and only if the sentence    $(alpha{;;{Leftrightarrow};;}beta)$ is valid.5.  $alpha{models}beta$ if and only if the sentence    $(alpha land lnot beta)$ is unsatisfiable.",
        "url": " /knowledge-logic-exercises/ex_6/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-8":  {
        "title": "Exercise 7.8",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Prove, or find a counterexample to, each of the following assertions:1.  If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then    $(alphaland beta)modelsgamma$2.  If $alphamodels (beta land gamma)$ then $alpha models beta$    and $alpha models gamma$.3.  If $alphamodels (beta lor gamma)$ then $alpha models beta$    or $alpha models gamma$ (or both).",
        "url": " /knowledge-logic-exercises/ex_8/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-30":  {
        "title": "Exercise 7.30",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Trace the behavior of {DPLL} on the knowledge base inFigure pl-horn-example-figure when trying to prove $Q$,and compare this behavior with that of the forward-chaining algorithm.",
        "url": " /knowledge-logic-exercises/ex_30/"
      }
    
  
    
  
    ,
      "bayesian-learning-exercises-ex-11":  {
        "title": "Exercise 20.11",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Consider the application of EM to learn the parameters for the networkin Figure mixture-networks-figure(a), given the trueparameters in Equation (candy-true-equation).1.  Explain why the EM algorithm would not work if there were just two    attributes in the model rather than three.2.  Show the calculations for the first iteration of EM starting from    Equation (candy-64-equation).3.  What happens if we start with all the parameters set to the same    value $p$? (Hint: you may find it helpful to    investigate this empirically before deriving the general result.)4.  Write out an expression for the log likelihood of the tabulated    candy data on page candy-counts-page in terms of the parameters,    calculate the partial derivatives with respect to each parameter,    and investigate the nature of the fixed point reached in part (c).",
        "url": " /bayesian-learning-exercises/ex_11/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-10":  {
        "title": "Exercise 20.10",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Consider a single Boolean random variable $Y$ (the “classification”).Let the prior probability $P(Y=true)$ be $pi$. Let’s try tofind $pi$, given a training set $D=(y_1,ldots,y_N)$ with $N$independent samples of $Y$. Furthermore, suppose $p$ of the $N$ arepositive and $n$ of the $N$ are negative.1.  Write down an expression for the likelihood of $D$ (i.e., the    probability of seeing this particular sequence of examples, given a    fixed value of $pi$) in terms of $pi$, $p$, and $n$.2.  By differentiating the log likelihood $L$, find the value of $pi$    that maximizes the likelihood.3.  Now suppose we add in $k$ Boolean random variables    $X_1, X_2,ldots,X_k$ (the “attributes”) that describe each sample,    and suppose we assume that the attributes are conditionally    independent of each other given the goal $Y$. Draw the Bayes net    corresponding to this assumption.4.  Write down the likelihood for the data including the attributes,    using the following additional notation:    -   $alpha_i$ is $P(X_i=true | Y=true)$.    -   $beta_i$ is $P(X_i=true | Y=false)$.    -   $p_i^+$ is the count of samples for which $X_i=true$        and $Y=true$.    -   $n_i^+$ is the count of samples for which $X_i=false$        and $Y=true$.    -   $p_i^-$ is the count of samples for which $X_i=true$        and $Y=false$.    -   $n_i^-$ is the count of samples for which $X_i=false$        and $Y=false$.    [Hint: consider first the probability of seeing a    single example with specified values for $X_1, X_2,ldots,X_k$ and    $Y$.]5.  By differentiating the log likelihood $L$, find the values of    $alpha_i$ and $beta_i$ (in terms of the various counts) that    maximize the likelihood and say in words what these    values represent.6.  Let $k = 2$, and consider a data set with 4 all four possible    examples of thexor function. Compute the maximum    likelihood estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,    and $beta_2$.7.  Given these estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,    and $beta_2$, what are the posterior probabilities    $P(Y=true | x_1,x_2)$ for each example?",
        "url": " /bayesian-learning-exercises/ex_10/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-3":  {
        "title": "Exercise 20.3",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Suppose that Ann’s utilities for cherry andlime candies are $c_A$ and $ell_A$, whereas Bob’s utilities are $c_B$and $ell_B$. (But once Ann has unwrapped a piece of candy, Bob won’tbuy it.) Presumably, if Bob likes lime candies much more than Ann, itwould be wise for Ann to sell her bag of candies once she issufficiently sure of its lime content. On the other hand, if Ann unwrapstoo many candies in the process, the bag will be worth less. Discuss theproblem of determining the optimal point at which to sell the bag.Determine the expected utility of the optimal procedure, given the priordistribution from Section statistical-learning-section.",
        "url": " /bayesian-learning-exercises/ex_3/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-4":  {
        "title": "Exercise 20.4",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Two statisticians go to the doctor and are both given the sameprognosis: A 40% chance that the problem is the deadly disease $A$, anda 60% chance of the fatal disease $B$. Fortunately, there are anti-$A$and anti-$B$ drugs that are inexpensive, 100% effective, and free ofside-effects. The statisticians have the choice of taking one drug,both, or neither. What will the first statistician (an avid Bayesian)do? How about the second statistician, who always uses the maximumlikelihood hypothesis?The doctor does some research and discovers that disease $B$ actuallycomes in two versions, dextro-$B$ and levo-$B$, which are equally likelyand equally treatable by the anti-$B$ drug. Now that there are threehypotheses, what will the two statisticians do?",
        "url": " /bayesian-learning-exercises/ex_4/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-5":  {
        "title": "Exercise 20.5",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Explain how to apply the boosting method ofChapter concept-learning-chapter to naive Bayeslearning. Test the performance of the resulting algorithm on therestaurant learning problem.",
        "url": " /bayesian-learning-exercises/ex_5/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-2":  {
        "title": "Exercise 20.2",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Repeat Exercise bayes-candy-exercise, this timeplotting the values of$P(D_{N+1}=lime|h_{MAP})$ and$P(D_{N+1}=lime|h_{ML})$.",
        "url": " /bayesian-learning-exercises/ex_2/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-9":  {
        "title": "Exercise 20.9",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Consider an arbitrary Bayesian network, acomplete data set for that network, and the likelihood for the data setaccording to the network. Give a simple proof that the likelihood of thedata cannot decrease if we add a new link to the network and recomputethe maximum-likelihood parameter values.",
        "url": " /bayesian-learning-exercises/ex_9/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-7":  {
        "title": "Exercise 20.7",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Consider the noisy-OR model for fever describedin Section canonical-distribution-section. Explain howto apply maximum-likelihood learning to fit the parameters of such amodel to a set of complete data. (Hint: use the chainrule for partial derivatives.)",
        "url": " /bayesian-learning-exercises/ex_7/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-1":  {
        "title": "Exercise 20.1",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "The data used forFigure bayes-candy-figure on page bayes-candy-figure can beviewed as being generated by $h_5$. For each of the other fourhypotheses, generate a data set of length 100 and plot the correspondinggraphs for $P(h_i|d_1,ldots,d_N)$ and$P(D_{N+1}=lime|d_1,ldots,d_N)$. Comment onyour results.",
        "url": " /bayesian-learning-exercises/ex_1/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-6":  {
        "title": "Exercise 20.6",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Consider $N$ data points $(x_j,y_j)$,where the $y_j$s are generated from the $x_j$s according to the linearGaussian model inEquation (linear-gaussian-likelihood-equation). Findthe values of $theta_1$, $theta_2$, and $sigma$ that maximize theconditional log likelihood of the data.",
        "url": " /bayesian-learning-exercises/ex_6/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-8":  {
        "title": "Exercise 20.8",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "This exercise investigates properties ofthe Beta distribution defined inEquation (beta-equation).1.  By integrating over the range $[0,1]$, show that the normalization    constant for the distribution $[a,b]$ is given by    $alpha = Gamma(a+b)/Gamma(a)Gamma(b)$ where $Gamma(x)$ is the Gamma function,    defined by $Gamma(x+1)xcdotGamma(x)$ and    $Gamma(1)1$. (For integer $x$,    $Gamma(x+1)x!$.)2.  Show that the mean is $a/(a+b)$.3.  Find the mode(s) (the most likely value(s) of $theta$).4.  Describe the distribution $[epsilon,epsilon]$ for very    small $epsilon$. What happens as such a distribution is updated?",
        "url": " /bayesian-learning-exercises/ex_8/"
      }
    
  
    
  
    ,
      "game-playing-exercises-ex-11":  {
        "title": "Exercise 5.11",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Develop a general game-playing program, capable of playing a variety ofgames.1.  Implement move generators and evaluation functions for one or more    of the following games: Kalah, Othello, checkers, and chess.2.  Construct a general alpha–beta game-playing agent.3.  Compare the effect of increasing search depth, improving move    ordering, and improving the evaluation function. How close does your    effective branching factor come to the ideal case of perfect move    ordering?4.  Implement a selective search algorithm, such as B* Berliner:1979,    conspiracy number search @McAllester:1988, or MGSS*    Russell+Wefald:1989 and compare its performance to A*.",
        "url": " /game-playing-exercises/ex_11/"
      }
    
  
    ,
      "game-playing-exercises-ex-16":  {
        "title": "Exercise 5.16",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Suppose you have a chess program that can evaluate 5 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a1-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?",
        "url": " /game-playing-exercises/ex_16/"
      }
    
  
    ,
      "game-playing-exercises-ex-20":  {
        "title": "Exercise 5.20",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Prove that with a positive lineartransformation of leaf values (i.e., transforming a value $x$ to$ax + b$ where $a &amp;gt; 0$), the choice of move remains unchanged in a gametree, even when there are chance nodes.",
        "url": " /game-playing-exercises/ex_20/"
      }
    
  
    ,
      "game-playing-exercises-ex-18":  {
        "title": "Exercise 5.18",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "This question considers pruning in games with chance nodes.Figure trivial-chance-game-figure shows the completegame tree for a trivial game. Assume that the leaf nodes are to beevaluated in left-to-right order, and that before a leaf node isevaluated, we know nothing about its value—the range of possible valuesis $-infty$ to $infty$.1.  Copy the figure, mark the value of all the internal nodes, and    indicate the best move at the root with an arrow.2.  Given the values of the first six leaves, do we need to evaluate the    seventh and eighth leaves? Given the values of the first seven    leaves, do we need to evaluate the eighth leaf? Explain    your answers.3.  Suppose the leaf node values are known to lie between –2 and 2    inclusive. After the first two leaves are evaluated, what is the    value range for the left-hand chance node?4.  Circle all the leaves that need not be evaluated under the    assumption in (c).",
        "url": " /game-playing-exercises/ex_18/"
      }
    
  
    ,
      "game-playing-exercises-ex-19":  {
        "title": "Exercise 5.19",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Implement the expectiminimax algorithm and the *-alpha–beta algorithm,which is described by Ballard:1983, for pruning game trees with chance nodes. Trythem on a game such as backgammon and measure the pruning effectivenessof *-alpha–beta.",
        "url": " /game-playing-exercises/ex_19/"
      }
    
  
    ,
      "game-playing-exercises-ex-21":  {
        "title": "Exercise 5.21",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Consider the following procedurefor choosing moves in games with chance nodes:-   Generate some dice-roll sequences (say, 50) down to a suitable depth    (say, 8).-   With known dice rolls, the game tree becomes deterministic. For each    dice-roll sequence, solve the resulting deterministic game tree    using alpha–beta.-   Use the results to estimate the value of each move and to choose    the best.Will this procedure work well? Why (or why not)?",
        "url": " /game-playing-exercises/ex_21/"
      }
    
  
    ,
      "game-playing-exercises-ex-17":  {
        "title": "Exercise 5.17",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Suppose you have a chess program that can evaluate 10 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a2-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?    The complete game tree for a trivial game with chance nodes..",
        "url": " /game-playing-exercises/ex_17/"
      }
    
  
    ,
      "game-playing-exercises-ex-10":  {
        "title": "Exercise 5.10",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Consider the family of generalized tic-tac-toe games, defined asfollows. Each particular game is specified by a set $mathcal S$ ofsquares and a collection $mathcal W$ of winningpositions. Each winning position is a subset of $mathcal S$.For example, in standard tic-tac-toe, $mathcal S$ is a set of 9 squaresand $mathcal W$ is a collection of 8 subsets of $cal W$: the threerows, the three columns, and the two diagonals. In other respects, thegame is identical to standard tic-tac-toe. Starting from an empty board,players alternate placing their marks on an empty square. A player whomarks every square in a winning position wins the game. It is a tie ifall squares are marked and neither player has won.1.  Let $N= |{mathcal S}|$, the number of squares. Give an upper bound    on the number of nodes in the complete game tree for generalized    tic-tac-toe as a function of $N$.2.  Give a lower bound on the size of the game tree for the worst case,    where ${mathcal W} = {{,}}$.3.  Propose a plausible evaluation function that can be used for any    instance of generalized tic-tac-toe. The function may depend on    $mathcal S$ and $mathcal W$.4.  Assume that it is possible to generate a new board and check whether    it is a winning position in 100$N$ machine instructions and assume a    2 gigahertz processor. Ignore memory limitations. Using your    estimate in (a), roughly how large a game tree can be completely    solved by alpha–beta in a second of CPU time? a minute? an hour?",
        "url": " /game-playing-exercises/ex_10/"
      }
    
  
    ,
      "game-playing-exercises-ex-3":  {
        "title": "Exercise 5.3",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Imagine that, in Exercise two-friends-exercise, one ofthe friends wants to avoid the other. The problem then becomes atwo-player game. We assume now that the players take turns moving. Thegame ends only when the players are on the same node; the terminalpayoff to the pursuer is minus the total time taken. (The evader “wins”by never losing.) An example is shown in Figure.pursuit-evasion-game-figure1.  Copy the game tree and mark the values of the terminal nodes.2.  Next to each internal node, write the strongest fact you can infer    about its value (a number, one or more inequalities such as    “$geq 14$”, or a “?”).3.  Beneath each question mark, write the name of the node reached by    that branch.4.  Explain how a bound on the value of the nodes in (c) can be derived    from consideration of shortest-path lengths on the map, and derive    such bounds for these nodes. Remember the cost to get to each leaf    as well as the cost to solve it.5.  Now suppose that the tree as given, with the leaf bounds from (d),    is evaluated from left to right. Circle those “?” nodes that would    not need to be expanded further, given the bounds    from part (d), and cross out those that need not be considered    at all.6.  Can you prove anything in general about who wins the game on a map    that is a tree?",
        "url": " /game-playing-exercises/ex_3/"
      }
    
  
    ,
      "game-playing-exercises-ex-4":  {
        "title": "Exercise 5.4",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Describe and implement statedescriptions, move generators, terminal tests, utility functions, andevaluation functions for one or more of the following stochastic games:Monopoly, Scrabble, bridge play with a given contract, or Texas hold’empoker.",
        "url": " /game-playing-exercises/ex_4/"
      }
    
  
    ,
      "game-playing-exercises-ex-5":  {
        "title": "Exercise 5.5",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Describe and implement a real-time,multiplayer game-playing environment, where time is partof the environment state and players are given fixed time allocations.",
        "url": " /game-playing-exercises/ex_5/"
      }
    
  
    ,
      "game-playing-exercises-ex-2":  {
        "title": "Exercise 5.2",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Consider the problem of solving two 8-puzzles.1.  Give a complete problem formulation in the style of    Chapter search-chapter.2.  How large is the reachable state space? Give an exact    numerical expression.3.  Suppose we make the problem adversarial as follows: the two players    take turns moving; a coin is flipped to determine the puzzle on    which to make a move in that turn; and the winner is the first to    solve one puzzle. Which algorithm can be used to choose a move in    this setting?4.  Does the game eventually end, given optimal play? Explain.(a) A map where the cost of every edge is 1. Initially the pursuer $P$ is atnode b and the evader $E$ is at node d (b) A partial game tree for this map.Each node is labeled with the $P,E$ positions. $P$ moves first. Branches marked &quot;?&quot; have yet to be explored.    Pursuit evasion game Figure",
        "url": " /game-playing-exercises/ex_2/"
      }
    
  
    ,
      "game-playing-exercises-ex-15":  {
        "title": "Exercise 5.15",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Prove that the alpha–beta algorithm takes time $O(b^{m/2})$ with optimalmove ordering, where $m$ is the maximum depth of the game tree.",
        "url": " /game-playing-exercises/ex_15/"
      }
    
  
    ,
      "game-playing-exercises-ex-12":  {
        "title": "Exercise 5.12",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state differ by at most a constant $k$, makingthe game almost cooperative?",
        "url": " /game-playing-exercises/ex_12/"
      }
    
  
    ,
      "game-playing-exercises-ex-24":  {
        "title": "Exercise 5.24",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Which of the following are true and which are false? Give briefexplanations.1.  In a fully observable, turn-taking, zero-sum game between two    perfectly rational players, it does not help the first player to    know what strategy the second player is using—that is, what move the    second player will make, given the first player’s move.2.  In a partially observable, turn-taking, zero-sum game between two    perfectly rational players, it does not help the first player to    know what move the second player will make, given the first    player’s move.3.  A perfectly rational backgammon agent never loses.",
        "url": " /game-playing-exercises/ex_24/"
      }
    
  
    ,
      "game-playing-exercises-ex-23":  {
        "title": "Exercise 5.23",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search.1.  Assuming that leaf values are finite but unbounded, is pruning (as    in alpha–beta) ever possible in a max tree? Give an example, or    explain why not.2.  Is pruning ever possible in an expectimax tree under the same    conditions? Give an example, or explain why not.3.  If leaf values are constrained to be in the range $[0,1]$, is    pruning ever possible in a max tree? Give an example, or explain    why not.4.  If leaf values are constrained to be in the range $[0,1]$, is    pruning ever possible in an expectimax tree? Give an example    (qualitatively different from your example in (e), if any), or    explain why not.5.  If leaf values are constrained to be nonnegative, is pruning ever    possible in a max tree? Give an example, or explain why not.6.  If leaf values are constrained to be nonnegative, is pruning ever    possible in an expectimax tree? Give an example, or explain why not.7.  Consider the outcomes of a chance node in an expectimax tree. Which    of the following evaluation orders is most likely to yield pruning    opportunities: (i) Lowest probability first; (ii) Highest    probability first; (iii) Doesn’t make any difference?",
        "url": " /game-playing-exercises/ex_23/"
      }
    
  
    ,
      "game-playing-exercises-ex-22":  {
        "title": "Exercise 5.22",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search. For each of (a)–(f), eithergive an example or explain why this is impossible.1.  Assuming that leaf values are finite but unbounded, is pruning (as    in alpha–beta) ever possible in a max tree?2.  Is pruning ever possible in an expectimax tree under the same    conditions?3.  If leaf values are all nonnegative, is pruning ever possible in a    max tree? Give an example, or explain why not.4.  If leaf values are all nonnegative, is pruning ever possible in an    expectimax tree? Give an example, or explain why not.5.  If leaf values are all in the range $[0,1]$, is pruning ever    possible in a max tree? Give an example, or explain why not.6.  If leaf values are all in the range $[0,1]$, is pruning ever    possible in an expectimax tree?17.  Consider the outcomes of a chance node in an expectimax tree. Which    of the following evaluation orders is most likely to yield pruning    opportunities?    i.  Lowest probability first    ii.  Highest probability first    iii.  Doesn’t make any difference",
        "url": " /game-playing-exercises/ex_22/"
      }
    
  
    ,
      "game-playing-exercises-ex-25":  {
        "title": "Exercise 5.25",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Consider carefully the interplay of chance events and partialinformation in each of the games inExercise game-playing-chance-exercise.1.  For which is the standard expectiminimax model appropriate?    Implement the algorithm and run it in your game-playing agent, with    appropriate modifications to the game-playing environment.2.  For which would the scheme described in    Exercise game-playing-monte-carlo-exercise be    appropriate?3.  Discuss how you might deal with the fact that in some of the games,    the players do not have the same knowledge of the current state.",
        "url": " /game-playing-exercises/ex_25/"
      }
    
  
    ,
      "game-playing-exercises-ex-13":  {
        "title": "Exercise 5.13",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state sum to a number between constants $-k$and $k$, making the game almost zero-sum?",
        "url": " /game-playing-exercises/ex_13/"
      }
    
  
    ,
      "game-playing-exercises-ex-14":  {
        "title": "Exercise 5.14",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Develop a formal proof of correctness for alpha–beta pruning. To dothis, consider the situation shown inFigure alpha-beta-proof-figure. The question is whetherto prune node $n_j$, which is a max-node and a descendant of node $n_1$.The basic idea is to prune it if and only if the minimax value of $n_1$can be shown to be independent of the value of $n_j$.1.  Mode $n_1$ takes on the minimum value among its children:    $n_1 = min(n_2,n_21,ldots,n_{2b_2})$. Find a similar    expression for $n_2$ and hence an expression for $n_1$ in terms of    $n_j$.2.  Let $l_i$ be the minimum (or maximum) value of the nodes to the    left of node $n_i$ at depth $i$, whose minimax value    is already known. Similarly, let $r_i$ be the minimum (or maximum)    value of the unexplored nodes to the right of $n_i$ at depth $i$.    Rewrite your expression for $n_1$ in terms of the $l_i$ and    $r_i$ values.3.  Now reformulate the expression to show that in order to affect    $n_1$, $n_j$ must not exceed a certain bound derived from the    $l_i$ values.4.  Repeat the process for the case where $n_j$ is a min-node.    Situation when considering whether to prune node $n_j$.",
        "url": " /game-playing-exercises/ex_14/"
      }
    
  
    ,
      "game-playing-exercises-ex-9":  {
        "title": "Exercise 5.9",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "This problem exercises the basic concepts of game playing, usingtic-tac-toe (noughts and crosses) as an example. We define$X_n$ as the number of rows, columns, or diagonals with exactly $n$$X$’s and no $O$’s. Similarly, $O_n$ is the number of rows, columns, ordiagonals with just $n$ $O$’s. The utility function assigns $+1$ to anyposition with $X_3=1$ and $-1$ to any position with $O_3 = 1$. All otherterminal positions have utility 0. For nonterminal positions, we use alinear evaluation function defined as ${Eval}(s) = 3X_2(s) + X_1(s) -(3O_2(s) + O_1(s))$. 1.  Approximately how many possible games of tic-tac-toe are there?2.  Show the whole game tree starting from an empty board down to depth    2 (i.e., one $X$ and one $O$ on the board), taking symmetry    into account.3.  Mark on your tree the evaluations of all the positions at depth 2.4.  Using the minimax algorithm, mark on your tree the backed-up values    for the positions at depths 1 and 0, and use those values to choose    the best starting move.5.  Circle the nodes at depth 2 that would not be    evaluated if alpha–beta pruning were applied, assuming the nodes are    generated in the optimal order for alpha–beta pruning.",
        "url": " /game-playing-exercises/ex_9/"
      }
    
  
    ,
      "game-playing-exercises-ex-7":  {
        "title": "Exercise 5.7",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Prove the following assertion: For everygame tree, the utility obtained by max using minimaxdecisions against a suboptimal min will never be lower thanthe utility obtained playing against an optimal min. Canyou come up with a game tree in which max can do stillbetter using a suboptimal strategy against a suboptimalmin?Player $A$ moves first. The two players take turns moving, and eachplayer must move his token to an open adjacent space in eitherdirection.  If the opponent occupies an adjacent space, then a playermay jump over the opponent to the next open space if any. (Forexample, if $A$ is on 3 and $B$ is on 2, then $A$ may move back to 1.)The game ends when one player reaches the opposite end of the board.If player $A$ reaches space 4 first, then the value of the game to $A$is $+1$; if player $B$ reaches space 1 first, then the value of thegame to $A$ is $-1$.    The starting position of a simple game.",
        "url": " /game-playing-exercises/ex_7/"
      }
    
  
    ,
      "game-playing-exercises-ex-1":  {
        "title": "Exercise 5.1",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Suppose you have an oracle, $OM(s)$, that correctly predicts theopponent’s move in any state. Using this, formulate the definition of agame as a (single-agent) search problem. Describe an algorithm forfinding the optimal move.",
        "url": " /game-playing-exercises/ex_1/"
      }
    
  
    ,
      "game-playing-exercises-ex-6":  {
        "title": "Exercise 5.6",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Discuss how well the standard approach to game playing would apply togames such as tennis, pool, and croquet, which take place in acontinuous physical state space.",
        "url": " /game-playing-exercises/ex_6/"
      }
    
  
    ,
      "game-playing-exercises-ex-8":  {
        "title": "Exercise 5.8",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Consider the two-player game described inFigure line-game4-figure1.  Draw the complete game tree, using the following conventions:    -   Write each state as $(s_A,s_B)$, where $s_A$ and $s_B$ denote        the token locations.    -   Put each terminal state in a square box and write its game value        in a circle.    -   Put loop states (states that already appear on        the path to the root) in double square boxes. Since their value        is unclear, annotate each with a “?” in a circle.2.  Now mark each node with its backed-up minimax value (also in    a circle). Explain how you handled the “?” values and why.3.  Explain why the standard minimax algorithm would fail on this game    tree and briefly sketch how you might fix it, drawing on your answer    to (b). Does your modified algorithm give optimal decisions for all    games with loops?4.  This 4-square game can be generalized to $n$ squares for any    $n &amp;gt; 2$. Prove that $A$ wins if $n$ is even and loses if $n$ is odd.",
        "url": " /game-playing-exercises/ex_8/"
      }
    
  
    
  
    ,
      "search-exercises-ex-12":  {
        "title": "Exercise 3.12",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "The problem is usually stated as follows. Threemissionaries and three cannibals are on one side of a river, along witha boat that can hold one or two people. Find a way to get everyone tothe other side without ever leaving a group of missionaries in one placeoutnumbered by the cannibals in that place. This problem is famous in AIbecause it was the subject of the first paper that approached problemformulation from an analytical viewpoint Amarel:1968. 1.  Formulate the problem precisely, making only those distinctions    necessary to ensure a valid solution. Draw a diagram of the complete    state space.2.  Implement and solve the problem optimally using an appropriate    search algorithm. Is it a good idea to check for repeated states? 3.  Why do you think people have a hard time solving this puzzle, given    that the state space is so simple? ",
        "url": " /search-exercises/ex_12/"
      }
    
  
    ,
      "search-exercises-ex-16":  {
        "title": "Exercise 3.16",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Prove that satisfies the graphseparation property illustrated in . (Hint: Begin byshowing that the property holds at the start, then show that if it holdsbefore an iteration of the algorithm, it holds afterwards.) Describe asearch algorithm that violates the property.",
        "url": " /search-exercises/ex_16/"
      }
    
  
    ,
      "search-exercises-ex-29":  {
        "title": "Exercise 3.29",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Devise a state space in which A using returns asuboptimal solution with an $h(n)$ function that is admissible butinconsistent.",
        "url": " /search-exercises/ex_29/"
      }
    
  
    ,
      "search-exercises-ex-20":  {
        "title": "Exercise 3.20",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Implement two versions of the function for the 8-puzzle: one that copiesand edits the data structure for the parent node $s$ and one thatmodifies the parent state directly (undoing the modifications asneeded). Write versions of iterative deepening depth-first search thatuse these functions and compare their performance.",
        "url": " /search-exercises/ex_20/"
      }
    
  
    ,
      "search-exercises-ex-27":  {
        "title": "Exercise 3.27",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Trace the operation of A search applied to the problem of getting toBucharest from Lugoj using the straight-line distance heuristic. Thatis, show the sequence of nodes that the algorithm will consider and the$f$, $g$, and $h$ score for each node.",
        "url": " /search-exercises/ex_27/"
      }
    
  
    ,
      "search-exercises-ex-18":  {
        "title": "Exercise 3.18",
        "breadcrumb": "3-Solving-Problems-By-Searching18",
      	"content"  : "Consider a state space where the start state is number 1 and each state$k$ has two successors: numbers $2k$ and $2k+1$. 1.  Draw the portion of the state space for states 1 to 15. 2.  Suppose the goal state is 11. List the order in which nodes will be    visited for breadth-first search, depth-limited search with limit 3,    and iterative deepening search. 3.  How well would bidirectional search work on this problem? What is    the branching factor in each direction of the bidirectional search?4.  Does the answer to (c) suggest a reformulation of the problem that    would allow you to solve the problem of getting from state 1 to a    given goal state with almost no search? 5.  Call the action going from $k$ to $2k$ Left, and the action going to    $2k+1$ Right. Can you find an algorithm that outputs the solution to    this problem without any search at all?",
        "url": " /search-exercises/ex_18/"
      }
    
  
    ,
      "search-exercises-ex-26":  {
        "title": "Exercise 3.26",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Compare the performance of A and RBFS on a set of randomly generatedproblems in the 8-puzzle (with Manhattan distance) and TSP (with MST—see) domains. Discuss your results. What happens to the performance of RBFSwhen a small random number is added to the heuristic values in the8-puzzle domain?",
        "url": " /search-exercises/ex_26/"
      }
    
  
    ,
      "search-exercises-ex-19":  {
        "title": "Exercise 3.19",
        "breadcrumb": "3-Solving-Problems-By-Searching19",
      	"content"  : "A basic wooden railway set contains the pieces shown in. The task is to connect these pieces into a railway that has nooverlapping tracks and no loose ends where a train could run off ontothe floor.1.  Suppose that the pieces fit together exactly with no    slack. Give a precise formulation of the task as a search problem.2.  Identify a suitable uninformed search algorithm for this task and    explain your choice.3.  Explain why removing any one of the “fork” pieces makes the    problem unsolvable. 4.  Give an upper bound on the total size of the state space defined by    your formulation. (Hint: think about the maximum    branching factor for the construction process and the maximum depth,    ignoring the problem of overlapping pieces and loose ends. Begin by    pretending that every piece is unique.)",
        "url": " /search-exercises/ex_19/"
      }
    
  
    ,
      "search-exercises-ex-21":  {
        "title": "Exercise 3.21",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "On page iterative-lengthening-page,we mentioned iterative lengthening search,an iterative analog of uniform cost search. The idea is to use increasing limits onpath cost. If a node is generated whose path cost exceeds the currentlimit, it is immediately discarded. For each new iteration, the limit isset to the lowest path cost of any node discarded in the previousiteration.1.  Show that this algorithm is optimal for general path costs.2.  Consider a uniform tree with branching factor $b$, solution depth    $d$, and unit step costs. How many iterations will iterative    lengthening require?3.  Now consider step costs drawn from the continuous range    $[epsilon,1]$, where $0 &amp;lt; epsilon &amp;lt; 1$. How many iterations are    required in the worst case? 4.  Implement the algorithm and apply it to instances of the 8-puzzle    and traveling salesperson problems. Compare the algorithm’s    performance to that of uniform-cost search, and comment on    your results. ",
        "url": " /search-exercises/ex_21/"
      }
    
  
    ,
      "search-exercises-ex-17":  {
        "title": "Exercise 3.17",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Which of the following are true and which are false? Explain youranswers.1.  Depth-first search always expands at least as many nodes as A search    with an admissible heuristic. 2.  $h(n)=0$ is an admissible heuristic for the 8-puzzle. 3.  A is of no use in robotics because percepts, states, and actions    are continuous.4.  Breadth-first search is complete even if zero step costs    are allowed. 5.  Assume that a rook can move on a chessboard any number of squares in    a straight line, vertically or horizontally, but cannot jump over    other pieces. Manhattan distance is an admissible heuristic for the    problem of moving the rook from square A to square B in the smallest    number of moves.",
        "url": " /search-exercises/ex_17/"
      }
    
  
    ,
      "search-exercises-ex-28":  {
        "title": "Exercise 3.28",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Sometimes there is no good evaluation function for a problem but thereis a good comparison method: a way to tell whether one node is betterthan another without assigning numerical values to either. Show thatthis is enough to do a best-first search. Is there an analog of A forthis setting?",
        "url": " /search-exercises/ex_28/"
      }
    
  
    ,
      "search-exercises-ex-10":  {
        "title": "Exercise 3.10",
        "breadcrumb": "3-Solving-Problems-By-Searching10",
      	"content"  : "On page non-negative-g, we said that we would not consider problemswith negative path costs. In this exercise, we explore this decision inmore depth.1.  Suppose that actions can have arbitrarily large negative costs;    explain why this possibility would force any optimal algorithm to    explore the entire state space.2.  Does it help if we insist that step costs must be greater than or    equal to some negative constant $c$? Consider both trees and graphs.3.  Suppose that a set of actions forms a loop in the state space such    that executing the set in some order results in no net change to    the state. If all of these actions have negative cost, what does    this imply about the optimal behavior for an agent in such an    environment?4.  One can easily imagine actions with high negative cost, even in    domains such as route finding. For example, some stretches of road    might have such beautiful scenery as to far outweigh the normal    costs in terms of time and fuel. Explain, in precise terms, within    the context of state-space search, why humans do not drive around    scenic loops indefinitely, and explain how to define the state space    and actions for route finding so that artificial agents can also    avoid looping.5.  Can you think of a real domain in which step costs are such as to    cause looping?",
        "url": " /search-exercises/ex_10/"
      }
    
  
    ,
      "search-exercises-ex-32":  {
        "title": "Exercise 3.32",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Consider the unbounded version of the regular 2D grid shown in . Thestart state is at the origin, (0,0), and the goal state is at $(x,y)$.1.  What is the branching factor $b$ in this state space?2.  How many distinct states are there at depth $k$ (for $k&amp;gt;0$)?3.  What is the maximum number of nodes expanded by breadth-first tree    search?4.  What is the maximum number of nodes expanded by breadth-first graph    search?5.  Is $h = |u-x| + |v-y|$ an admissible heuristic for a state at    $(u,v)$? Explain.6.  How many nodes are expanded by A graph search using $h$?7.  Does $h$ remain admissible if some links are removed?8.  Does $h$ remain admissible if some links are added between    nonadjacent states?",
        "url": " /search-exercises/ex_32/"
      }
    
  
    ,
      "search-exercises-ex-35":  {
        "title": "Exercise 3.35",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "We saw on page I-to-F that the straight-line distance heuristic leads greedybest-first search astray on the problem of going from Iasi to Fagaras.However, the heuristic is perfect on the opposite problem: going fromFagaras to Iasi. Are there problems for which the heuristic ismisleading in both directions?",
        "url": " /search-exercises/ex_35/"
      }
    
  
    ,
      "search-exercises-ex-3":  {
        "title": "Exercise 3.3",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Your goal is to navigate a robot out of a maze. The robot starts in thecenter of the maze facing north. You can turn the robot to face north,east, south, or west. You can direct the robot to move forward a certaindistance, although it will stop before hitting a wall.1.  Formulate this problem. How large is the state space?2.  In navigating a maze, the only place we need to turn is at the    intersection of two or more corridors. Reformulate this problem    using this observation. How large is the state space now?3.  From each point in the maze, we can move in any of the four    directions until we reach a turning point, and this is the only    action we need to do. Reformulate the problem using these actions.    Do we need to keep track of the robot’s orientation now?4.  In our initial description of the problem we already abstracted from    the real world, restricting actions and removing details. List three    such simplifications we made.",
        "url": " /search-exercises/ex_3/"
      }
    
  
    ,
      "search-exercises-ex-4":  {
        "title": "Exercise 3.4",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "You have a $9 times 9$ grid of squares, each of which can be coloredred or blue. The grid is initially colored all blue, but you can changethe color of any square any number of times. Imagining the grid dividedinto nine $3 times 3$ sub-squares, you want each sub-square to be allone color but neighboring sub-squares to be different colors.1.  Formulate this problem in the straightforward way. Compute the size    of the state space.2.  You need color a square only once. Reformulate, and compute the size    of the state space. Would breadth-first graph search perform faster    on this problem than on the one in (a)? How about iterative    deepening tree search?3.  Given the goal, we need consider only colorings where each    sub-square is uniformly colored. Reformulate the problem and compute    the size of the state space.4.  How many solutions does this problem have?5.  Parts (b) and (c) successively abstracted the original problem (a).    Can you give a translation from solutions in problem (c) into    solutions in problem (b), and from solutions in problem (b) into    solutions for problem (a)?",
        "url": " /search-exercises/ex_4/"
      }
    
  
    ,
      "search-exercises-ex-34":  {
        "title": "Exercise 3.34",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Consider the problem of moving $k$ knights from $k$ starting squares$s_1,ldots,s_k$ to $k$ goal squares $g_1,ldots,g_k$, on an unboundedchessboard, subject to the rule that no two knights can land on the samesquare at the same time. Each action consists of moving upto $k$ knights simultaneously. We would like to complete themaneuver in the smallest number of actions.1.  What is the maximum branching factor in this state space, expressed    as a function of $k$?2.  Suppose $h_i$ is an admissible heuristic for the problem of moving    knight $i$ to goal $g_i$ by itself. Which of the following    heuristics are admissible for the $k$-knight problem? Of those,    which is the best?    1.  $min{h_1,ldots,h_k}$.    2.  $max{h_1,ldots,h_k}$.    3.  $sum_{i= 1}^{k} h_i$.3.  Repeat (b) for the case where you are allowed to move only one    knight at a time.",
        "url": " /search-exercises/ex_34/"
      }
    
  
    ,
      "search-exercises-ex-33":  {
        "title": "Exercise 3.33",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "$n$ vehicles occupy squares $(1,1)$ through $(n,1)$ (i.e., the bottomrow) of an $ntimes n$ grid. The vehicles must be moved to the top rowbut in reverse order; so the vehicle $i$ that starts in $(i,1)$ must endup in $(n-i+1,n)$. On each time step, every one of the $n$ vehicles canmove one square up, down, left, or right, or stay put; but if a vehiclestays put, one other adjacent vehicle (but not more than one) can hopover it. Two vehicles cannot occupy the same square. 1.  Calculate the size of the state space as a function of $n$.2.  Calculate the branching factor as a function of $n$.3.  Suppose that vehicle $i$ is at $(x_i,y_i)$; write a nontrivial    admissible heuristic $h_i$ for the number of moves it will require    to get to its goal location $(n-i+1,n)$, assuming no other vehicles    are on the grid.4.  Which of the following heuristics are admissible for the problem of    moving all $n$ vehicles to their destinations? Explain.    1.  $sum_{i= 1}^{n} h_i$.    2.  $max{h_1,ldots,h_n}$.    3.  $min{h_1,ldots,h_n}$.",
        "url": " /search-exercises/ex_33/"
      }
    
  
    ,
      "search-exercises-ex-5":  {
        "title": "Exercise 3.5",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Suppose two friends live in different cities ona map, such as the Romania map shown in . On every turn, we cansimultaneously move each friend to a neighboring city on the map. Theamount of time needed to move from city $i$ to neighbor $j$ is equal tothe road distance $d(i,j)$ between the cities, but on each turn thefriend that arrives first must wait until the other one arrives (andcalls the first on his/her cell phone) before the next turn can begin.We want the two friends to meet as quickly as possible.1.  Write a detailed formulation for this search problem. (You will find    it helpful to define some formal notation here.)2.  Let $D(i,j)$ be the straight-line distance between cities $i$ and    $j$. Which of the following heuristic functions are admissible? (i)    $D(i,j)$; (ii) $2cdot D(i,j)$; (iii) $D(i,j)/2$. 3.  Are there completely connected maps for which no solution exists? 4.  Are there maps in which all solutions require one friend to visit    the same city twice?",
        "url": " /search-exercises/ex_5/"
      }
    
  
    ,
      "search-exercises-ex-2":  {
        "title": "Exercise 3.2",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Give a complete problem formulation for each of the following problems.Choose a formulation that is precise enough to be implemented.1.  There are six glass boxes in a row, each with a lock. Each of the    first five boxes holds a key unlocking the next box in line; the    last box holds a banana. You have the key to the first box, and you    want the banana.2.  You start with the sequence ABABAECCEC, or in general any sequence    made from A, B, C, and E. You can transform this sequence using the    following equalities: AC = E, AB = BC, BB = E, and E$x$ = $x$ for    any $x$. For example, ABBC can be transformed into AEC, and then AC,    and then E. Your goal is to produce the sequence E.3.  There is an $n times n$ grid of squares, each square initially    being either unpainted floor or a bottomless pit. You start standing    on an unpainted floor square, and can either paint the square under    you or move onto an adjacent unpainted floor square. You want the    whole floor painted.4.  A container ship is in port, loaded high with containers. There 13    rows of containers, each 13 containers wide and 5 containers tall.    You control a crane that can move to any location above the ship,    pick up the container under it, and move it onto the dock. You want    the ship unloaded.",
        "url": " /search-exercises/ex_2/"
      }
    
  
    ,
      "search-exercises-ex-15":  {
        "title": "Exercise 3.15",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Does a finite state space always lead to a finite search tree? How abouta finite state space that is a tree? Can you be more precise about whattypes of state spaces always lead to finite search trees? (Adapted from, 1996.)",
        "url": " /search-exercises/ex_15/"
      }
    
  
    ,
      "search-exercises-ex-12":  {
        "title": "Exercise 3.12",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Define in your own words the following terms: state, state space, searchtree, search node, goal, action, transition model, and branching factor.",
        "url": " /search-exercises/ex_12/"
      }
    
  
    ,
      "search-exercises-ex-24":  {
        "title": "Exercise 3.24",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Consider the vacuum-world problem defined in .1.  Which of the algorithms defined in this chapter would be appropriate    for this problem? Should the algorithm use tree search or graph    search?2.  Apply your chosen algorithm to compute an optimal sequence of    actions for a $3times 3$ world whose initial state has dirt in the    three top squares and the agent in the center.3.  Construct a search agent for the vacuum world, and evaluate its    performance in a set of $3times 3$ worlds with probability 0.2 of    dirt in each square. Include the search cost as well as path cost in    the performance measure, using a reasonable exchange rate.4.  Compare your best search agent with a simple randomized reflex agent    that sucks if there is dirt and otherwise moves randomly.5.  Consider what would happen if the world were enlarged to    $n times n$. How does the performance of the search agent and of    the reflex agent vary with $n$? ",
        "url": " /search-exercises/ex_24/"
      }
    
  
    ,
      "search-exercises-ex-23":  {
        "title": "Exercise 3.23",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Write a program that will take as input two Web page URLs and find apath of links from one to the other. What is an appropriate searchstrategy? Is bidirectional search a good idea? Could a search engine beused to implement a predecessor function?",
        "url": " /search-exercises/ex_23/"
      }
    
  
    ,
      "search-exercises-ex-22":  {
        "title": "Exercise 3.22",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Describe a state space in which iterative deepening search performs muchworse than depth-first search (for example, $O(n^{2})$ vs. $O(n)$).",
        "url": " /search-exercises/ex_22/"
      }
    
  
    ,
      "search-exercises-ex-25":  {
        "title": "Exercise 3.25",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Prove each of the following statements,or give a counterexample: 1.  Breadth-first search is a special case of uniform-cost search.2.  Depth-first search is a special case of best-first tree search.3.  Uniform-cost search is a special case of A search.",
        "url": " /search-exercises/ex_25/"
      }
    
  
    ,
      "search-exercises-ex-13":  {
        "title": "Exercise 3.13",
        "breadcrumb": "3-Solving-Problems-By-Searching13",
      	"content"  : "What’s the difference between a world state, a state description, and asearch node? Why is this distinction useful?",
        "url": " /search-exercises/ex_13/"
      }
    
  
    ,
      "search-exercises-ex-14":  {
        "title": "Exercise 3.14",
        "breadcrumb": "3-Solving-Problems-By-Searching14",
      	"content"  : "An action such as really consists of a long sequence of finer-grainedactions: turn on the car, release the brake, accelerate forward, etc.Having composite actions of this kind reduces the number of steps in asolution sequence, thereby reducing the search time. Suppose we takethis to the logical extreme, by making super-composite actions out ofevery possible sequence of actions. Then every problem instance issolved by a single super-composite action, such as . Explain how searchwould work in this formulation. Is this a practical approach forspeeding up problem solving?",
        "url": " /search-exercises/ex_14/"
      }
    
  
    ,
      "search-exercises-ex-40":  {
        "title": "Exercise 3.40",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "We gave two simple heuristics for the 8-puzzle: Manhattan distance andmisplaced tiles. Several heuristics in the literature purport to improveon this—see, for example, Nilsson:1971,Mostow+Prieditis:1989, and Hansson+al:1992. Test these claims by implementingthe heuristics and comparing the performance of the resultingalgorithms.",
        "url": " /search-exercises/ex_40/"
      }
    
  
    ,
      "search-exercises-ex-9":  {
        "title": "Exercise 3.9",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Consider the problem of finding the shortestpath between two points on a plane that has convex polygonal obstaclesas shown in . This is an idealization of the problem that a robot has tosolve to navigate in a crowded environment.1.  Suppose the state space consists of all positions $(x,y)$ in    the plane. How many states are there? How many paths are there to    the goal?2.  Explain briefly why the shortest path from one polygon vertex to any    other in the scene must consist of straight-line segments joining    some of the vertices of the polygons. Define a good state space now.    How large is this state space?3.  Define the necessary functions to implement the search problem,    including an function that takes a vertex as input and returns a set    of vectors, each of which maps the current vertex to one of the    vertices that can be reached in a straight line. (Do not forget the    neighbors on the same polygon.) Use the straight-line distance for    the heuristic function.4.  Apply one or more of the algorithms in this chapter to solve a range    of problems in the domain, and comment on their performance.",
        "url": " /search-exercises/ex_9/"
      }
    
  
    ,
      "search-exercises-ex-7":  {
        "title": "Exercise 3.7",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Consider the $n$-queens problem using the“efficient” incremental formulation given on page nqueens-page. Explain why the statespace has at least $sqrt[3]{n!}$ states and estimate the largest $n$for which exhaustive exploration is feasible. (Hint:Derive a lower bound on the branching factor by considering the maximumnumber of squares that a queen can attack in any column.)",
        "url": " /search-exercises/ex_7/"
      }
    
  
    ,
      "search-exercises-ex-36":  {
        "title": "Exercise 3.36",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Invent a heuristic function for the 8-puzzle that sometimesoverestimates, and show how it can lead to a suboptimal solution on aparticular problem. (You can use a computer to help if you want.) Provethat if $h$ never overestimates by more than $c$, A using $h$ returns asolution whose cost exceeds that of the optimal solution by no more than$c$.",
        "url": " /search-exercises/ex_36/"
      }
    
  
    ,
      "search-exercises-ex-31":  {
        "title": "Exercise 3.31",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "The heuristic path algorithm Pohl:1977 is a best-first search in which the evaluation functionis $f(n) =(2-w)g(n) + wh(n)$. For what values of $w$ is this complete? For whatvalues is it optimal, assuming that $h$ is admissible? What kind ofsearch does this perform for $w=0$, $w=1$, and $w=2$?",
        "url": " /search-exercises/ex_31/"
      }
    
  
    ,
      "search-exercises-ex-38":  {
        "title": "Exercise 3.38",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "The traveling salesperson problem (TSP) can besolved with the minimum-spanning-tree (MST) heuristic, which estimatesthe cost of completing a tour, given that a partial tour has alreadybeen constructed. The MST cost of a set of cities is the smallest sum ofthe link costs of any tree that connects all the cities.1.  Show how this heuristic can be derived from a relaxed version of    the TSP.2.  Show that the MST heuristic dominates straight-line distance.3.  Write a problem generator for instances of the TSP where cities are    represented by random points in the unit square.4.  Find an efficient algorithm in the literature for constructing the    MST, and use it with A graph search to solve instances of the TSP.",
        "url": " /search-exercises/ex_38/"
      }
    
  
    ,
      "search-exercises-ex-1":  {
        "title": "Exercise 3.1",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Explain why problem formulation must follow goal formulation.",
        "url": " /search-exercises/ex_1/"
      }
    
  
    ,
      "search-exercises-ex-6":  {
        "title": "Exercise 3.6",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Show that the 8-puzzle states are dividedinto two disjoint sets, such that any state is reachable from any otherstate in the same set, while no state is reachable from any state in theother set. (Hint: See Berlekamp+al:1982) Devise a procedure to decidewhich set a given state is in, and explain why this is useful forgenerating random states.",
        "url": " /search-exercises/ex_6/"
      }
    
  
    ,
      "search-exercises-ex-8":  {
        "title": "Exercise 3.8",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Give a complete problem formulation for each of the following. Choose aformulation that is precise enough to be implemented.1.  Using only four colors, you have to color a planar map in such a way    that no two adjacent regions have the same color.2.  A 3-foot-tall monkey is in a room where some bananas are suspended    from the 8-foot ceiling. He would like to get the bananas. The room    contains two stackable, movable, climbable 3-foot-high crates.3.  You have a program that outputs the message “illegal input record”    when fed a certain file of input records. You know that processing    of each record is independent of the other records. You want to    discover what record is illegal.4.  You have three jugs, measuring 12 gallons, 8 gallons, and 3 gallons,    and a water faucet. You can fill the jugs up or empty them out from    one to another or onto the ground. You need to measure out exactly    one gallon.",
        "url": " /search-exercises/ex_8/"
      }
    
  
    ,
      "search-exercises-ex-39":  {
        "title": "Exercise 3.39",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "On page Gaschnig-h-page , we defined the relaxation of the 8-puzzle inwhich a tile can move from square A to square B if B is blank. The exactsolution of this problem defines Gaschnig&#39;s heuristic Gaschnig:1979. Explain why Gaschnig’sheuristic is at least as accurate as $h_1$ (misplaced tiles), and showcases where it is more accurate than both $h_1$ and $h_2$ (Manhattandistance). Explain how to calculate Gaschnig’s heuristic efficiently.",
        "url": " /search-exercises/ex_39/"
      }
    
  
    ,
      "search-exercises-ex-30":  {
        "title": "Exercise 3.30",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Accurate heuristics don’t necessarily reduce search time in the worstcase. Given any depth $d$, define a search problem with a goal node atdepth $d$, and write a heuristic function such that $|h(n) - h^*(n)|  le O(log h^*(n))$ but $A^*$ expands all nodes of depth lessthan $d$.",
        "url": " /search-exercises/ex_30/"
      }
    
  
    ,
      "search-exercises-ex-37":  {
        "title": "Exercise 3.37",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Prove that if a heuristic isconsistent, it must be admissible. Construct an admissible heuristicthat is not consistent.",
        "url": " /search-exercises/ex_37/"
      }
    
  
    
  
    ,
      "logical-inference-exercises-ex-11":  {
        "title": "Exercise 9.11",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Suppose you are given the following axioms: 1. $0 leq 3$. 2. $7 leq 9$. 3. ${forall,x;;} ; ; x leq x$. 4. ${forall,x;;} ; ; x leq x+0$. 5. ${forall,x;;} ; ; x+0 leq x$. 6. ${forall,x,y;;} ; ; x+y leq y+x$. 7. ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z$ ${:;{Rightarrow}:;}$ $w+x leq y+z$. 8. ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$ 1.  Give a backward-chaining proof of the sentence $7 leq 3+9$. (Be    sure, of course, to use only the axioms given here, not anything    else you may know about arithmetic.) Show only the steps that leads    to success, not the irrelevant steps.2.  Give a forward-chaining proof of the sentence $7 leq 3+9$. Again,    show only the steps that lead to success.",
        "url": " /logical-inference-exercises/ex_11/"
      }
    
  
    ,
      "logical-inference-exercises-ex-16":  {
        "title": "Exercise 9.16",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "In this exercise, use the sentences you wrote inExercise fol-horses-exercise to answer a question byusing a backward-chaining algorithm.1.  Draw the proof tree generated by an exhaustive backward-chaining    algorithm for the query ${exists,h;;}{Horse}(h)$, where    clauses are matched in the order given.2.  What do you notice about this domain?3.  How many solutions for $h$ actually follow from your sentences?4.  Can you think of a way to find all of them? (Hint:    See Smith+al:1986.)",
        "url": " /logical-inference-exercises/ex_16/"
      }
    
  
    ,
      "logical-inference-exercises-ex-29":  {
        "title": "Exercise 9.29",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Here are two sentences in the language offirst-order logic:-   (A)    ${forall,x;;} {exists,y;;} ( x geq y )$-   (B)    ${exists,y;;} {forall,x;;} ( x geq y )$1.  Assume that the variables range over all the natural numbers    $0,1,2,ldots, infty$ and that the “$geq$” predicate means “is    greater than or equal to.” Under this interpretation, translate (A)    and (B) into English.2.  Is (A) true under this interpretation?3.  Is (B) true under this interpretation?4.  Does (A) logically entail (B)?5.  Does (B) logically entail (A)?6.  Using resolution, try to prove that (A) follows from (B). Do this    even if you think that (B) does not logically entail (A); continue    until the proof breaks down and you cannot proceed (if it does    break down). Show the unifying substitution for each resolution    step. If the proof fails, explain exactly where, how, and why it    breaks down.7.  Now try to prove that (B) follows from (A).",
        "url": " /logical-inference-exercises/ex_29/"
      }
    
  
    ,
      "logical-inference-exercises-ex-20":  {
        "title": "Exercise 9.20",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "This exercise looks at sorting in Prolog.1.  Write Prolog clauses that define the predicate    sorted(L), which is true if and only if list    L is sorted in ascending order.2.  Write a Prolog definition for the predicate perm(L,M),    which is true if and only if L is a permutation of    M.3.  Define sort(L,M) (M is a sorted version of    L) using perm and sorted.4.  Run sort on longer and longer lists until you lose    patience. What is the time complexity of your program?5.  Write a faster sorting algorithm, such as insertion sort or    quicksort, in Prolog.",
        "url": " /logical-inference-exercises/ex_20/"
      }
    
  
    ,
      "logical-inference-exercises-ex-27":  {
        "title": "Exercise 9.27",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "From “Horses are animals,” it follows that “The head of a horse is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:1.  Translate the premise and the conclusion into the language of    first-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning    “$h$ is the head of $x$”), ${Horse}(x)$, and ${Animal}(x)$.2.  Negate the conclusion, and convert the premise and the negated    conclusion into conjunctive normal form.3.  Use resolution to show that the conclusion follows from the premise.",
        "url": " /logical-inference-exercises/ex_27/"
      }
    
  
    ,
      "logical-inference-exercises-ex-18":  {
        "title": "Exercise 9.18",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)        P(X,[X|Y]).        P(X,[Y|Z]) :- P(X,Z).1.  Show proof trees and solutions for the queries    P(A,[2,1,3]) and P(2,[1,A,3]).2.  What standard list operation does P represent?",
        "url": " /logical-inference-exercises/ex_18/"
      }
    
  
    ,
      "logical-inference-exercises-ex-26":  {
        "title": "Exercise 9.26",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Construct an example of two clauses that can be resolved together in twodifferent ways giving two different outcomes.",
        "url": " /logical-inference-exercises/ex_26/"
      }
    
  
    ,
      "logical-inference-exercises-ex-19":  {
        "title": "Exercise 9.19",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)        P(X,[X|Y]).        P(X,[Y|Z]) :- P(X,Z).1.  Show proof trees and solutions for the queries    P(A,[1,2,3]) and P(2,[1,A,3]).2.  What standard list operation does P represent?",
        "url": " /logical-inference-exercises/ex_19/"
      }
    
  
    ,
      "logical-inference-exercises-ex-21":  {
        "title": "Exercise 9.21",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "This exercise looks at the recursiveapplication of rewrite rules, using logic programming. A rewrite rule(or demodulator in terminology) is anequation with a specified direction. For example, the rewrite rule$x+0 rightarrow x$ suggests replacing any expression that matches $x+0$with the expression $x$. Rewrite rules are a key component of equationalreasoning systems. Use the predicate rewrite(X,Y) torepresent rewrite rules. For example, the earlier rewrite rule iswritten as rewrite(X+0,X). Some terms areprimitive and cannot be further simplified; thus, wewrite primitive(0) to say that 0 is a primitive term.1.  Write a definition of a predicate simplify(X,Y), that    is true when Y is a simplified version of    X—that is, when no further rewrite rules apply to any    subexpression of Y.2.  Write a collection of rules for the simplification of expressions    involving arithmetic operators, and apply your simplification    algorithm to some sample expressions.3.  Write a collection of rewrite rules for symbolic differentiation,    and use them along with your simplification rules to differentiate    and simplify expressions involving arithmetic expressions,    including exponentiation.",
        "url": " /logical-inference-exercises/ex_21/"
      }
    
  
    ,
      "logical-inference-exercises-ex-17":  {
        "title": "Exercise 9.17",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Trace the execution of the backward-chainingalgorithm in Figure backward-chaining-algorithm(page backward-chaining-algorithm when it is applied to solve the crime problem(page west-problem-page. Show the sequence of values taken on by the${goals}$ variable, and arrange them into a tree.",
        "url": " /logical-inference-exercises/ex_17/"
      }
    
  
    ,
      "logical-inference-exercises-ex-28":  {
        "title": "Exercise 9.28",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "From “Sheep are animals,” it follows that “The head of a sheep is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:1.  Translate the premise and the conclusion into the language of    first-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning    “$h$ is the head of $x$”), ${Sheep}(x)$, and ${Animal}(x)$.2.  Negate the conclusion, and convert the premise and the negated    conclusion into conjunctive normal form.3.  Use resolution to show that the conclusion follows from the premise.",
        "url": " /logical-inference-exercises/ex_28/"
      }
    
  
    ,
      "logical-inference-exercises-ex-10":  {
        "title": "Exercise 9.10",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Explain how to write any given 3-SAT problem ofarbitrary size using a single first-order definite clause and no morethan 30 ground facts.",
        "url": " /logical-inference-exercises/ex_10/"
      }
    
  
    ,
      "logical-inference-exercises-ex-3":  {
        "title": "Exercise 9.3",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Suppose a knowledge base contains just one sentence,$exists,x {AsHighAs}(x,{Everest})$. Which of the following arelegitimate results of applying Existential Instantiation?1.  ${AsHighAs}({Everest},{Everest})$.2.  ${AsHighAs}({Kilimanjaro},{Everest})$.3.  ${AsHighAs}({Kilimanjaro},{Everest}) land {AsHighAs}({BenNevis},{Everest})$    (after two applications).",
        "url": " /logical-inference-exercises/ex_3/"
      }
    
  
    ,
      "logical-inference-exercises-ex-4":  {
        "title": "Exercise 9.4",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "For each pair of atomic sentences, give the most general unifier if itexists:1.  $P(A,B,B)$, $P(x,y,z)$.2.  $Q(y,G(A,B))$, $Q(G(x,x),y)$.3.  ${Older}({Father}(y),y)$, ${Older}({Father}(x),{John})$.4.  ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.",
        "url": " /logical-inference-exercises/ex_4/"
      }
    
  
    ,
      "logical-inference-exercises-ex-5":  {
        "title": "Exercise 9.5",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "For each pair of atomic sentences, give the most general unifier if itexists:1.  $P(A,B,B)$, $P(x,y,z)$.2.  $Q(y,G(A,B))$, $Q(G(x,x),y)$.3.  ${Older}({Father}(y),y)$, ${Older}({Father}(x),{John})$.4.  ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.",
        "url": " /logical-inference-exercises/ex_5/"
      }
    
  
    ,
      "logical-inference-exercises-ex-2":  {
        "title": "Exercise 9.2",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "From ${Likes}({Jerry},{IceCream})$ it seems reasonable to infer${exists,x;;}{Likes}(x,{IceCream})$. Write down a general inference rule, , thatsanctions this inference. State carefully the conditions that must besatisfied by the variables and terms involved.",
        "url": " /logical-inference-exercises/ex_2/"
      }
    
  
    ,
      "logical-inference-exercises-ex-15":  {
        "title": "Exercise 9.15",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "One might suppose that we can avoid theproblem of variable conflict in unification during backward chaining bystandardizing apart all of the sentences in the knowledge base once andfor all. Show that, for some sentences, this approach cannot work.(Hint: Consider a sentence in which one part unifies withanother.)",
        "url": " /logical-inference-exercises/ex_15/"
      }
    
  
    ,
      "logical-inference-exercises-ex-12":  {
        "title": "Exercise 9.12",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Suppose you are given the following axioms:&amp;gt; 1. $0 leq 4$.&amp;gt; 2. $5 leq 9$.&amp;gt; 3. ${forall,x;;} ; ; x leq x$.&amp;gt; 4. ${forall,x;;} ; ; x leq x+0$.&amp;gt; 5. ${forall,x;;} ; ; x+0 leq x$.&amp;gt; 6. ${forall,x,y;;} ; ; x+y leq y+x$.&amp;gt; 7. ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z {:;{Rightarrow}:;}$ $w+x leq y+z$.&amp;gt; 8. ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$1.  Give a backward-chaining proof of the sentence $5 leq 4+9$. (Be    sure, of course, to use only the axioms given here, not anything    else you may know about arithmetic.) Show only the steps that leads    to success, not the irrelevant steps.2.  Give a forward-chaining proof of the sentence $5 leq 4+9$. Again,    show only the steps that lead to success.",
        "url": " /logical-inference-exercises/ex_12/"
      }
    
  
    ,
      "logical-inference-exercises-ex-24":  {
        "title": "Exercise 9.24",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Let $cal L$ be the first-order language with a single predicate$S(p,q)$, meaning “$p$ shaves  $q$.” Assume a domain of people.1.  Consider the sentence “There exists a person $P$ who shaves every    one who does not shave themselves, and only people that do not    shave themselves.” Express this in $cal L$.2.  Convert the sentence in (a) to clausal form.3.  Construct a resolution proof to show that the clauses in (b) are    inherently inconsistent. (Note: you do not need any    additional axioms.)",
        "url": " /logical-inference-exercises/ex_24/"
      }
    
  
    ,
      "logical-inference-exercises-ex-23":  {
        "title": "Exercise 9.23",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Suppose a knowledge base contains just the following first-order Hornclauses:$$Ancestor(Mother(x),x)$$$$Ancestor(x,y) land Ancestor(y,z) implies Ancestor(x,z)$$Consider a forward chaining algorithm that, on the $j$th iteration,terminates if the KB contains a sentence that unifies with the query,else adds to the KB every atomic sentence that can be inferred from thesentences already in the KB after iteration $j-1$.1.  For each of the following queries, say whether the algorithm    will (1) give an answer (if so, write down that answer); or (2)    terminate with no answer; or (3) never terminate.    1.  $Ancestor(Mother(y),John)$    2.  $Ancestor(Mother(Mother(y)),John)$    3.  $Ancestor(Mother(Mother(Mother(y))),Mother(y))$    4.  $Ancestor(Mother(John),Mother(Mother(John)))$2.  Can a resolution algorithm prove the sentence    $lnot Ancestor(John,John)$ from the original knowledge base?    Explain how, or why not.3.  Suppose we add the assertion that $lnot(Mother(x)x)$ and    augment the resolution algorithm with inference rules for equality.    Now what is the answer to (b)?",
        "url": " /logical-inference-exercises/ex_23/"
      }
    
  
    ,
      "logical-inference-exercises-ex-22":  {
        "title": "Exercise 9.22",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "This exercise considers the implementation of search algorithms inProlog. Suppose that successor(X,Y) is true when stateY is a successor of state X; and thatgoal(X) is true when X is a goal state. Writea definition for solve(X,P), which means thatP is a path (list of states) beginning with X,ending in a goal state, and consisting of a sequence of legal steps asdefined by successor. You will find that depth-first searchis the easiest way to do this. How easy would it be to add heuristicsearch control?",
        "url": " /logical-inference-exercises/ex_22/"
      }
    
  
    ,
      "logical-inference-exercises-ex-25":  {
        "title": "Exercise 9.25",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "How can resolution be used to show that a sentence is valid?Unsatisfiable?",
        "url": " /logical-inference-exercises/ex_25/"
      }
    
  
    ,
      "logical-inference-exercises-ex-13":  {
        "title": "Exercise 9.13",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "A popular children’s riddle is “Brothers and sisters have I none, butthat man’s father is my father’s son.” Use the rules of the familydomain (Section kinship-domain-section onpage kinship-domain-section to show who that man is. You may apply any of theinference methods described in this chapter. Why do you think that thisriddle is difficult?",
        "url": " /logical-inference-exercises/ex_13/"
      }
    
  
    ,
      "logical-inference-exercises-ex-14":  {
        "title": "Exercise 9.14",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Suppose we put into a logical knowledge base a segment of theU.S. census data listing the age, city of residence, date of birth, andmother of every person, using social security numbers as identifyingconstants for each person. Thus, George’s age is given by${Age}(443-65-1282, 56)$. Which of the followingindexing schemes S1–S5 enable an efficient solution for which of thequeries Q1–Q4 (assuming normal backward chaining)?- S1: an index for each atom in each position.- S2: an index for each first argument.- S3: an index for each predicate atom.- S4: an index for each combination of predicate and first argument.- S5: an index for each combination of predicate and second argument and an index for each first argument.- Q1: ${Age}(mbox 443-44-4321,x)$- Q2: ${ResidesIn}(x,{Houston})$- Q3: ${Mother}(x,y)$- Q4: ${Age}(x,{34}) land {ResidesIn}(x,{TinyTownUSA})$",
        "url": " /logical-inference-exercises/ex_14/"
      }
    
  
    ,
      "logical-inference-exercises-ex-9":  {
        "title": "Exercise 9.9",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "This question considers Horn KBs, such as the following:$$begin{array}{l}P(F(x)) {:;{Rightarrow}:;}P(x)Q(x) {:;{Rightarrow}:;}P(F(x))P(A)Q(B)end{array}$$ Let FC be a breadth-first forward-chaining algorithm thatrepeatedly adds all consequences of currently satisfied rules; let BC bea depth-first left-to-right backward-chaining algorithm that triesclauses in the order given in the KB. Which of the following are true?1.  FC will infer the literal $Q(A)$.2.  FC will infer the literal $P(B)$.3.  If FC has failed to infer a given literal, then it is not entailed    by the KB.4.  BC will return ${true}$ given the query $P(B)$.5.  If BC does not return ${true}$ given a query literal, then it is    not entailed by the KB.",
        "url": " /logical-inference-exercises/ex_9/"
      }
    
  
    ,
      "logical-inference-exercises-ex-7":  {
        "title": "Exercise 9.7",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Write down logical representations for thefollowing sentences, suitable for use with Generalized Modus Ponens:1.  Horses, cows, and pigs are mammals.2.  An offspring of a horse is a horse.3.  Bluebeard is a horse.4.  Bluebeard is Charlie’s parent.5.  Offspring and parent are inverse relations.6.  Every mammal has a parent.",
        "url": " /logical-inference-exercises/ex_7/"
      }
    
  
    ,
      "logical-inference-exercises-ex-31":  {
        "title": "Exercise 9.31",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "We said in this chapter that resolution cannot be used to generate alllogical consequences of a set of sentences. Can any algorithm do this?",
        "url": " /logical-inference-exercises/ex_31/"
      }
    
  
    ,
      "logical-inference-exercises-ex-1":  {
        "title": "Exercise 9.1",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Prove that Universal Instantiation is sound and that ExistentialInstantiation produces an inferentially equivalent knowledge base.",
        "url": " /logical-inference-exercises/ex_1/"
      }
    
  
    ,
      "logical-inference-exercises-ex-6":  {
        "title": "Exercise 9.6",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Consider the subsumption lattices shownin Figure subsumption-lattice-figure(page subsumption-lattice-figure.1.  Construct the lattice for the sentence    ${Employs}({Mother}({John}),{Father}({Richard}))$.2.  Construct the lattice for the sentence ${Employs}({IBM},y)$    (“Everyone works for IBM”). Remember to include every kind of query    that unifies with the sentence.3.  Assume that indexes each sentence under every node in its    subsumption lattice. Explain how should work when some of these    sentences contain variables; use as examples the sentences in (a)    and (b) and the query ${Employs}(x,{Father}(x))$.",
        "url": " /logical-inference-exercises/ex_6/"
      }
    
  
    ,
      "logical-inference-exercises-ex-8":  {
        "title": "Exercise 9.8",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "These questions concern concern issues with substitution andSkolemization.1.  Given the premise ${forall,x;;} {exists,y;;} P(x,y)$, it is    not valid to conclude that ${exists,q;;} P(q,q)$. Give an    example of a predicate $P$ where the first is true but the second    is false.2.  Suppose that an inference engine is incorrectly written with the    occurs check omitted, so that it allows a literal like $P(x,F(x))$    to be unified with $P(q,q)$. (As mentioned, most standard    implementations of Prolog actually do allow this.) Show that such an    inference engine will allow the conclusion ${exists,y;;} P(q,q)$    to be inferred from the premise    ${forall,x;;} {exists,y;;} P(x,y)$.3.  Suppose that a procedure that converts first-order logic to clausal    form incorrectly Skolemizes    ${forall,x;;} {exists,y;;} P(x,y)$ to $P(x,Sk0)$—that is, it    replaces $y$ by a Skolem constant rather than by a Skolem function    of $x$. Show that an inference engine that uses such a procedure    will likewise allow ${exists,q;;} P(q,q)$ to be inferred from    the premise ${forall,x;;} {exists,y;;} P(x,y)$.4.  A common error among students is to suppose that, in unification,    one is allowed to substitute a term for a Skolem constant instead of    for a variable. For instance, they will say that the formulas    $P(Sk1)$ and $P(A)$ can be unified under the substitution    ${ Sk1/A }$. Give an example where this leads to an    invalid inference.",
        "url": " /logical-inference-exercises/ex_8/"
      }
    
  
    ,
      "logical-inference-exercises-ex-30":  {
        "title": "Exercise 9.30",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Resolution can produce nonconstructive proofs for queries withvariables, so we had to introduce special mechanisms to extract definiteanswers. Explain why this issue does not arise with knowledge basescontaining only definite clauses.",
        "url": " /logical-inference-exercises/ex_30/"
      }
    
  
    
  
    ,
      "agents-exercises-ex-11":  {
        "title": "Exercise 2.11",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Implement a performance-measuring environmentsimulator for the vacuum-cleaner world depicted inFigure vacuum-world-figure and specified onpage vacuum-rationality-page. Your implementation should be modular so that thesensors, actuators, and environment characteristics (size, shape, dirtplacement, etc.) can be changed easily. (Note: for somechoices of programming language and operating system there are alreadyimplementations in the online code repository.)",
        "url": " /agents-exercises/ex_11/"
      }
    
  
    ,
      "agents-exercises-ex-16":  {
        "title": "Exercise 2.16",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "The vacuum environments in the precedingexercises have all been deterministic. Discuss possible agent programsfor each of the following stochastic versions:1.  Murphy’s law: twenty-five percent of the time, the Suck action    fails to clean the floor if it is dirty and deposits dirt onto the    floor if the floor is clean. How is your agent program affected if    the dirt sensor gives the wrong answer 10% of the time?2.  Small children: At each time step, each clean square has a 10%    chance of becoming dirty. Can you come up with a rational agent    design for this case?",
        "url": " /agents-exercises/ex_16/"
      }
    
  
    ,
      "agents-exercises-ex-10":  {
        "title": "Exercise 2.10",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Consider a simple thermostat that turns on a furnace when thetemperature is at least 3 degrees below the setting, and turns off afurnace when the temperature is at least 3 degrees above the setting. Isa thermostat an instance of a simple reflex agent, a model-based reflexagent, or a goal-based agent?",
        "url": " /agents-exercises/ex_10/"
      }
    
  
    ,
      "agents-exercises-ex-3":  {
        "title": "Exercise 2.3",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Write an essay on the relationship between evolution and one or more ofautonomy, intelligence, and learning.",
        "url": " /agents-exercises/ex_3/"
      }
    
  
    ,
      "agents-exercises-ex-4":  {
        "title": "Exercise 2.4",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "For each of the following assertions, say whether it is true or falseand support your answer with examples or counterexamples whereappropriate.1.  An agent that senses only partial information about the state cannot    be perfectly rational.2.  There exist task environments in which no pure reflex agent can    behave rationally.3.  There exists a task environment in which every agent is rational.4.  The input to an agent program is the same as the input to the    agent function.5.  Every agent function is implementable by some    program/machine combination.6.  Suppose an agent selects its action uniformly at random from the set    of possible actions. There exists a deterministic task environment    in which this agent is rational.7.  It is possible for a given agent to be perfectly rational in two    distinct task environments.8.  Every agent is rational in an unobservable environment.9.  A perfectly rational poker-playing agent never loses.",
        "url": " /agents-exercises/ex_4/"
      }
    
  
    ,
      "agents-exercises-ex-5":  {
        "title": "Exercise 2.5 (PEAS-exercise)",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Playing soccer.-   Exploring the subsurface oceans of Titan.-   Shopping for used AI books on the Internet.-   Playing a tennis match.-   Practicing tennis against a wall.-   Performing a high jump.-   Knitting a sweater.-   Bidding on an item at an auction.",
        "url": " /agents-exercises/ex_5/"
      }
    
  
    ,
      "agents-exercises-ex-2":  {
        "title": "Exercise 2.2",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Let us examine the rationality of variousvacuum-cleaner agent functions.1.  Show that the simple vacuum-cleaner agent function described in    Figure vacuum-agent-function-table is indeed    rational under the assumptions listed on page vacuum-rationality-page2.  Describe a rational agent function for the case in which each    movement costs one point. Does the corresponding agent program    require internal state?3.  Discuss possible agent designs for the cases in which clean squares    can become dirty and the geography of the environment is unknown.    Does it make sense for the agent to learn from its experience in    these cases? If so, what should it learn? If not, why not?",
        "url": " /agents-exercises/ex_2/"
      }
    
  
    ,
      "agents-exercises-ex-15":  {
        "title": "Exercise 2.15",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Repeat Exercise vacuum-unknown-geog-exercise for the case inwhich the location sensor is replaced with a “bump” sensor that detectsthe agent’s attempts to move into an obstacle or to cross the boundariesof the environment. Suppose the bump sensor stops working; how shouldthe agent behave?",
        "url": " /agents-exercises/ex_15/"
      }
    
  
    ,
      "agents-exercises-ex-12":  {
        "title": "Exercise 2.12",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Implement a simple reflex agent for the vacuum environment inExercise vacuum-start-exercise. Run the environmentwith this agent for all possible initial dirt configurations and agentlocations. Record the performance score for each configuration and theoverall average score.",
        "url": " /agents-exercises/ex_12/"
      }
    
  
    ,
      "agents-exercises-ex-13":  {
        "title": "Exercise 2.13",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the agent is penalized one point for each movement.1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  What about a reflex agent with state? Design such an agent.3.  How do your answers to 1 and 2    change if the agent’s percepts give it the clean/dirty status of    every square in the environment?",
        "url": " /agents-exercises/ex_13/"
      }
    
  
    ,
      "agents-exercises-ex-14":  {
        "title": "Exercise 2.14",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the geography of the environment—its extent, boundaries, andobstacles—is unknown, as is the initial dirt configuration. (The agentcan go Up and Down as well as Left and Right.)1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  Can a simple reflex agent with a randomized agent    function outperform a simple reflex agent? Design such an agent and    measure its performance on several environments.3.  Can you design an environment in which your randomized agent will    perform poorly? Show your results.4.  Can a reflex agent with state outperform a simple reflex agent?    Design such an agent and measure its performance on several    environments. Can you design a rational agent of this type?",
        "url": " /agents-exercises/ex_14/"
      }
    
  
    ,
      "agents-exercises-ex-9":  {
        "title": "Exercise 2.9",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Write pseudocode agent programs for the goal-based and utility-basedagents.",
        "url": " /agents-exercises/ex_9/"
      }
    
  
    ,
      "agents-exercises-ex-7":  {
        "title": "Exercise 2.7",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Define in your own words the following terms: agent, agent function,agent program, rationality, autonomy, reflex agent, model-based agent,goal-based agent, utility-based agent, learning agent.",
        "url": " /agents-exercises/ex_7/"
      }
    
  
    ,
      "agents-exercises-ex-1":  {
        "title": "Exercise 2.1",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Suppose that the performance measure is concerned with just the first$T$ time steps of the environment and ignores everything thereafter.Show that a rational agent’s action may depend not just on the state ofthe environment but also on the time step it has reached.",
        "url": " /agents-exercises/ex_1/"
      }
    
  
    ,
      "agents-exercises-ex-6":  {
        "title": "Exercise 2.6",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Performing a gymnastics floor routine.-   Exploring the subsurface oceans of Titan.-   Playing soccer.-   Shopping for used AI books on the Internet.-   Practicing tennis against a wall.-   Performing a high jump.-   Bidding on an item at an auction.",
        "url": " /agents-exercises/ex_6/"
      }
    
  
    ,
      "agents-exercises-ex-8":  {
        "title": "Exercise 2.8",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "This exercise explores the differences betweenagent functions and agent programs.1.  Can there be more than one agent program that implements a given    agent function? Give an example, or show why one is not possible.2.  Are there agent functions that cannot be implemented by any agent    program?3.  Given a fixed machine architecture, does each agent program    implement exactly one agent function?4.  Given an architecture with $n$ bits of storage, how many different    possible agent programs are there?5.  Suppose we keep the agent program fixed but speed up the machine by    a factor of two. Does that change the agent function?",
        "url": " /agents-exercises/ex_8/"
      }
    
  
    ,
      "agents-exercises":  {
        "title": "Intelligent Agent",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "2. Intelligent Agents            Exercise 1                                Suppose that the performance measure is concerned with just the first$T$ time steps of the environment and ignores everything thereafter.Show that a rational agent’s action may depend not just on the state ofthe environment but also on the time step it has reached.                Exercise 2 (vacuum-rationality-exercise)                                Let us examine the rationality of variousvacuum-cleaner agent functions.1.  Show that the simple vacuum-cleaner agent function described in    Figure vacuum-agent-function-table is indeed    rational under the assumptions listed on page vacuum-rationality-page2.  Describe a rational agent function for the case in which each    movement costs one point. Does the corresponding agent program    require internal state?3.  Discuss possible agent designs for the cases in which clean squares    can become dirty and the geography of the environment is unknown.    Does it make sense for the agent to learn from its experience in    these cases? If so, what should it learn? If not, why not?                Exercise 3                                Write an essay on the relationship between evolution and one or more ofautonomy, intelligence, and learning.                Exercise 4                                For each of the following assertions, say whether it is true or falseand support your answer with examples or counterexamples whereappropriate.1.  An agent that senses only partial information about the state cannot    be perfectly rational.2.  There exist task environments in which no pure reflex agent can    behave rationally.3.  There exists a task environment in which every agent is rational.4.  The input to an agent program is the same as the input to the    agent function.5.  Every agent function is implementable by some    program/machine combination.6.  Suppose an agent selects its action uniformly at random from the set    of possible actions. There exists a deterministic task environment    in which this agent is rational.7.  It is possible for a given agent to be perfectly rational in two    distinct task environments.8.  Every agent is rational in an unobservable environment.9.  A perfectly rational poker-playing agent never loses.                Exercise 5 (PEAS-exercise)                                For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Playing soccer.-   Exploring the subsurface oceans of Titan.-   Shopping for used AI books on the Internet.-   Playing a tennis match.-   Practicing tennis against a wall.-   Performing a high jump.-   Knitting a sweater.-   Bidding on an item at an auction.                Exercise 6                                For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Performing a gymnastics floor routine.-   Exploring the subsurface oceans of Titan.-   Playing soccer.-   Shopping for used AI books on the Internet.-   Practicing tennis against a wall.-   Performing a high jump.-   Bidding on an item at an auction.                Exercise 7 (agent-fn-prog-exercise)                                Define in your own words the following terms: agent, agent function,agent program, rationality, autonomy, reflex agent, model-based agent,goal-based agent, utility-based agent, learning agent.                Exercise 8                                This exercise explores the differences betweenagent functions and agent programs.1.  Can there be more than one agent program that implements a given    agent function? Give an example, or show why one is not possible.2.  Are there agent functions that cannot be implemented by any agent    program?3.  Given a fixed machine architecture, does each agent program    implement exactly one agent function?4.  Given an architecture with $n$ bits of storage, how many different    possible agent programs are there?5.  Suppose we keep the agent program fixed but speed up the machine by    a factor of two. Does that change the agent function?                Exercise 9                                Write pseudocode agent programs for the goal-based and utility-basedagents.    The following exercises all concern the implementation of environmentsand agents for the vacuum-cleaner world.            Exercise 10 (vacuum-start-exercise)                                Consider a simple thermostat that turns on a furnace when thetemperature is at least 3 degrees below the setting, and turns off afurnace when the temperature is at least 3 degrees above the setting. Isa thermostat an instance of a simple reflex agent, a model-based reflexagent, or a goal-based agent?                Exercise 11                                Implement a performance-measuring environmentsimulator for the vacuum-cleaner world depicted inFigure vacuum-world-figure and specified onpage vacuum-rationality-page. Your implementation should be modular so that thesensors, actuators, and environment characteristics (size, shape, dirtplacement, etc.) can be changed easily. (Note: for somechoices of programming language and operating system there are alreadyimplementations in the online code repository.)                Exercise 12 (vacuum-motion-penalty-exercise)                                Implement a simple reflex agent for the vacuum environment inExercise vacuum-start-exercise. Run the environmentwith this agent for all possible initial dirt configurations and agentlocations. Record the performance score for each configuration and theoverall average score.                Exercise 13 (vacuum-unknown-geog-exercise)                                Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the agent is penalized one point for each movement.1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  What about a reflex agent with state? Design such an agent.3.  How do your answers to 1 and 2    change if the agent’s percepts give it the clean/dirty status of    every square in the environment?                Exercise 14 (vacuum-bump-exercise)                                Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the geography of the environment—its extent, boundaries, andobstacles—is unknown, as is the initial dirt configuration. (The agentcan go Up and Down as well as Left and Right.)1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  Can a simple reflex agent with a randomized agent    function outperform a simple reflex agent? Design such an agent and    measure its performance on several environments.3.  Can you design an environment in which your randomized agent will    perform poorly? Show your results.4.  Can a reflex agent with state outperform a simple reflex agent?    Design such an agent and measure its performance on several    environments. Can you design a rational agent of this type?                Exercise 15 (vacuum-finish-exercise)                                Repeat Exercise vacuum-unknown-geog-exercise for the case inwhich the location sensor is replaced with a “bump” sensor that detectsthe agent’s attempts to move into an obstacle or to cross the boundariesof the environment. Suppose the bump sensor stops working; how shouldthe agent behave?                Exercise 16                                The vacuum environments in the precedingexercises have all been deterministic. Discuss possible agent programsfor each of the following stochastic versions:1.  Murphy’s law: twenty-five percent of the time, the Suck action    fails to clean the floor if it is dirty and deposits dirt onto the    floor if the floor is clean. How is your agent program affected if    the dirt sensor gives the wrong answer 10% of the time?2.  Small children: At each time step, each clean square has a 10%    chance of becoming dirty. Can you come up with a rational agent    design for this case?    ",
        "url": " /agents-exercises/"
      }
    
  
    ,
      "csp-exercises-ex-11":  {
        "title": "Exercise 6.11",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${green},V{red}$ for the problemshown in Figure australia-figure.",
        "url": " /csp-exercises/ex_11/"
      }
    
  
    ,
      "csp-exercises-ex-16":  {
        "title": "Exercise 6.16",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "We introduced Sudoku as a CSP to be solved by search over partialassignments because that is the way people generally undertake solvingSudoku problems. It is also possible, of course, to attack theseproblems with local search over complete assignments. How well would alocal solver using the min-conflicts heuristic do on Sudoku problems?",
        "url": " /csp-exercises/ex_16/"
      }
    
  
    ,
      "csp-exercises-ex-20":  {
        "title": "Exercise 6.20",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Consider the problem of tiling a surface (completely and exactlycovering it) with $n$ dominoes ($2times1$ rectangles). The surface is an arbitrary edge-connected (i.e.,adjacent along an edge, not just a corner) collection of $2n$$1times 1$ squares (e.g., a checkerboard, a checkerboard with somesquares missing, a $10times 1$ row of squares, etc.).1.  Formulate this problem precisely as a CSP where the dominoes are    the variables.2.  Formulate this problem precisely as a CSP where the squares are the    variables, keeping the state space as small as possible.    (*Hint:* does it matter which particular domino goes on    a given pair of squares?)3.  Construct a surface consisting of 6 squares such that your CSP    formulation from part (b) has a *tree-structured*    constraint graph.4.  Describe exactly the set of solvable instances that have a    tree-structured constraint graph.",
        "url": " /csp-exercises/ex_20/"
      }
    
  
    ,
      "csp-exercises-ex-18":  {
        "title": "Exercise 6.18",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Define in your own words the terms constraint, commutativity, arcconsistency, backjumping, min-conflicts, and cycle cutset.",
        "url": " /csp-exercises/ex_18/"
      }
    
  
    ,
      "csp-exercises-ex-19":  {
        "title": "Exercise 6.19",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Suppose that a graph is known to have a cycle cutset of no more than $k$nodes. Describe a simple algorithm for finding a minimal cycle cutsetwhose run time is not much more than $O(n^k)$ for a CSP with $n$variables. Search the literature for methods for finding approximatelyminimal cycle cutsets in time that is polynomial in the size of thecutset. Does the existence of such algorithms make the cycle cutsetmethod practical?",
        "url": " /csp-exercises/ex_19/"
      }
    
  
    ,
      "csp-exercises-ex-17":  {
        "title": "Exercise 6.17",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Define in your own words the terms constraint, backtracking search, arcconsistency, backjumping, min-conflicts, and cycle cutset.",
        "url": " /csp-exercises/ex_17/"
      }
    
  
    ,
      "csp-exercises-ex-10":  {
        "title": "Exercise 6.100",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Generate random instances of map-coloring problems as follows: scatter$n$ points on the unit square; select a point $X$ at random, connect $X$by a straight line to the nearest point $Y$ such that $X$ is not alreadyconnected to $Y$ and the line crosses no other line; repeat the previousstep until no more connections are possible. The points representregions on the map and the lines connect neighbors. Now try to find$k$-colorings of each map, for both $k3$ and$k4$, using min-conflicts, backtracking, backtracking withforward checking, and backtracking with MAC. Construct a table ofaverage run times for each algorithm for values of $n$ up to the largestyou can manage. Comment on your results.",
        "url": " /csp-exercises/ex_10/"
      }
    
  
    ,
      "csp-exercises-ex-3":  {
        "title": "Exercise 6.3",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Consider the problem of constructing (not solving)crossword puzzles fitting words into a rectangular grid. The grid,which is given as part of the problem, specifies which squares are blankand which are shaded. Assume that a list of words (i.e., a dictionary)is provided and that the task is to fill in the blank squares by usingany subset of the list. Formulate this problem precisely in two ways:1.  As a general search problem. Choose an appropriate search algorithm    and specify a heuristic function. Is it better to fill in blanks one    letter at a time or one word at a time?2.  As a constraint satisfaction problem. Should the variables be words    or letters?Which formulation do you think will be better? Why?",
        "url": " /csp-exercises/ex_3/"
      }
    
  
    ,
      "csp-exercises-ex-4":  {
        "title": "Exercise 6.4",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Give precise formulations for each of thefollowing as constraint satisfaction problems:1.  Rectilinear floor-planning: find non-overlapping places in a large    rectangle for a number of smaller rectangles.2.  Class scheduling: There is a fixed number of professors and    classrooms, a list of classes to be offered, and a list of possible    time slots for classes. Each professor has a set of classes that he    or she can teach.3.  Hamiltonian tour: given a network of cities connected by roads,    choose an order to visit all cities in a country without    repeating any.",
        "url": " /csp-exercises/ex_4/"
      }
    
  
    ,
      "csp-exercises-ex-5":  {
        "title": "Exercise 6.5",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Solve the cryptarithmetic problem inFigure cryptarithmetic-figure by hand, using thestrategy of backtracking with forward checking and the MRV andleast-constraining-value heuristics.",
        "url": " /csp-exercises/ex_5/"
      }
    
  
    ,
      "csp-exercises-ex-2":  {
        "title": "Exercise 6.2",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Consider the problem of placing $k$ knights on an $ntimes n$chessboard such that no two knights are attacking each other, where $k$is given and $kleq n^2$.1.  Choose a CSP formulation. In your formulation, what are the    variables?2.  What are the possible values of each variable?3.  What sets of variables are constrained, and how?4.  Now consider the problem of putting *as many knights as    possible* on the board without any attacks. Explain how to    solve this with local search by defining appropriate ACTIONS and RESULT functions    and a sensible objective function.",
        "url": " /csp-exercises/ex_2/"
      }
    
  
    ,
      "csp-exercises-ex-15":  {
        "title": "Exercise 6.15",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "The Tree-CSP-Solver (Figure tree-csp-figure) makes arcs consistentstarting at the leaves and working backwards towards the root. Why doesit do that? What would happen if it went in the opposite direction?",
        "url": " /csp-exercises/ex_15/"
      }
    
  
    ,
      "csp-exercises-ex-12":  {
        "title": "Exercise 6.12",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${red},V{blue}$ for the problemshown in Figure australia-figure.",
        "url": " /csp-exercises/ex_12/"
      }
    
  
    ,
      "csp-exercises-ex-13":  {
        "title": "Exercise 6.13",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "What is the worst-case complexity of running AC-3 on a tree-structuredCSP?",
        "url": " /csp-exercises/ex_13/"
      }
    
  
    ,
      "csp-exercises-ex-14":  {
        "title": "Exercise 6.14",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "AC-3 puts back on the queue every arc($X_{k}, X_{i}$) whenever any value is deleted from thedomain of $X_{i}$, even if each value of $X_{k}$ is consistent withseveral remaining values of $X_{i}$. Suppose that, for every arc($X_{k}, X_{i}$), we keep track of the number of remaining values of$X_{i}$ that are consistent with each value of $X_{k}$. Explain how toupdate these numbers efficiently and hence show that arc consistency canbe enforced in total time $O(n^2d^2)$.",
        "url": " /csp-exercises/ex_14/"
      }
    
  
    ,
      "csp-exercises-ex-9":  {
        "title": "Exercise 6.9",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Explain why it is a good heuristic to choose the variable that is*most* constrained but the value that is*least* constraining in a CSP search.",
        "url": " /csp-exercises/ex_9/"
      }
    
  
    ,
      "csp-exercises-ex-7":  {
        "title": "Exercise 6.7",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Consider the following logic puzzle: In five houses,each with a different color, live five persons of differentnationalities, each of whom prefers a different brand of candy, adifferent drink, and a different pet. Given the following facts, thequestions to answer are “Where does the zebra live, and in which housedo they drink water?”The Englishman lives in the red house.The Spaniard owns the dog.The Norwegian lives in the first house on the left.The green house is immediately to the right of the ivory house.The man who eats Hershey bars lives in the house next to the man withthe fox.Kit Kats are eaten in the yellow house.The Norwegian lives next to the blue house.The Smarties eater owns snails.The Snickers eater drinks orange juice.The Ukrainian drinks tea.The Japanese eats Milky Ways.Kit Kats are eaten in a house next to the house where the horse is kept.Coffee is drunk in the green house.Milk is drunk in the middle house.Discuss different representations of this problem as a CSP. Why wouldone prefer one representation over another?",
        "url": " /csp-exercises/ex_7/"
      }
    
  
    ,
      "csp-exercises-ex-1":  {
        "title": "Exercise 6.1",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "How many solutions are there for the map-coloring problem inFigure australia-figure? How many solutions if fourcolors are allowed? Two colors?",
        "url": " /csp-exercises/ex_1/"
      }
    
  
    ,
      "csp-exercises-ex-6":  {
        "title": "Exercise 6.6",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Show how a single ternary constraint such as“$A + B = C$” can be turned into three binary constraints by using anauxiliary variable. You may assume finite domains. (*Hint:*Consider a new variable that takes on values that are pairs of othervalues, and consider constraints such as “$X$ is the first element ofthe pair $Y$.”) Next, show how constraints with more than threevariables can be treated similarly. Finally, show how unary constraintscan be eliminated by altering the domains of variables. This completesthe demonstration that any CSP can be transformed into a CSP with onlybinary constraints.",
        "url": " /csp-exercises/ex_6/"
      }
    
  
    ,
      "csp-exercises-ex-8":  {
        "title": "Exercise 6.8",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Consider the graph with 8 nodes $A_1$, $A_2$, $A_3$, $A_4$, $H$, $T$,$F_1$, $F_2$. $A_i$ is connected to $A_{i+1}$ for all $i$, each $A_i$ isconnected to $H$, $H$ is connected to $T$, and $T$ is connected to each$F_i$. Find a 3-coloring of this graph by hand using the followingstrategy: backtracking with conflict-directed backjumping, the variableorder $A_1$, $H$, $A_4$, $F_1$, $A_2$, $F_2$, $A_3$, $T$, and the valueorder $R$, $G$, $B$.",
        "url": " /csp-exercises/ex_8/"
      }
    
  
    
  
    ,
      "bayes-nets-exercises-ex-11":  {
        "title": "Exercise 14.11",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the family of linear Gaussian networks, asdefined on page LG-network-page.1.  In a two-variable network, let $X_1$ be the parent of $X_2$, let    $X_1$ have a Gaussian prior, and let    ${textbf{P}}(X_2X_1)$ be a linear    Gaussian distribution. Show that the joint distribution $P(X_1,X_2)$    is a multivariate Gaussian, and calculate its covariance matrix.2.  Prove by induction that the joint distribution for a general linear    Gaussian network on $X_1,ldots,X_n$ is also a    multivariate Gaussian.",
        "url": " /bayes-nets-exercises/ex_11/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-16":  {
        "title": "Exercise 14.16",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the Bayes net shown in Figure politics-figure.1.  Which of the following are asserted by the network    structure?    1.  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.    2.  ${textbf{P}}(J|G) = {textbf{P}}(J|G,I)$.    3.  ${textbf{P}}(M|G,B,I) = {textbf{P}}(M|G,B,I,J)$.2.  Calculate the value of $P(b,i,lnot m,g,j)$.3.  Calculate the probability that someone goes to jail given that they    broke the law, have been indicted, and face a politically    motivated prosecutor.4.  A context-specific independence (see    page CSI-page) allows a variable to be independent of some of    its parents given certain values of others. In addition to the usual    conditional independences given by the graph structure, what    context-specific independences exist in the Bayes net in    Figure politics-figure?5.  Suppose we want to add the variable    $P={PresidentialPardon}$ to the network; draw the new    network and briefly explain any links you add.    A simple Bayes net with  Boolean variables B = {BrokeElectionLaw}, I = {Indicted}, M = {PoliticallyMotivatedProsecutor}, G= {FoundGuilty}, J = {Jailed}.",
        "url": " /bayes-nets-exercises/ex_16/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-20":  {
        "title": "Exercise 14.20",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the problem of generating arandom sample from a specified distribution on a single variable. Assumeyou have a random number generator that returns a random numberuniformly distributed between 0 and 1.1.  Let $X$ be a discrete variable with    $P(Xx_i)p_i$ for    $i{1,ldots,k}$. The cumulative distribution of $X$ gives the probability    that $X{x_1,ldots,x_j}$ for each possible $j$. (See    also Appendix [math-appendix].) Explain how to    calculate the cumulative distribution in $O(k)$ time and how to    generate a single sample of $X$ from it. Can the latter be done in    less than $O(k)$ time?2.  Now suppose we want to generate $N$ samples of $X$, where $Ngg k$.    Explain how to do this with an expected run time per sample that is    constant (i.e., independent of $k$).3.  Now consider a continuous-valued variable with a parameterized    distribution (e.g., Gaussian). How can samples be generated from    such a distribution?4.  Suppose you want to query a continuous-valued variable and you are    using a sampling algorithm such as LIKELIHOODWEIGHTING to do the inference. How would    you have to modify the query-answering process?",
        "url": " /bayes-nets-exercises/ex_20/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-18":  {
        "title": "Exercise 14.18",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the variable elimination algorithm inFigure elimination-ask-algorithm (page elimination-ask-algorithm).1.  Section exact-inference-section applies variable    elimination to the query    $${textbf{P}}({Burglary}{JohnCalls}{true},{MaryCalls}{true}) .$$    Perform the calculations indicated and check that the answer    is correct.2.  Count the number of arithmetic operations performed, and compare it    with the number performed by the enumeration algorithm.3.  Suppose a network has the form of a chain: a sequence    of Boolean variables $X_1,ldots, X_n$ where    ${Parents}(X_i){X_{i-1}}$ for $i2,ldots,n$.    What is the complexity of computing    ${textbf{P}}(X_1X_n{true})$ using    enumeration? Using variable elimination?4.  Prove that the complexity of running variable elimination on a    polytree network is linear in the size of the tree for any variable    ordering consistent with the network structure.",
        "url": " /bayes-nets-exercises/ex_18/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-19":  {
        "title": "Exercise 14.19",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Investigate the complexity of exact inferencein general Bayesian networks:1.  Prove that any 3-SAT problem can be reduced to exact inference in a    Bayesian network constructed to represent the particular problem and    hence that exact inference is NP-hard. (Hint:    Consider a network with one variable for each proposition symbol,    one for each clause, and one for the conjunction of clauses.)2.  The problem of counting the number of satisfying assignments for a    3-SAT problem is #P-complete. Show that exact inference is at least    as hard as this.",
        "url": " /bayes-nets-exercises/ex_19/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-21":  {
        "title": "Exercise 14.21",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the query${textbf{P}}({Rain}{Sprinkler}{true},{WetGrass}{true})$in Figure rain-clustering-figure(a)(page rain-clustering-figure) and how Gibbs sampling can answer it.1.  How many states does the Markov chain have?2.  Calculate the transition matrix    ${textbf{Q}}$ containing    $q({textbf{y}}$ $rightarrow$ ${textbf{y}}&#39;)$    for all ${textbf{y}}$, ${textbf{y}}&#39;$.3.  What does ${textbf{ Q}}^2$, the square of the    transition matrix, represent?4.  What about ${textbf{Q}}^n$ as $nto infty$?5.  Explain how to do probabilistic inference in Bayesian networks,    assuming that ${textbf{Q}}^n$ is available. Is this a    practical way to do inference?",
        "url": " /bayes-nets-exercises/ex_21/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-17":  {
        "title": "Exercise 14.17",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the Bayes net shown in Figure politics-figure.1.  Which of the following are asserted by the network    structure?    1.  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.    2.  ${textbf{P}}(J|G) = {textbf{P}}(J|G,I)$.    3.  ${textbf{P}}(M|G,B,I) = {textbf{P}}(M|G,B,I,J)$.2.  Calculate the value of $P(b,i,lnot m,g,j)$.3.  Calculate the probability that someone goes to jail given that they    broke the law, have been indicted, and face a politically    motivated prosecutor.4.  A context-specific independence (see    page CSI-page) allows a variable to be independent of some of    its parents given certain values of others. In addition to the usual    conditional independences given by the graph structure, what    context-specific independences exist in the Bayes net in    Figure politics-figure?5.  Suppose we want to add the variable    $P={PresidentialPardon}$ to the network; draw the new    network and briefly explain any links you add.",
        "url": " /bayes-nets-exercises/ex_17/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-10":  {
        "title": "Exercise 14.10",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider a simple Bayesian network with root variables ${Cold}$,${Flu}$, and ${Malaria}$ and child variable ${Fever}$, with anoisy-OR conditional distribution for ${Fever}$ as described inSection canonical-distribution-section. By addingappropriate auxiliary variables for inhibition events and fever-inducingevents, construct an equivalent Bayesian network whose CPTs (except forroot variables) are deterministic. Define the CPTs and proveequivalence.",
        "url": " /bayes-nets-exercises/ex_10/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-3":  {
        "title": "Exercise 14.3",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Equation (parameter-joint-repn-equation onpage parameter-joint-repn-equation defines the joint distribution represented by aBayesian network in terms of the parameters$theta(X_i{Parents}(X_i))$. This exercise asks you to derivethe equivalence between the parameters and the conditional probabilities${textbf{ P}}(X_i{Parents}(X_i))$ from this definition.1.  Consider a simple network $Xrightarrow Yrightarrow Z$ with three    Boolean variables. Use    Equations (conditional-probability-equation and (marginalization-equation    (pages conditional-probability-equation and marginalization-equation)    to express the conditional probability $P(zy)$ as the ratio of two sums, each over entries in the    joint distribution ${textbf{P}}(X,Y,Z)$.2.  Now use Equation (parameter-joint-repn-equation to    write this expression in terms of the network parameters    $theta(X)$, $theta(YX)$, and $theta(ZY)$.3.  Next, expand out the summations in your expression from part (b),    writing out explicitly the terms for the true and false values of    each summed variable. Assuming that all network parameters satisfy    the constraint    $sum_{x_i} theta(x_i{parents}(X_i))1$, show    that the resulting expression reduces to $theta(zy)$.4.  Generalize this derivation to show that    $theta(X_i{Parents}(X_i)) = {textbf{P}}(X_i{Parents}(X_i))$    for any Bayesian network.",
        "url": " /bayes-nets-exercises/ex_3/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-4":  {
        "title": "Exercise 14.4",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "The arc reversal operation of in a Bayesian network allows us to change the directionof an arc $Xrightarrow Y$ while preserving the joint probabilitydistribution that the network represents Shachter:1986. Arc reversalmay require introducing new arcs: all the parents of $X$ also becomeparents of $Y$, and all parents of $Y$ also become parents of $X$.1.  Assume that $X$ and $Y$ start with $m$ and $n$ parents,    respectively, and that all variables have $k$ values. By calculating    the change in size for the CPTs of $X$ and $Y$, show that the total    number of parameters in the network cannot decrease during    arc reversal. (Hint: the parents of $X$ and $Y$ need    not be disjoint.)2.  Under what circumstances can the total number remain constant?3.  Let the parents of $X$ be $textbf{U} cup textbf{V}$ and the parents of $Y$ be    $textbf{V} cup textbf{W}$, where $textbf{U}$ and $textbf{W}$ are disjoint. The formulas for the    new CPTs after arc reversal are as follows: $$begin{aligned}    {textbf{P}}(Y | textbf{U},textbf{V},textbf{W}) &amp;amp;=&amp;amp; sum_x {textbf{P}}(Y | textbf{V},textbf{W}, x) {textbf{P}}(x | textbf{U}, textbf{V})     {textbf{P}}(X | textbf{U},textbf{V},textbf{W}, Y) &amp;amp;=&amp;amp; {textbf{P}}(Y | X, textbf{V}, textbf{W}) {textbf{P}}(X | textbf{U}, textbf{V}) / {textbf{P}}(Y | textbf{U},textbf{V},textbf{W}) .end{aligned}$$    Prove that the new network expresses the same joint distribution    over all variables as the original network.",
        "url": " /bayes-nets-exercises/ex_4/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-5":  {
        "title": "Exercise 14.5",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the Bayesian network inFigure burglary-figure.1.  If no evidence is observed, are ${Burglary}$ and ${Earthquake}$    independent? Prove this from the numerical semantics and from the    topological semantics.2.  If we observe ${Alarm}{true}$, are ${Burglary}$ and    ${Earthquake}$ independent? Justify your answer by calculating    whether the probabilities involved satisfy the definition of    conditional independence.",
        "url": " /bayes-nets-exercises/ex_5/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-2":  {
        "title": "Exercise 14.2",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 30%, 60%, and 75%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.1.  Draw the Bayesian network corresponding to this setup and define the    necessary CPTs.2.  Calculate which coin was most likely to have been drawn from the bag    if the observed flips come out heads twice and tails once.",
        "url": " /bayes-nets-exercises/ex_2/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-15":  {
        "title": "Exercise 14.15",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the network shown inFigure telescope-nets-figure(ii), and assume that thetwo telescopes work identically. $N{1,2,3}$ and$M_1,M_2{0,1,2,3,4}$, with the symbolic CPTs as describedin Exercise telescope-exercise. Using the enumerationalgorithm (Figure enumeration-algorithm onpage enumeration-algorithm), calculate the probability distribution${textbf{P}}(NM_12,M_22)$.    Three possible networks for the telescope problem.",
        "url": " /bayes-nets-exercises/ex_15/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-12":  {
        "title": "Exercise 14.12",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "The probit distribution defined onpage probit-page describes the probability distribution for a Booleanchild, given a single continuous parent.1.  How might the definition be extended to cover multiple continuous    parents?2.  How might it be extended to handle a multivalued    child variable? Consider both cases where the child’s values are    ordered (as in selecting a gear while driving, depending on speed,    slope, desired acceleration, etc.) and cases where they are    unordered (as in selecting bus, train, or car to get to work).    (Hint: Consider ways to divide the possible values    into two sets, to mimic a Boolean variable.)",
        "url": " /bayes-nets-exercises/ex_12/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-24":  {
        "title": "Exercise 14.24",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Three soccer teams $A$, $B$, and $C$, play eachother once. Each match is between two teams, and can be won, drawn, orlost. Each team has a fixed, unknown degree of quality—an integerranging from 0 to 3—and the outcome of a match depends probabilisticallyon the difference in quality between the two teams.1.  Construct a relational probability model to describe this domain,    and suggest numerical values for all the necessary    probability distributions.2.  Construct the equivalent Bayesian network for the three matches.3.  Suppose that in the first two matches $A$ beats $B$ and draws with    $C$. Using an exact inference algorithm of your choice, compute the    posterior distribution for the outcome of the third match.4.  Suppose there are $n$ teams in the league and we have the results    for all but the last match. How does the complexity of predicting    the last game vary with $n$?5.  Investigate the application of MCMC to this problem. How quickly    does it converge in practice and how well does it scale?",
        "url": " /bayes-nets-exercises/ex_24/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-23":  {
        "title": "Exercise 14.23",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "The Metropolis--Hastings algorithm is a member of the MCMC family; as such,it is designed to generate samples $textbf{x}$ (eventually) according to targetprobabilities $pi(textbf{x})$. (Typically we are interested in sampling from$pi(textbf{x})P(textbf{x}textbf{e})$.) Like simulated annealing,Metropolis–Hastings operates in two stages. First, it samples a newstate $textbf{x&#39;}$ from a proposal distribution $q(textbf{x&#39;}textbf{x})$, given the current state $textbf{x}$.Then, it probabilistically accepts or rejects $textbf{x&#39;}$ according to the acceptance probability$$alpha(textbf{x&#39;}textbf{x}) = min left(1,frac{pi(textbf{x&#39;})q(textbf{x}textbf{x&#39;})}{pi(textbf{x})q(textbf{x&#39;}textbf{x})}  right) .$$If the proposal is rejected, the state remains at $textbf{x}$.1.  Consider an ordinary Gibbs sampling step for a specific variable    $X_i$. Show that this step, considered as a proposal, is guaranteed    to be accepted by Metropolis–Hastings. (Hence, Gibbs sampling is a    special case of Metropolis–Hastings.)2.  Show that the two-step process above, viewed as a transition    probability distribution, is in detailed balance with $pi$.",
        "url": " /bayes-nets-exercises/ex_23/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-22":  {
        "title": "Exercise 14.22",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "This exercise explores the stationarydistribution for Gibbs sampling methods.1.  The convex composition $[alpha, q_1; 1-alpha, q_2]$ of $q_1$ and    $q_2$ is a transition probability distribution that first chooses    one of $q_1$ and $q_2$ with probabilities $alpha$ and $1-alpha$,    respectively, and then applies whichever is chosen. Prove that if    $q_1$ and $q_2$ are in detailed balance with $pi$, then their    convex composition is also in detailed balance with $pi$.    (Note: this result justifies a variant of GIBBS-ASK in which    variables are chosen at random rather than sampled in a    fixed sequence.)2.  Prove that if each of $q_1$ and $q_2$ has $pi$ as its stationary    distribution, then the sequential composition    $q q_1 circ q_2$ also has $pi$ as its    stationary distribution.",
        "url": " /bayes-nets-exercises/ex_22/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-13":  {
        "title": "Exercise 14.13",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "In your local nuclear power station, there is an alarm that senses whena temperature gauge exceeds a given threshold. The gauge measures thetemperature of the core. Consider the Boolean variables $A$ (alarmsounds), $F_A$ (alarm is faulty), and $F_G$ (gauge is faulty) and themultivalued nodes $G$ (gauge reading) and $T$ (actual core temperature).1.  Draw a Bayesian network for this domain, given that the gauge is    more likely to fail when the core temperature gets too high.2.  Is your network a polytree? Why or why not?3.  Suppose there are just two possible actual and measured    temperatures, normal and high; the probability that the gauge gives    the correct temperature is $x$ when it is working, but $y$ when it    is faulty. Give the conditional probability table associated with    $G$.4.  Suppose the alarm works correctly unless it is faulty, in which case    it never sounds. Give the conditional probability table associated    with $A$.5.  Suppose the alarm and gauge are working and the alarm sounds.    Calculate an expression for the probability that the temperature of    the core is too high, in terms of the various conditional    probabilities in the network.",
        "url": " /bayes-nets-exercises/ex_13/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-14":  {
        "title": "Exercise 14.14",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Two astronomers in different parts of the worldmake measurements $M_1$ and $M_2$ of the number of stars $N$ in somesmall region of the sky, using their telescopes. Normally, there is asmall possibility $e$ of error by up to one star in each direction. Eachtelescope can also (with a much smaller probability $f$) be badly out offocus (events $F_1$ and $F_2$), in which case the scientist willundercount by three or more stars (or if $N$ is less than 3, fail todetect any stars at all). Consider the three networks shown inFigure telescope-nets-figure.1.  Which of these Bayesian networks are correct (but not    necessarily efficient) representations of the preceding information?2.  Which is the best network? Explain.3.  Write out a conditional distribution for    ${textbf{P}}(M_1N)$, for the case where    $N{1,2,3}$ and $M_1{0,1,2,3,4}$. Each    entry in the conditional distribution should be expressed as a    function of the parameters $e$ and/or $f$.4.  Suppose $M_11$ and $M_23$. What are the    possible numbers of stars if you assume no prior    constraint on the values of $N$?5.  What is the most likely number of stars, given these    observations? Explain how to compute this, or if it is not possible    to compute, explain what additional information is needed and how it    would affect the result.",
        "url": " /bayes-nets-exercises/ex_14/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-9":  {
        "title": "Exercise 14.9",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Consider the network for car diagnosis shown inFigure car-starts-figure.1.  Extend the network with the Boolean variables ${IcyWeather}$ and    ${StarterMotor}$.2.  Give reasonable conditional probability tables for all the nodes.3.  How many independent values are contained in the joint probability    distribution for eight Boolean nodes, assuming that no conditional    independence relations are known to hold among them?4.  How many independent probability values do your network tables    contain?5.  The conditional distribution for ${Starts}$ could be described as    a noisy-AND distribution. Define this    family in general and relate it to the noisy-OR distribution.",
        "url": " /bayes-nets-exercises/ex_9/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-7":  {
        "title": "Exercise 14.7",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Let $H_x$ be a random variable denoting thehandedness of an individual $x$, with possible values $l$ or $r$. Acommon hypothesis is that left- or right-handedness is inherited by asimple mechanism; that is, perhaps there is a gene $G_x$, also withvalues $l$ or $r$, and perhaps actual handedness turns out mostly thesame (with some probability $s$) as the gene an individual possesses.Furthermore, perhaps the gene itself is equally likely to be inheritedfrom either of an individual’s parents, with a small nonzero probability$m$ of a random mutation flipping the handedness.1.  Which of the three networks in    Figure handedness-figure claim that    $ {textbf{P}}(G_{father},G_{mother},G_{child}) = {textbf{P}}(G_{father}){textbf{P}}(G_{mother}){textbf{P}}(G_{child})$?2.  Which of the three networks make independence claims that are    consistent with the hypothesis about the inheritance of handedness?3.  Which of the three networks is the best description of the    hypothesis?4.  Write down the CPT for the $G_{child}$ node in network (a), in    terms of $s$ and $m$.5.  Suppose that    $P(G_{father}l)=P(G_{mother}l)=q$. In    network (a), derive an expression for $P(G_{child}l)$    in terms of $m$ and $q$ only, by conditioning on its parent nodes.6.  Under conditions of genetic equilibrium, we expect the distribution    of genes to be the same across generations. Use this to calculate    the value of $q$, and, given what you know about handedness in    humans, explain why the hypothesis described at the beginning of    this question must be wrong.",
        "url": " /bayes-nets-exercises/ex_7/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-1":  {
        "title": "Exercise 14.1",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 20%, 60%, and 80%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.1.  Draw the Bayesian network corresponding to this setup and define the    necessary CPTs.2.  Calculate which coin was most likely to have been drawn from the bag    if the observed flips come out heads twice and tails once.",
        "url": " /bayes-nets-exercises/ex_1/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-6":  {
        "title": "Exercise 14.6",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Suppose that in a Bayesian network containing an unobserved variable$Y$, all the variables in the Markov blanket ${MB}(Y)$ have beenobserved.1.  Prove that removing the node $Y$ from the network will not affect    the posterior distribution for any other unobserved variable in    the network.2.  Discuss whether we can remove $Y$ if we are planning to use (i)    rejection sampling and (ii) likelihood weighting.                Three possible structures for a Bayesian network describing genetic inheritance of handedness.    ",
        "url": " /bayes-nets-exercises/ex_6/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-8":  {
        "title": "Exercise 14.8",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "The Markovblanket of a variable is defined on page markov-blanket-page.Prove that a variable is independent of all other variables in thenetwork, given its Markov blanket and deriveEquation (markov-blanket-equation)(page markov-blanket-equation).      A Bayesian network describing some features of a car&#39;s electrical system and engine. Each variable is Boolean, and the true value indicates that the corresponding aspect of the vehicle is in working order.",
        "url": " /bayes-nets-exercises/ex_8/"
      }
    
  
    
  
    ,
      "advanced-search-exercises-ex-11":  {
        "title": "Exercise 4.11",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${ 1,3,5,7 }$, and explain why the problemis unsolvable.",
        "url": " /advanced-search-exercises/ex_11/"
      }
    
  
    ,
      "advanced-search-exercises-ex-16":  {
        "title": "Exercise 4.16",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Like DFS, online DFS is incomplete for reversible state spaces withinfinite paths. For example, suppose that states are points on theinfinite two-dimensional grid and actions are unit vectors $(1,0)$,$(0,1)$, $(-1,0)$, $(0,-1)$, tried in that order. Show that online DFSstarting at $(0,0)$ will not reach $(1,-1)$. Suppose the agent canobserve, in addition to its current state, all successor states and theactions that would lead to them. Write an algorithm that is completeeven for bidirected state spaces with infinite paths. What states doesit visit in reaching $(1,-1)$?",
        "url": " /advanced-search-exercises/ex_16/"
      }
    
  
    ,
      "advanced-search-exercises-ex-17":  {
        "title": "Exercise 4.17",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Relate the time complexity of LRTA* to its space complexity.",
        "url": " /advanced-search-exercises/ex_17/"
      }
    
  
    ,
      "advanced-search-exercises-ex-10":  {
        "title": "Exercise 4.10",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${1,2,3,4,5,6,7,8}$, and explain why theproblem is unsolvable.",
        "url": " /advanced-search-exercises/ex_10/"
      }
    
  
    ,
      "advanced-search-exercises-ex-3":  {
        "title": "Exercise 4.3",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "In this exercise, we explore the use of local search methods to solveTSPs of the type defined in Exercise tsp-mst-exercise1.  Implement and test a hill-climbing method to solve TSPs. Compare the    results with optimal solutions obtained from the A* algorithm with    the MST heuristic (Exercise tsp-mst-exercise)2.  Repeat part (a) using a genetic algorithm instead of hill climbing.    You may want to consult @Larranaga+al:1999 for some suggestions for representations.",
        "url": " /advanced-search-exercises/ex_3/"
      }
    
  
    ,
      "advanced-search-exercises-ex-4":  {
        "title": "Exercise 4.4",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Generate a large number of 8-puzzle and8-queens instances and solve them (where possible) by hill climbing(steepest-ascent and first-choice variants), hill climbing with randomrestart, and simulated annealing. Measure the search cost and percentageof solved problems and graph these against the optimal solution cost.Comment on your results.",
        "url": " /advanced-search-exercises/ex_4/"
      }
    
  
    ,
      "advanced-search-exercises-ex-5":  {
        "title": "Exercise 4.5",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "The And-Or-Graph-Search algorithm inFigure and-or-graph-search-algorithm checks forrepeated states only on the path from the root to the current state.Suppose that, in addition, the algorithm were to storeevery visited state and check against that list. (See inFigure breadth-first-search-algorithm for an example.)Determine the information that should be stored and how the algorithmshould use that information when a repeated state is found.(*Hint*: You will need to distinguish at least betweenstates for which a successful subplan was constructed previously andstates for which no subplan could be found.) Explain how to use labels,as defined in Section cyclic-plan-section, to avoidhaving multiple copies of subplans.",
        "url": " /advanced-search-exercises/ex_5/"
      }
    
  
    ,
      "advanced-search-exercises-ex-2":  {
        "title": "Exercise 4.2",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise brio-exercise considers the problem ofbuilding railway tracks under the assumption that pieces fit exactlywith no slack. Now consider the real problem, in which pieces don’t fitexactly but allow for up to 10 degrees of rotation to either side of the“proper” alignment. Explain how to formulate the problem so it could besolved by simulated annealing.",
        "url": " /advanced-search-exercises/ex_2/"
      }
    
  
    ,
      "advanced-search-exercises-ex-15":  {
        "title": "Exercise 4.15",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "In this exercise, we examine hill climbingin the context of robot navigation, using the environment inFigure geometric-scene-figure as an example.1.  Repeat Exercise path-planning-agent-exercise using    hill climbing. Does your agent ever get stuck in a local minimum? Is    it *possible* for it to get stuck with convex    obstacles?2.  Construct a nonconvex polygonal environment in which the agent    gets stuck.3.  Modify the hill-climbing algorithm so that, instead of doing a    depth-1 search to decide where to go next, it does a    depth-$k$ search. It should find the best $k$-step path and do one    step along it, and then repeat the process.4.  Is there some $k$ for which the new algorithm is guaranteed to    escape from local minima?5.  Explain how LRTA enables the agent to escape from local minima in    this case.",
        "url": " /advanced-search-exercises/ex_15/"
      }
    
  
    ,
      "advanced-search-exercises-ex-12":  {
        "title": "Exercise 4.12",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "We can turn the navigation problem inExercise path-planning-exercise into an environment asfollows:-   The percept will be a list of the positions, relative to the    agent, of the visible vertices. The percept does    not include the position of the robot! The robot must    learn its own position from the map; for now, you can assume that    each location has a different “view.”-   Each action will be a vector describing a straight-line path    to follow. If the path is unobstructed, the action succeeds;    otherwise, the robot stops at the point where its path first    intersects an obstacle. If the agent returns a zero motion vector    and is at the goal (which is fixed and known), then the environment    teleports the agent to a random location (not inside    an obstacle).-   The performance measure charges the agent 1 point for each unit of    distance traversed and awards 1000 points each time the goal    is reached.1.  Implement this environment and a problem-solving agent for it. After    each teleportation, the agent will need to formulate a new problem,    which will involve discovering its current location.2.  Document your agent’s performance (by having the agent generate    suitable commentary as it moves around) and report its performance    over 100 episodes.3.  Modify the environment so that 30% of the time the agent ends up at    an unintended destination (chosen randomly from the other visible    vertices if any; otherwise, no move at all). This is a crude model    of the motion errors of a real robot. Modify the agent so that when    such an error is detected, it finds out where it is and then    constructs a plan to get back to where it was and resume the    old plan. Remember that sometimes getting back to where it was might    also fail! Show an example of the agent successfully overcoming two    successive motion errors and still reaching the goal.4.  Now try two different recovery schemes after an error: (1) head for    the closest vertex on the original route; and (2) replan a route to    the goal from the new location. Compare the performance of the three    recovery schemes. Would the inclusion of search costs affect the    comparison?5.  Now suppose that there are locations from which the view    is identical. (For example, suppose the world is a grid with    square obstacles.) What kind of problem does the agent now face?    What do solutions look like?",
        "url": " /advanced-search-exercises/ex_12/"
      }
    
  
    ,
      "advanced-search-exercises-ex-13":  {
        "title": "Exercise 4.13",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (1,1), that the goal is at (3,3), and that theactions Up, Down, Left, Right have their usualeffects unless blocked by a wall. The agent does not knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before.1.  Explain how this online search problem can be viewed as an offline    search in belief-state space, where the initial belief state    includes all possible environment configurations. How large is the    initial belief state? How large is the space of belief states?2.  How many distinct percepts are possible in the initial state?3.  Describe the first few branches of a contingency plan for this    problem. How large (roughly) is the complete plan?Notice that this contingency plan is a solution for everypossible environment fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.",
        "url": " /advanced-search-exercises/ex_13/"
      }
    
  
    ,
      "advanced-search-exercises-ex-14":  {
        "title": "Exercise 4.14",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (3,3), that the goal is at (1,1), and that the fouractions *Up*, *Down*, *Left*, *Right* have their usualeffects unless blocked by a wall. The agent does *not* knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before or is a new state.1.  Explain how this online search problem can be viewed as an offline    search in belief-state space, where the initial belief state    includes all possible environment configurations. How large is the    initial belief state? How large is the space of belief states?2.  How many distinct percepts are possible in the initial state?3.  Describe the first few branches of a contingency plan for this    problem. How large (roughly) is the complete plan?Notice that this contingency plan is a solution for *everypossible environment* fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.",
        "url": " /advanced-search-exercises/ex_14/"
      }
    
  
    ,
      "advanced-search-exercises-ex-9":  {
        "title": "Exercise 4.9",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "On page multivalued-sensorless-page it was assumedthat a given action would have the same cost when executed in anyphysical state within a given belief state. (This leads to abelief-state search problem with well-defined step costs.) Now considerwhat happens when the assumption does not hold. Does the notion ofoptimality still make sense in this context, or does it requiremodification? Consider also various possible definitions of the “cost”of executing an action in a belief state; for example, we could use theminimum of the physical costs; or themaximum; or a cost interval with the lowerbound being the minimum cost and the upper bound being the maximum; orjust keep the set of all possible costs for that action. For each ofthese, explore whether A* (with modifications if necessary) can returnoptimal solutions.",
        "url": " /advanced-search-exercises/ex_9/"
      }
    
  
    ,
      "advanced-search-exercises-ex-7":  {
        "title": "Exercise 4.7",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "In Section conformant-section we introduced beliefstates to solve sensorless search problems. A sequence of actions solvesa sensorless problem if it maps every physical state in the initialbelief state $b$ to a goal state. Suppose the agent knows $h^*(s)$, thetrue optimal cost of solving the physical state $s$ in the fullyobservable problem, for every state $s$ in $b$. Find an admissibleheuristic $h(b)$ for the sensorless problem in terms of these costs, andprove its admissibilty. Comment on the accuracy of this heuristic on thesensorless vacuum problem ofFigure vacuum2-sets-figure. How well does A* perform?",
        "url": " /advanced-search-exercises/ex_7/"
      }
    
  
    ,
      "advanced-search-exercises-ex-1":  {
        "title": "Exercise 4.1",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Give the name of the algorithm that results from each of the followingspecial cases:1.  Local beam search with $k = 1$.2.  Local beam search with one initial state and no limit on the number    of states retained.3.  Simulated annealing with $T = 0$ at all times (and omitting the    termination test).4.  Simulated annealing with $T=infty$ at all times.5.  Genetic algorithm with population size $N = 1$.",
        "url": " /advanced-search-exercises/ex_1/"
      }
    
  
    ,
      "advanced-search-exercises-ex-6":  {
        "title": "Exercise 4.6",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Explain precisely how to modify the And-Or-Graph-Search algorithm togenerate a cyclic plan if no acyclic plan exists. You will need to dealwith three issues: labeling the plan steps so that a cyclic plan canpoint back to an earlier part of the plan, modifying Or-Search so that itcontinues to look for acyclic plans after finding a cyclic plan, andaugmenting the plan representation to indicate whether a plan is cyclic.Show how your algorithm works on (a) the slippery vacuum world, and (b)the slippery, erratic vacuum world. You might wish to use a computerimplementation to check your results.",
        "url": " /advanced-search-exercises/ex_6/"
      }
    
  
    ,
      "advanced-search-exercises-ex-8":  {
        "title": "Exercise 4.8",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "This exercise exploressubset–superset relations between belief states in sensorless orpartially observable environments.1.  Prove that if an action sequence is a solution for a belief state    $b$, it is also a solution for any subset of $b$. Can anything be    said about supersets of $b$?2.  Explain in detail how to modify graph search for sensorless problems    to take advantage of your answers in (a).3.  Explain in detail how to modify and–or search for    partially observable problems, beyond the modifications you describe    in (b).",
        "url": " /advanced-search-exercises/ex_8/"
      }
    
  
    
  
    ,
      "decision-theory-exercises-ex-11":  {
        "title": "Exercise 16.11",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Assess your own utility for different incrementalamounts of money by running a series of preference tests between somedefinite amount $M_1$ and a lottery $[p,M_2; (1-p), 0]$. Choosedifferent values of $M_1$ and $M_2$, and vary $p$ until you areindifferent between the two choices. Plot the resulting utilityfunction.",
        "url": " /decision-theory-exercises/ex_11/"
      }
    
  
    ,
      "decision-theory-exercises-ex-16":  {
        "title": "Exercise 16.16",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Alex is given the choice between two games. In Game 1, a fair coin isflipped and if it comes up heads, Alex receives $$100$. If the coin comesup tails, Alex receives nothing. In Game 2, a fair coin is flippedtwice. Each time the coin comes up heads, Alex receives $$50$, and Alexreceives nothing for each coin flip that comes up tails. Assuming thatAlex has a monotonically increasing utility function for money in therange [$0, $100], show mathematically that if Alex prefers Game 2 toGame 1, then Alex is risk averse (at least with respect to this range ofmonetary amounts).Show that if $X_1$ and $X_2$ are preferentially independent of $X_3$,and $X_2$ and $X_3$ are preferentially independent of $X_1$, then $X_3$and $X_1$ are preferentially independent of $X_2$.",
        "url": " /decision-theory-exercises/ex_16/"
      }
    
  
    ,
      "decision-theory-exercises-ex-20":  {
        "title": "Exercise 16.20",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Consider a student who has the choice to buy or not buy a textbook for acourse. We’ll model this as a decision problem with one Boolean decisionnode, $B$, indicating whether the agent chooses to buy the book, and twoBoolean chance nodes, $M$, indicating whether the student has masteredthe material in the book, and $P$, indicating whether the student passesthe course. Of course, there is also a utility node, $U$. A certainstudent, Sam, has an additive utility function: 0 for not buying thebook and -$100 for buying it; and $2000 for passing the course and 0for not passing. Sam’s conditional probability estimates are as follows:$$begin{array}{ll}P(p|b,m) = 0.9              &amp;amp; P(m|b) = 0.9       P(p|b, lnot m) = 0.5       &amp;amp; P(m|lnot b) = 0.7 P(p|lnot b, m) = 0.8       &amp;amp; P(p|lnot b, lnot m) = 0.3 &amp;amp; end{array}$$You might think that $P$ would be independent of $B$ given$M$, But this course has an open-book final—so having the book helps.1.  Draw the decision network for this problem.2.  Compute the expected utility of buying the book and of not    buying it.3.  What should Sam do?",
        "url": " /decision-theory-exercises/ex_20/"
      }
    
  
    ,
      "decision-theory-exercises-ex-18":  {
        "title": "Exercise 16.18",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "For either of the airport-siting diagrams from Exercisesairport-id-exercise and airport-au-id-exercise, to whichconditional probability table entry is the utility most sensitive, giventhe available evidence?",
        "url": " /decision-theory-exercises/ex_18/"
      }
    
  
    ,
      "decision-theory-exercises-ex-19":  {
        "title": "Exercise 16.19",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Modify and extend the Bayesian network code in the code repository toprovide for creation and evaluation of decision networks and thecalculation of information value.",
        "url": " /decision-theory-exercises/ex_19/"
      }
    
  
    ,
      "decision-theory-exercises-ex-21":  {
        "title": "Exercise 16.21",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "This exercise completes the analysis of theairport-siting problem in Figure airport-id-figure.1.  Provide reasonable variable domains, probabilities, and utilities    for the network, assuming that there are three possible sites.2.  Solve the decision problem.3.  What happens if changes in technology mean that each aircraft    generates half the noise?4.  What if noise avoidance becomes three times more important?5.  Calculate the VPI for ${AirTraffic}$, ${Litigation}$, and    ${Construction}$ in your model.",
        "url": " /decision-theory-exercises/ex_21/"
      }
    
  
    ,
      "decision-theory-exercises-ex-17":  {
        "title": "Exercise 16.17",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Repeat Exercise airport-id-exercise, using the action-utilityrepresentation shown in Figure airport-au-id-figure.",
        "url": " /decision-theory-exercises/ex_17/"
      }
    
  
    ,
      "decision-theory-exercises-ex-10":  {
        "title": "Exercise 16.10",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Tickets to a lottery cost 1. There are two possible prizes:a 10 payoff with probability 1/50, and a 1,000,000 payoff withprobability 1/2,000,000. What is the expected monetary value of alottery ticket? When (if ever) is it rational to buy a ticket? Beprecise—show an equation involving utilities. You may assume currentwealth of $k$ and that $U(S_k)=0$. You may also assume that$U(S_{k+{10}}) = {10}times U(S_{k+1})$, but you may not make anyassumptions about $U(S_{k+1,{000},{000}})$. Sociological studies showthat people with lower income buy a disproportionate number of lotterytickets. Do you think this is because they are worse decision makers orbecause they have a different utility function? Consider the value ofcontemplating the possibility of winning the lottery versus the value ofcontemplating becoming an action hero while watching an adventure movie.",
        "url": " /decision-theory-exercises/ex_10/"
      }
    
  
    ,
      "decision-theory-exercises-ex-3":  {
        "title": "Exercise 16.3",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Chris considers five used cars before buying the one with maximumexpected utility. Pat considers eleven cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?",
        "url": " /decision-theory-exercises/ex_3/"
      }
    
  
    ,
      "decision-theory-exercises-ex-4":  {
        "title": "Exercise 16.4",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "In 1713, Nicolas Bernoulli stated a puzzle,now called the St. Petersburg paradox, which works as follows. You havethe opportunity to play a game in which a fair coin is tossed repeatedlyuntil it comes up heads. If the first heads appears on the $n$th toss,you win $2^n$ dollars.1.  Show that the expected monetary value of this game is infinite.2.  How much would you, personally, pay to play the game?3.  Nicolas’s cousin Daniel Bernoulli resolved the apparent paradox in    1738 by suggesting that the utility of money is measured on a    logarithmic scale (i.e., $U(S_{n}) = alog_2 n +b$, where $S_n$ is    the state of having $n$). What is the expected utility of the game    under this assumption?4.  What is the maximum amount that it would be rational to pay to play    the game, assuming that one’s initial wealth is $k$?",
        "url": " /decision-theory-exercises/ex_4/"
      }
    
  
    ,
      "decision-theory-exercises-ex-5":  {
        "title": "Exercise 16.5",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Write a computer program to automate the process inExercise assessment-exercise. Try your program out onseveral people of different net worth and political outlook. Comment onthe consistency of your results, both for an individual and acrossindividuals.",
        "url": " /decision-theory-exercises/ex_5/"
      }
    
  
    ,
      "decision-theory-exercises-ex-2":  {
        "title": "Exercise 16.2",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Chris considers four used cars before buying the one with maximumexpected utility. Pat considers ten cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?",
        "url": " /decision-theory-exercises/ex_2/"
      }
    
  
    ,
      "decision-theory-exercises-ex-15":  {
        "title": "Exercise 16.15",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.1.  Assume Mary has an exponential utility function with $R = $400$.    Mary is given the choice between receiving $$400$ with certainty    (probability 1) or participating in a lottery which has a 60%    probability of winning $5000 and a 40% probability of    winning nothing. Assuming Marry acts rationally, which option would    she choose? Show how you derived your answer.2.  Consider the choice between receiving $$100$ with certainty    (probability 1) or participating in a lottery which has a 50%    probability of winning $500 and a 50% probability of winning    nothing. Approximate the value of R (to 3 significant digits) in an    exponential utility function that would cause an individual to be    indifferent to these two alternatives. (You might find it helpful to    write a short program to help you solve this problem.)",
        "url": " /decision-theory-exercises/ex_15/"
      }
    
  
    ,
      "decision-theory-exercises-ex-12":  {
        "title": "Exercise 16.12",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "How much is a micromort worth to you? Devise a protocol to determinethis. Ask questions based both on paying to avoid risk and being paid toaccept risk.",
        "url": " /decision-theory-exercises/ex_12/"
      }
    
  
    ,
      "decision-theory-exercises-ex-23":  {
        "title": "Exercise 16.23",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Recall the definition of value ofinformation in Section VPI-section.1.  Prove that the value of information is nonnegative and    order independent.2.  Explain why it is that some people would prefer not to get some    information—for example, not wanting to know the sex of their baby    when an ultrasound is done.3.  A function $f$ on sets is submodular if, for any element $x$ and any sets $A$    and $B$ such that $Asubseteq B$, adding $x$ to $A$ gives a greater    increase in $f$ than adding $x$ to $B$:    $$Asubseteq B Rightarrow (f(A cup {x}) - f(A)) geq (f(Bcup {x}) - f(B)) .$$    Submodularity captures the intuitive notion of diminishing    returns. Is the value of information, viewed as a function    $f$ on sets of possible observations, submodular? Prove this or find    a counterexample.",
        "url": " /decision-theory-exercises/ex_23/"
      }
    
  
    ,
      "decision-theory-exercises-ex-22":  {
        "title": "Exercise 16.22",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "(Adapted from Pearl [Pearl:1988].) A used-carbuyer can decide to carry out various tests with various costs (e.g.,kick the tires, take the car to a qualified mechanic) and then,depending on the outcome of the tests, decide which car to buy. We willassume that the buyer is deciding whether to buy car $c_1$, that thereis time to carry out at most one test, and that $t_1$ is the test of$c_1$ and costs $50.A car can be in good shape (quality $q^+$) or bad shape (quality $q^-$),and the tests might help indicate what shape the car is in. Car $c_1$costs $1,500, and its market value is $$2,000$ if it is in good shape; ifnot, $$700$ in repairs will be needed to make it in good shape. The buyer’sestimate is that $c_1$ has a 70% chance of being in good shape.1.  Draw the decision network that represents this problem.2.  Calculate the expected net gain from buying $c_1$, given no test.3.  Tests can be described by the probability that the car will pass or    fail the test given that the car is in good or bad shape. We have    the following information:    $P({pass}(c_1,t_1) | q^+(c_1)) = {0.8}$    $P({pass}(c_1,t_1) | q^-(c_1)) = {0.35}$    Use Bayes’ theorem to calculate the probability that the car will pass (or fail) its test and hence the probability that it is in good (or bad) shape given each possible test outcome.4.  Calculate the optimal decisions given either a pass or a fail, and    their expected utilities.5.  Calculate the value of information of the test, and derive an    optimal conditional plan for the buyer.",
        "url": " /decision-theory-exercises/ex_22/"
      }
    
  
    ,
      "decision-theory-exercises-ex-13":  {
        "title": "Exercise 16.13",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Let continuous variables $X_1,ldots,X_k$ beindependently distributed according to the same probability densityfunction $f(x)$. Prove that the density function for$max{X_1,ldots,X_k}$ is given by $kf(x)(F(x))^{k-1}$, where $F$ isthe cumulative distribution for $f$.",
        "url": " /decision-theory-exercises/ex_13/"
      }
    
  
    ,
      "decision-theory-exercises-ex-14":  {
        "title": "Exercise 16.14",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.1.  Assume Mary has an exponential utility function with $R = $500$.    Mary is given the choice between receiving $$500$ with certainty    (probability 1) or participating in a lottery which has a 60%    probability of winning $5000 and a 40% probability of    winning nothing. Assuming Marry acts rationally, which option would    she choose? Show how you derived your answer.2.  Consider the choice between receiving $$100$ with certainty    (probability 1) or participating in a lottery which has a 50%    probability of winning $$500$ and a 50% probability of winning    nothing. Approximate the value of R (to 3 significant digits) in an    exponential utility function that would cause an individual to be    indifferent to these two alternatives. (You might find it helpful to    write a short program to help you solve this problem.)",
        "url": " /decision-theory-exercises/ex_14/"
      }
    
  
    ,
      "decision-theory-exercises-ex-9":  {
        "title": "Exercise 16.9",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Consider the Allais paradox described on page allais-page: an agentwho prefers $B$ over $A$ (taking the sure thing), and $C$ over $D$(taking the higher EMV) is not acting rationally, according to utilitytheory. Do you think this indicates a problem for the agent, a problemfor the theory, or no problem at all? Explain.",
        "url": " /decision-theory-exercises/ex_9/"
      }
    
  
    ,
      "decision-theory-exercises-ex-7":  {
        "title": "Exercise 16.7",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "The Surprise Candy Company makes candy intwo flavors: 70% are strawberry flavor and 30% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 80% of the strawberrycandies are round and 80% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.1.  Which network(s) can correctly represent    ${textbf{P}}(Flavor,Wrapper,Shape)$?2.  Which network is the best representation for this problem?3.  Does network (i) assert that    ${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?4.  What is the probability that your candy has a red wrapper?5.  In the box is a round candy with a red wrapper. What is the    probability that its flavor is strawberry?6.  A unwrapped strawberry candy is worth $s$ on the open market and an    unwrapped anchovy candy is worth $a$. Write an expression for the    value of an unopened candy box.7.  A new law prohibits trading of unwrapped candies, but it is still    legal to trade wrapped candies (out of the box). Is an unopened    candy box now worth more than less than, or the same as before?",
        "url": " /decision-theory-exercises/ex_7/"
      }
    
  
    ,
      "decision-theory-exercises-ex-1":  {
        "title": "Exercise 16.1",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "(Adapted from David Heckerman.) This exercise concernsthe Almanac Game, which is used bydecision analysts to calibrate numeric estimation. For each of thequestions that follow, give your best guess of the answer, that is, anumber that you think is as likely to be too high as it is to be toolow. Also give your guess at a 25th percentile estimate, that is, anumber that you think has a 25% chance of being too high, and a 75%chance of being too low. Do the same for the 75th percentile. (Thus, youshould give three estimates in all—low, median, and high—for eachquestion.)1.  Number of passengers who flew between New York and Los Angeles    in 1989.2.  Population of Warsaw in 1992.3.  Year in which Coronado discovered the Mississippi River.4.  Number of votes received by Jimmy Carter in the 1976    presidential election.5.  Age of the oldest living tree, as of 2002.6.  Height of the Hoover Dam in feet.7.  Number of eggs produced in Oregon in 1985.8.  Number of Buddhists in the world in 1992.9.  Number of deaths due to AIDS in the United States    in 1981.10. Number of U.S. patents granted in 1901.The correct answers appear after the last exercise of this chapter. Fromthe point of view of decision analysis, the interesting thing is not howclose your median guesses came to the real answers, but rather how oftenthe real answer came within your 25% and 75% bounds. If it was abouthalf the time, then your bounds are accurate. But if you’re like mostpeople, you will be more sure of yourself than you should be, and fewerthan half the answers will fall within the bounds. With practice, youcan calibrate yourself to give realistic bounds, and thus be more usefulin supplying information for decision making. Try this second set ofquestions and see if there is any improvement:1.  Year of birth of Zsa Zsa Gabor.2.  Maximum distance from Mars to the sun in miles.3.  Value in dollars of exports of wheat from the United States in 1992.4.  Tons handled by the port of Honolulu in 1991.5.  Annual salary in dollars of the governor of California in 1993.6.  Population of San Diego in 1990.7.  Year in which Roger Williams founded Providence, Rhode Island.8.  Height of Mt. Kilimanjaro in feet.9.  Length of the Brooklyn Bridge in feet.10. Number of deaths due to automobile accidents in the United States    in 1992.",
        "url": " /decision-theory-exercises/ex_1/"
      }
    
  
    ,
      "decision-theory-exercises-ex-6":  {
        "title": "Exercise 16.6",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "The Surprise Candy Company makes candy intwo flavors: 75% are strawberry flavor and 25% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 70% of the strawberrycandies are round and 70% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.1.  Which network(s) can correctly represent    ${textbf{P}}(Flavor,Wrapper,Shape)$?2.  Which network is the best representation for this problem?3.  Does network (i) assert that    ${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?4.  What is the probability that your candy has a red wrapper?5.  In the box is a round candy with a red wrapper. What is the    probability that its flavor is strawberry?6.  A unwrapped strawberry candy is worth $s$ on the open market and an    unwrapped anchovy candy is worth $a$. Write an expression for the    value of an unopened candy box.7.  A new law prohibits trading of unwrapped candies, but it is still    legal to trade wrapped candies (out of the box). Is an unopened    candy box now worth more than less than, or the same as before?                Three proposed Bayes nets for the Surprise Candy      problem        ",
        "url": " /decision-theory-exercises/ex_6/"
      }
    
  
    ,
      "decision-theory-exercises-ex-8":  {
        "title": "Exercise 16.8",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Prove that the judgments $B succ A$ and $C succ D$ in the Allaisparadox (page allais-page) violate the axiom of substitutability.",
        "url": " /decision-theory-exercises/ex_8/"
      }
    
  
    
  
    ,
      "reinforcement-learning-exercises-ex-11":  {
        "title": "Exercise 21.11",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Implement the REINFORCE and PEGASUS algorithms and apply them to the $4times 3$ world,using a policy family of your own choosing. Comment on the results.",
        "url": " /reinforcement-learning-exercises/ex_11/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-10":  {
        "title": "Exercise 21.10",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Compute the true utility function and the best linearapproximation in $x$ and $y$ (as inEquation (4x3-linear-approx-equation)) for thefollowing environments:1.  A ${10}times {10}$ world with a single $+1$ terminal state    at (10,10).2.  As in (a), but add a $-1$ terminal state at (10,1).3.  As in (b), but add obstacles in 10 randomly selected squares.4.  As in (b), but place a wall stretching from (5,2) to (5,9).5.  As in (a), but with the terminal state at (5,5).The actions are deterministic moves in the four directions. In eachcase, compare the results using three-dimensional plots. For eachenvironment, propose additional features (besides $x$ and $y$) thatwould improve the approximation and show the results.",
        "url": " /reinforcement-learning-exercises/ex_10/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-3":  {
        "title": "Exercise 21.3",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Starting with the passive ADP agent,modify it to use an approximate ADP algorithm as discussed in the text.Do this in two steps:1.  Implement a priority queue for adjustments to the utility estimates.    Whenever a state is adjusted, all of its predecessors also become    candidates for adjustment and should be added to the queue. The    queue is initialized with the state from which the most recent    transition took place. Allow only a fixed number of adjustments.2.  Experiment with various heuristics for ordering the priority queue,    examining their effect on learning rates and computation time.",
        "url": " /reinforcement-learning-exercises/ex_3/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-4":  {
        "title": "Exercise 21.4",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "The direct utility estimation method inSection passive-rl-section uses distinguished terminalstates to indicate the end of a trial. How could it be modified forenvironments with discounted rewards and no terminal states?",
        "url": " /reinforcement-learning-exercises/ex_4/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-5":  {
        "title": "Exercise 21.5",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Write out the parameter update equations for TD learning with$$hat{U}(x,y) = theta_0 + theta_1 x + theta_2 y + theta_3,sqrt{(x-x_g)^2 + (y-y_g)^2} .$$",
        "url": " /reinforcement-learning-exercises/ex_5/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-2":  {
        "title": "Exercise 21.2",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Chapter complex-decisions-chapter defined aproper policy for an MDP as one that isguaranteed to reach a terminal state. Show that it is possible for apassive ADP agent to learn a transition model for which its policy $pi$is improper even if $pi$ is proper for the true MDP; with such models,the POLICY-EVALUATION step may fail if $gamma1$. Show that this problem cannotarise if POLICY-EVALUATION is applied to the learned model only at the end of a trial.",
        "url": " /reinforcement-learning-exercises/ex_2/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-12":  {
        "title": "Exercise 21.12",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Investigate the application of reinforcement learning ideas to themodeling of human and animal behavior.",
        "url": " /reinforcement-learning-exercises/ex_12/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-13":  {
        "title": "Exercise 21.13",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Is reinforcement learning an appropriate abstract model for evolution?What connection exists, if any, between hardwired reward signals andevolutionary fitness?",
        "url": " /reinforcement-learning-exercises/ex_13/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-9":  {
        "title": "Exercise 21.9",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Extend the standard game-playing environment(Chapter game-playing-chapter) to incorporate a rewardsignal. Put two reinforcement learning agents into the environment (theymay, of course, share the agent program) and have them play against eachother. Apply the generalized TD update rule(Equation (generalized-td-equation)) to update theevaluation function. You might wish to start with a simple linearweighted evaluation function and a simple game, such as tic-tac-toe.",
        "url": " /reinforcement-learning-exercises/ex_9/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-7":  {
        "title": "Exercise 21.7",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Implement an exploring reinforcement learningagent that uses direct utility estimation. Make two versions—one with atabular representation and one using the function approximator inEquation (4x3-linear-approx-equation). Compare theirperformance in three environments:1.  The $4times 3$ world described in the chapter.2.  A ${10}times {10}$ world with no obstacles and a +1 reward    at (10,10).3.  A ${10}times {10}$ world with no obstacles and a +1 reward    at (5,5).",
        "url": " /reinforcement-learning-exercises/ex_7/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-1":  {
        "title": "Exercise 21.1",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Implement a passive learning agent in a simple environment, such as the$4times 3$ world. For the case of an initially unknown environmentmodel, compare the learning performance of the direct utilityestimation, TD, and ADP algorithms. Do the comparison for the optimalpolicy and for several random policies. For which do the utilityestimates converge faster? What happens when the size of the environmentis increased? (Try environments with and without obstacles.)",
        "url": " /reinforcement-learning-exercises/ex_1/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-6":  {
        "title": "Exercise 21.6",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Adapt the vacuum world (Chapter agents-chapter forreinforcement learning by including rewards for squares being clean.Make the world observable by providing suitable percepts. Now experimentwith different reinforcement learning agents. Is function approximationnecessary for success? What sort of approximator works for thisapplication?",
        "url": " /reinforcement-learning-exercises/ex_6/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-8":  {
        "title": "Exercise 21.8",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Devise suitable features for reinforcement learning in stochastic gridworlds (generalizations of the $4times 3$ world) that contain multipleobstacles and multiple terminal states with rewards of $+1$ or $-1$.",
        "url": " /reinforcement-learning-exercises/ex_8/"
      }
    
  
    
  
    
  
    ,
      "advanced-planning-exercises-ex-11":  {
        "title": "Exercise 11.11",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Conditional effects were illustrated for the${Suck}$ action in the vacuum world—which square becomes clean dependson which square the robot is in. Can you think of a new set ofpropositional variables to define states of the vacuum world, such that${Suck}$ has an unconditional description? Write outthe descriptions of ${Suck}$, ${Left}$, and ${Right}$, using yourpropositions, and demonstrate that they suffice to describe all possiblestates of the world.",
        "url": " /advanced-planning-exercises/ex_11/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-10":  {
        "title": "Exercise 11.10",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "In the blocks world we were forced to introduce two action schemas,${Move}$ and ${MoveToTable}$, in order to maintain the ${Clear}$predicate properly. Show how conditional effects can be used torepresent both of these cases with a single action.",
        "url": " /advanced-planning-exercises/ex_10/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-3":  {
        "title": "Exercise 11.3",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Suppose that a high-level action has exactly oneimplementation as a sequence of primitive actions. Give an algorithm forcomputing its preconditions and effects, given the complete refinementhierarchy and schemas for the primitive actions.",
        "url": " /advanced-planning-exercises/ex_3/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-4":  {
        "title": "Exercise 11.4",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Suppose that the optimistic reachable set of a high-level plan is asuperset of the goal set; can anything be concluded about whether theplan achieves the goal? What if the pessimistic reachable set doesn’tintersect the goal set? Explain.",
        "url": " /advanced-planning-exercises/ex_4/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-5":  {
        "title": "Exercise 11.5",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Write an algorithm that takes an initialstate (specified by a set of propositional literals) and a sequence ofHLAs (each defined by preconditions and angelic specifications ofoptimistic and pessimistic reachable sets) and computes optimistic andpessimistic descriptions of the reachable set of the sequence.",
        "url": " /advanced-planning-exercises/ex_5/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-2":  {
        "title": "Exercise 11.2",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "You have a number of trucks with which to deliver a set of packages.Each package starts at some location on a grid map, and has adestination somewhere else. Each truck is directly controlled by movingforward and turning. Construct a hierarchy of high-level actions forthis problem. What knowledge about the solution does your hierarchyencode?",
        "url": " /advanced-planning-exercises/ex_2/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-15":  {
        "title": "Exercise 11.15",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "To the medication problem in the previous exercise, add a ${Test}$action that has the conditional effect ${CultureGrowth}$ when${Disease}$ is true and in any case has the perceptual effect${Known}({CultureGrowth})$. Diagram a conditional plan that solvesthe problem and minimizes the use of the ${Medicate}$ action.",
        "url": " /advanced-planning-exercises/ex_15/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-12":  {
        "title": "Exercise 11.12",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Find a suitably dirty carpet, free of obstacles, and vacuum it. Draw thepath taken by the vacuum cleaner as accurately as you can. Explain it,with reference to the forms of planning discussed in this chapter.",
        "url": " /advanced-planning-exercises/ex_12/"
      }
    
  
    ,
      "dbn-exercises-ex-11":  {
        "title": "Exercise 15.11",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .7 on each step; the robot switches to arandomly selected new heading with probability .3 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?    A Bayesian network representation of a switching Kalman filter. The switching variable $S_t$ is a discrete state variable whose value determines  the transition model for the continuous state variables $textbf{X}_t$.  For any discrete state $textit{i}$, the transition model  $textbf{P}(textbf{X}_{t+1}|textbf{X}_t,S_t= i)$ is a linear Gaussian model, just as in a  regular Kalman filter. The transition model for the discrete state,  $textbf{P}(S_{t+1}|S_t)$, can be thought of as a matrix, as in a hidden  Markov model.",
        "url": " /dbn-exercises/ex_11/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-14":  {
        "title": "Exercise 11.14",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Consider the following problem: A patient arrives at the doctor’s officewith symptoms that could have been caused either by dehydration or bydisease $D$ (but not both). There are two possible actions: ${Drink}$,which unconditionally cures dehydration, and ${Medicate}$, which curesdisease $D$ but has an undesirable side effect if taken when the patientis dehydrated. Write the problem description, and diagram a sensorlessplan that solves the problem, enumerating all relevant possible worlds.",
        "url": " /advanced-planning-exercises/ex_14/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-9":  {
        "title": "Exercise 11.9",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Suppose the ${Flip}$ actionalways changes the truth value of variable $L$. Show how to define itseffects by using an action schema with conditional effects. Show that,despite the use of conditional effects, a 1-CNF belief staterepresentation remains in 1-CNF after a ${Flip}$.",
        "url": " /advanced-planning-exercises/ex_9/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-7":  {
        "title": "Exercise 11.7",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Some of the operations in standard programming languages can be modeledas actions that change the state of the world. For example, theassignment operation changes the contents of a memory location, and theprint operation changes the state of the output stream. A programconsisting of these operations can also be considered as a plan, whosegoal is given by the specification of the program. Therefore, planningalgorithms can be used to construct programs that achieve a givenspecification. 1.  Write an action schema for the assignment operator (assigning the    value of one variable to another). Remember that the original value    will be overwritten! 2.  Show how object creation can be used by a planner to produce a plan    for exchanging the values of two variables by using a    temporary variable. ",
        "url": " /advanced-planning-exercises/ex_7/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-1":  {
        "title": "Exercise 11.1",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "The goals we have considered so far all ask the planner to make theworld satisfy the goal at just one time step. Not all goals can beexpressed this way: you do not achieve the goal of suspending achandelier above the ground by throwing it in the air. More seriously,you wouldn’t want your spacecraft life-support system to supply oxygenone day but not the next. A maintenance goal is achievedwhen the agent’s plan causes a condition to hold continuously from agiven state onward. Describe how to extend the formalism of this chapterto support maintenance goals.",
        "url": " /advanced-planning-exercises/ex_1/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-6":  {
        "title": "Exercise 11.6",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "In Figure jobshop-cpm-figure we showed how to describeactions in a scheduling problem by using separate fields for , , and .Now suppose we wanted to combine scheduling with nondeterministicplanning, which requires nondeterministic and conditional effects.Consider each of the three fields and explain if they should remainseparate fields, or if they should become effects of the action. Give anexample for each of the three.",
        "url": " /advanced-planning-exercises/ex_6/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-8":  {
        "title": "Exercise 11.8",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Consider the following argument: In a framework that allows uncertaininitial states, nondeterministic effectsare just a notational convenience, not a source of additionalrepresentational power. For any action schema $a$ with nondeterministiceffect $P lor Q$, we could always replace it with the conditionaleffects ${~R{:}~P} land{~lnot R{:}~Q}$, which in turn can bereduced to two regular actions. The proposition $R$ stands for a randomproposition that is unknown in the initial state and for which there areno sensing actions. Is this argument correct? Consider separately twocases, one in which only one instance of action schema $a$ is in theplan, the other in which more than one instance is.",
        "url": " /advanced-planning-exercises/ex_8/"
      }
    
  
    
  
    ,
      "nlp-communicating-exercises-ex-11":  {
        "title": "Exercise 22.11",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Consider the problem of trying to evaluate the quality of an IR systemthat returns a ranked list of answers (like most Web search engines).The appropriate measure of quality depends on the presumed model of whatthe searcher is trying to achieve, and what strategy she employs. Foreach of the following models, propose a corresponding numeric measure.1.  The searcher will look at the first twenty answers returned, with    the objective of getting as much relevant information as possible.2.  The searcher needs only one relevant document, and will go down the    list until she finds the first one.3.  The searcher has a fairly narrow query and is able to examine all    the answers retrieved. She wants to be sure that she has seen    everything in the document collection that is relevant to her query.    (E.g., a lawyer wants to be sure that she has found    all relevant precedents, and is willing to spend    considerable resources on that.)4.  The searcher needs just one document relevant to the query, and can    afford to pay a research assistant for an hour’s work looking    through the results. The assistant can look through 100 retrieved    documents in an hour. The assistant will charge the searcher for the    full hour regardless of whether he finds it immediately or at the    end of the hour.5.  The searcher will look through all the answers. Examining a document    has cost $ A; finding a relevant document has value $ B; failing    to find a relevant document has cost $ C for each relevant    document not found.6.  The searcher wants to collect as many relevant documents as    possible, but needs steady encouragement. She looks through the    documents in order. If the documents she has looked at so far are    mostly good, she will continue; otherwise, she will stop.",
        "url": " /nlp-communicating-exercises/ex_11/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-10":  {
        "title": "Exercise 22.10",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Write a regular expression or a short program to extract company names.Test it on a corpus of business news articles. Report your recall andprecision.",
        "url": " /nlp-communicating-exercises/ex_10/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-3":  {
        "title": "Exercise 22.3",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Zipf’s law of word distribution states the following:Take a large corpus of text, count the frequency of every word in thecorpus, and then rank these frequencies in decreasing order. Let $f_{I}$be the $I$th largest frequency in this list; that is, $f_{1}$ is thefrequency of the most common word (usually “the”), $f_{2}$ is thefrequency of the second most common word, and so on. Zipf’s law statesthat $f_{I}$ is approximately equal to $alpha / I$ for some constant$alpha$. The law tends to be highly accurate except for very small andvery large values of $I$.",
        "url": " /nlp-communicating-exercises/ex_3/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-4":  {
        "title": "Exercise 22.4",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Choose a corpus of at least 20,000 words of online text, and verifyZipf’s law experimentally. Define an error measure and find the value of$alpha$ where Zipf’s law best matches your experimental data. Create alog–log graph plotting $f_{I}$ vs. $I$ and $alpha/I$ vs. $I$. (On alog–log graph, the function $alpha/I$ is a straight line.) In carryingout the experiment, be sure to eliminate any formatting tokens (e.g.,HTML tags) and normalize upper and lower case.",
        "url": " /nlp-communicating-exercises/ex_4/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-5":  {
        "title": "Exercise 22.5",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "(Adapted from Jurafsky+Martin:2000.) In this exercise you will develop a classifier forauthorship: given a text, the classifier predicts which of two candidateauthors wrote the text. Obtain samples of text from two differentauthors. Separate them into training and test sets. Now train a languagemodel on the training set. You can choose what features to use;$n$-grams of words or letters are the easiest, but you can addadditional features that you think may help. Then compute theprobability of the text under each language model and chose the mostprobable model. Assess the accuracy of this technique. How does accuracychange as you alter the set of features? This subfield of linguistics iscalled stylometry; its successes include the identification of the author of thedisputed Federalist Papers Mosteller+Wallace:1964 andsome disputed works of Shakespeare Hope:1994. Khmelev+Tweedie:2001 produce good results witha simple letter bigram model.",
        "url": " /nlp-communicating-exercises/ex_5/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-2":  {
        "title": "Exercise 22.2",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Write a program to do segmentation ofwords without spaces. Given a string, such as the URL“thelongestlistofthelongeststuffatthelongestdomainnameatlonglast.com,”return a list of component words: [“the,” “longest,” “list,”$ldots$]. This task is useful for parsing URLs, for spellingcorrection when words runtogether, and for languages such as Chinesethat do not have spaces between words. It can be solved with a unigramor bigram word model and a dynamic programming algorithm similar to theViterbi algorithm.",
        "url": " /nlp-communicating-exercises/ex_2/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-9":  {
        "title": "Exercise 22.9",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Estimate how much storage space is necessary for the index to a 100billion-page corpus of Web pages. Show the assumptions you made.",
        "url": " /nlp-communicating-exercises/ex_9/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-7":  {
        "title": "Exercise 22.7",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Create a test set of ten queries, and pose them to three major Websearch engines. Evaluate each one for precision at 1, 3, and 10documents. Can you explain the differences between engines?",
        "url": " /nlp-communicating-exercises/ex_7/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-1":  {
        "title": "Exercise 22.1",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "This exercise explores the quality of the $n$-gram model of language.Find or create a monolingual corpus of 100,000 words or more. Segment itinto words, and compute the frequency of each word. How many distinctwords are there? Also count frequencies of bigrams (two consecutivewords) and trigrams (three consecutive words). Now use those frequenciesto generate language: from the unigram, bigram, and trigram models, inturn, generate a 100-word text by making random choices according to thefrequency counts. Compare the three generated texts with actuallanguage. Finally, calculate the perplexity of each model.",
        "url": " /nlp-communicating-exercises/ex_1/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-6":  {
        "title": "Exercise 22.6",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "This exercise concerns the classification of spam email.Create a corpus of spam email and one of non-spam mail. Examine eachcorpus and decide what features appear to be useful for classification:unigram words? bigrams? message length, sender, time of arrival? Thentrain a classification algorithm (decision tree, naive Bayes, SVM,logistic regression, or some other algorithm of your choosing) on atraining set and report its accuracy on a test set.",
        "url": " /nlp-communicating-exercises/ex_6/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-8":  {
        "title": "Exercise 22.8",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Try to ascertain which of the search engines from the previous exerciseare using case folding, stemming, synonyms, and spelling correction.",
        "url": " /nlp-communicating-exercises/ex_8/"
      }
    
  
    
  
    ,
      "fol-exercises-ex-11":  {
        "title": "Exercise 8.11",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Consider a vocabulary with the following symbols:&amp;gt; ${Occupation}(p,o)$: Predicate. Person $p$ has occupation $o$.&amp;gt; ${Customer}(p1,p2)$: Predicate. Person $p1$ is a customer of person $p2$.&amp;gt; ${Boss}(p1,p2)$: Predicate. Person $p1$ is a boss of person $p2$.&amp;gt; ${Doctor}$, $ {Surgeon}$, $ {Lawyer}$, $ {Actor}$: Constants denoting occupations.&amp;gt; ${Emily}$, $ {Joe}$: Constants denoting people.Use these symbols to write the following assertions in first-orderlogic:1.  Emily is either a surgeon or a lawyer.2.  Joe is an actor, but he also holds another job.3.  All surgeons are doctors.4.  Joe does not have a lawyer (i.e., is not a customer of any lawyer).5.  Emily has a boss who is a lawyer.6.  There exists a lawyer all of whose customers are doctors.7.  Every surgeon has a lawyer.",
        "url": " /fol-exercises/ex_11/"
      }
    
  
    ,
      "fol-exercises-ex-16":  {
        "title": "Exercise 8.16",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Equation (pit-biconditional-equation) onpage pit-biconditional-equation defines the conditions under which a square isbreezy. Here we consider two other ways to describe this aspect of thewumpus world.1.  We can write [diagnostic rule] leading from observed effects to hidden causes. For    finding pits, the obvious diagnostic rules say that if a square is    breezy, some adjacent square must contain a pit; and if a square is    not breezy, then no adjacent square contains a pit. Write these two    rules in first-order logic and show that their conjunction is    logically equivalent to    Equation (pit-biconditional-equation).2.  We can write [causal rule] leading from cause to effect. One obvious causal rule    is that a pit causes all adjacent squares to be breezy. Write this    rule in first-order logic, explain why it is incomplete compared to    Equation (pit-biconditional-equation), and supply    the missing axiom.",
        "url": " /fol-exercises/ex_16/"
      }
    
  
    ,
      "fol-exercises-ex-29":  {
        "title": "Exercise 8.29",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it.1.  Any apartment in London has lower rent than some apartments    in Paris.$$forall {x} [{Apt}(x) land {In}(x,{London})]implies exists {y} ([{Apt}(y) land {In}(y,{Paris})] implies ({Rent}(x) &amp;lt; {Rent}(y)))$$2.  There is exactly one apartment in Paris with rent below $1000.$$exists {x} {Apt}(x) land {In}(x,{Paris}) land forall{y} [{Apt}(y) land {In}(y,{Paris}) land ({Rent}(y) &amp;lt; {Dollars}(1000))] implies (y = x)$$3.  If an apartment is more expensive than all apartments in London, it    must be in Moscow.$$forall{x} {Apt}(x) land [forall{y} {Apt}(y) land {In}(y,{London}) land ({Rent}(x) &amp;gt; {Rent}(y))] implies{In}(x,{Moscow}).$$",
        "url": " /fol-exercises/ex_29/"
      }
    
  
    ,
      "fol-exercises-ex-20":  {
        "title": "Exercise 8.20",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Using the set axioms as examples, writeaxioms for the list domain, including all the constants, functions, andpredicates mentioned in the chapter.",
        "url": " /fol-exercises/ex_20/"
      }
    
  
    ,
      "fol-exercises-ex-27":  {
        "title": "Exercise 8.27",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it. (Some sentences may have more than oneerror!)1.  No two people have the same social security number.    $$lnot {exists,x,y,n;;} {Person}(x) land {Person}(y) {:;{Rightarrow}:;}[{HasSS}#(x,n) land {HasSS}#(y,n)].$$2.  John’s social security number is the same as Mary’s.    $${exists,n;;} {HasSS}#({John},n) land {HasSS}#({Mary},n).$$3.  Everyone’s social security number has nine digits.    $${forall,x,n;;} {Person}(x) {:;{Rightarrow}:;}[{HasSS}#(x,n) land {Digits}(n,9)].$$4.  Rewrite each of the above (uncorrected) sentences using a function    symbol ${SS}#$ instead of the predicate ${HasSS}#$.",
        "url": " /fol-exercises/ex_27/"
      }
    
  
    ,
      "fol-exercises-ex-18":  {
        "title": "Exercise 8.18",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write down a sentence asserting that + is a commutative function. Doesyour sentence follow from the Peano axioms? If so, explain why; if not,give a model in which the axioms are true and your sentence is false.",
        "url": " /fol-exercises/ex_18/"
      }
    
  
    ,
      "fol-exercises-ex-26":  {
        "title": "Exercise 8.26",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write in first-order logic the assertion that every key and at least oneof every pair of socks will eventually be lost forever, using only thefollowing vocabulary: ${Key}(x)$, $x$ is a key; ${Sock}(x)$, $x$ isa sock; ${Pair}(x,y)$, $x$ and $y$ are a pair; ${Now}$, the currenttime; ${Before}(t_1,t_2)$, time $t_1$ comes before time $t_2$;${Lost}(x,t)$, object $x$ is lost at time $t$.",
        "url": " /fol-exercises/ex_26/"
      }
    
  
    ,
      "fol-exercises-ex-19":  {
        "title": "Exercise 8.19",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Explain what is wrong with the following proposed definition of the setmembership predicate $$ {forall,x,s;;} x in {x|s} $$ $$ {forall,x,s;;} x in s implies {forall,y;;} x in {y|s} $$",
        "url": " /fol-exercises/ex_19/"
      }
    
  
    ,
      "fol-exercises-ex-21":  {
        "title": "Exercise 8.21",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Explain what is wrong with the following proposeddefinition of adjacent squares in the wumpus world:$${forall,x,y;;} {Adjacent}([x,y], [x+1, y]) land {Adjacent}([x,y], [x, y+1]) .$$",
        "url": " /fol-exercises/ex_21/"
      }
    
  
    ,
      "fol-exercises-ex-17":  {
        "title": "Exercise 8.17",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write axioms describing the predicates${Grandchild}$, ${Greatgrandparent}$, ${Ancestor}$, ${Brother}$,${Sister}$, ${Daughter}$, ${Son}$, ${FirstCousin}$,${BrotherInLaw}$, ${SisterInLaw}$, ${Aunt}$, and ${Uncle}$. Findout the proper definition of $m$th cousin $n$ times removed, and writethe definition in first-order logic. Now write down the basic factsdepicted in the family tree in Figure family1-figure.Using a suitable logical reasoning system, it all the sentences you havewritten down, and it who are Elizabeth’s grandchildren, Diana’sbrothers-in-law, Zara’s great-grandparents, and Eugenie’s ancestors.    A typical family tree. The symbol $bowtie$ connects spouses and arrows point to children.",
        "url": " /fol-exercises/ex_17/"
      }
    
  
    ,
      "fol-exercises-ex-28":  {
        "title": "Exercise 8.28",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Translate into first-order logic the sentence “Everyone’s DNA is uniqueand is derived from their parents’ DNA.” You must specify the preciseintended meaning of your vocabulary terms. (*Hint*: Do notuse the predicate ${Unique}(x)$, since uniqueness is not really aproperty of an object in itself!)",
        "url": " /fol-exercises/ex_28/"
      }
    
  
    ,
      "fol-exercises-ex-10":  {
        "title": "Exercise 8.10",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "This exercise uses the function ${MapColor}$ and predicates${In}(x,y)$, ${Borders}(x,y)$, and ${Country}(x)$, whose argumentsare geographical regions, along with constant symbols for variousregions. In each of the following we give an English sentence and anumber of candidate logical expressions. For each of the logicalexpressions, state whether it (1) correctly expresses the Englishsentence; (2) is syntactically invalid and therefore meaningless; or (3)is syntactically valid but does not express the meaning of the Englishsentence.1.  Paris and Marseilles are both in France.    1.  ${In}({Paris} land {Marseilles}, {France})$.    2.  ${In}({Paris},{France}) land {In}({Marseilles},{France})$.    3.  ${In}({Paris},{France}) lor {In}({Marseilles},{France})$.2.  There is a country that borders both Iraq and Pakistan.    1.  ${exists,c;;}$        ${Country}(c) land {Border}(c,{Iraq}) land {Border}(c,{Pakistan})$.    2.  ${exists,c;;}$        ${Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.    3.  $[{exists,c;;}$        ${Country}(c)] {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.    4.  ${exists,c;;}$        ${Border}({Country}(c),{Iraq} land {Pakistan})$.3.  All countries that border Ecuador are in South America.    1.  ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.    2.  ${forall,c;;}  {Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})]$.    3.  ${forall,c;;}  [{Country}(c) {:;{Rightarrow}:;}{Border}(c,{Ecuador})] {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.    4.  ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) land {In}(c,{SouthAmerica})$.4.  No region in South America borders any region in Europe.    1.  $lnot [{exists,c,d;;}  {In}(c,{SouthAmerica}) land {In}(d,{Europe}) land {Borders}(c,d)]$.    2.  ${forall,c,d;;}  [{In}(c,{SouthAmerica}) land {In}(d,{Europe})] {:;{Rightarrow}:;}lnot {Borders}(c,d)]$.    3.  $lnot {forall,c;;}  {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{exists,d;;} {In}(d,{Europe}) land        lnot {Borders}(c,d)$.    4.  ${forall,c;;} {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{forall,d;;} {In}(d,{Europe}) {:;{Rightarrow}:;}lnot {Borders}(c,d)$.5.  No two adjacent countries have the same map color.    1.  ${forall,x,y;;} lnot {Country}(x) lor lnot {Country}(y) lor lnot {Borders}(x,y) lor {}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    2.  ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) land lnot(x=y)) {:;{Rightarrow}:;}{}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    3.  ${forall,x,y;;} {Country}(x) land {Country}(y) land {Borders}(x,y) land {}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    4.  ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) ) {:;{Rightarrow}:;}{MapColor}(xneq y)$.",
        "url": " /fol-exercises/ex_10/"
      }
    
  
    ,
      "fol-exercises-ex-32":  {
        "title": "Exercise 8.32",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write a general set of facts and axioms to represent the assertion“Wellington heard about Napoleon’s death” and to correctly answer thequestion “Did Napoleon hear about Wellington’s death?”",
        "url": " /fol-exercises/ex_32/"
      }
    
  
    ,
      "fol-exercises-ex-35":  {
        "title": "Exercise 8.35",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Obtain a passport application for your country, identify the rulesdetermining eligibility for a passport, and translate them intofirst-order logic, following the steps outlined inSection circuits-section",
        "url": " /fol-exercises/ex_35/"
      }
    
  
    ,
      "fol-exercises-ex-3":  {
        "title": "Exercise 8.3",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Is the sentence ${exists,x,y;;} xy$ valid? Explain.",
        "url": " /fol-exercises/ex_3/"
      }
    
  
    ,
      "fol-exercises-ex-4":  {
        "title": "Exercise 8.4",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write down a logical sentence such that every world in which it is truecontains exactly one object.",
        "url": " /fol-exercises/ex_4/"
      }
    
  
    ,
      "fol-exercises-ex-34":  {
        "title": "Exercise 8.34",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "The circuit representation in the chapter is more detailed thannecessary if we care only about circuit functionality. A simplerformulation describes any $m$-input, $n$-output gate or circuit using apredicate with $m+n$ arguments, such that the predicate is true exactlywhen the inputs and outputs are consistent. For example, NOT gates aredescribed by the binary predicate ${NOT}(i,o)$, for which${NOT}(0,1)$ and ${NOT}(1,0)$ are known. Compositions of gates aredefined by conjunctions of gate predicates in which shared variablesindicate direct connections. For example, a NAND circuit can be composedfrom ${AND}$s and ${NOT}$s:$${forall,i_1,i_2,o_a,o;;} {AND}(i_1,i_2,o_a) land {NOT}(o_a,o) {:;{Rightarrow}:;}{NAND}(i_1,i_2,o) .$$Using this representation, define the one-bit adder inFigure adder-figure and the four-bit adder inFigure adder-figure, and explain what queries youwould use to verify the designs. What kinds of queries are*not* supported by this representation that*are* supported by the representation inSection circuits-section?",
        "url": " /fol-exercises/ex_34/"
      }
    
  
    ,
      "fol-exercises-ex-33":  {
        "title": "Exercise 8.33",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Extend the vocabulary fromSection circuits-section to define addition for $n$-bitbinary numbers. Then encode the description of the four-bit adder inFigure 4bit-adder-figure, and pose the queries neededto verify that it is in fact correct.    A four-bit adder. Each ${Ad}_i$ is a one-bit adder, as in figure adder-figure on page &amp;lt;a href=&quot;&quot;#&quot;&amp;gt;adder-figure&amp;lt;/a&amp;gt;",
        "url": " /fol-exercises/ex_33/"
      }
    
  
    ,
      "fol-exercises-ex-5":  {
        "title": "Exercise 8.5",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write down a logical sentence such that every world in which it is truecontains exactly two objects.",
        "url": " /fol-exercises/ex_5/"
      }
    
  
    ,
      "fol-exercises-ex-2":  {
        "title": "Exercise 8.2",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Consider a knowledge base containing just two sentences: $P(a)$ and$P(b)$. Does this knowledge base entail $forall,x P(x)$? Explain youranswer in terms of models.",
        "url": " /fol-exercises/ex_2/"
      }
    
  
    ,
      "fol-exercises-ex-15":  {
        "title": "Exercise 8.15",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Rewrite the first two Peano axioms inSection Peano-section as a single axiom that defines${NatNum}(x)$ so as to exclude the possibility of natural numbersexcept for those generated by the successor function.",
        "url": " /fol-exercises/ex_15/"
      }
    
  
    ,
      "fol-exercises-ex-12":  {
        "title": "Exercise 8.12",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "In each of the following we give an English sentence and a number ofcandidate logical expressions. For each of the logical expressions,state whether it (1) correctly expresses the English sentence; (2) issyntactically invalid and therefore meaningless; or (3) is syntacticallyvalid but does not express the meaning of the English sentence.1.  Every cat loves its mother or father.    1.  ${forall,x;;} {Cat}(x) {:;{Rightarrow}:;}{Loves}(x,{Mother}(x)lor {Father}(x))$.    2.  ${forall,x;;} lnot {Cat}(x) lor {Loves}(x,{Mother}(x)) lor {Loves}(x,{Father}(x))$.    3.  ${forall,x;;} {Cat}(x) land ({Loves}(x,{Mother}(x))lor {Loves}(x,{Father}(x)))$.2.  Every dog who loves one of its brothers is happy.    1.  ${forall,x;;} {Dog}(x) land (exists y {Brother}(y,x) land {Loves}(x,y)) {:;{Rightarrow}:;}{Happy}(x)$.    2.  ${forall,x,y;;} {Dog}(x) land {Brother}(y,x) land {Loves}(x,y) {:;{Rightarrow}:;}{Happy}(x)$.    3.  ${forall,x;;} {Dog}(x) land [{forall,y;;} {Brother}(y,x) {;;{Leftrightarrow};;}{Loves}(x,y)] {:;{Rightarrow}:;}{Happy}(x)$.3.  No dog bites a child of its owner.    1.  ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}lnot {Bites}(x,{Child}({Owner}(x)))$.    2.  $lnot {exists,x,y;;} {Dog}(x) land {Child}(y,{Owner}(x)) land {Bites}(x,y)$.    3.  ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}({forall,y;;} {Child}(y,{Owner}(x)) {:;{Rightarrow}:;}lnot {Bites}(x,y))$.    4.  $lnot {exists,x;;} {Dog}(x) {:;{Rightarrow}:;}({exists,y;;} {Child}(y,{Owner}(x)) land {Bites}(x,y))$.4.  Everyone’s zip code within a state has the same first digit.    1.  ${forall,x,s,z_1;;} [{State}(s) land {LivesIn}(x,s) land {Zip}(x)z_1] {:;{Rightarrow}:;}{}$        $[{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 {:;{Rightarrow}:;}{Digit}(1,z_1) {Digit}(1,z_2) ]$.    2.  ${forall,x,s;;} [{State}(s) land {LivesIn}(x,s) land {exists,z_1;;} {Zip}(x)z_1] {:;{Rightarrow}:;}{}$        $ [{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 land {Digit}(1,z_1) {Digit}(1,z_2) ]$.    3.  ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{Digit}(1,{Zip}(x){Zip}(y))$.    4.  ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{}$        ${Digit}(1,{Zip}(x)) {Digit}(1,{Zip}(y))$.",
        "url": " /fol-exercises/ex_12/"
      }
    
  
    ,
      "fol-exercises-ex-24":  {
        "title": "Exercise 8.24",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Arithmetic assertions can be written in first-order logic with thepredicate symbol $&amp;lt;$, the function symbols ${+}$ and ${times}$, and theconstant symbols 0 and 1. Additional predicates can also be defined withbiconditionals.1.  Represent the property “$x$ is an even number.”2.  Represent the property “$x$ is prime.”3.  Goldbach’s conjecture is the conjecture (unproven as yet) that every    even number is equal to the sum of two primes. Represent this    conjecture as a logical sentence.",
        "url": " /fol-exercises/ex_24/"
      }
    
  
    ,
      "fol-exercises-ex-23":  {
        "title": "Exercise 8.23",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Assuming predicates ${Parent}(p,q)$ and ${Female}(p)$ and constants${Joan}$ and ${Kevin}$, with the obvious meanings, express each ofthe following sentences in first-order logic. (You may use theabbreviation $exists^{1}$ to mean “there exists exactly one.”)1.  Joan has a daughter (possibly more than one, and possibly sons    as well).2.  Joan has exactly one daughter (but may have sons as well).3.  Joan has exactly one child, a daughter.4.  Joan and Kevin have exactly one child together.5.  Joan has at least one child with Kevin, and no children with    anyone else.",
        "url": " /fol-exercises/ex_23/"
      }
    
  
    ,
      "fol-exercises-ex-22":  {
        "title": "Exercise 8.22",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Write out the axioms required for reasoning about the wumpus’s location,using a constant symbol ${Wumpus}$ and a binary predicate${At}({Wumpus}, {Location})$. Remember that there is only onewumpus.",
        "url": " /fol-exercises/ex_22/"
      }
    
  
    ,
      "fol-exercises-ex-25":  {
        "title": "Exercise 8.25",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "In Chapter csp-chapter, we used equality to indicatethe relation between a variable and its value. For instance, we wrote${WA}{red}$ to mean that Western Australia is coloredred. Representing this in first-order logic, we must write moreverbosely ${ColorOf}({WA}){red}$. What incorrectinference could be drawn if we wrote sentences such as${WA}{red}$ directly as logical assertions?",
        "url": " /fol-exercises/ex_25/"
      }
    
  
    ,
      "fol-exercises-ex-13":  {
        "title": "Exercise 8.13",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Complete the following exercisesabout logical sentences:1.  Translate into *good, natural* English (no $x$s or $y$s!):$${forall,x,y,l;;} SpeaksLanguage(x, l) land SpeaksLanguage(y, l)    implies Understands(x, y) land Understands(y,x).$$2.  Explain why this sentence is entailed by the sentence$${forall,x,y,l;;} SpeaksLanguage(x, l) land SpeaksLanguage(y, l)    implies Understands(x, y).$$3.  Translate into first-order logic the following sentences:    1.  Understanding leads to friendship.    2.  Friendship is transitive.    Remember to define all predicates, functions, and constants you use.",
        "url": " /fol-exercises/ex_13/"
      }
    
  
    ,
      "fol-exercises-ex-14":  {
        "title": "Exercise 8.14",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "True or false? Explain.1.  ${exists,x;;} x{Rumpelstiltskin}$ is a valid    (necessarily true) sentence of first-order logic.2.  Every existentially quantified sentence in first-order logic is true    in any model that contains exactly one object.3.  ${forall,x,y;;} xy$is satisfiable.",
        "url": " /fol-exercises/ex_14/"
      }
    
  
    ,
      "fol-exercises-ex-9":  {
        "title": "Exercise 8.9",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Does the fact$lnot {Spouse}({George},{Laura})$ follow from the facts${Jim}neq {George}$ and ${Spouse}({Jim},{Laura})$? If so,give a proof; if not, supply additional axioms as needed. What happensif we use ${Spouse}$ as a unary function symbol instead of a binarypredicate?",
        "url": " /fol-exercises/ex_9/"
      }
    
  
    ,
      "fol-exercises-ex-7":  {
        "title": "Exercise 8.7",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Which of the following are valid (necessarily true) sentences?1.  $(exists x xx) {:;{Rightarrow}:;}({forall,y;;} exists z yz)$. 2.  ${forall,x;;} P(x) lor lnot P(x)$.3.  ${forall,x;;} {Smart}(x) lor (xx)$.",
        "url": " /fol-exercises/ex_7/"
      }
    
  
    ,
      "fol-exercises-ex-36":  {
        "title": "Exercise 8.36",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Consider a first-order logical knowledge base that describes worldscontaining people, songs, albums (e.g., “Meet the Beatles”) and disks(i.e., particular physical instances of CDs). The vocabulary containsthe following symbols:&amp;gt; ${CopyOf}(d,a)$: Predicate. Disk $d$ is a copy of album $a$.&amp;gt; ${Owns}(p,d)$: Predicate. Person $p$ owns disk $d$.&amp;gt; ${Sings}(p,s,a)$: Album $a$ includes a recording of song $s$ sung by person $p$.&amp;gt; ${Wrote}(p,s)$: Person $p$ wrote song $s$.&amp;gt; ${McCartney}$, ${Gershwin}$, ${BHoliday}$, ${Joe}$, ${EleanorRigby}$, ${TheManILove}$, ${Revolver}$: Constants with the obvious meanings.Express the following statements in first-order logic:1.  Gershwin wrote “The Man I Love.”2.  Gershwin did not write “Eleanor Rigby.”3.  Either Gershwin or McCartney wrote “The Man I Love.”4.  Joe has written at least one song.5.  Joe owns a copy of *Revolver*.6.  Every song that McCartney sings on *Revolver* was    written by McCartney.7.  Gershwin did not write any of the songs on *Revolver*.8.  Every song that Gershwin wrote has been recorded on some album.    (Possibly different songs are recorded on different albums.)9.  There is a single album that contains every song that Joe    has written.10. Joe owns a copy of an album that has Billie Holiday singing “The Man    I Love.”11. Joe owns a copy of every album that has a song sung by McCartney.    (Of course, each different album is instantiated in a different    physical CD.)12. Joe owns a copy of every album on which all the songs are sung by    Billie Holiday.",
        "url": " /fol-exercises/ex_36/"
      }
    
  
    ,
      "fol-exercises-ex-31":  {
        "title": "Exercise 8.31",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):1.  Some students took French in spring 2001.2.  Every student who takes French passes it.3.  Only one student took Greek in spring 2001.4.  The best score in Greek is always higher than the best score    in French.5.  Every person who buys a policy is smart.6.  No person buys an expensive policy.7.  There is an agent who sells policies only to people who are    not insured.8.  There is a barber who shaves all men in town who do not    shave themselves.9.  A person born in the UK, each of whose parents is a UK citizen or a    UK resident, is a UK citizen by birth.10. A person born outside the UK, one of whose parents is a UK citizen    by birth, is a UK citizen by descent.11. Politicians can fool some of the people all of the time, and they    can fool all of the people some of the time, but they can’t fool all    of the people all of the time.12. All Greeks speak the same language. (Use ${Speaks}(x,l)$ to mean    that person $x$ speaks language $l$.)",
        "url": " /fol-exercises/ex_31/"
      }
    
  
    ,
      "fol-exercises-ex-1":  {
        "title": "Exercise 8.1",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "A logical knowledge base represents the world using a set of sentenceswith no explicit structure. An analogicalrepresentation, on the other hand, has physical structure thatcorresponds directly to the structure of the thing represented. Considera road map of your country as an analogical representation of factsabout the country—it represents facts with a map language. Thetwo-dimensional structure of the map corresponds to the two-dimensionalsurface of the area.1.  Give five examples of symbols in the map language.2.  An explicit sentence is a sentence that the creator    of the representation actually writes down. An    implicit sentence is a sentence that results from    explicit sentences because of properties of the analogical    representation. Give three examples each of implicit    and explicit sentences in the map language.3.  Give three examples of facts about the physical structure of your    country that cannot be represented in the map language.4.  Give two examples of facts that are much easier to express in the    map language than in first-order logic.5.  Give two other examples of useful analogical representations. What    are the advantages and disadvantages of each of these languages?",
        "url": " /fol-exercises/ex_1/"
      }
    
  
    ,
      "fol-exercises-ex-6":  {
        "title": "Exercise 8.6",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Consider a symbol vocabulary that contains$c$ constant symbols, $p_k$ predicate symbols of each arity $k$, and$f_k$ function symbols of each arity $k$, where $1leq kleq A$. Let thedomain size be fixed at $D$. For any given model, each predicate orfunction symbol is mapped onto a relation or function, respectively, ofthe same arity. You may assume that the functions in the model allowsome input tuples to have no value for the function (i.e., the value isthe invisible object). Derive a formula for the number of possiblemodels for a domain with $D$ elements. Don’t worry about eliminatingredundant combinations.",
        "url": " /fol-exercises/ex_6/"
      }
    
  
    ,
      "fol-exercises-ex-8":  {
        "title": "Exercise 8.8",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Consider a version of the semantics forfirst-order logic in which models with empty domains are allowed. Giveat least two examples of sentences that are valid according to thestandard semantics but not according to the new semantics. Discuss whichoutcome makes more intuitive sense for your examples.",
        "url": " /fol-exercises/ex_8/"
      }
    
  
    ,
      "fol-exercises-ex-30":  {
        "title": "Exercise 8.30",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):1.  Some students took French in spring 2001.2.  Every student who takes French passes it.3.  Only one student took Greek in spring 2001.4.  The best score in Greek is always higher than the best score    in French.5.  Every person who buys a policy is smart.6.  No person buys an expensive policy.7.  There is an agent who sells policies only to people who are    not insured.8.  There is a barber who shaves all men in town who do not    shave themselves.9.  A person born in the UK, each of whose parents is a UK citizen or a    UK resident, is a UK citizen by birth.10. A person born outside the UK, one of whose parents is a UK citizen    by birth, is a UK citizen by descent.11. Politicians can fool some of the people all of the time, and they    can fool all of the people some of the time, but they can’t fool all    of the people all of the time.12. All Greeks speak the same language. (Use ${Speaks}(x,l)$ to mean    that person $x$ speaks language $l$.)",
        "url": " /fol-exercises/ex_30/"
      }
    
  
    
  
    ,
      "perception-exercises-ex-3":  {
        "title": "Exercise 24.3",
        "breadcrumb": "24-Perception",
      	"content"  : "Consider an infinitely long cylinder of radius $r$ oriented with itsaxis along the $y$-axis. The cylinder has a Lambertian surface and isviewed by a camera along the positive $z$-axis. What will you expect tosee in the image if the cylinder is illuminated by a point source atinfinity located on the positive $x$-axis? Draw the contours of constantbrightness in the projected image. Are the contours of equal brightnessuniformly spaced?",
        "url": " /perception-exercises/ex_3/"
      }
    
  
    ,
      "perception-exercises-ex-4":  {
        "title": "Exercise 24.4",
        "breadcrumb": "24-Perception",
      	"content"  : "Edges in an image can correspond to a variety of events in a scene.Consider Figure illuminationfigure(page illuminationfigure, and assume that it is a picture of a realthree-dimensional scene. Identify ten different brightness edges in theimage, and for each, state whether it corresponds to a discontinuity in(a) depth, (b) surface orientation, (c) reflectance, or (d)illumination.",
        "url": " /perception-exercises/ex_4/"
      }
    
  
    ,
      "perception-exercises-ex-5":  {
        "title": "Exercise 24.5",
        "breadcrumb": "24-Perception",
      	"content"  : "A stereoscopic system is being contemplated for terrain mapping. It willconsist of two CCD cameras, each having ${512}times {512}$ pixels on a10 cm $times$ 10 cm square sensor. The lenses to be used have a focallength of 16 cm, with the focus fixed at infinity. For correspondingpoints ($u_1,v_1$) in the left image and ($u_2,v_2$) in the right image,$v_1=v_2$ because the $x$-axes in the two image planes are parallel tothe epipolar lines—the lines from the object to the camera. The opticalaxes of the two cameras are parallel. The baseline between the camerasis 1 meter.1.  If the nearest distance to be measured is 16 meters, what is the    largest disparity that will occur (in pixels)?2.  What is the distance resolution at 16 meters, due to the pixel    spacing?3.  What distance corresponds to a disparity of one pixel?",
        "url": " /perception-exercises/ex_5/"
      }
    
  
    ,
      "perception-exercises-ex-2":  {
        "title": "Exercise 24.2",
        "breadcrumb": "24-Perception",
      	"content"  : "Consider a picture of a white sphere floating in front of a blackbackdrop. The image curve separating white pixels from black pixels issometimes called the “outline” of the sphere. Show that the outline of asphere, viewed in a perspective camera, can be an ellipse. Why dospheres not look like ellipses to you?",
        "url": " /perception-exercises/ex_2/"
      }
    
  
    ,
      "perception-exercises-ex-7":  {
        "title": "Exercise 24.7",
        "breadcrumb": "24-Perception",
      	"content"  : "Which of the following are true, and which are false?1.  Finding corresponding points in stereo images is the easiest phase    of the stereo depth-finding process.2.  In stereo views of the same scene, greater accuracy is obtained in    the depth calculations if the two camera positions are    farther apart.3.  Lines with equal lengths in the scene always project to equal    lengths in the image.4.  Straight lines in the image necessarily correspond to straight lines    in the scene.                Top view of      a two-camera vision system observing a bottle with a wall behind it.    ",
        "url": " /perception-exercises/ex_7/"
      }
    
  
    ,
      "perception-exercises-ex-1":  {
        "title": "Exercise 24.1",
        "breadcrumb": "24-Perception",
      	"content"  : "In the shadow of a tree with a dense, leafy canopy, one sees a number oflight spots. Surprisingly, they all appear to be circular. Why? Afterall, the gaps between the leaves through which the sun shines are notlikely to be circular.",
        "url": " /perception-exercises/ex_1/"
      }
    
  
    ,
      "perception-exercises-ex-6":  {
        "title": "Exercise 24.6",
        "breadcrumb": "24-Perception",
      	"content"  : "Which of the following are true, and which are false?1.  Finding corresponding points in stereo images is the easiest phase    of the stereo depth-finding process.2.  Shape-from-texture can be done by projecting a grid of light-stripes    onto the scene.3.  Lines with equal lengths in the scene always project to equal    lengths in the image.4.  Straight lines in the image necessarily correspond to straight lines    in the scene.",
        "url": " /perception-exercises/ex_6/"
      }
    
  
    ,
      "perception-exercises-ex-8":  {
        "title": "Exercise 24.8",
        "breadcrumb": "24-Perception",
      	"content"  : "(Courtesy of Pietro Perona.) Figure bottle-figure showstwo cameras at X and Y observing a scene. Draw the image seen at eachcamera, assuming that all named points are in the same horizontal plane.What can be concluded from these two images about the relative distancesof points A, B, C, D, and E from the camera baseline, and on what basis?",
        "url": " /perception-exercises/ex_8/"
      }
    
  
    
  
    ,
      "advanced-planning-exercises-ex-13":  {
        "title": "Exercise 11.13",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "The following quotes are from the backs of shampoo bottles. Identifyeach as an unconditional, conditional, or execution-monitoring plan. (a)“Lather. Rinse. Repeat.” (b) “Apply shampoo to scalp and let it remainfor several minutes. Rinse and repeat if necessary.” (c) “See a doctorif problems persist.”",
        "url": " /advanced-planning-exercises/ex_13/"
      }
    
  
    ,
      "dbn-exercises-ex-16":  {
        "title": "Exercise 15.16",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:-   The prior probability of getting enough sleep, with no observations,    is 0.7.-   The probability of getting enough sleep on night $t$ is 0.8 given    that the student got enough sleep the previous night, and 0.3    if not.-   The probability of having red eyes is 0.2 if the student got enough    sleep, and 0.7 if not.-   The probability of sleeping in class is 0.1 if the student got    enough sleep, and 0.3 if not.Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.",
        "url": " /dbn-exercises/ex_16/"
      }
    
  
    ,
      "dbn-exercises-ex-20":  {
        "title": "Exercise 15.20",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Consider applying the variable eliminationalgorithm to the umbrella DBN unrolled for three slices, where the queryis ${textbf{P}}(R_3|u_1,u_2,u_3)$. Show that the spacecomplexity of the algorithm—the size of the largest factor—is the same,regardless of whether the rain variables are eliminated in forward orbackward order.",
        "url": " /dbn-exercises/ex_20/"
      }
    
  
    ,
      "dbn-exercises-ex-18":  {
        "title": "Exercise 15.18",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Suppose that a particular student shows up with red eyes and sleeps inclass every day. Given the model described inExercise sleep1-exercise, explain why the probabilitythat the student had enough sleep the previous night converges to afixed point rather than continuing to go down as we gather more days ofevidence. What is the fixed point? Answer this both numerically (bycomputation) and analytically.",
        "url": " /dbn-exercises/ex_18/"
      }
    
  
    ,
      "dbn-exercises-ex-19":  {
        "title": "Exercise 15.19",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "This exercise analyzes in more detail thepersistent-failure model for the battery sensor inFigure battery-persistence-figure(a)(page battery-persistence-figure).1.  Figure battery-persistence-figure(b) stops at    $t=32$. Describe qualitatively what should happen as    $ttoinfty$ if the sensor continues to read 0.2.  Suppose that the external temperature affects the battery sensor in    such a way that transient failures become more likely as    temperature increases. Show how to augment the DBN structure in    Figure battery-persistence-figure(a), and explain    any required changes to the CPTs.3.  Given the new network structure, can battery readings be used by the    robot to infer the current temperature?",
        "url": " /dbn-exercises/ex_19/"
      }
    
  
    ,
      "dbn-exercises-ex-17":  {
        "title": "Exercise 15.17",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "For the DBN specified in Exercise sleep1-exercise andfor the evidence values$textbf{e}_1 = notspace redspace eyes,space notspace sleepingspace inspace class$$textbf{e}_2 = redspace eyes,space notspace sleepingspace inspace class$$textbf{e}_3 = redspace eyes,space sleepingspace inspace class$perform the following computations:1.  State estimation: Compute $P({EnoughSleep}_t | textbf{e}_{1:t})$ for each    of $t = 1,2,3$.2.  Smoothing: Compute $P({EnoughSleep}_t | textbf{e}_{1:3})$ for each of    $t = 1,2,3$.3.  Compare the filtered and smoothed probabilities for $t=1$ and $t=2$.",
        "url": " /dbn-exercises/ex_17/"
      }
    
  
    ,
      "question-bank":  {
        "title": "Question Bank",
        "breadcrumb": "questionbank",
      	"content"  : "            Exercise 1                                Define in your own words: (a) intelligence, (b) artificial intelligence,(c) agent, (d) rationality, (e) logical reasoning.                Exercise 2                                Read Turing’s original paper on AI Turing:1950 .In the paper, he discusses several objections to his proposed enterprise and his test forintelligence. Which objections still carry weight? Are his refutationsvalid? Can you think of new objections arising from developments sincehe wrote the paper? In the paper, he predicts that, by the year 2000, acomputer will have a 30% chance of passing a five-minute Turing Testwith an unskilled interrogator. What chance do you think a computerwould have today? In another 50 years?                Exercise 3                                Every year the Loebner Prize is awarded to the program that comesclosest to passing a version of the Turing Test. Research and report onthe latest winner of the Loebner prize. What techniques does it use? Howdoes it advance the state of the art in AI?                Exercise 4                                Are reflex actions (such as flinching from a hot stove) rational? Arethey intelligent?                Exercise 5                                There are well-known classes of problems that are intractably difficultfor computers, and other classes that are provably undecidable. Doesthis mean that AI is impossible?                Exercise 6                                Suppose we extend Evans’s SYSTEM program so that it can score 200 on a standardIQ test. Would we then have a program more intelligent than a human?Explain.                Exercise 7                                The neural structure of the sea slug Aplysis has beenwidely studied (first by Nobel Laureate Eric Kandel) because it has onlyabout 20,000 neurons, most of them large and easily manipulated.Assuming that the cycle time for an Aplysis neuron isroughly the same as for a human neuron, how does the computationalpower, in terms of memory updates per second, compare with the high-endcomputer described in (Figure computer-brain-table)?                Exercise 8                                How could introspection—reporting on one’s inner thoughts—be inaccurate?Could I be wrong about what I’m thinking? Discuss.                Exercise 9                                To what extent are the following computer systems instances ofartificial intelligence:-   Supermarket bar code scanners.-   Web search engines.-   Voice-activated telephone menus.-   Internet routing algorithms that respond dynamically to the state of    the network.                Exercise 10                                To what extent are the following computer systems instances ofartificial intelligence:- Supermarket bar code scanners.- Voice-activated telephone menus.- Spelling and grammar correction features in Microsoft Word.- Internet routing algorithms that respond dynamically to the state of the network.                Exercise 11                                Many of the computational models of cognitive activities that have beenproposed involve quite complex mathematical operations, such asconvolving an image with a Gaussian or finding a minimum of the entropyfunction. Most humans (and certainly all animals) never learn this kindof mathematics at all, almost no one learns it before college, andalmost no one can compute the convolution of a function with a Gaussianin their head. What sense does it make to say that the “vision system”is doing this kind of mathematics, whereas the actual person has no ideahow to do it?                Exercise 12                                Some authors have claimed that perception and motor skills are the mostimportant part of intelligence, and that “higher level” capacities arenecessarily parasitic—simple add-ons to these underlying facilities.Certainly, most of evolution and a large part of the brain have beendevoted to perception and motor skills, whereas AI has found tasks suchas game playing and logical inference to be easier, in many ways, thanperceiving and acting in the real world. Do you think that AI’straditional focus on higher-level cognitive abilities is misplaced?                Exercise 13                                Why would evolution tend to result in systems that act rationally? Whatgoals are such systems designed to achieve?                Exercise 14                                Is AI a science, or is it engineering? Or neither or both? Explain.                Exercise 15                                “Surely computers cannot be intelligent—they can do only what theirprogrammers tell them.” Is the latter statement true, and does it implythe former?                Exercise 16                                “Surely animals cannot be intelligent—they can do only what their genestell them.” Is the latter statement true, and does it imply the former?                Exercise 17                                “Surely animals, humans, and computers cannot be intelligent—they can doonly what their constituent atoms are told to do by the laws ofphysics.” Is the latter statement true, and does it imply the former?                Exercise 18                                Examine the AI literature to discover whether the following tasks cancurrently be solved by computers:- Playing a decent game of table tennis (Ping-Pong).- Driving in the center of Cairo, Egypt.- Driving in Victorville, California.- Buying a week’s worth of groceries at the market.- Buying a week’s worth of groceries on the Web.- Playing a decent game of bridge at a competitive level.- Discovering and proving new mathematical theorems.- Writing an intentionally funny story.- Giving competent legal advice in a specialized area of law.- Translating spoken English into spoken Swedish in real time.- Performing a complex surgical operation.                Exercise 19                                For the currently infeasible tasks, try to find out what thedifficulties are and predict when, if ever, they will be overcome.                Exercise 20                                Various subfields of AI have held contests by defining a standard taskand inviting researchers to do their best. Examples include the DARPAGrand Challenge for robotic cars, the International PlanningCompetition, the Robocup robotic soccer league, the TREC informationretrieval event, and contests in machine translation and speechrecognition. Investigate five of these contests and describe theprogress made over the years. To what degree have the contests advancedthe state of the art in AI? To what degree do they hurt the field bydrawing energy away from new ideas?                Exercise 21                                Suppose that the performance measure is concerned with just the first$T$ time steps of the environment and ignores everything thereafter.Show that a rational agent’s action may depend not just on the state ofthe environment but also on the time step it has reached.                Exercise 22 (vacuum-rationality-exercise)                                Let us examine the rationality of variousvacuum-cleaner agent functions.1.  Show that the simple vacuum-cleaner agent function described in    Figure vacuum-agent-function-table is indeed    rational under the assumptions listed on page vacuum-rationality-page2.  Describe a rational agent function for the case in which each    movement costs one point. Does the corresponding agent program    require internal state?3.  Discuss possible agent designs for the cases in which clean squares    can become dirty and the geography of the environment is unknown.    Does it make sense for the agent to learn from its experience in    these cases? If so, what should it learn? If not, why not?                Exercise 23                                Write an essay on the relationship between evolution and one or more ofautonomy, intelligence, and learning.                Exercise 24                                For each of the following assertions, say whether it is true or falseand support your answer with examples or counterexamples whereappropriate.1.  An agent that senses only partial information about the state cannot    be perfectly rational.2.  There exist task environments in which no pure reflex agent can    behave rationally.3.  There exists a task environment in which every agent is rational.4.  The input to an agent program is the same as the input to the    agent function.5.  Every agent function is implementable by some    program/machine combination.6.  Suppose an agent selects its action uniformly at random from the set    of possible actions. There exists a deterministic task environment    in which this agent is rational.7.  It is possible for a given agent to be perfectly rational in two    distinct task environments.8.  Every agent is rational in an unobservable environment.9.  A perfectly rational poker-playing agent never loses.                Exercise 25 (PEAS-exercise)                                For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Playing soccer.-   Exploring the subsurface oceans of Titan.-   Shopping for used AI books on the Internet.-   Playing a tennis match.-   Practicing tennis against a wall.-   Performing a high jump.-   Knitting a sweater.-   Bidding on an item at an auction.                Exercise 26                                For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection-   Performing a gymnastics floor routine.-   Exploring the subsurface oceans of Titan.-   Playing soccer.-   Shopping for used AI books on the Internet.-   Practicing tennis against a wall.-   Performing a high jump.-   Bidding on an item at an auction.                Exercise 27 (agent-fn-prog-exercise)                                Define in your own words the following terms: agent, agent function,agent program, rationality, autonomy, reflex agent, model-based agent,goal-based agent, utility-based agent, learning agent.                Exercise 28                                This exercise explores the differences betweenagent functions and agent programs.1.  Can there be more than one agent program that implements a given    agent function? Give an example, or show why one is not possible.2.  Are there agent functions that cannot be implemented by any agent    program?3.  Given a fixed machine architecture, does each agent program    implement exactly one agent function?4.  Given an architecture with $n$ bits of storage, how many different    possible agent programs are there?5.  Suppose we keep the agent program fixed but speed up the machine by    a factor of two. Does that change the agent function?                Exercise 29                                Write pseudocode agent programs for the goal-based and utility-basedagents.    The following exercises all concern the implementation of environmentsand agents for the vacuum-cleaner world.            Exercise 30 (vacuum-start-exercise)                                Consider a simple thermostat that turns on a furnace when thetemperature is at least 3 degrees below the setting, and turns off afurnace when the temperature is at least 3 degrees above the setting. Isa thermostat an instance of a simple reflex agent, a model-based reflexagent, or a goal-based agent?                Exercise 31                                Implement a performance-measuring environmentsimulator for the vacuum-cleaner world depicted inFigure vacuum-world-figure and specified onpage vacuum-rationality-page. Your implementation should be modular so that thesensors, actuators, and environment characteristics (size, shape, dirtplacement, etc.) can be changed easily. (Note: for somechoices of programming language and operating system there are alreadyimplementations in the online code repository.)                Exercise 32 (vacuum-motion-penalty-exercise)                                Implement a simple reflex agent for the vacuum environment inExercise vacuum-start-exercise. Run the environmentwith this agent for all possible initial dirt configurations and agentlocations. Record the performance score for each configuration and theoverall average score.                Exercise 33 (vacuum-unknown-geog-exercise)                                Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the agent is penalized one point for each movement.1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  What about a reflex agent with state? Design such an agent.3.  How do your answers to 1 and 2    change if the agent’s percepts give it the clean/dirty status of    every square in the environment?                Exercise 34 (vacuum-bump-exercise)                                Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the geography of the environment—its extent, boundaries, andobstacles—is unknown, as is the initial dirt configuration. (The agentcan go Up and Down as well as Left and Right.)1.  Can a simple reflex agent be perfectly rational for this    environment? Explain.2.  Can a simple reflex agent with a randomized agent    function outperform a simple reflex agent? Design such an agent and    measure its performance on several environments.3.  Can you design an environment in which your randomized agent will    perform poorly? Show your results.4.  Can a reflex agent with state outperform a simple reflex agent?    Design such an agent and measure its performance on several    environments. Can you design a rational agent of this type?                Exercise 35 (vacuum-finish-exercise)                                Repeat Exercise vacuum-unknown-geog-exercise for the case inwhich the location sensor is replaced with a “bump” sensor that detectsthe agent’s attempts to move into an obstacle or to cross the boundariesof the environment. Suppose the bump sensor stops working; how shouldthe agent behave?                Exercise 36                                Explain why problem formulation must follow goal formulation.                Exercise 37                                Give a complete problem formulation for each of the following problems.Choose a formulation that is precise enough to be implemented.1.  There are six glass boxes in a row, each with a lock. Each of the    first five boxes holds a key unlocking the next box in line; the    last box holds a banana. You have the key to the first box, and you    want the banana.2.  You start with the sequence ABABAECCEC, or in general any sequence    made from A, B, C, and E. You can transform this sequence using the    following equalities: AC = E, AB = BC, BB = E, and E$x$ = $x$ for    any $x$. For example, ABBC can be transformed into AEC, and then AC,    and then E. Your goal is to produce the sequence E.3.  There is an $n times n$ grid of squares, each square initially    being either unpainted floor or a bottomless pit. You start standing    on an unpainted floor square, and can either paint the square under    you or move onto an adjacent unpainted floor square. You want the    whole floor painted.4.  A container ship is in port, loaded high with containers. There 13    rows of containers, each 13 containers wide and 5 containers tall.    You control a crane that can move to any location above the ship,    pick up the container under it, and move it onto the dock. You want    the ship unloaded.                Exercise 38                                Your goal is to navigate a robot out of a maze. The robot starts in thecenter of the maze facing north. You can turn the robot to face north,east, south, or west. You can direct the robot to move forward a certaindistance, although it will stop before hitting a wall.1.  Formulate this problem. How large is the state space?2.  In navigating a maze, the only place we need to turn is at the    intersection of two or more corridors. Reformulate this problem    using this observation. How large is the state space now?3.  From each point in the maze, we can move in any of the four    directions until we reach a turning point, and this is the only    action we need to do. Reformulate the problem using these actions.    Do we need to keep track of the robot’s orientation now?4.  In our initial description of the problem we already abstracted from    the real world, restricting actions and removing details. List three    such simplifications we made.                Exercise 39                                You have a $9 times 9$ grid of squares, each of which can be coloredred or blue. The grid is initially colored all blue, but you can changethe color of any square any number of times. Imagining the grid dividedinto nine $3 times 3$ sub-squares, you want each sub-square to be allone color but neighboring sub-squares to be different colors.1.  Formulate this problem in the straightforward way. Compute the size    of the state space.2.  You need color a square only once. Reformulate, and compute the size    of the state space. Would breadth-first graph search perform faster    on this problem than on the one in (a)? How about iterative    deepening tree search?3.  Given the goal, we need consider only colorings where each    sub-square is uniformly colored. Reformulate the problem and compute    the size of the state space.4.  How many solutions does this problem have?5.  Parts (b) and (c) successively abstracted the original problem (a).    Can you give a translation from solutions in problem (c) into    solutions in problem (b), and from solutions in problem (b) into    solutions for problem (a)?                Exercise 40 (two-friends-exercise)                                Suppose two friends live in different cities ona map, such as the Romania map shown in . On every turn, we cansimultaneously move each friend to a neighboring city on the map. Theamount of time needed to move from city $i$ to neighbor $j$ is equal tothe road distance $d(i,j)$ between the cities, but on each turn thefriend that arrives first must wait until the other one arrives (andcalls the first on his/her cell phone) before the next turn can begin.We want the two friends to meet as quickly as possible.1.  Write a detailed formulation for this search problem. (You will find    it helpful to define some formal notation here.)2.  Let $D(i,j)$ be the straight-line distance between cities $i$ and    $j$. Which of the following heuristic functions are admissible? (i)    $D(i,j)$; (ii) $2cdot D(i,j)$; (iii) $D(i,j)/2$. 3.  Are there completely connected maps for which no solution exists? 4.  Are there maps in which all solutions require one friend to visit    the same city twice?                Exercise 41 (8puzzle-parity-exercise)                                Show that the 8-puzzle states are dividedinto two disjoint sets, such that any state is reachable from any otherstate in the same set, while no state is reachable from any state in theother set. (Hint: See Berlekamp+al:1982) Devise a procedure to decidewhich set a given state is in, and explain why this is useful forgenerating random states.                Exercise 42 (nqueens-size-exercise)                                Consider the $n$-queens problem using the“efficient” incremental formulation given on page nqueens-page. Explain why the statespace has at least $sqrt[3]{n!}$ states and estimate the largest $n$for which exhaustive exploration is feasible. (Hint:Derive a lower bound on the branching factor by considering the maximumnumber of squares that a queen can attack in any column.)                Exercise 43                                Give a complete problem formulation for each of the following. Choose aformulation that is precise enough to be implemented.1.  Using only four colors, you have to color a planar map in such a way    that no two adjacent regions have the same color.2.  A 3-foot-tall monkey is in a room where some bananas are suspended    from the 8-foot ceiling. He would like to get the bananas. The room    contains two stackable, movable, climbable 3-foot-high crates.3.  You have a program that outputs the message “illegal input record”    when fed a certain file of input records. You know that processing    of each record is independent of the other records. You want to    discover what record is illegal.4.  You have three jugs, measuring 12 gallons, 8 gallons, and 3 gallons,    and a water faucet. You can fill the jugs up or empty them out from    one to another or onto the ground. You need to measure out exactly    one gallon.                Exercise 44 (path-planning-exercise)                                Consider the problem of finding the shortestpath between two points on a plane that has convex polygonal obstaclesas shown in . This is an idealization of the problem that a robot has tosolve to navigate in a crowded environment.1.  Suppose the state space consists of all positions $(x,y)$ in    the plane. How many states are there? How many paths are there to    the goal?2.  Explain briefly why the shortest path from one polygon vertex to any    other in the scene must consist of straight-line segments joining    some of the vertices of the polygons. Define a good state space now.    How large is this state space?3.  Define the necessary functions to implement the search problem,    including an function that takes a vertex as input and returns a set    of vectors, each of which maps the current vertex to one of the    vertices that can be reached in a straight line. (Do not forget the    neighbors on the same polygon.) Use the straight-line distance for    the heuristic function.4.  Apply one or more of the algorithms in this chapter to solve a range    of problems in the domain, and comment on their performance.                Exercise 45 (negative-g-exercise)                                On page non-negative-g, we said that we would not consider problemswith negative path costs. In this exercise, we explore this decision inmore depth.1.  Suppose that actions can have arbitrarily large negative costs;    explain why this possibility would force any optimal algorithm to    explore the entire state space.2.  Does it help if we insist that step costs must be greater than or    equal to some negative constant $c$? Consider both trees and graphs.3.  Suppose that a set of actions forms a loop in the state space such    that executing the set in some order results in no net change to    the state. If all of these actions have negative cost, what does    this imply about the optimal behavior for an agent in such an    environment?4.  One can easily imagine actions with high negative cost, even in    domains such as route finding. For example, some stretches of road    might have such beautiful scenery as to far outweigh the normal    costs in terms of time and fuel. Explain, in precise terms, within    the context of state-space search, why humans do not drive around    scenic loops indefinitely, and explain how to define the state space    and actions for route finding so that artificial agents can also    avoid looping.5.  Can you think of a real domain in which step costs are such as to    cause looping?                Exercise 46 (mc-problem)                                The problem is usually stated as follows. Threemissionaries and three cannibals are on one side of a river, along witha boat that can hold one or two people. Find a way to get everyone tothe other side without ever leaving a group of missionaries in one placeoutnumbered by the cannibals in that place. This problem is famous in AIbecause it was the subject of the first paper that approached problemformulation from an analytical viewpoint Amarel:1968. 1.  Formulate the problem precisely, making only those distinctions    necessary to ensure a valid solution. Draw a diagram of the complete    state space.2.  Implement and solve the problem optimally using an appropriate    search algorithm. Is it a good idea to check for repeated states? 3.  Why do you think people have a hard time solving this puzzle, given    that the state space is so simple?                 Exercise 47                                Define in your own words the following terms: state, state space, searchtree, search node, goal, action, transition model, and branching factor.                Exercise 48                                What’s the difference between a world state, a state description, and asearch node? Why is this distinction useful?                Exercise 49                                An action such as really consists of a long sequence of finer-grainedactions: turn on the car, release the brake, accelerate forward, etc.Having composite actions of this kind reduces the number of steps in asolution sequence, thereby reducing the search time. Suppose we takethis to the logical extreme, by making super-composite actions out ofevery possible sequence of actions. Then every problem instance issolved by a single super-composite action, such as . Explain how searchwould work in this formulation. Is this a practical approach forspeeding up problem solving?                Exercise 50                                Does a finite state space always lead to a finite search tree? How abouta finite state space that is a tree? Can you be more precise about whattypes of state spaces always lead to finite search trees? (Adapted from, 1996.)                Exercise 51 (graph-separation-property-exercise)                                Prove that satisfies the graphseparation property illustrated in . (Hint: Begin byshowing that the property holds at the start, then show that if it holdsbefore an iteration of the algorithm, it holds afterwards.) Describe asearch algorithm that violates the property.                Exercise 52                                Which of the following are true and which are false? Explain youranswers.1.  Depth-first search always expands at least as many nodes as A search    with an admissible heuristic. 2.  $h(n)=0$ is an admissible heuristic for the 8-puzzle. 3.  A is of no use in robotics because percepts, states, and actions    are continuous.4.  Breadth-first search is complete even if zero step costs    are allowed. 5.  Assume that a rook can move on a chessboard any number of squares in    a straight line, vertically or horizontally, but cannot jump over    other pieces. Manhattan distance is an admissible heuristic for the    problem of moving the rook from square A to square B in the smallest    number of moves.                Exercise 53                                Consider a state space where the start state is number 1 and each state$k$ has two successors: numbers $2k$ and $2k+1$. 1.  Draw the portion of the state space for states 1 to 15. 2.  Suppose the goal state is 11. List the order in which nodes will be    visited for breadth-first search, depth-limited search with limit 3,    and iterative deepening search. 3.  How well would bidirectional search work on this problem? What is    the branching factor in each direction of the bidirectional search?4.  Does the answer to (c) suggest a reformulation of the problem that    would allow you to solve the problem of getting from state 1 to a    given goal state with almost no search? 5.  Call the action going from $k$ to $2k$ Left, and the action going to    $2k+1$ Right. Can you find an algorithm that outputs the solution to    this problem without any search at all?                Exercise 54 (brio-exercise)                                A basic wooden railway set contains the pieces shown in. The task is to connect these pieces into a railway that has nooverlapping tracks and no loose ends where a train could run off ontothe floor.1.  Suppose that the pieces fit together exactly with no    slack. Give a precise formulation of the task as a search problem.2.  Identify a suitable uninformed search algorithm for this task and    explain your choice.3.  Explain why removing any one of the “fork” pieces makes the    problem unsolvable. 4.  Give an upper bound on the total size of the state space defined by    your formulation. (Hint: think about the maximum    branching factor for the construction process and the maximum depth,    ignoring the problem of overlapping pieces and loose ends. Begin by    pretending that every piece is unique.)                Exercise 55                                Implement two versions of the function for the 8-puzzle: one that copiesand edits the data structure for the parent node $s$ and one thatmodifies the parent state directly (undoing the modifications asneeded). Write versions of iterative deepening depth-first search thatuse these functions and compare their performance.                Exercise 56 (iterative-lengthening-exercise)                                On page iterative-lengthening-page,we mentioned iterative lengthening search,an iterative analog of uniform cost search. The idea is to use increasing limits onpath cost. If a node is generated whose path cost exceeds the currentlimit, it is immediately discarded. For each new iteration, the limit isset to the lowest path cost of any node discarded in the previousiteration.1.  Show that this algorithm is optimal for general path costs.2.  Consider a uniform tree with branching factor $b$, solution depth    $d$, and unit step costs. How many iterations will iterative    lengthening require?3.  Now consider step costs drawn from the continuous range    $[epsilon,1]$, where $0 &amp;lt; epsilon &amp;lt; 1$. How many iterations are    required in the worst case? 4.  Implement the algorithm and apply it to instances of the 8-puzzle    and traveling salesperson problems. Compare the algorithm’s    performance to that of uniform-cost search, and comment on    your results.                 Exercise 57                                Describe a state space in which iterative deepening search performs muchworse than depth-first search (for example, $O(n^{2})$ vs. $O(n)$).                Exercise 58                                Write a program that will take as input two Web page URLs and find apath of links from one to the other. What is an appropriate searchstrategy? Is bidirectional search a good idea? Could a search engine beused to implement a predecessor function?                Exercise 59 (vacuum-search-exercise)                                Consider the vacuum-world problem defined in .1.  Which of the algorithms defined in this chapter would be appropriate    for this problem? Should the algorithm use tree search or graph    search?2.  Apply your chosen algorithm to compute an optimal sequence of    actions for a $3times 3$ world whose initial state has dirt in the    three top squares and the agent in the center.3.  Construct a search agent for the vacuum world, and evaluate its    performance in a set of $3times 3$ worlds with probability 0.2 of    dirt in each square. Include the search cost as well as path cost in    the performance measure, using a reasonable exchange rate.4.  Compare your best search agent with a simple randomized reflex agent    that sucks if there is dirt and otherwise moves randomly.5.  Consider what would happen if the world were enlarged to    $n times n$. How does the performance of the search agent and of    the reflex agent vary with $n$?                 Exercise 60 (search-special-case-exercise)                                Prove each of the following statements,or give a counterexample: 1.  Breadth-first search is a special case of uniform-cost search.2.  Depth-first search is a special case of best-first tree search.3.  Uniform-cost search is a special case of A search.                Exercise 61                                Compare the performance of A and RBFS on a set of randomly generatedproblems in the 8-puzzle (with Manhattan distance) and TSP (with MST—see) domains. Discuss your results. What happens to the performance of RBFSwhen a small random number is added to the heuristic values in the8-puzzle domain?                Exercise 62                                Trace the operation of A search applied to the problem of getting toBucharest from Lugoj using the straight-line distance heuristic. Thatis, show the sequence of nodes that the algorithm will consider and the$f$, $g$, and $h$ score for each node.                Exercise 63                                Sometimes there is no good evaluation function for a problem but thereis a good comparison method: a way to tell whether one node is betterthan another without assigning numerical values to either. Show thatthis is enough to do a best-first search. Is there an analog of A forthis setting?                Exercise 64 (failure-exercise)                                Devise a state space in which A using returns asuboptimal solution with an $h(n)$ function that is admissible butinconsistent.                Exercise 65                                Accurate heuristics don’t necessarily reduce search time in the worstcase. Given any depth $d$, define a search problem with a goal node atdepth $d$, and write a heuristic function such that $|h(n) - h^*(n)|  le O(log h^*(n))$ but $A^*$ expands all nodes of depth lessthan $d$.                Exercise 66                                The heuristic path algorithm Pohl:1977 is a best-first search in which the evaluation functionis $f(n) =(2-w)g(n) + wh(n)$. For what values of $w$ is this complete? For whatvalues is it optimal, assuming that $h$ is admissible? What kind ofsearch does this perform for $w=0$, $w=1$, and $w=2$?                Exercise 67                                Consider the unbounded version of the regular 2D grid shown in . Thestart state is at the origin, (0,0), and the goal state is at $(x,y)$.1.  What is the branching factor $b$ in this state space?2.  How many distinct states are there at depth $k$ (for $k&amp;gt;0$)?3.  What is the maximum number of nodes expanded by breadth-first tree    search?4.  What is the maximum number of nodes expanded by breadth-first graph    search?5.  Is $h = |u-x| + |v-y|$ an admissible heuristic for a state at    $(u,v)$? Explain.6.  How many nodes are expanded by A graph search using $h$?7.  Does $h$ remain admissible if some links are removed?8.  Does $h$ remain admissible if some links are added between    nonadjacent states?                Exercise 68                                $n$ vehicles occupy squares $(1,1)$ through $(n,1)$ (i.e., the bottomrow) of an $ntimes n$ grid. The vehicles must be moved to the top rowbut in reverse order; so the vehicle $i$ that starts in $(i,1)$ must endup in $(n-i+1,n)$. On each time step, every one of the $n$ vehicles canmove one square up, down, left, or right, or stay put; but if a vehiclestays put, one other adjacent vehicle (but not more than one) can hopover it. Two vehicles cannot occupy the same square. 1.  Calculate the size of the state space as a function of $n$.2.  Calculate the branching factor as a function of $n$.3.  Suppose that vehicle $i$ is at $(x_i,y_i)$; write a nontrivial    admissible heuristic $h_i$ for the number of moves it will require    to get to its goal location $(n-i+1,n)$, assuming no other vehicles    are on the grid.4.  Which of the following heuristics are admissible for the problem of    moving all $n$ vehicles to their destinations? Explain.    1.  $sum_{i= 1}^{n} h_i$.    2.  $max{h_1,ldots,h_n}$.    3.  $min{h_1,ldots,h_n}$.                Exercise 69                                Consider the problem of moving $k$ knights from $k$ starting squares$s_1,ldots,s_k$ to $k$ goal squares $g_1,ldots,g_k$, on an unboundedchessboard, subject to the rule that no two knights can land on the samesquare at the same time. Each action consists of moving upto $k$ knights simultaneously. We would like to complete themaneuver in the smallest number of actions.1.  What is the maximum branching factor in this state space, expressed    as a function of $k$?2.  Suppose $h_i$ is an admissible heuristic for the problem of moving    knight $i$ to goal $g_i$ by itself. Which of the following    heuristics are admissible for the $k$-knight problem? Of those,    which is the best?    1.  $min{h_1,ldots,h_k}$.    2.  $max{h_1,ldots,h_k}$.    3.  $sum_{i= 1}^{k} h_i$.3.  Repeat (b) for the case where you are allowed to move only one    knight at a time.                Exercise 70                                We saw on page I-to-F that the straight-line distance heuristic leads greedybest-first search astray on the problem of going from Iasi to Fagaras.However, the heuristic is perfect on the opposite problem: going fromFagaras to Iasi. Are there problems for which the heuristic ismisleading in both directions?                Exercise 71                                Invent a heuristic function for the 8-puzzle that sometimesoverestimates, and show how it can lead to a suboptimal solution on aparticular problem. (You can use a computer to help if you want.) Provethat if $h$ never overestimates by more than $c$, A using $h$ returns asolution whose cost exceeds that of the optimal solution by no more than$c$.                Exercise 72                                Prove that if a heuristic isconsistent, it must be admissible. Construct an admissible heuristicthat is not consistent.                Exercise 73                                The traveling salesperson problem (TSP) can besolved with the minimum-spanning-tree (MST) heuristic, which estimatesthe cost of completing a tour, given that a partial tour has alreadybeen constructed. The MST cost of a set of cities is the smallest sum ofthe link costs of any tree that connects all the cities.1.  Show how this heuristic can be derived from a relaxed version of    the TSP.2.  Show that the MST heuristic dominates straight-line distance.3.  Write a problem generator for instances of the TSP where cities are    represented by random points in the unit square.4.  Find an efficient algorithm in the literature for constructing the    MST, and use it with A graph search to solve instances of the TSP.                Exercise 74 (Gaschnig-h-exercise)                                On page Gaschnig-h-page , we defined the relaxation of the 8-puzzle inwhich a tile can move from square A to square B if B is blank. The exactsolution of this problem defines Gaschnig&#39;s heuristic Gaschnig:1979. Explain why Gaschnig’sheuristic is at least as accurate as $h_1$ (misplaced tiles), and showcases where it is more accurate than both $h_1$ and $h_2$ (Manhattandistance). Explain how to calculate Gaschnig’s heuristic efficiently.                Exercise 75                                We gave two simple heuristics for the 8-puzzle: Manhattan distance andmisplaced tiles. Several heuristics in the literature purport to improveon this—see, for example, Nilsson:1971,Mostow+Prieditis:1989, and Hansson+al:1992. Test these claims by implementingthe heuristics and comparing the performance of the resultingalgorithms.                Exercise 1                                Give the name of the algorithm that results from each of the followingspecial cases:1.  Local beam search with $k = 1$.2.  Local beam search with one initial state and no limit on the number    of states retained.3.  Simulated annealing with $T = 0$ at all times (and omitting the    termination test).4.  Simulated annealing with $T=infty$ at all times.5.  Genetic algorithm with population size $N = 1$.                Exercise 2                                Exercise brio-exercise considers the problem ofbuilding railway tracks under the assumption that pieces fit exactlywith no slack. Now consider the real problem, in which pieces don’t fitexactly but allow for up to 10 degrees of rotation to either side of the“proper” alignment. Explain how to formulate the problem so it could besolved by simulated annealing.                Exercise 3                                In this exercise, we explore the use of local search methods to solveTSPs of the type defined in Exercise tsp-mst-exercise1.  Implement and test a hill-climbing method to solve TSPs. Compare the    results with optimal solutions obtained from the A* algorithm with    the MST heuristic (Exercise tsp-mst-exercise)2.  Repeat part (a) using a genetic algorithm instead of hill climbing.    You may want to consult @Larranaga+al:1999 for some suggestions for representations.                Exercise 4 (hill-climbing-exercise)                                Generate a large number of 8-puzzle and8-queens instances and solve them (where possible) by hill climbing(steepest-ascent and first-choice variants), hill climbing with randomrestart, and simulated annealing. Measure the search cost and percentageof solved problems and graph these against the optimal solution cost.Comment on your results.                Exercise 5 (cond-plan-repeated-exercise)                                The And-Or-Graph-Search algorithm inFigure and-or-graph-search-algorithm checks forrepeated states only on the path from the root to the current state.Suppose that, in addition, the algorithm were to storeevery visited state and check against that list. (See inFigure breadth-first-search-algorithm for an example.)Determine the information that should be stored and how the algorithmshould use that information when a repeated state is found.(*Hint*: You will need to distinguish at least betweenstates for which a successful subplan was constructed previously andstates for which no subplan could be found.) Explain how to use labels,as defined in Section cyclic-plan-section, to avoidhaving multiple copies of subplans.                Exercise 6 (cond-loop-exercise)                                Explain precisely how to modify the And-Or-Graph-Search algorithm togenerate a cyclic plan if no acyclic plan exists. You will need to dealwith three issues: labeling the plan steps so that a cyclic plan canpoint back to an earlier part of the plan, modifying Or-Search so that itcontinues to look for acyclic plans after finding a cyclic plan, andaugmenting the plan representation to indicate whether a plan is cyclic.Show how your algorithm works on (a) the slippery vacuum world, and (b)the slippery, erratic vacuum world. You might wish to use a computerimplementation to check your results.                Exercise 7                                In Section conformant-section we introduced beliefstates to solve sensorless search problems. A sequence of actions solvesa sensorless problem if it maps every physical state in the initialbelief state $b$ to a goal state. Suppose the agent knows $h^*(s)$, thetrue optimal cost of solving the physical state $s$ in the fullyobservable problem, for every state $s$ in $b$. Find an admissibleheuristic $h(b)$ for the sensorless problem in terms of these costs, andprove its admissibilty. Comment on the accuracy of this heuristic on thesensorless vacuum problem ofFigure vacuum2-sets-figure. How well does A* perform?                Exercise 8 (belief-state-superset-exercise)                                This exercise exploressubset–superset relations between belief states in sensorless orpartially observable environments.1.  Prove that if an action sequence is a solution for a belief state    $b$, it is also a solution for any subset of $b$. Can anything be    said about supersets of $b$?2.  Explain in detail how to modify graph search for sensorless problems    to take advantage of your answers in (a).3.  Explain in detail how to modify and–or search for    partially observable problems, beyond the modifications you describe    in (b).                Exercise 9 (multivalued-sensorless-exercise)                                On page multivalued-sensorless-page it was assumedthat a given action would have the same cost when executed in anyphysical state within a given belief state. (This leads to abelief-state search problem with well-defined step costs.) Now considerwhat happens when the assumption does not hold. Does the notion ofoptimality still make sense in this context, or does it requiremodification? Consider also various possible definitions of the “cost”of executing an action in a belief state; for example, we could use theminimum of the physical costs; or themaximum; or a cost interval with the lowerbound being the minimum cost and the upper bound being the maximum; orjust keep the set of all possible costs for that action. For each ofthese, explore whether A* (with modifications if necessary) can returnoptimal solutions.                Exercise 10 (vacuum-solvable-exercise)                                Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${1,2,3,4,5,6,7,8}$, and explain why theproblem is unsolvable.                Exercise 11 (vacuum-solvable-exercise)                                Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${ 1,3,5,7 }$, and explain why the problemis unsolvable.                Exercise 12 (path-planning-agent-exercise)                                We can turn the navigation problem inExercise path-planning-exercise into an environment asfollows:-   The percept will be a list of the positions, relative to the    agent, of the visible vertices. The percept does    not include the position of the robot! The robot must    learn its own position from the map; for now, you can assume that    each location has a different “view.”-   Each action will be a vector describing a straight-line path    to follow. If the path is unobstructed, the action succeeds;    otherwise, the robot stops at the point where its path first    intersects an obstacle. If the agent returns a zero motion vector    and is at the goal (which is fixed and known), then the environment    teleports the agent to a random location (not inside    an obstacle).-   The performance measure charges the agent 1 point for each unit of    distance traversed and awards 1000 points each time the goal    is reached.1.  Implement this environment and a problem-solving agent for it. After    each teleportation, the agent will need to formulate a new problem,    which will involve discovering its current location.2.  Document your agent’s performance (by having the agent generate    suitable commentary as it moves around) and report its performance    over 100 episodes.3.  Modify the environment so that 30% of the time the agent ends up at    an unintended destination (chosen randomly from the other visible    vertices if any; otherwise, no move at all). This is a crude model    of the motion errors of a real robot. Modify the agent so that when    such an error is detected, it finds out where it is and then    constructs a plan to get back to where it was and resume the    old plan. Remember that sometimes getting back to where it was might    also fail! Show an example of the agent successfully overcoming two    successive motion errors and still reaching the goal.4.  Now try two different recovery schemes after an error: (1) head for    the closest vertex on the original route; and (2) replan a route to    the goal from the new location. Compare the performance of the three    recovery schemes. Would the inclusion of search costs affect the    comparison?5.  Now suppose that there are locations from which the view    is identical. (For example, suppose the world is a grid with    square obstacles.) What kind of problem does the agent now face?    What do solutions look like?                Exercise 13 (online-offline-exercise)                                Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (1,1), that the goal is at (3,3), and that theactions Up, Down, Left, Right have their usualeffects unless blocked by a wall. The agent does not knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before.1.  Explain how this online search problem can be viewed as an offline    search in belief-state space, where the initial belief state    includes all possible environment configurations. How large is the    initial belief state? How large is the space of belief states?2.  How many distinct percepts are possible in the initial state?3.  Describe the first few branches of a contingency plan for this    problem. How large (roughly) is the complete plan?Notice that this contingency plan is a solution for everypossible environment fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.                Exercise 14 (online-offline-exercise)                                Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (3,3), that the goal is at (1,1), and that the fouractions *Up*, *Down*, *Left*, *Right* have their usualeffects unless blocked by a wall. The agent does *not* knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before or is a new state.1.  Explain how this online search problem can be viewed as an offline    search in belief-state space, where the initial belief state    includes all possible environment configurations. How large is the    initial belief state? How large is the space of belief states?2.  How many distinct percepts are possible in the initial state?3.  Describe the first few branches of a contingency plan for this    problem. How large (roughly) is the complete plan?Notice that this contingency plan is a solution for *everypossible environment* fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.                Exercise 15 (path-planning-hc-exercise)                                In this exercise, we examine hill climbingin the context of robot navigation, using the environment inFigure geometric-scene-figure as an example.1.  Repeat Exercise path-planning-agent-exercise using    hill climbing. Does your agent ever get stuck in a local minimum? Is    it *possible* for it to get stuck with convex    obstacles?2.  Construct a nonconvex polygonal environment in which the agent    gets stuck.3.  Modify the hill-climbing algorithm so that, instead of doing a    depth-1 search to decide where to go next, it does a    depth-$k$ search. It should find the best $k$-step path and do one    step along it, and then repeat the process.4.  Is there some $k$ for which the new algorithm is guaranteed to    escape from local minima?5.  Explain how LRTA enables the agent to escape from local minima in    this case.                Exercise 16                                Like DFS, online DFS is incomplete for reversible state spaces withinfinite paths. For example, suppose that states are points on theinfinite two-dimensional grid and actions are unit vectors $(1,0)$,$(0,1)$, $(-1,0)$, $(0,-1)$, tried in that order. Show that online DFSstarting at $(0,0)$ will not reach $(1,-1)$. Suppose the agent canobserve, in addition to its current state, all successor states and theactions that would lead to them. Write an algorithm that is completeeven for bidirected state spaces with infinite paths. What states doesit visit in reaching $(1,-1)$?                Exercise 17                                Relate the time complexity of LRTA* to its space complexity.                Exercise 1                                Suppose you have an oracle, $OM(s)$, that correctly predicts theopponent’s move in any state. Using this, formulate the definition of agame as a (single-agent) search problem. Describe an algorithm forfinding the optimal move.                Exercise 2                                Consider the problem of solving two 8-puzzles.1.  Give a complete problem formulation in the style of    Chapter search-chapter.2.  How large is the reachable state space? Give an exact    numerical expression.3.  Suppose we make the problem adversarial as follows: the two players    take turns moving; a coin is flipped to determine the puzzle on    which to make a move in that turn; and the winner is the first to    solve one puzzle. Which algorithm can be used to choose a move in    this setting?4.  Does the game eventually end, given optimal play? Explain.(a) A map where the cost of every edge is 1. Initially the pursuer $P$ is atnode b and the evader $E$ is at node d (b) A partial game tree for this map.Each node is labeled with the $P,E$ positions. $P$ moves first. Branches marked &quot;?&quot; have yet to be explored.    Pursuit evasion game Figure                Exercise 3                                Imagine that, in Exercise two-friends-exercise, one ofthe friends wants to avoid the other. The problem then becomes atwo-player game. We assume now that the players take turns moving. Thegame ends only when the players are on the same node; the terminalpayoff to the pursuer is minus the total time taken. (The evader “wins”by never losing.) An example is shown in Figure.pursuit-evasion-game-figure1.  Copy the game tree and mark the values of the terminal nodes.2.  Next to each internal node, write the strongest fact you can infer    about its value (a number, one or more inequalities such as    “$geq 14$”, or a “?”).3.  Beneath each question mark, write the name of the node reached by    that branch.4.  Explain how a bound on the value of the nodes in (c) can be derived    from consideration of shortest-path lengths on the map, and derive    such bounds for these nodes. Remember the cost to get to each leaf    as well as the cost to solve it.5.  Now suppose that the tree as given, with the leaf bounds from (d),    is evaluated from left to right. Circle those “?” nodes that would    not need to be expanded further, given the bounds    from part (d), and cross out those that need not be considered    at all.6.  Can you prove anything in general about who wins the game on a map    that is a tree?                Exercise 4 (game-playing-chance-exercise)                                Describe and implement statedescriptions, move generators, terminal tests, utility functions, andevaluation functions for one or more of the following stochastic games:Monopoly, Scrabble, bridge play with a given contract, or Texas hold’empoker.                Exercise 5                                Describe and implement a real-time,multiplayer game-playing environment, where time is partof the environment state and players are given fixed time allocations.                Exercise 6                                Discuss how well the standard approach to game playing would apply togames such as tennis, pool, and croquet, which take place in acontinuous physical state space.                Exercise 7 (minimax-optimality-exercise)                                Prove the following assertion: For everygame tree, the utility obtained by max using minimaxdecisions against a suboptimal min will never be lower thanthe utility obtained playing against an optimal min. Canyou come up with a game tree in which max can do stillbetter using a suboptimal strategy against a suboptimalmin?Player $A$ moves first. The two players take turns moving, and eachplayer must move his token to an open adjacent space in eitherdirection.  If the opponent occupies an adjacent space, then a playermay jump over the opponent to the next open space if any. (Forexample, if $A$ is on 3 and $B$ is on 2, then $A$ may move back to 1.)The game ends when one player reaches the opposite end of the board.If player $A$ reaches space 4 first, then the value of the game to $A$is $+1$; if player $B$ reaches space 1 first, then the value of thegame to $A$ is $-1$.    The starting position of a simple game.                Exercise 8                                Consider the two-player game described inFigure line-game4-figure1.  Draw the complete game tree, using the following conventions:    -   Write each state as $(s_A,s_B)$, where $s_A$ and $s_B$ denote        the token locations.    -   Put each terminal state in a square box and write its game value        in a circle.    -   Put loop states (states that already appear on        the path to the root) in double square boxes. Since their value        is unclear, annotate each with a “?” in a circle.2.  Now mark each node with its backed-up minimax value (also in    a circle). Explain how you handled the “?” values and why.3.  Explain why the standard minimax algorithm would fail on this game    tree and briefly sketch how you might fix it, drawing on your answer    to (b). Does your modified algorithm give optimal decisions for all    games with loops?4.  This 4-square game can be generalized to $n$ squares for any    $n &amp;gt; 2$. Prove that $A$ wins if $n$ is even and loses if $n$ is odd.                Exercise 9                                This problem exercises the basic concepts of game playing, usingtic-tac-toe (noughts and crosses) as an example. We define$X_n$ as the number of rows, columns, or diagonals with exactly $n$$X$’s and no $O$’s. Similarly, $O_n$ is the number of rows, columns, ordiagonals with just $n$ $O$’s. The utility function assigns $+1$ to anyposition with $X_3=1$ and $-1$ to any position with $O_3 = 1$. All otherterminal positions have utility 0. For nonterminal positions, we use alinear evaluation function defined as ${Eval}(s) = 3X_2(s) + X_1(s) -(3O_2(s) + O_1(s))$. 1.  Approximately how many possible games of tic-tac-toe are there?2.  Show the whole game tree starting from an empty board down to depth    2 (i.e., one $X$ and one $O$ on the board), taking symmetry    into account.3.  Mark on your tree the evaluations of all the positions at depth 2.4.  Using the minimax algorithm, mark on your tree the backed-up values    for the positions at depths 1 and 0, and use those values to choose    the best starting move.5.  Circle the nodes at depth 2 that would not be    evaluated if alpha–beta pruning were applied, assuming the nodes are    generated in the optimal order for alpha–beta pruning.                Exercise 10                                Consider the family of generalized tic-tac-toe games, defined asfollows. Each particular game is specified by a set $mathcal S$ ofsquares and a collection $mathcal W$ of winningpositions. Each winning position is a subset of $mathcal S$.For example, in standard tic-tac-toe, $mathcal S$ is a set of 9 squaresand $mathcal W$ is a collection of 8 subsets of $cal W$: the threerows, the three columns, and the two diagonals. In other respects, thegame is identical to standard tic-tac-toe. Starting from an empty board,players alternate placing their marks on an empty square. A player whomarks every square in a winning position wins the game. It is a tie ifall squares are marked and neither player has won.1.  Let $N= |{mathcal S}|$, the number of squares. Give an upper bound    on the number of nodes in the complete game tree for generalized    tic-tac-toe as a function of $N$.2.  Give a lower bound on the size of the game tree for the worst case,    where ${mathcal W} = {{,}}$.3.  Propose a plausible evaluation function that can be used for any    instance of generalized tic-tac-toe. The function may depend on    $mathcal S$ and $mathcal W$.4.  Assume that it is possible to generate a new board and check whether    it is a winning position in 100$N$ machine instructions and assume a    2 gigahertz processor. Ignore memory limitations. Using your    estimate in (a), roughly how large a game tree can be completely    solved by alpha–beta in a second of CPU time? a minute? an hour?                Exercise 11                                Develop a general game-playing program, capable of playing a variety ofgames.1.  Implement move generators and evaluation functions for one or more    of the following games: Kalah, Othello, checkers, and chess.2.  Construct a general alpha–beta game-playing agent.3.  Compare the effect of increasing search depth, improving move    ordering, and improving the evaluation function. How close does your    effective branching factor come to the ideal case of perfect move    ordering?4.  Implement a selective search algorithm, such as B* Berliner:1979,    conspiracy number search @McAllester:1988, or MGSS*    Russell+Wefald:1989 and compare its performance to A*.                Exercise 12                                Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state differ by at most a constant $k$, makingthe game almost cooperative?                Exercise 13                                Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state sum to a number between constants $-k$and $k$, making the game almost zero-sum?                Exercise 14                                Develop a formal proof of correctness for alpha–beta pruning. To dothis, consider the situation shown inFigure alpha-beta-proof-figure. The question is whetherto prune node $n_j$, which is a max-node and a descendant of node $n_1$.The basic idea is to prune it if and only if the minimax value of $n_1$can be shown to be independent of the value of $n_j$.1.  Mode $n_1$ takes on the minimum value among its children:    $n_1 = min(n_2,n_21,ldots,n_{2b_2})$. Find a similar    expression for $n_2$ and hence an expression for $n_1$ in terms of    $n_j$.2.  Let $l_i$ be the minimum (or maximum) value of the nodes to the    left of node $n_i$ at depth $i$, whose minimax value    is already known. Similarly, let $r_i$ be the minimum (or maximum)    value of the unexplored nodes to the right of $n_i$ at depth $i$.    Rewrite your expression for $n_1$ in terms of the $l_i$ and    $r_i$ values.3.  Now reformulate the expression to show that in order to affect    $n_1$, $n_j$ must not exceed a certain bound derived from the    $l_i$ values.4.  Repeat the process for the case where $n_j$ is a min-node.    Situation when considering whether to prune node $n_j$.                Exercise 15                                Prove that the alpha–beta algorithm takes time $O(b^{m/2})$ with optimalmove ordering, where $m$ is the maximum depth of the game tree.                Exercise 16                                Suppose you have a chess program that can evaluate 5 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a1-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?                Exercise 17                                Suppose you have a chess program that can evaluate 10 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a2-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?    The complete game tree for a trivial game with chance nodes..                Exercise 18                                This question considers pruning in games with chance nodes.Figure trivial-chance-game-figure shows the completegame tree for a trivial game. Assume that the leaf nodes are to beevaluated in left-to-right order, and that before a leaf node isevaluated, we know nothing about its value—the range of possible valuesis $-infty$ to $infty$.1.  Copy the figure, mark the value of all the internal nodes, and    indicate the best move at the root with an arrow.2.  Given the values of the first six leaves, do we need to evaluate the    seventh and eighth leaves? Given the values of the first seven    leaves, do we need to evaluate the eighth leaf? Explain    your answers.3.  Suppose the leaf node values are known to lie between –2 and 2    inclusive. After the first two leaves are evaluated, what is the    value range for the left-hand chance node?4.  Circle all the leaves that need not be evaluated under the    assumption in (c).                Exercise 19                                Implement the expectiminimax algorithm and the *-alpha–beta algorithm,which is described by Ballard:1983, for pruning game trees with chance nodes. Trythem on a game such as backgammon and measure the pruning effectivenessof *-alpha–beta.                Exercise 20 (game-linear-transform)                                Prove that with a positive lineartransformation of leaf values (i.e., transforming a value $x$ to$ax + b$ where $a &amp;gt; 0$), the choice of move remains unchanged in a gametree, even when there are chance nodes.                Exercise 21 (game-playing-monte-carlo-exercise)                                Consider the following procedurefor choosing moves in games with chance nodes:-   Generate some dice-roll sequences (say, 50) down to a suitable depth    (say, 8).-   With known dice rolls, the game tree becomes deterministic. For each    dice-roll sequence, solve the resulting deterministic game tree    using alpha–beta.-   Use the results to estimate the value of each move and to choose    the best.Will this procedure work well? Why (or why not)?                Exercise 22                                In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search. For each of (a)–(f), eithergive an example or explain why this is impossible.1.  Assuming that leaf values are finite but unbounded, is pruning (as    in alpha–beta) ever possible in a max tree?2.  Is pruning ever possible in an expectimax tree under the same    conditions?3.  If leaf values are all nonnegative, is pruning ever possible in a    max tree? Give an example, or explain why not.4.  If leaf values are all nonnegative, is pruning ever possible in an    expectimax tree? Give an example, or explain why not.5.  If leaf values are all in the range $[0,1]$, is pruning ever    possible in a max tree? Give an example, or explain why not.6.  If leaf values are all in the range $[0,1]$, is pruning ever    possible in an expectimax tree?17.  Consider the outcomes of a chance node in an expectimax tree. Which    of the following evaluation orders is most likely to yield pruning    opportunities?    i.  Lowest probability first    ii.  Highest probability first    iii.  Doesn’t make any difference                Exercise 23                                In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search.1.  Assuming that leaf values are finite but unbounded, is pruning (as    in alpha–beta) ever possible in a max tree? Give an example, or    explain why not.2.  Is pruning ever possible in an expectimax tree under the same    conditions? Give an example, or explain why not.3.  If leaf values are constrained to be in the range $[0,1]$, is    pruning ever possible in a max tree? Give an example, or explain    why not.4.  If leaf values are constrained to be in the range $[0,1]$, is    pruning ever possible in an expectimax tree? Give an example    (qualitatively different from your example in (e), if any), or    explain why not.5.  If leaf values are constrained to be nonnegative, is pruning ever    possible in a max tree? Give an example, or explain why not.6.  If leaf values are constrained to be nonnegative, is pruning ever    possible in an expectimax tree? Give an example, or explain why not.7.  Consider the outcomes of a chance node in an expectimax tree. Which    of the following evaluation orders is most likely to yield pruning    opportunities: (i) Lowest probability first; (ii) Highest    probability first; (iii) Doesn’t make any difference?                Exercise 24                                Suppose you have an oracle, $OM(s)$, that correctly predicts theopponent’s move in any state. Using this, formulate the definition of agame as a (single-agent) search problem. Describe an algorithm forfinding the optimal move.                Exercise 25                                Consider carefully the interplay of chance events and partialinformation in each of the games inExercise game-playing-chance-exercise.1.  For which is the standard expectiminimax model appropriate?    Implement the algorithm and run it in your game-playing agent, with    appropriate modifications to the game-playing environment.2.  For which would the scheme described in    Exercise game-playing-monte-carlo-exercise be    appropriate?3.  Discuss how you might deal with the fact that in some of the games,    the players do not have the same knowledge of the current state.                Exercise 1                                 How many solutions are there for the map-coloring problem inFigure australia-figure? How many solutions if fourcolors are allowed? Two colors?                Exercise 2                                 Consider the problem of placing $k$ knights on an $ntimes n$chessboard such that no two knights are attacking each other, where $k$is given and $kleq n^2$.1.  Choose a CSP formulation. In your formulation, what are the    variables?2.  What are the possible values of each variable?3.  What sets of variables are constrained, and how?4.  Now consider the problem of putting *as many knights as    possible* on the board without any attacks. Explain how to    solve this with local search by defining appropriate ACTIONS and RESULT functions    and a sensible objective function.                Exercise 3 (crossword-exercise)                                 Consider the problem of constructing (not solving)crossword puzzles fitting words into a rectangular grid. The grid,which is given as part of the problem, specifies which squares are blankand which are shaded. Assume that a list of words (i.e., a dictionary)is provided and that the task is to fill in the blank squares by usingany subset of the list. Formulate this problem precisely in two ways:1.  As a general search problem. Choose an appropriate search algorithm    and specify a heuristic function. Is it better to fill in blanks one    letter at a time or one word at a time?2.  As a constraint satisfaction problem. Should the variables be words    or letters?Which formulation do you think will be better? Why?                Exercise 4 (csp-definition-exercise)                                 Give precise formulations for each of thefollowing as constraint satisfaction problems:1.  Rectilinear floor-planning: find non-overlapping places in a large    rectangle for a number of smaller rectangles.2.  Class scheduling: There is a fixed number of professors and    classrooms, a list of classes to be offered, and a list of possible    time slots for classes. Each professor has a set of classes that he    or she can teach.3.  Hamiltonian tour: given a network of cities connected by roads,    choose an order to visit all cities in a country without    repeating any.                Exercise 5                                 Solve the cryptarithmetic problem inFigure cryptarithmetic-figure by hand, using thestrategy of backtracking with forward checking and the MRV andleast-constraining-value heuristics.                Exercise 6 (nary-csp-exercise)                                 Show how a single ternary constraint such as“$A + B = C$” can be turned into three binary constraints by using anauxiliary variable. You may assume finite domains. (*Hint:*Consider a new variable that takes on values that are pairs of othervalues, and consider constraints such as “$X$ is the first element ofthe pair $Y$.”) Next, show how constraints with more than threevariables can be treated similarly. Finally, show how unary constraintscan be eliminated by altering the domains of variables. This completesthe demonstration that any CSP can be transformed into a CSP with onlybinary constraints.                Exercise 7 (zebra-exercise)                                 Consider the following logic puzzle: In five houses,each with a different color, live five persons of differentnationalities, each of whom prefers a different brand of candy, adifferent drink, and a different pet. Given the following facts, thequestions to answer are “Where does the zebra live, and in which housedo they drink water?”The Englishman lives in the red house.The Spaniard owns the dog.The Norwegian lives in the first house on the left.The green house is immediately to the right of the ivory house.The man who eats Hershey bars lives in the house next to the man withthe fox.Kit Kats are eaten in the yellow house.The Norwegian lives next to the blue house.The Smarties eater owns snails.The Snickers eater drinks orange juice.The Ukrainian drinks tea.The Japanese eats Milky Ways.Kit Kats are eaten in a house next to the house where the horse is kept.Coffee is drunk in the green house.Milk is drunk in the middle house.Discuss different representations of this problem as a CSP. Why wouldone prefer one representation over another?                Exercise 8                                 Consider the graph with 8 nodes $A_1$, $A_2$, $A_3$, $A_4$, $H$, $T$,$F_1$, $F_2$. $A_i$ is connected to $A_{i+1}$ for all $i$, each $A_i$ isconnected to $H$, $H$ is connected to $T$, and $T$ is connected to each$F_i$. Find a 3-coloring of this graph by hand using the followingstrategy: backtracking with conflict-directed backjumping, the variableorder $A_1$, $H$, $A_4$, $F_1$, $A_2$, $F_2$, $A_3$, $T$, and the valueorder $R$, $G$, $B$.                Exercise 9                                 Explain why it is a good heuristic to choose the variable that is*most* constrained but the value that is*least* constraining in a CSP search.                Exercise 10                                 Generate random instances of map-coloring problems as follows: scatter$n$ points on the unit square; select a point $X$ at random, connect $X$by a straight line to the nearest point $Y$ such that $X$ is not alreadyconnected to $Y$ and the line crosses no other line; repeat the previousstep until no more connections are possible. The points representregions on the map and the lines connect neighbors. Now try to find$k$-colorings of each map, for both $k3$ and$k4$, using min-conflicts, backtracking, backtracking withforward checking, and backtracking with MAC. Construct a table ofaverage run times for each algorithm for values of $n$ up to the largestyou can manage. Comment on your results.                Exercise 11                                 Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${green},V{red}$ for the problemshown in Figure australia-figure.                Exercise 12                                 Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${red},V{blue}$ for the problemshown in Figure australia-figure.                Exercise 13                                 What is the worst-case complexity of running AC-3 on a tree-structuredCSP?                Exercise 14 (ac4-exercise)                                AC-3 puts back on the queue every arc($X_{k}, X_{i}$) whenever any value is deleted from thedomain of $X_{i}$, even if each value of $X_{k}$ is consistent withseveral remaining values of $X_{i}$. Suppose that, for every arc($X_{k}, X_{i}$), we keep track of the number of remaining values of$X_{i}$ that are consistent with each value of $X_{k}$. Explain how toupdate these numbers efficiently and hence show that arc consistency canbe enforced in total time $O(n^2d^2)$.                Exercise 15                                 The Tree-CSP-Solver (Figure tree-csp-figure) makes arcs consistentstarting at the leaves and working backwards towards the root. Why doesit do that? What would happen if it went in the opposite direction?                Exercise 16                                 We introduced Sudoku as a CSP to be solved by search over partialassignments because that is the way people generally undertake solvingSudoku problems. It is also possible, of course, to attack theseproblems with local search over complete assignments. How well would alocal solver using the min-conflicts heuristic do on Sudoku problems?                Exercise 17                                 Define in your own words the terms constraint, backtracking search, arcconsistency, backjumping, min-conflicts, and cycle cutset.                Exercise 18                                 Define in your own words the terms constraint, commutativity, arcconsistency, backjumping, min-conflicts, and cycle cutset.                Exercise 19                                 Suppose that a graph is known to have a cycle cutset of no more than $k$nodes. Describe a simple algorithm for finding a minimal cycle cutsetwhose run time is not much more than $O(n^k)$ for a CSP with $n$variables. Search the literature for methods for finding approximatelyminimal cycle cutsets in time that is polynomial in the size of thecutset. Does the existence of such algorithms make the cycle cutsetmethod practical?                Exercise 20                                 Consider the problem of tiling a surface (completely and exactlycovering it) with $n$ dominoes ($2times1$ rectangles). The surface is an arbitrary edge-connected (i.e.,adjacent along an edge, not just a corner) collection of $2n$$1times 1$ squares (e.g., a checkerboard, a checkerboard with somesquares missing, a $10times 1$ row of squares, etc.).1.  Formulate this problem precisely as a CSP where the dominoes are    the variables.2.  Formulate this problem precisely as a CSP where the squares are the    variables, keeping the state space as small as possible.    (*Hint:* does it matter which particular domino goes on    a given pair of squares?)3.  Construct a surface consisting of 6 squares such that your CSP    formulation from part (b) has a *tree-structured*    constraint graph.4.  Describe exactly the set of solvable instances that have a    tree-structured constraint graph.                Exercise 1                                 Suppose the agent has progressed to the point shown inFigure wumpus-seq35-figure(a), page wumpus-seq35-figure,having perceived nothing in [1,1], a breeze in [2,1], and a stenchin [1,2], and is now concerned with the contents of [1,3], [2,2],and [3,1]. Each of these can contain a pit, and at most one cancontain a wumpus. Following the example ofFigure wumpus-entailment-figure, construct the set ofpossible worlds. (You should find 32 of them.) Mark the worlds in whichthe KB is true and those in which each of the following sentences istrue:$alpha_2$ = “There is no pit in [2,2].”$alpha_3$ = “There is a wumpus in [1,3].”Hence show that ${KB} {models}alpha_2$ and${KB} {models}alpha_3$.                Exercise 2                                 (Adapted from Barwise+Etchemendy:1993 .) Given the following, can you prove that the unicorn ismythical? How about magical? Horned?Note: If the unicorn is mythical, then it is immortal, but if it is not mythical, then it is a mortal mammal. If the unicorn is either immortal or a mammal, then it is horned. The unicorn is magical if it is horned.                Exercise 3 (truth-value-exercise)                                 Consider the problem of deciding whether apropositional logic sentence is true in a given model.1.  Write a recursive algorithm PL-True?$ (s, m )$ that returns ${true}$ if and    only if the sentence $s$ is true in the model $m$ (where $m$ assigns    a truth value for every symbol in $s$). The algorithm should run in    time linear in the size of the sentence. (Alternatively, use a    version of this function from the online code repository.)2.  Give three examples of sentences that can be determined to be true    or false in a partial model that does not specify a    truth value for some of the symbols.3.  Show that the truth value (if any) of a sentence in a partial model    cannot be determined efficiently in general.4.  Modify your algorithm so that it can sometimes judge truth from    partial models, while retaining its recursive structure and linear    run time. Give three examples of sentences whose truth in a partial    model is not detected by your algorithm.5.  Investigate whether the modified algorithm makes $TT-Entails?$ more efficient.                Exercise 4                                 Which of the following are correct?1.  ${False} models {True}$.2.  ${True} models {False}$.3.  $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.4.  $A{;;{Leftrightarrow};;}B models A lor B$.5.  $A{;;{Leftrightarrow};;}B models lnot A lor B$.6.  $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.7.  $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.8.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B)$.9.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.10. $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.11. $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$    is satisfiable.12. $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ has    the same number of models as $(A{;;{Leftrightarrow};;}B)$ for    any fixed set of proposition symbols that includes $A$, $B$, $C$.                Exercise 5                                 Which of the following are correct?1.  ${False} models {True}$.2.  ${True} models {False}$.3.  $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.4.  $A{;;{Leftrightarrow};;}B models A lor B$.5.  $A{;;{Leftrightarrow};;}B models lnot A lor B$.6.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor Blor C) land (Bland Cland D{:;{Rightarrow}:;}E)$.7.  $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.8.  $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.9.  $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.10. $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.11. $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$    is satisfiable.12. $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ has    the same number of models as $(A{;;{Leftrightarrow};;}B)$ for    any fixed set of proposition symbols that includes $A$, $B$, $C$.                Exercise 6 (deduction-theorem-exercise)                                 Prove each of the following assertions:1.  $alpha$ is valid if and only if ${True}{models}alpha$.2.  For any $alpha$, ${False}{models}alpha$.3.  $alpha{models}beta$ if and only if the sentence    $(alpha {:;{Rightarrow}:;}beta)$ is valid.4.  $alpha equiv beta$ if and only if the sentence    $(alpha{;;{Leftrightarrow};;}beta)$ is valid.5.  $alpha{models}beta$ if and only if the sentence    $(alpha land lnot beta)$ is unsatisfiable.                Exercise 7                                 Prove, or find a counterexample to, each of the following assertions:1.  If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then    $(alphaland beta)modelsgamma$2.  If $(alphaland beta)modelsgamma$ then $alphamodelsgamma$ or    $betamodelsgamma$ (or both).3.  If $alphamodels (beta lor gamma)$ then $alpha models beta$    or $alpha models gamma$ (or both).                Exercise 8                                 Prove, or find a counterexample to, each of the following assertions:1.  If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then    $(alphaland beta)modelsgamma$2.  If $alphamodels (beta land gamma)$ then $alpha models beta$    and $alpha models gamma$.3.  If $alphamodels (beta lor gamma)$ then $alpha models beta$    or $alpha models gamma$ (or both).                Exercise 9                                 Consider a vocabulary with only four propositions, $A$, $B$, $C$, and$D$. How many models are there for the following sentences?1.  $Blor C$.2.  $lnot Alor lnot B lor lnot C lor lnot D$.3.  $(A{:;{Rightarrow}:;}B) land A land lnot B land C land D$.                Exercise 10                                 We have defined four binary logical connectives.1.  Are there any others that might be useful?2.  How many binary connectives can there be?3.  Why are some of them not very useful?                Exercise 11 (logical-equivalence-exercise)                                 Using a method of your choice, verifyeach of the equivalences inTable logical-equivalence-table (page logical-equivalence-table).                Exercise 12 (propositional-validity-exercise)                                 Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable logical-equivalence-table (page logical-equivalence-table).1.  ${Smoke} {:;{Rightarrow}:;}{Smoke}$2.  ${Smoke} {:;{Rightarrow}:;}{Fire}$3.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$4.  ${Smoke} lor {Fire} lor lnot {Fire}$5.  $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})            {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$6.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire}) $7.  ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$                Exercise 13 (propositional-validity-exercise)                                 Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable logical-equivalence-table (page logical-equivalence-table).1.  ${Smoke} {:;{Rightarrow}:;}{Smoke}$2.  ${Smoke} {:;{Rightarrow}:;}{Fire}$3.  $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$4.  ${Smoke} lor {Fire} lor lnot {Fire}$5.  $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})            {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$6.  ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$7.  $({Big} land {Dumb}) lor lnot {Dumb}$                Exercise 14 (cnf-proof-exercise)                                Any propositional logic sentence is logicallyequivalent to the assertion that each possible world in which it wouldbe false is not the case. From this observation, prove that any sentencecan be written in CNF.                Exercise 15                                 Use resolution to prove the sentence $lnot A land lnot B$ from theclauses in Exercise convert-clausal-exercise.                Exercise 16 (inf-exercise)                                 This exercise looks into the relationship betweenclauses and implication sentences.1.  Show that the clause $(lnot P_1 lor cdots lor lnot P_m lor Q)$    is logically equivalent to the implication sentence    $(P_1 land cdots land P_m) {;{Rightarrow};}Q$.2.  Show that every clause (regardless of the number of    positive literals) can be written in the form    $(P_1 land cdots land P_m) {;{Rightarrow};}(Q_1 lor cdots lor Q_n)$,    where the $P$s and $Q$s are proposition symbols. A knowledge base    consisting of such sentences is in implicative normal form or Kowalski    form Kowalski:1979.3.  Write down the full resolution rule for sentences in implicative    normal form.                Exercise 17                                 According to some political pundits, a person who is radical ($R$) iselectable ($E$) if he/she is conservative ($C$), but otherwise is notelectable.1.  Which of the following are correct representations of this    assertion?    1.  $(Rland E)iff C$    2.  $R{:;{Rightarrow}:;}(Eiff C)$    3.  $R{:;{Rightarrow}:;}((C{:;{Rightarrow}:;}E) lor lnot E)$2.  Which of the sentences in (a) can be expressed in Horn form?                Exercise 18                                 This question considers representing satisfiability (SAT) problems asCSPs.1.  Draw the constraint graph corresponding to the SAT problem    $$(lnot X_1 lor X_2) land (lnot X_2 lor X_3) land ldots land (lnot X_{n-1} lor X_n)$$    for the particular case $n5$.2.  How many solutions are there for this general SAT problem as a    function of $n$?3.  Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find all    solutions to a SAT CSP of the type given in (a). (To find    all solutions to a CSP, we simply modify the basic    algorithm so it continues searching after each solution is found.)    Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$    is ordered before ${true}$. How much time will the algorithm take    to terminate? (Write an $O(cdot)$ expression as a function of $n$.)4.  We know that SAT problems in Horn form can be solved in linear time    by forward chaining (unit propagation). We also know that every    tree-structured binary CSP with discrete, finite domains can be    solved in time linear in the number of variables    (Section csp-structure-section). Are these two    facts connected? Discuss.                Exercise 19                                 This question considers representing satisfiability (SAT) problems asCSPs.1.  Draw the constraint graph corresponding to the SAT problem    $$(lnot X_1 lor X_2) land (lnot X_2 lor X_3) land ldots land (lnot X_{n-1} lor X_n)$$    for the particular case $n4$.2.  How many solutions are there for this general SAT problem as a    function of $n$?3.  Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find all    solutions to a SAT CSP of the type given in (a). (To find    all solutions to a CSP, we simply modify the basic    algorithm so it continues searching after each solution is found.)    Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$    is ordered before ${true}$. How much time will the algorithm take    to terminate? (Write an $O(cdot)$ expression as a function of $n$.)4.  We know that SAT problems in Horn form can be solved in linear time    by forward chaining (unit propagation). We also know that every    tree-structured binary CSP with discrete, finite domains can be    solved in time linear in the number of variables    (Section csp-structure-section). Are these two    facts connected? Discuss.                Exercise 20                                 Explain why every nonempty propositional clause, by itself, issatisfiable. Prove rigorously that every set of five 3-SAT clauses issatisfiable, provided that each clause mentions exactly three distinctvariables. What is the smallest set of such clauses that isunsatisfiable? Construct such a set.                Exercise 21                                 A propositional 2-CNF expression is a conjunction ofclauses, each containing exactly 2 literals, e.g.,$$(Alor B) land (lnot A lor C) land (lnot B lor D) land (lnot  C lor G) land (lnot D lor G) .$$1.  Prove using resolution that the above sentence entails $G$.2.  Two clauses are semantically distinct if they are not    logically equivalent. How many semantically distinct 2-CNF clauses    can be constructed from $n$ proposition symbols?3.  Using your answer to (b), prove that propositional resolution always    terminates in time polynomial in $n$ given a 2-CNF sentence    containing no more than $n$ distinct symbols.4.  Explain why your argument in (c) does not apply to 3-CNF.                Exercise 22                                 Prove each of the following assertions:1.  Every pair of propositional clauses either has no resolvents, or all    their resolvents are logically equivalent.2.  There is no clause that, when resolved with itself, yields    (after factoring) the clause $(lnot P lor lnot Q)$.3.  If a propositional clause $C$ can be resolved with a copy of itself,    it must be logically equivalent to $ True $.                Exercise 23                                 Consider the following sentence:$$[ ({Food} {:;{Rightarrow}:;}{Party}) lor ({Drinks} {:;{Rightarrow}:;}{Party}) ] {:;{Rightarrow}:;}[ ( {Food} land {Drinks} )  {:;{Rightarrow}:;}{Party}] .$$1.  Determine, using enumeration, whether this sentence is valid,    satisfiable (but not valid), or unsatisfiable.2.  Convert the left-hand and right-hand sides of the main implication    into CNF, showing each step, and explain how the results confirm    your answer to (a).3.  Prove your answer to (a) using resolution.                Exercise 24 (dnf-exercise)                                 A sentence is in disjunctive normal form(DNF) if it is the disjunction ofconjunctions of literals. For example, the sentence$(A land B land lnot C) lor (lnot A land C) lor (B land lnot C)$is in DNF.1.  Any propositional logic sentence is logically equivalent to the    assertion that some possible world in which it would be true is in    fact the case. From this observation, prove that any sentence can be    written in DNF.2.  Construct an algorithm that converts any sentence in propositional    logic into DNF. (Hint: The algorithm is similar to    the algorithm for conversion to CNF iven in    Sectio pl-resolution-section.)3.  Construct a simple algorithm that takes as input a sentence in DNF    and returns a satisfying assignment if one exists, or reports that    no satisfying assignment exists.4.  Apply the algorithms in (b) and (c) to the following set of    sentences: $A {Rightarrow} B$ $B {Rightarrow} C$ $C {Rightarrow} A$5.  Since the algorithm in (b) is very similar to the algorithm for    conversion to CNF, and since the algorithm in (c) is much simpler    than any algorithm for solving a set of sentences in CNF, why is    this technique not used in automated reasoning?                Exercise 25 (convert-clausal-exercise)                                 Convert the following set of sentences toclausal form.1.  S1: $A {;;{Leftrightarrow};;}(B lor E)$.2.  S2: $E {:;{Rightarrow}:;}D$.3.  S3: $C land F {:;{Rightarrow}:;}lnot B$.4.  S4: $E {:;{Rightarrow}:;}B$.5.  S5: $B {:;{Rightarrow}:;}F$.6.  S6: $B {:;{Rightarrow}:;}C$Give a trace of the execution of DPLL on the conjunction of theseclauses.                Exercise 26 (convert-clausal-exercise)                                 Convert the following set of sentences toclausal form.1.  S1: $A {;;{Leftrightarrow};;}(B lor E)$.2.  S2: $E {:;{Rightarrow}:;}D$.3.  S3: $C land F {:;{Rightarrow}:;}lnot B$.4.  S4: $E {:;{Rightarrow}:;}B$.5.  S5: $B {:;{Rightarrow}:;}F$.6.  S6: $B {:;{Rightarrow}:;}C$Give a trace of the execution of DPLL on the conjunction of theseclauses.                Exercise 27                                 Is a randomly generated 4-CNF sentence with $n$ symbols and $m$ clausesmore or less likely to be solvable than a randomly generated 3-CNFsentence with $n$ symbols and $m$ clauses? Explain.                Exercise 28                                 Minesweeper, the well-known computer game, isclosely related to the wumpus world. A minesweeper world isa rectangular grid of $N$ squares with $M$ invisible mines scatteredamong them. Any square may be probed by the agent; instant death followsif a mine is probed. Minesweeper indicates the presence of mines byrevealing, in each probed square, the number of minesthat are directly or diagonally adjacent. The goal is to probe everyunmined square.1.  Let $X_{i,j}$ be true iff square $[i,j]$ contains a mine. Write down    the assertion that exactly two mines are adjacent to [1,1] as a    sentence involving some logical combination of    $X_{i,j}$ propositions.2.  Generalize your assertion from (a) by explaining how to construct a    CNF sentence asserting that $k$ of $n$ neighbors contain mines.3.  Explain precisely how an agent can use {DPLL} to prove that a given square    does (or does not) contain a mine, ignoring the global constraint    that there are exactly $M$ mines in all.4.  Suppose that the global constraint is constructed from your method    from part (b). How does the number of clauses depend on $M$ and $N$?    Suggest a way to modify {DPLL} so that the global constraint does not need    to be represented explicitly.5.  Are any conclusions derived by the method in part (c) invalidated    when the global constraint is taken into account?6.  Give examples of configurations of probe values that induce    long-range dependencies such that the contents of a    given unprobed square would give information about the contents of a    far-distant square. (Hint: consider an    $Ntimes 1$ board.)                Exercise 29 (known-literal-exercise)                                 How long does it take to prove${KB}{models}alpha$ using {DPLL} when $alpha$ is a literal alreadycontained in ${KB}$? Explain.                Exercise 30 (dpll-fc-exercise)                                 Trace the behavior of {DPLL} on the knowledge base inFigure pl-horn-example-figure when trying to prove $Q$,and compare this behavior with that of the forward-chaining algorithm.                Exercise 31                                 Write a successor-state axiom for the ${Locked}$ predicate, whichapplies to doors, assuming the only actions available are ${Lock}$ and${Unlock}$.                Exercise 32                                 Discuss what is meant by optimal behavior in the wumpusworld. Show that the {Hybrid-Wumpus-Agent} is not optimal, and suggest ways to improve it.                Exercise 33                                  Suppose an agent inhabits a world with two states, $S$ and $lnot S$,and can do exactly one of two actions, $a$ and $b$. Action $a$ doesnothing and action $b$ flips from one state to the other. Let $S^t$ bethe proposition that the agent is in state $S$ at time $t$, and let$a^t$ be the proposition that the agent does action $a$ at time $t$(similarly for $b^t$).1.  Write a successor-state axiom for $S^{t+1}$.2.  Convert the sentence in (a) into CNF.3.  Show a resolution refutation proof that if the agent is in $lnot S$    at time $t$ and does $a$, it will still be in $lnot S$ at time    $t+1$.                Exercise 34 (ss-axiom-exercise)                                 Section successor-state-sectionprovides some of the successor-state axioms required for the wumpusworld. Write down axioms for all remaining fluent symbols.                Exercise 35 (hybrid-wumpus-exercise)                                 Modify the {Hybrid-Wumpus-Agent} to use the 1-CNF logical stateestimation method described on page 1cnf-belief-state-page. We noted on that pagethat such an agent will not be able to acquire, maintain, and use morecomplex beliefs such as the disjunction $P_{3,1}lor P_{2,2}$. Suggest amethod for overcoming this problem by defining additional propositionsymbols, and try it out in the wumpus world. Does it improve theperformance of the agent?                Exercise 1                                 A logical knowledge base represents the world using a set of sentenceswith no explicit structure. An analogicalrepresentation, on the other hand, has physical structure thatcorresponds directly to the structure of the thing represented. Considera road map of your country as an analogical representation of factsabout the country—it represents facts with a map language. Thetwo-dimensional structure of the map corresponds to the two-dimensionalsurface of the area.1.  Give five examples of symbols in the map language.2.  An explicit sentence is a sentence that the creator    of the representation actually writes down. An    implicit sentence is a sentence that results from    explicit sentences because of properties of the analogical    representation. Give three examples each of implicit    and explicit sentences in the map language.3.  Give three examples of facts about the physical structure of your    country that cannot be represented in the map language.4.  Give two examples of facts that are much easier to express in the    map language than in first-order logic.5.  Give two other examples of useful analogical representations. What    are the advantages and disadvantages of each of these languages?                Exercise 2                                 Consider a knowledge base containing just two sentences: $P(a)$ and$P(b)$. Does this knowledge base entail $forall,x P(x)$? Explain youranswer in terms of models.                Exercise 3                                 Is the sentence ${exists,x,y;;} xy$ valid? Explain.                Exercise 4                                  Write down a logical sentence such that every world in which it is truecontains exactly one object.                Exercise 5 (two-friends-exercise)                                 Write down a logical sentence such that every world in which it is truecontains exactly two objects.                Exercise 6 (8puzzle-parity-exercise)                                Consider a symbol vocabulary that contains$c$ constant symbols, $p_k$ predicate symbols of each arity $k$, and$f_k$ function symbols of each arity $k$, where $1leq kleq A$. Let thedomain size be fixed at $D$. For any given model, each predicate orfunction symbol is mapped onto a relation or function, respectively, ofthe same arity. You may assume that the functions in the model allowsome input tuples to have no value for the function (i.e., the value isthe invisible object). Derive a formula for the number of possiblemodels for a domain with $D$ elements. Don’t worry about eliminatingredundant combinations.                Exercise 7 (nqueens-size-exercise)                                 Which of the following are valid (necessarily true) sentences?1.  $(exists x xx) {:;{Rightarrow}:;}({forall,y;;} exists z yz)$. 2.  ${forall,x;;} P(x) lor lnot P(x)$.3.  ${forall,x;;} {Smart}(x) lor (xx)$.                Exercise 8 (empty-universe-exercise)                                 Consider a version of the semantics forfirst-order logic in which models with empty domains are allowed. Giveat least two examples of sentences that are valid according to thestandard semantics but not according to the new semantics. Discuss whichoutcome makes more intuitive sense for your examples.                Exercise 9 (hillary-exercise)                                 Does the fact$lnot {Spouse}({George},{Laura})$ follow from the facts${Jim}neq {George}$ and ${Spouse}({Jim},{Laura})$? If so,give a proof; if not, supply additional axioms as needed. What happensif we use ${Spouse}$ as a unary function symbol instead of a binarypredicate?                Exercise 10                                 This exercise uses the function ${MapColor}$ and predicates${In}(x,y)$, ${Borders}(x,y)$, and ${Country}(x)$, whose argumentsare geographical regions, along with constant symbols for variousregions. In each of the following we give an English sentence and anumber of candidate logical expressions. For each of the logicalexpressions, state whether it (1) correctly expresses the Englishsentence; (2) is syntactically invalid and therefore meaningless; or (3)is syntactically valid but does not express the meaning of the Englishsentence.1.  Paris and Marseilles are both in France.    1.  ${In}({Paris} land {Marseilles}, {France})$.    2.  ${In}({Paris},{France}) land {In}({Marseilles},{France})$.    3.  ${In}({Paris},{France}) lor {In}({Marseilles},{France})$.2.  There is a country that borders both Iraq and Pakistan.    1.  ${exists,c;;}$        ${Country}(c) land {Border}(c,{Iraq}) land {Border}(c,{Pakistan})$.    2.  ${exists,c;;}$        ${Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.    3.  $[{exists,c;;}$        ${Country}(c)] {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.    4.  ${exists,c;;}$        ${Border}({Country}(c),{Iraq} land {Pakistan})$.3.  All countries that border Ecuador are in South America.    1.  ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.    2.  ${forall,c;;}  {Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})]$.    3.  ${forall,c;;}  [{Country}(c) {:;{Rightarrow}:;}{Border}(c,{Ecuador})] {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.    4.  ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) land {In}(c,{SouthAmerica})$.4.  No region in South America borders any region in Europe.    1.  $lnot [{exists,c,d;;}  {In}(c,{SouthAmerica}) land {In}(d,{Europe}) land {Borders}(c,d)]$.    2.  ${forall,c,d;;}  [{In}(c,{SouthAmerica}) land {In}(d,{Europe})] {:;{Rightarrow}:;}lnot {Borders}(c,d)]$.    3.  $lnot {forall,c;;}  {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{exists,d;;} {In}(d,{Europe}) land        lnot {Borders}(c,d)$.    4.  ${forall,c;;} {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{forall,d;;} {In}(d,{Europe}) {:;{Rightarrow}:;}lnot {Borders}(c,d)$.5.  No two adjacent countries have the same map color.    1.  ${forall,x,y;;} lnot {Country}(x) lor lnot {Country}(y) lor lnot {Borders}(x,y) lor {}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    2.  ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) land lnot(x=y)) {:;{Rightarrow}:;}{}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    3.  ${forall,x,y;;} {Country}(x) land {Country}(y) land {Borders}(x,y) land {}$        $lnot ({MapColor}(x) = {MapColor}(y))$.    4.  ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) ) {:;{Rightarrow}:;}{MapColor}(xneq y)$.                Exercise 11                                 Consider a vocabulary with the following symbols:&amp;gt; ${Occupation}(p,o)$: Predicate. Person $p$ has occupation $o$.&amp;gt; ${Customer}(p1,p2)$: Predicate. Person $p1$ is a customer of person $p2$.&amp;gt; ${Boss}(p1,p2)$: Predicate. Person $p1$ is a boss of person $p2$.&amp;gt; ${Doctor}$, $ {Surgeon}$, $ {Lawyer}$, $ {Actor}$: Constants denoting occupations.&amp;gt; ${Emily}$, $ {Joe}$: Constants denoting people.Use these symbols to write the following assertions in first-orderlogic:1.  Emily is either a surgeon or a lawyer.2.  Joe is an actor, but he also holds another job.3.  All surgeons are doctors.4.  Joe does not have a lawyer (i.e., is not a customer of any lawyer).5.  Emily has a boss who is a lawyer.6.  There exists a lawyer all of whose customers are doctors.7.  Every surgeon has a lawyer.                Exercise 12                                 In each of the following we give an English sentence and a number ofcandidate logical expressions. For each of the logical expressions,state whether it (1) correctly expresses the English sentence; (2) issyntactically invalid and therefore meaningless; or (3) is syntacticallyvalid but does not express the meaning of the English sentence.1.  Every cat loves its mother or father.    1.  ${forall,x;;} {Cat}(x) {:;{Rightarrow}:;}{Loves}(x,{Mother}(x)lor {Father}(x))$.    2.  ${forall,x;;} lnot {Cat}(x) lor {Loves}(x,{Mother}(x)) lor {Loves}(x,{Father}(x))$.    3.  ${forall,x;;} {Cat}(x) land ({Loves}(x,{Mother}(x))lor {Loves}(x,{Father}(x)))$.2.  Every dog who loves one of its brothers is happy.    1.  ${forall,x;;} {Dog}(x) land (exists y {Brother}(y,x) land {Loves}(x,y)) {:;{Rightarrow}:;}{Happy}(x)$.    2.  ${forall,x,y;;} {Dog}(x) land {Brother}(y,x) land {Loves}(x,y) {:;{Rightarrow}:;}{Happy}(x)$.    3.  ${forall,x;;} {Dog}(x) land [{forall,y;;} {Brother}(y,x) {;;{Leftrightarrow};;}{Loves}(x,y)] {:;{Rightarrow}:;}{Happy}(x)$.3.  No dog bites a child of its owner.    1.  ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}lnot {Bites}(x,{Child}({Owner}(x)))$.    2.  $lnot {exists,x,y;;} {Dog}(x) land {Child}(y,{Owner}(x)) land {Bites}(x,y)$.    3.  ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}({forall,y;;} {Child}(y,{Owner}(x)) {:;{Rightarrow}:;}lnot {Bites}(x,y))$.    4.  $lnot {exists,x;;} {Dog}(x) {:;{Rightarrow}:;}({exists,y;;} {Child}(y,{Owner}(x)) land {Bites}(x,y))$.4.  Everyone’s zip code within a state has the same first digit.    1.  ${forall,x,s,z_1;;} [{State}(s) land {LivesIn}(x,s) land {Zip}(x)z_1] {:;{Rightarrow}:;}{}$        $[{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 {:;{Rightarrow}:;}{Digit}(1,z_1) {Digit}(1,z_2) ]$.    2.  ${forall,x,s;;} [{State}(s) land {LivesIn}(x,s) land {exists,z_1;;} {Zip}(x)z_1] {:;{Rightarrow}:;}{}$        $ [{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 land {Digit}(1,z_1) {Digit}(1,z_2) ]$.    3.  ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{Digit}(1,{Zip}(x){Zip}(y))$.    4.  ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{}$        ${Digit}(1,{Zip}(x)) {Digit}(1,{Zip}(y))$.                Exercise 13 (language-determination-exercise)                                 Complete the following exercisesabout logical sentences:1.  Translate into *good, natural* English (no $x$s or $y$s!):$${forall,x,y,l;;} SpeaksLanguage(x, l) land SpeaksLanguage(y, l)    implies Understands(x, y) land Understands(y,x).$$2.  Explain why this sentence is entailed by the sentence$${forall,x,y,l;;} SpeaksLanguage(x, l) land SpeaksLanguage(y, l)    implies Understands(x, y).$$3.  Translate into first-order logic the following sentences:    1.  Understanding leads to friendship.    2.  Friendship is transitive.    Remember to define all predicates, functions, and constants you use.                Exercise 14                                 True or false? Explain.1.  ${exists,x;;} x{Rumpelstiltskin}$ is a valid    (necessarily true) sentence of first-order logic.2.  Every existentially quantified sentence in first-order logic is true    in any model that contains exactly one object.3.  ${forall,x,y;;} xy$is satisfiable.                Exercise 15 (Peano-completion-exercise)                                 Rewrite the first two Peano axioms inSection Peano-section as a single axiom that defines${NatNum}(x)$ so as to exclude the possibility of natural numbersexcept for those generated by the successor function.                Exercise 16 (wumpus-diagnostic-exercise)                                 Equation (pit-biconditional-equation) onpage pit-biconditional-equation defines the conditions under which a square isbreezy. Here we consider two other ways to describe this aspect of thewumpus world.1.  We can write [diagnostic rule] leading from observed effects to hidden causes. For    finding pits, the obvious diagnostic rules say that if a square is    breezy, some adjacent square must contain a pit; and if a square is    not breezy, then no adjacent square contains a pit. Write these two    rules in first-order logic and show that their conjunction is    logically equivalent to    Equation (pit-biconditional-equation).2.  We can write [causal rule] leading from cause to effect. One obvious causal rule    is that a pit causes all adjacent squares to be breezy. Write this    rule in first-order logic, explain why it is incomplete compared to    Equation (pit-biconditional-equation), and supply    the missing axiom.                Exercise 17 (kinship-exercise)                                 Write axioms describing the predicates${Grandchild}$, ${Greatgrandparent}$, ${Ancestor}$, ${Brother}$,${Sister}$, ${Daughter}$, ${Son}$, ${FirstCousin}$,${BrotherInLaw}$, ${SisterInLaw}$, ${Aunt}$, and ${Uncle}$. Findout the proper definition of $m$th cousin $n$ times removed, and writethe definition in first-order logic. Now write down the basic factsdepicted in the family tree in Figure family1-figure.Using a suitable logical reasoning system, it all the sentences you havewritten down, and it who are Elizabeth’s grandchildren, Diana’sbrothers-in-law, Zara’s great-grandparents, and Eugenie’s ancestors.    A typical family tree. The symbol $bowtie$ connects spouses and arrows point to children.                Exercise 18                                 Write down a sentence asserting that + is a commutative function. Doesyour sentence follow from the Peano axioms? If so, explain why; if not,give a model in which the axioms are true and your sentence is false.                Exercise 19                                 Explain what is wrong with the following proposed definition of the setmembership predicate $$ {forall,x,s;;} x in {x|s} $$ $$ {forall,x,s;;} x in s implies {forall,y;;} x in {y|s} $$                Exercise 20 (list-representation-exercise)                                 Using the set axioms as examples, writeaxioms for the list domain, including all the constants, functions, andpredicates mentioned in the chapter.                Exercise 21 (adjacency-exercise)                                Explain what is wrong with the following proposeddefinition of adjacent squares in the wumpus world:$${forall,x,y;;} {Adjacent}([x,y], [x+1, y]) land {Adjacent}([x,y], [x, y+1]) .$$                Exercise 22                                 Write out the axioms required for reasoning about the wumpus’s location,using a constant symbol ${Wumpus}$ and a binary predicate${At}({Wumpus}, {Location})$. Remember that there is only onewumpus.                Exercise 23                                 Assuming predicates ${Parent}(p,q)$ and ${Female}(p)$ and constants${Joan}$ and ${Kevin}$, with the obvious meanings, express each ofthe following sentences in first-order logic. (You may use theabbreviation $exists^{1}$ to mean “there exists exactly one.”)1.  Joan has a daughter (possibly more than one, and possibly sons    as well).2.  Joan has exactly one daughter (but may have sons as well).3.  Joan has exactly one child, a daughter.4.  Joan and Kevin have exactly one child together.5.  Joan has at least one child with Kevin, and no children with    anyone else.                Exercise 24                                 Arithmetic assertions can be written in first-order logic with thepredicate symbol $&amp;lt;$, the function symbols ${+}$ and ${times}$, and theconstant symbols 0 and 1. Additional predicates can also be defined withbiconditionals.1.  Represent the property “$x$ is an even number.”2.  Represent the property “$x$ is prime.”3.  Goldbach’s conjecture is the conjecture (unproven as yet) that every    even number is equal to the sum of two primes. Represent this    conjecture as a logical sentence.                Exercise 25                                 In Chapter csp-chapter, we used equality to indicatethe relation between a variable and its value. For instance, we wrote${WA}{red}$ to mean that Western Australia is coloredred. Representing this in first-order logic, we must write moreverbosely ${ColorOf}({WA}){red}$. What incorrectinference could be drawn if we wrote sentences such as${WA}{red}$ directly as logical assertions?                Exercise 26                                 Write in first-order logic the assertion that every key and at least oneof every pair of socks will eventually be lost forever, using only thefollowing vocabulary: ${Key}(x)$, $x$ is a key; ${Sock}(x)$, $x$ isa sock; ${Pair}(x,y)$, $x$ and $y$ are a pair; ${Now}$, the currenttime; ${Before}(t_1,t_2)$, time $t_1$ comes before time $t_2$;${Lost}(x,t)$, object $x$ is lost at time $t$.                Exercise 27                                 For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it. (Some sentences may have more than oneerror!)1.  No two people have the same social security number.    $$lnot {exists,x,y,n;;} {Person}(x) land {Person}(y) {:;{Rightarrow}:;}[{HasSS}#(x,n) land {HasSS}#(y,n)].$$2.  John’s social security number is the same as Mary’s.    $${exists,n;;} {HasSS}#({John},n) land {HasSS}#({Mary},n).$$3.  Everyone’s social security number has nine digits.    $${forall,x,n;;} {Person}(x) {:;{Rightarrow}:;}[{HasSS}#(x,n) land {Digits}(n,9)].$$4.  Rewrite each of the above (uncorrected) sentences using a function    symbol ${SS}#$ instead of the predicate ${HasSS}#$.                Exercise 28                                 Translate into first-order logic the sentence “Everyone’s DNA is uniqueand is derived from their parents’ DNA.” You must specify the preciseintended meaning of your vocabulary terms. (*Hint*: Do notuse the predicate ${Unique}(x)$, since uniqueness is not really aproperty of an object in itself!)                Exercise 29                                 For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it.1.  Any apartment in London has lower rent than some apartments    in Paris.$$forall {x} [{Apt}(x) land {In}(x,{London})]implies exists {y} ([{Apt}(y) land {In}(y,{Paris})] implies ({Rent}(x) &amp;lt; {Rent}(y)))$$2.  There is exactly one apartment in Paris with rent below $1000.$$exists {x} {Apt}(x) land {In}(x,{Paris}) land forall{y} [{Apt}(y) land {In}(y,{Paris}) land ({Rent}(y) &amp;lt; {Dollars}(1000))] implies (y = x)$$3.  If an apartment is more expensive than all apartments in London, it    must be in Moscow.$$forall{x} {Apt}(x) land [forall{y} {Apt}(y) land {In}(y,{London}) land ({Rent}(x) &amp;gt; {Rent}(y))] implies{In}(x,{Moscow}).$$                Exercise 30                                 Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):1.  Some students took French in spring 2001.2.  Every student who takes French passes it.3.  Only one student took Greek in spring 2001.4.  The best score in Greek is always higher than the best score    in French.5.  Every person who buys a policy is smart.6.  No person buys an expensive policy.7.  There is an agent who sells policies only to people who are    not insured.8.  There is a barber who shaves all men in town who do not    shave themselves.9.  A person born in the UK, each of whose parents is a UK citizen or a    UK resident, is a UK citizen by birth.10. A person born outside the UK, one of whose parents is a UK citizen    by birth, is a UK citizen by descent.11. Politicians can fool some of the people all of the time, and they    can fool all of the people some of the time, but they can’t fool all    of the people all of the time.12. All Greeks speak the same language. (Use ${Speaks}(x,l)$ to mean    that person $x$ speaks language $l$.)                Exercise 31                                 Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):1.  Some students took French in spring 2001.2.  Every student who takes French passes it.3.  Only one student took Greek in spring 2001.4.  The best score in Greek is always higher than the best score    in French.5.  Every person who buys a policy is smart.6.  No person buys an expensive policy.7.  There is an agent who sells policies only to people who are    not insured.8.  There is a barber who shaves all men in town who do not    shave themselves.9.  A person born in the UK, each of whose parents is a UK citizen or a    UK resident, is a UK citizen by birth.10. A person born outside the UK, one of whose parents is a UK citizen    by birth, is a UK citizen by descent.11. Politicians can fool some of the people all of the time, and they    can fool all of the people some of the time, but they can’t fool all    of the people all of the time.12. All Greeks speak the same language. (Use ${Speaks}(x,l)$ to mean    that person $x$ speaks language $l$.)                Exercise 32                                 Write a general set of facts and axioms to represent the assertion“Wellington heard about Napoleon’s death” and to correctly answer thequestion “Did Napoleon hear about Wellington’s death?”                Exercise 33 (4bit-adder-exercise)                                 Extend the vocabulary fromSection circuits-section to define addition for $n$-bitbinary numbers. Then encode the description of the four-bit adder inFigure 4bit-adder-figure, and pose the queries neededto verify that it is in fact correct.    A four-bit adder. Each ${Ad}_i$ is a one-bit adder, as in figure adder-figure on page &amp;lt;a href=&quot;&quot;#&quot;&amp;gt;adder-figure&amp;lt;/a&amp;gt;                Exercise 34                                 The circuit representation in the chapter is more detailed thannecessary if we care only about circuit functionality. A simplerformulation describes any $m$-input, $n$-output gate or circuit using apredicate with $m+n$ arguments, such that the predicate is true exactlywhen the inputs and outputs are consistent. For example, NOT gates aredescribed by the binary predicate ${NOT}(i,o)$, for which${NOT}(0,1)$ and ${NOT}(1,0)$ are known. Compositions of gates aredefined by conjunctions of gate predicates in which shared variablesindicate direct connections. For example, a NAND circuit can be composedfrom ${AND}$s and ${NOT}$s:$${forall,i_1,i_2,o_a,o;;} {AND}(i_1,i_2,o_a) land {NOT}(o_a,o) {:;{Rightarrow}:;}{NAND}(i_1,i_2,o) .$$Using this representation, define the one-bit adder inFigure adder-figure and the four-bit adder inFigure adder-figure, and explain what queries youwould use to verify the designs. What kinds of queries are*not* supported by this representation that*are* supported by the representation inSection circuits-section?                Exercise 35                                 Obtain a passport application for your country, identify the rulesdetermining eligibility for a passport, and translate them intofirst-order logic, following the steps outlined inSection circuits-section                Exercise 36                                 Consider a first-order logical knowledge base that describes worldscontaining people, songs, albums (e.g., “Meet the Beatles”) and disks(i.e., particular physical instances of CDs). The vocabulary containsthe following symbols:&amp;gt; ${CopyOf}(d,a)$: Predicate. Disk $d$ is a copy of album $a$.&amp;gt; ${Owns}(p,d)$: Predicate. Person $p$ owns disk $d$.&amp;gt; ${Sings}(p,s,a)$: Album $a$ includes a recording of song $s$ sung by person $p$.&amp;gt; ${Wrote}(p,s)$: Person $p$ wrote song $s$.&amp;gt; ${McCartney}$, ${Gershwin}$, ${BHoliday}$, ${Joe}$, ${EleanorRigby}$, ${TheManILove}$, ${Revolver}$: Constants with the obvious meanings.Express the following statements in first-order logic:1.  Gershwin wrote “The Man I Love.”2.  Gershwin did not write “Eleanor Rigby.”3.  Either Gershwin or McCartney wrote “The Man I Love.”4.  Joe has written at least one song.5.  Joe owns a copy of *Revolver*.6.  Every song that McCartney sings on *Revolver* was    written by McCartney.7.  Gershwin did not write any of the songs on *Revolver*.8.  Every song that Gershwin wrote has been recorded on some album.    (Possibly different songs are recorded on different albums.)9.  There is a single album that contains every song that Joe    has written.10. Joe owns a copy of an album that has Billie Holiday singing “The Man    I Love.”11. Joe owns a copy of every album that has a song sung by McCartney.    (Of course, each different album is instantiated in a different    physical CD.)12. Joe owns a copy of every album on which all the songs are sung by    Billie Holiday.                Exercise 1                                 Prove that Universal Instantiation is sound and that ExistentialInstantiation produces an inferentially equivalent knowledge base.                Exercise 2                                 From ${Likes}({Jerry},{IceCream})$ it seems reasonable to infer${exists,x;;}{Likes}(x,{IceCream})$. Write down a general inference rule, , thatsanctions this inference. State carefully the conditions that must besatisfied by the variables and terms involved.                Exercise 3                                 Suppose a knowledge base contains just one sentence,$exists,x {AsHighAs}(x,{Everest})$. Which of the following arelegitimate results of applying Existential Instantiation?1.  ${AsHighAs}({Everest},{Everest})$.2.  ${AsHighAs}({Kilimanjaro},{Everest})$.3.  ${AsHighAs}({Kilimanjaro},{Everest}) land {AsHighAs}({BenNevis},{Everest})$    (after two applications).                Exercise 4                                 For each pair of atomic sentences, give the most general unifier if itexists:1.  $P(A,B,B)$, $P(x,y,z)$.2.  $Q(y,G(A,B))$, $Q(G(x,x),y)$.3.  ${Older}({Father}(y),y)$, ${Older}({Father}(x),{John})$.4.  ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.                Exercise 5                                 For each pair of atomic sentences, give the most general unifier if itexists:1.  $P(A,B,B)$, $P(x,y,z)$.2.  $Q(y,G(A,B))$, $Q(G(x,x),y)$.3.  ${Older}({Father}(y),y)$, ${Older}({Father}(x),{John})$.4.  ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.                Exercise 6 (subsumption-lattice-exercise)                                 Consider the subsumption lattices shownin Figure subsumption-lattice-figure(page subsumption-lattice-figure.1.  Construct the lattice for the sentence    ${Employs}({Mother}({John}),{Father}({Richard}))$.2.  Construct the lattice for the sentence ${Employs}({IBM},y)$    (“Everyone works for IBM”). Remember to include every kind of query    that unifies with the sentence.3.  Assume that indexes each sentence under every node in its    subsumption lattice. Explain how should work when some of these    sentences contain variables; use as examples the sentences in (a)    and (b) and the query ${Employs}(x,{Father}(x))$.                Exercise 7 (fol-horses-exercise)                                 Write down logical representations for thefollowing sentences, suitable for use with Generalized Modus Ponens:1.  Horses, cows, and pigs are mammals.2.  An offspring of a horse is a horse.3.  Bluebeard is a horse.4.  Bluebeard is Charlie’s parent.5.  Offspring and parent are inverse relations.6.  Every mammal has a parent.                Exercise 8                                 These questions concern concern issues with substitution andSkolemization.1.  Given the premise ${forall,x;;} {exists,y;;} P(x,y)$, it is    not valid to conclude that ${exists,q;;} P(q,q)$. Give an    example of a predicate $P$ where the first is true but the second    is false.2.  Suppose that an inference engine is incorrectly written with the    occurs check omitted, so that it allows a literal like $P(x,F(x))$    to be unified with $P(q,q)$. (As mentioned, most standard    implementations of Prolog actually do allow this.) Show that such an    inference engine will allow the conclusion ${exists,y;;} P(q,q)$    to be inferred from the premise    ${forall,x;;} {exists,y;;} P(x,y)$.3.  Suppose that a procedure that converts first-order logic to clausal    form incorrectly Skolemizes    ${forall,x;;} {exists,y;;} P(x,y)$ to $P(x,Sk0)$—that is, it    replaces $y$ by a Skolem constant rather than by a Skolem function    of $x$. Show that an inference engine that uses such a procedure    will likewise allow ${exists,q;;} P(q,q)$ to be inferred from    the premise ${forall,x;;} {exists,y;;} P(x,y)$.4.  A common error among students is to suppose that, in unification,    one is allowed to substitute a term for a Skolem constant instead of    for a variable. For instance, they will say that the formulas    $P(Sk1)$ and $P(A)$ can be unified under the substitution    ${ Sk1/A }$. Give an example where this leads to an    invalid inference.                Exercise 9                                 This question considers Horn KBs, such as the following:$$begin{array}{l}P(F(x)) {:;{Rightarrow}:;}P(x)Q(x) {:;{Rightarrow}:;}P(F(x))P(A)Q(B)end{array}$$ Let FC be a breadth-first forward-chaining algorithm thatrepeatedly adds all consequences of currently satisfied rules; let BC bea depth-first left-to-right backward-chaining algorithm that triesclauses in the order given in the KB. Which of the following are true?1.  FC will infer the literal $Q(A)$.2.  FC will infer the literal $P(B)$.3.  If FC has failed to infer a given literal, then it is not entailed    by the KB.4.  BC will return ${true}$ given the query $P(B)$.5.  If BC does not return ${true}$ given a query literal, then it is    not entailed by the KB.                Exercise 10 (csp-clause-exercise)                                 Explain how to write any given 3-SAT problem ofarbitrary size using a single first-order definite clause and no morethan 30 ground facts.                Exercise 11                                 Suppose you are given the following axioms: 1. $0 leq 3$. 2. $7 leq 9$. 3. ${forall,x;;} ; ; x leq x$. 4. ${forall,x;;} ; ; x leq x+0$. 5. ${forall,x;;} ; ; x+0 leq x$. 6. ${forall,x,y;;} ; ; x+y leq y+x$. 7. ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z$ ${:;{Rightarrow}:;}$ $w+x leq y+z$. 8. ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$ 1.  Give a backward-chaining proof of the sentence $7 leq 3+9$. (Be    sure, of course, to use only the axioms given here, not anything    else you may know about arithmetic.) Show only the steps that leads    to success, not the irrelevant steps.2.  Give a forward-chaining proof of the sentence $7 leq 3+9$. Again,    show only the steps that lead to success.                Exercise 12                                 Suppose you are given the following axioms:&amp;gt; 1. $0 leq 4$.&amp;gt; 2. $5 leq 9$.&amp;gt; 3. ${forall,x;;} ; ; x leq x$.&amp;gt; 4. ${forall,x;;} ; ; x leq x+0$.&amp;gt; 5. ${forall,x;;} ; ; x+0 leq x$.&amp;gt; 6. ${forall,x,y;;} ; ; x+y leq y+x$.&amp;gt; 7. ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z {:;{Rightarrow}:;}$ $w+x leq y+z$.&amp;gt; 8. ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$1.  Give a backward-chaining proof of the sentence $5 leq 4+9$. (Be    sure, of course, to use only the axioms given here, not anything    else you may know about arithmetic.) Show only the steps that leads    to success, not the irrelevant steps.2.  Give a forward-chaining proof of the sentence $5 leq 4+9$. Again,    show only the steps that lead to success.                Exercise 13                                 A popular children’s riddle is “Brothers and sisters have I none, butthat man’s father is my father’s son.” Use the rules of the familydomain (Section kinship-domain-section onpage kinship-domain-section to show who that man is. You may apply any of theinference methods described in this chapter. Why do you think that thisriddle is difficult?                Exercise 14                                 Suppose we put into a logical knowledge base a segment of theU.S. census data listing the age, city of residence, date of birth, andmother of every person, using social security numbers as identifyingconstants for each person. Thus, George’s age is given by${Age}(443-65-1282, 56)$. Which of the followingindexing schemes S1–S5 enable an efficient solution for which of thequeries Q1–Q4 (assuming normal backward chaining)?- S1: an index for each atom in each position.- S2: an index for each first argument.- S3: an index for each predicate atom.- S4: an index for each combination of predicate and first argument.- S5: an index for each combination of predicate and second argument and an index for each first argument.- Q1: ${Age}(mbox 443-44-4321,x)$- Q2: ${ResidesIn}(x,{Houston})$- Q3: ${Mother}(x,y)$- Q4: ${Age}(x,{34}) land {ResidesIn}(x,{TinyTownUSA})$                Exercise 15 (standardize-failure-exercise)                                 One might suppose that we can avoid theproblem of variable conflict in unification during backward chaining bystandardizing apart all of the sentences in the knowledge base once andfor all. Show that, for some sentences, this approach cannot work.(Hint: Consider a sentence in which one part unifies withanother.)                Exercise 16                                 In this exercise, use the sentences you wrote inExercise fol-horses-exercise to answer a question byusing a backward-chaining algorithm.1.  Draw the proof tree generated by an exhaustive backward-chaining    algorithm for the query ${exists,h;;}{Horse}(h)$, where    clauses are matched in the order given.2.  What do you notice about this domain?3.  How many solutions for $h$ actually follow from your sentences?4.  Can you think of a way to find all of them? (Hint:    See Smith+al:1986.)                Exercise 17 (bc-trace-exercise)                                 Trace the execution of the backward-chainingalgorithm in Figure backward-chaining-algorithm(page backward-chaining-algorithm when it is applied to solve the crime problem(page west-problem-page. Show the sequence of values taken on by the${goals}$ variable, and arrange them into a tree.                Exercise 18                                 The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)        P(X,[X|Y]).        P(X,[Y|Z]) :- P(X,Z).1.  Show proof trees and solutions for the queries    P(A,[2,1,3]) and P(2,[1,A,3]).2.  What standard list operation does P represent?                Exercise 19                                 The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)        P(X,[X|Y]).        P(X,[Y|Z]) :- P(X,Z).1.  Show proof trees and solutions for the queries    P(A,[1,2,3]) and P(2,[1,A,3]).2.  What standard list operation does P represent?                Exercise 20                                 This exercise looks at sorting in Prolog.1.  Write Prolog clauses that define the predicate    sorted(L), which is true if and only if list    L is sorted in ascending order.2.  Write a Prolog definition for the predicate perm(L,M),    which is true if and only if L is a permutation of    M.3.  Define sort(L,M) (M is a sorted version of    L) using perm and sorted.4.  Run sort on longer and longer lists until you lose    patience. What is the time complexity of your program?5.  Write a faster sorting algorithm, such as insertion sort or    quicksort, in Prolog.                Exercise 21 (diff-simplify-exercise)                                 This exercise looks at the recursiveapplication of rewrite rules, using logic programming. A rewrite rule(or demodulator in terminology) is anequation with a specified direction. For example, the rewrite rule$x+0 rightarrow x$ suggests replacing any expression that matches $x+0$with the expression $x$. Rewrite rules are a key component of equationalreasoning systems. Use the predicate rewrite(X,Y) torepresent rewrite rules. For example, the earlier rewrite rule iswritten as rewrite(X+0,X). Some terms areprimitive and cannot be further simplified; thus, wewrite primitive(0) to say that 0 is a primitive term.1.  Write a definition of a predicate simplify(X,Y), that    is true when Y is a simplified version of    X—that is, when no further rewrite rules apply to any    subexpression of Y.2.  Write a collection of rules for the simplification of expressions    involving arithmetic operators, and apply your simplification    algorithm to some sample expressions.3.  Write a collection of rewrite rules for symbolic differentiation,    and use them along with your simplification rules to differentiate    and simplify expressions involving arithmetic expressions,    including exponentiation.                Exercise 22                                 This exercise considers the implementation of search algorithms inProlog. Suppose that successor(X,Y) is true when stateY is a successor of state X; and thatgoal(X) is true when X is a goal state. Writea definition for solve(X,P), which means thatP is a path (list of states) beginning with X,ending in a goal state, and consisting of a sequence of legal steps asdefined by successor. You will find that depth-first searchis the easiest way to do this. How easy would it be to add heuristicsearch control?                Exercise 23                                 Suppose a knowledge base contains just the following first-order Hornclauses:$$Ancestor(Mother(x),x)$$$$Ancestor(x,y) land Ancestor(y,z) implies Ancestor(x,z)$$Consider a forward chaining algorithm that, on the $j$th iteration,terminates if the KB contains a sentence that unifies with the query,else adds to the KB every atomic sentence that can be inferred from thesentences already in the KB after iteration $j-1$.1.  For each of the following queries, say whether the algorithm    will (1) give an answer (if so, write down that answer); or (2)    terminate with no answer; or (3) never terminate.    1.  $Ancestor(Mother(y),John)$    2.  $Ancestor(Mother(Mother(y)),John)$    3.  $Ancestor(Mother(Mother(Mother(y))),Mother(y))$    4.  $Ancestor(Mother(John),Mother(Mother(John)))$2.  Can a resolution algorithm prove the sentence    $lnot Ancestor(John,John)$ from the original knowledge base?    Explain how, or why not.3.  Suppose we add the assertion that $lnot(Mother(x)x)$ and    augment the resolution algorithm with inference rules for equality.    Now what is the answer to (b)?                Exercise 24                                 Let $cal L$ be the first-order language with a single predicate$S(p,q)$, meaning “$p$ shaves  $q$.” Assume a domain of people.1.  Consider the sentence “There exists a person $P$ who shaves every    one who does not shave themselves, and only people that do not    shave themselves.” Express this in $cal L$.2.  Convert the sentence in (a) to clausal form.3.  Construct a resolution proof to show that the clauses in (b) are    inherently inconsistent. (Note: you do not need any    additional axioms.)                Exercise 25                                 How can resolution be used to show that a sentence is valid?Unsatisfiable?                Exercise 26                                 Construct an example of two clauses that can be resolved together in twodifferent ways giving two different outcomes.                Exercise 27                                 From “Horses are animals,” it follows that “The head of a horse is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:1.  Translate the premise and the conclusion into the language of    first-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning    “$h$ is the head of $x$”), ${Horse}(x)$, and ${Animal}(x)$.2.  Negate the conclusion, and convert the premise and the negated    conclusion into conjunctive normal form.3.  Use resolution to show that the conclusion follows from the premise.                Exercise 28                                 From “Sheep are animals,” it follows that “The head of a sheep is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:1.  Translate the premise and the conclusion into the language of    first-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning    “$h$ is the head of $x$”), ${Sheep}(x)$, and ${Animal}(x)$.2.  Negate the conclusion, and convert the premise and the negated    conclusion into conjunctive normal form.3.  Use resolution to show that the conclusion follows from the premise.                Exercise 29 (quantifier-order-exercise)                                 Here are two sentences in the language offirst-order logic:-   (A)    ${forall,x;;} {exists,y;;} ( x geq y )$-   (B)    ${exists,y;;} {forall,x;;} ( x geq y )$1.  Assume that the variables range over all the natural numbers    $0,1,2,ldots, infty$ and that the “$geq$” predicate means “is    greater than or equal to.” Under this interpretation, translate (A)    and (B) into English.2.  Is (A) true under this interpretation?3.  Is (B) true under this interpretation?4.  Does (A) logically entail (B)?5.  Does (B) logically entail (A)?6.  Using resolution, try to prove that (A) follows from (B). Do this    even if you think that (B) does not logically entail (A); continue    until the proof breaks down and you cannot proceed (if it does    break down). Show the unifying substitution for each resolution    step. If the proof fails, explain exactly where, how, and why it    breaks down.7.  Now try to prove that (B) follows from (A).                Exercise 30                                 Resolution can produce nonconstructive proofs for queries withvariables, so we had to introduce special mechanisms to extract definiteanswers. Explain why this issue does not arise with knowledge basescontaining only definite clauses.                Exercise 31                                 We said in this chapter that resolution cannot be used to generate alllogical consequences of a set of sentences. Can any algorithm do this?    Exercise 1 Consider a robot whose operation is described by the following PDDLoperators:$$Op({Go(x,y)},{At(Robot,x)},{lnot At(Robot,x) land At(Robot,y)})$$$$Op({Pick(o)},{At(Robot,x)land At(o,x)},{lnot At(o,x) land Holding(o)})$$$$Op({Drop(o)},{At(Robot,x)land Holding(o)},{At(o,x) land lnot Holding(o)}$$1.  The operators allow the robot to hold more than one object. Show how    to modify them with an $EmptyHand$ predicate for a robot that can    hold only one object.2.  Assuming that these are the only actions in the world, write a    successor-state axiom for $EmptyHand$.Exercise 2 Describe the differences and similarities between problem solving andplanning.Exercise 3 Given the action schemas and initial statefrom Figure airport-pddl-algorithm, what are all theapplicable concrete instances of ${Fly}(p,{from},{to})$ in thestate described by$$At(P_1,JFK) land At(P_2,SFO) land Plane(P_1) land Plane(P_2) land Airport(JFK) land Airport(SFO)?$$Exercise 4 The monkey-and-bananas problem is faced by a monkey in a laboratory withsome bananas hanging out of reach from the ceiling. A box is availablethat will enable the monkey to reach the bananas if he climbs on it.Initially, the monkey is at $A$, the bananas at $B$, and the box at $C$.The monkey and box have height ${Low}$, but if the monkey climbs ontothe box he will have height ${High}$, the same as the bananas. Theactions available to the monkey include ${Go}$ from one place toanother, ${Push}$ an object from one place to another, ${ClimbUp}$onto or ${ClimbDown}$ from an object, and ${Grasp}$ or ${Ungrasp}$an object. The result of a ${Grasp}$ is that the monkey holds theobject if the monkey and object are in the same place at the sameheight.1.  Write down the initial state description.2.  Write the six action schemas.3.  Suppose the monkey wants to fool the scientists, who are off to tea,    by grabbing the bananas, but leaving the box in its original place.    Write this as a general goal (i.e., not assuming that the box is    necessarily at C) in the language of situation calculus. Can this    goal be solved by a classical planning system?4.  Your schema for pushing is probably incorrect, because if the object    is too heavy, its position will remain the same when the ${Push}$    schema is applied. Fix your action schema to account for    heavy objects.Exercise 5 The original {Strips} planner was designed to control Shakey the robot.Figure shakey-figure shows a version of Shakey’s worldconsisting of four rooms lined up along a corridor, where each room hasa door and a light switch. The actions in Shakey’s world include moving from place to place,pushing movable objects (such as boxes), climbing onto and down fromrigid objects (such as boxes), and turning light switches on and off.The robot itself could not climb on a box or toggle a switch, but theplanner was capable of finding and printing out plans that were beyondthe robot’s abilities. Shakey’s six actions are the following:-   ${Go}(x,y,r)$, which requires that Shakey be ${At}$ $x$ and that    $x$ and $y$ are locations ${In}$ the same room $r$. By convention    a door between two rooms is in both of them.-   Push a box $b$ from location $x$ to location $y$ within the same    room: ${Push}(b,x,y,r)$. You will need the predicate ${Box}$ and    constants for the boxes.-   Climb onto a box from position $x$: ${ClimbUp}(x, b)$; climb down    from a box to position $x$: ${ClimbDown}(b, x)$. We will need the    predicate ${On}$ and the constant ${Floor}$.-   Turn a light switch on or off: ${TurnOn}(s,b)$;    ${TurnOff}(s,b)$. To turn a light on or off, Shakey must be on top    of a box at the light switch’s location.Write PDDL sentences for Shakey’s six actions and the initial state fromConstruct a plan for Shakey toget ${Box}{}_2$ into ${Room}{}_2$.          Shakey&#39;s world. Shakey can move between landmarks within a room, can pass through the door between rooms, can climb climbable objects and push pushable objects, and can flip light switches.  Exercise 6 A finite Turing machine has a finite one-dimensional tape of cells, eachcell containing one of a finite number of symbols. One cell has a readand write head above it. There is a finite set of states the machine canbe in, one of which is the accept state. At each time step, depending onthe symbol on the cell under the head and the machine’s current state,there are a set of actions we can choose from. Each action involveswriting a symbol to the cell under the head, transitioning the machineto a state, and optionally moving the head left or right. The mappingthat determines which actions are allowed is the Turing machine’sprogram. Your goal is to control the machine into the accept state.Represent the Turing machine acceptance problem as a planning problem.If you can do this, it demonstrates that determining whether a planningproblem has a solution is at least as hard as the Turing acceptanceproblem, which is PSPACE-hard.Exercise 7 (negative-effects-exercise) Explain why dropping negative effects fromevery action schema results in a relaxed problem, provided thatpreconditions and goals contain only positive literals.Exercise 8 (sussman-anomaly-exercise) Figure sussman-anomaly-figure(page sussman-anomaly-figure) shows a blocks-world problem that is known as the {Sussman anomaly}.The problem was considered anomalous because the noninterleaved plannersof the early 1970s could not solve it. Write a definition of the problemand solve it, either by hand or with a planning program. Anoninterleaved planner is a planner that, when given two subgoals$G_{1}$ and $G_{2}$, produces either a plan for $G_{1}$ concatenatedwith a plan for $G_{2}$, or vice versa. Can a noninterleaved plannersolve this problem? How, or why not?Exercise 9 Prove that backward search with PDDL problems is complete.Exercise 10 Construct levels 0, 1, and 2 of the planning graph for the problem inFigure airport-pddl-algorithmExercise 11 (graphplan-proof-exercise) Prove the following assertions aboutplanning graphs:1.  A literal that does not appear in the final level of the graph    cannot be achieved.2.  The level cost of a literal in a serial graph is no greater than the    actual cost of an optimal plan for achieving it.Exercise 12 We saw that planning graphs can handle only propositional actions. Whatif we want to use planning graphs for a problem with variables in thegoal, such as ${At}(P_{1}, x)    land {At}(P_{2}, x)$, where $x$ is assumed to be bound by anexistential quantifier that ranges over a finite domain of locations?How could you encode such a problem to work with planning graphs?Exercise 13 The set-level heuristic (see page set-level-page uses a planning graphto estimate the cost of achieving a conjunctive goal from the currentstate. What relaxed problem is the set-level heuristic the solution to?Exercise 14 Examine the definition of bidirectional search in Chapter search-chapter.1.  Would bidirectional state-space search be a good idea for planning?2.  What about bidirectional search in the space of partial-order plans?3.  Devise a version of partial-order planning in which an action can be    added to a plan if its preconditions can be achieved by the effects    of actions already in the plan. Explain how to deal with conflicts    and ordering constraints. Is the algorithm essentially identical to    forward state-space search?Exercise 15 We contrasted forward and backward state-space searchers withpartial-order planners, saying that the latter is a plan-space searcher.Explain how forward and backward state-space search can also beconsidered plan-space searchers, and say what the plan refinementoperators are.Exercise 16 (satplan-preconditions-exercise) Up to now we have assumed that theplans we create always make sure that an action’s preconditions aresatisfied. Let us now investigate what propositional successor-stateaxioms such as ${HaveArrow}^{t+1} {;;{Leftrightarrow};;}{}$$({HaveArrow}^tland lnot {Shoot}^t)$ have to say about actions whose preconditionsare not satisfied.1.  Show that the axioms predict that nothing will happen when an action    is executed in a state where its preconditions are not satisfied.2.  Consider a plan $p$ that contains the actions required to achieve a    goal but also includes illegal actions. Is it the case that$$initial state land successor-state axioms landp {models} goal ?$$3.  With first-order successor-state axioms in situation calculus, is it    possible to prove that a plan containing illegal actions will    achieve the goal?Exercise 17 (strips-translation-exercise) Consider how to translate a set of actionschemas into the successor-state axioms of situation calculus.1.  Consider the schema for ${Fly}(p,{from},{to})$. Write a    logical definition for the predicate    ${Poss}({Fly}(p,{from},{to}),s)$, which is true if the    preconditions for ${Fly}(p,{from},{to})$ are satisfied in    situation $s$.2.  Next, assuming that ${Fly}(p,{from},{to})$ is the only action    schema available to the agent, write down a successor-state axiom    for ${At}(p,x,s)$ that captures the same information as the    action schema.3.  Now suppose there is an additional method of travel:    ${Teleport}(p,{from},{to})$. It has the additional    precondition $lnot {Warped}(p)$ and the additional effect    ${Warped}(p)$. Explain how the situation calculus knowledge base    must be modified.4.  Finally, develop a general and precisely specified procedure for    carrying out the translation from a set of action schemas to a set    of successor-state axioms.Exercise 18 (disjunctive-satplan-exercise) In the $SATPlan$ algorithm inFigure satplan-agent-algorithm (page satplan-agent-algorithm,each call to the satisfiability algorithm asserts a goal $g^T$, where$T$ ranges from 0 to $T_{max}$. Suppose instead that thesatisfiability algorithm is called only once, with the goal$g^0 vee g^1 vee cdots vee g^{T_{max}}$. 1.  Will this always return a plan if one exists with length less than    or equal to $T_{max}$? 2.  Does this approach introduce any new spurious “solutions”?3.  Discuss how one might modify a satisfiability algorithm such as $WalkSAT$ so    that it finds short solutions (if they exist) when given a    disjunctive goal of this form.Exercise 1 The goals we have considered so far all ask the planner to make theworld satisfy the goal at just one time step. Not all goals can beexpressed this way: you do not achieve the goal of suspending achandelier above the ground by throwing it in the air. More seriously,you wouldn’t want your spacecraft life-support system to supply oxygenone day but not the next. A maintenance goal is achievedwhen the agent’s plan causes a condition to hold continuously from agiven state onward. Describe how to extend the formalism of this chapterto support maintenance goals.Exercise 2 You have a number of trucks with which to deliver a set of packages.Each package starts at some location on a grid map, and has adestination somewhere else. Each truck is directly controlled by movingforward and turning. Construct a hierarchy of high-level actions forthis problem. What knowledge about the solution does your hierarchyencode?Exercise 3 (HLA-unique-exercise) Suppose that a high-level action has exactly oneimplementation as a sequence of primitive actions. Give an algorithm forcomputing its preconditions and effects, given the complete refinementhierarchy and schemas for the primitive actions.Exercise 4 Suppose that the optimistic reachable set of a high-level plan is asuperset of the goal set; can anything be concluded about whether theplan achieves the goal? What if the pessimistic reachable set doesn’tintersect the goal set? Explain.Exercise 5 (HLA-progression-exercise) Write an algorithm that takes an initialstate (specified by a set of propositional literals) and a sequence ofHLAs (each defined by preconditions and angelic specifications ofoptimistic and pessimistic reachable sets) and computes optimistic andpessimistic descriptions of the reachable set of the sequence.Exercise 6 In Figure jobshop-cpm-figure we showed how to describeactions in a scheduling problem by using separate fields for , , and .Now suppose we wanted to combine scheduling with nondeterministicplanning, which requires nondeterministic and conditional effects.Consider each of the three fields and explain if they should remainseparate fields, or if they should become effects of the action. Give anexample for each of the three.Exercise 7 Some of the operations in standard programming languages can be modeledas actions that change the state of the world. For example, theassignment operation changes the contents of a memory location, and theprint operation changes the state of the output stream. A programconsisting of these operations can also be considered as a plan, whosegoal is given by the specification of the program. Therefore, planningalgorithms can be used to construct programs that achieve a givenspecification. 1.  Write an action schema for the assignment operator (assigning the    value of one variable to another). Remember that the original value    will be overwritten! 2.  Show how object creation can be used by a planner to produce a plan    for exchanging the values of two variables by using a    temporary variable. Exercise 8 Consider the following argument: In a framework that allows uncertaininitial states, nondeterministic effectsare just a notational convenience, not a source of additionalrepresentational power. For any action schema $a$ with nondeterministiceffect $P lor Q$, we could always replace it with the conditionaleffects ${~R{:}~P} land{~lnot R{:}~Q}$, which in turn can bereduced to two regular actions. The proposition $R$ stands for a randomproposition that is unknown in the initial state and for which there areno sensing actions. Is this argument correct? Consider separately twocases, one in which only one instance of action schema $a$ is in theplan, the other in which more than one instance is.Exercise 9 (conformant-flip-literal-exercise) Suppose the ${Flip}$ actionalways changes the truth value of variable $L$. Show how to define itseffects by using an action schema with conditional effects. Show that,despite the use of conditional effects, a 1-CNF belief staterepresentation remains in 1-CNF after a ${Flip}$.Exercise 10 In the blocks world we were forced to introduce two action schemas,${Move}$ and ${MoveToTable}$, in order to maintain the ${Clear}$predicate properly. Show how conditional effects can be used torepresent both of these cases with a single action.Exercise 11 (alt-vacuum-exercise) Conditional effects were illustrated for the${Suck}$ action in the vacuum world—which square becomes clean dependson which square the robot is in. Can you think of a new set ofpropositional variables to define states of the vacuum world, such that${Suck}$ has an unconditional description? Write outthe descriptions of ${Suck}$, ${Left}$, and ${Right}$, using yourpropositions, and demonstrate that they suffice to describe all possiblestates of the world.Exercise 12 Find a suitably dirty carpet, free of obstacles, and vacuum it. Draw thepath taken by the vacuum cleaner as accurately as you can. Explain it,with reference to the forms of planning discussed in this chapter.Exercise 13 The following quotes are from the backs of shampoo bottles. Identifyeach as an unconditional, conditional, or execution-monitoring plan. (a)“Lather. Rinse. Repeat.” (b) “Apply shampoo to scalp and let it remainfor several minutes. Rinse and repeat if necessary.” (c) “See a doctorif problems persist.”Exercise 14 Consider the following problem: A patient arrives at the doctor’s officewith symptoms that could have been caused either by dehydration or bydisease $D$ (but not both). There are two possible actions: ${Drink}$,which unconditionally cures dehydration, and ${Medicate}$, which curesdisease $D$ but has an undesirable side effect if taken when the patientis dehydrated. Write the problem description, and diagram a sensorlessplan that solves the problem, enumerating all relevant possible worlds.Exercise 15 To the medication problem in the previous exercise, add a ${Test}$action that has the conditional effect ${CultureGrowth}$ when${Disease}$ is true and in any case has the perceptual effect${Known}({CultureGrowth})$. Diagram a conditional plan that solvesthe problem and minimizes the use of the ${Medicate}$ action.Exercise 1 Define an ontology in first-order logic for tic-tac-toe. The ontologyshould contain situations, actions, squares, players, marks (X, O, orblank), and the notion of winning, losing, or drawing a game. Alsodefine the notion of a forced win (or draw): a position from which aplayer can force a win (or draw) with the right sequence of actions.Write axioms for the domain. (Note: The axioms that enumerate thedifferent squares and that characterize the winning positions are ratherlong. You need not write these out in full, but indicate clearly whatthey look like.)Exercise 2 You are to create a system for advising computer science undergraduateson what courses to take over an extended period in order to satisfy theprogram requirements. (Use whatever requirements are appropriate foryour institution.) First, decide on a vocabulary for representing allthe information, and then represent it; then formulate a query to thesystem that will return a legal program of study as a solution. Youshould allow for some tailoring to individual students, in that yoursystem should ask what courses or equivalents the student has alreadytaken, and not generate programs that repeat those courses.Suggest ways in which your system could be improved—for example to takeinto account knowledge about student preferences, the workload, good andbad instructors, and so on. For each kind of knowledge, explain how itcould be expressed logically. Could your system easily incorporate thisinformation to find all feasible programs of study for a student? Couldit find the best program?Exercise 3 Figure ontology-figure shows the top levels of ahierarchy for everything. Extend it to include as many real categoriesas possible. A good way to do this is to cover all the things in youreveryday life. This includes objects and events. Start with waking up,and proceed in an orderly fashion noting everything that you see, touch,do, and think about. For example, a random sampling produces music,news, milk, walking, driving, gas, Soda Hall, carpet, talking, ProfessorFateman, chicken curry, tongue, $ 7, sun, the daily newspaper, and so on.You should produce both a single hierarchy chart (on a large sheet ofpaper) and a listing of objects and categories with the relationssatisfied by members of each category. Every object should be in acategory, and every category should be in the hierarchy.Exercise 4 (windows-exercise) Develop a representational system for reasoningabout windows in a window-based computer interface. In particular, yourrepresentation should be able to describe:-   The state of a window: minimized, displayed, or nonexistent.-   Which window (if any) is the active window.-   The position of every window at a given time.-   The order (front to back) of overlapping windows.-   The actions of creating, destroying, resizing, and moving windows;    changing the state of a window; and bringing a window to the front.    Treat these actions as atomic; that is, do not deal with the issue    of relating them to mouse actions. Give axioms describing the    effects of actions on fluents. You may use either event or    situation calculus.Assume an ontology containing situations,actions, integers (for $x$ and $y$coordinates) and windows. Define a language over thisontology; that is, a list of constants, function symbols, and predicateswith an English description of each. If you need to add more categoriesto the ontology (e.g., pixels), you may do so, but be sure to specifythese in your write-up. You may (and should) use symbols defined in thetext, but be sure to list these explicitly.Exercise 5 State the following in the language you developed for the previousexercise:1.  In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out on    the top and bottom. Do not state exact coordinates    for these; describe the general situation.2.  If a window is displayed, then its top edge is higher than its    bottom edge.3.  After you create a window $w$, it is displayed.4.  A window can be minimized only if it is displayed.Exercise 6 State the following in the language you developed for the previousexercise:1.  In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out on    the top and bottom. Do not state exact coordinates    for these; describe the general situation.2.  If a window is displayed, then its top edge is higher than its    bottom edge.3.  After you create a window $w$, it is displayed.4.  A window can be minimized only if it is displayed.Exercise 7 (Adapted from an example by Doug Lenat.) Your mission is to capture, inlogical form, enough knowledge to answer a series of questions about thefollowing simple scenario: Yesterday John went to the North Berkeley Safeway supermarket and bought two pounds of tomatoes and a pound of ground beef.Start by trying to represent the content of the sentence as a series ofassertions. You should write sentences that have straightforward logicalstructure (e.g., statements that objects have certain properties, thatobjects are related in certain ways, that all objects satisfying oneproperty satisfy another). The following might help you get started:-   Which classes, objects, and relations would you need? What are their    parents, siblings and so on? (You will need events and temporal    ordering, among other things.)-   Where would they fit in a more general hierarchy?-   What are the constraints and interrelationships among them?-   How detailed must you be about each of the various concepts?To answer the questions below, your knowledge base must includebackground knowledge. You’ll have to deal with what kind of things areat a supermarket, what is involved with purchasing the things oneselects, what the purchases will be used for, and so on. Try to makeyour representation as general as possible. To give a trivial example:don’t say “People buy food from Safeway,” because that won’t help youwith those who shop at another supermarket. Also, don’t turn thequestions into answers; for example, question (c) asks “Did John buy anymeat?”—not “Did John buy a pound of ground beef?”Sketch the chains of reasoning that would answer the questions. Ifpossible, use a logical reasoning system to demonstrate the sufficiencyof your knowledge base. Many of the things you write might be onlyapproximately correct in reality, but don’t worry too much; the idea isto extract the common sense that lets you answer these questions at all.A truly complete answer to this question is extremelydifficult, probably beyond the state of the art of current knowledgerepresentation. But you should be able to put together a consistent setof axioms for the limited questions posed here.1.  Is John a child or an adult? [Adult]2.  Does John now have at least two tomatoes? [Yes]3.  Did John buy any meat? [Yes]4.  If Mary was buying tomatoes at the same time as John, did he see    her? [Yes]5.  Are the tomatoes made in the supermarket? [No]6.  What is John going to do with the tomatoes? [Eat them]7.  Does Safeway sell deodorant? [Yes]8.  Did John bring some money or a credit card to the supermarket?    [Yes]9.  Does John have less money after going to the supermarket? [Yes]Exercise 8 Make the necessary additions or changes to your knowledge base from theprevious exercise so that the questions that follow can be answered.Include in your report a discussion of your changes, explaining why theywere needed, whether they were minor or major, and what kinds ofquestions would necessitate further changes.1.  Are there other people in Safeway while John is there?    [Yes—staff!]2.  Is John a vegetarian? [No]3.  Who owns the deodorant in Safeway? [Safeway Corporation]4.  Did John have an ounce of ground beef? [Yes]5.  Does the Shell station next door have any gas? [Yes]6.  Do the tomatoes fit in John’s car trunk? [Yes]Exercise 9 Represent the following seven sentences using and extending therepresentations developed in the chapter: 1.  Water is a liquid between 0 and 100 degrees.2.  Water boils at 100 degrees.3.  The water in John’s water bottle is frozen.4.  Perrier is a kind of water.5.  John has Perrier in his water bottle.6.  All liquids have a freezing point.7.  A liter of water weighs more than a liter of alcohol.Exercise 10 (part-decomposition-exercise) Write definitions for the following:1.  ${ExhaustivePartDecomposition}$2.  ${PartPartition}$3.  ${PartwiseDisjoint}$These should be analogous to the definitions for${ExhaustiveDecomposition}$, ${Partition}$, and ${Disjoint}$. Isit the case that ${PartPartition}(s,{BunchOf}(s))$? If so, prove it;if not, give a counterexample and define sufficient conditions underwhich it does hold.Exercise 11 (alt-measure-exercise) An alternative scheme for representing measuresinvolves applying the units function to an abstract length object. Insuch a scheme, one would write ${Inches}({Length}(L_1)) = {1.5}$.How does this scheme compare with the one in the chapter? Issues includeconversion axioms, names for abstract quantities (such as “50 dollars”),and comparisons of abstract measures in different units (50 inches ismore than 50 centimeters).Exercise 12 Write a set of sentences that allows one to calculate the price of anindividual tomato (or other object), given the price per pound. Extendthe theory to allow the price of a bag of tomatoes to be calculated.Exercise 13 (namematch-exercise) Add sentences to extend the definition of thepredicate ${Name}(s, c)$ so that a string such as “laptop computer”matches the appropriate category names from a variety of stores. Try tomake your definition general. Test it by looking at ten online stores,and at the category names they give for three different categories. Forexample, for the category of laptops, we found the names “Notebooks,”“Laptops,” “Notebook Computers,” “Notebook,” “Laptops and Notebooks,”and “Notebook PCs.” Some of these can be covered by explicit ${Name}$facts, while others could be covered by sentences for handling plurals,conjunctions, etc.Exercise 14 Write event calculus axioms to describe the actions in the wumpus world.Exercise 15 State the interval-algebra relation that holds between every pair of thefollowing real-world events:&amp;gt; $LK$: The life of President Kennedy.&amp;gt; $IK$: The infancy of President Kennedy.&amp;gt; $PK$: The presidency of President Kennedy.&amp;gt; $LJ$: The life of President Johnson.&amp;gt; $PJ$: The presidency of President Johnson.&amp;gt; $LO$: The life of President Obama.Exercise 16 This exercise concerns the problem of planning a route for a robot totake from one city to another. The basic action taken by the robot is${Go}(x,y)$, which takes it from city $x$ to city $y$ if there is aroute between those cities. ${Road}(x, y)$ is true if and only ifthere is a road connecting cities $x$ and $y$; if there is, then${Distance}(x, y)$ gives the length of the road. See the map onpage romania-distances-figure for an example. The robot begins in Arad and mustreach Bucharest.1.  Write a suitable logical description of the initial situation of    the robot.2.  Write a suitable logical query whose solutions provide possible    paths to the goal.3.  Write a sentence describing the ${Go}$ action.4.  Now suppose that the robot consumes fuel at the rate of .02 gallons    per mile. The robot starts with 20 gallons of fuel. Augment your    representation to include these considerations.5.  Now suppose some of the cities have gas stations at which the robot    can fill its tank. Extend your representation and write all the    rules needed to describe gas stations, including the    ${Fillup}$ action.Exercise 17 Investigate ways to extend the event calculus to handlesimultaneous events. Is it possible to avoid acombinatorial explosion of axioms?Exercise 18 (exchange-rates-exercise) Construct a representation for exchange ratesbetween currencies that allows for daily fluctuations.Exercise 19 (fixed-definition-exercise) Define the predicate ${Fixed}$, where${Fixed}({Location}(x))$ means that the location of object $x$ isfixed over time.Exercise 20 Describe the event of trading something for something else. Describebuying as a kind of trading in which one of the objects traded is a sumof money.Exercise 21 The two preceding exercises assume a fairly primitive notion ofownership. For example, the buyer starts by owning thedollar bills. This picture begins to break down when, for example, one’smoney is in the bank, because there is no longer any specific collectionof dollar bills that one owns. The picture is complicated still furtherby borrowing, leasing, renting, and bailment. Investigate the variouscommonsense and legal concepts of ownership, and propose a scheme bywhich they can be represented formally.Exercise 22 (card-on-forehead-exercise)(Adapted from Fagin+al:1995.) Consider a game playedwith a deck of just 8 cards, 4 aces and 4 kings. The three players,Alice, Bob, and Carlos, are dealt two cards each. Without looking atthem, they place the cards on their foreheads so that the other playerscan see them. Then the players take turns either announcing that theyknow what cards are on their own forehead, thereby winning the game, orsaying “I don’t know.” Everyone knows the players are truthful and areperfect at reasoning about beliefs.1.  Game 1. Alice and Bob have both said “I don’t know.” Carlos sees    that Alice has two aces (A-A) and Bob has two kings (K-K). What    should Carlos say? (Hint: consider all three possible    cases for Carlos: A-A, K-K, A-K.)2.  Describe each step of Game 1 using the notation of modal logic.3.  Game 2. Carlos, Alice, and Bob all said “I don’t know” on their    first turn. Alice holds K-K and Bob holds A-K. What should Carlos    say on his second turn?4.  Game 3. Alice, Carlos, and Bob all say “I don’t know” on their first    turn, as does Alice on her second turn. Alice and Bob both hold A-K.    What should Carlos say?5.  Prove that there will always be a winner to this game.Exercise 23 The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:1.  Partial knowledge adversary games, such as card games. Here one    player wants to reason about what his opponent knows about the state    of the game.2.  Chess with a clock. Here the player may wish to reason about the    limits of his opponent’s or his own ability to find the best move in    the time available. For instance, if player A has much more time    left than player B, then A will sometimes make a move that greatly    complicates the situation, in the hopes of gaining an advantage    because he has more time to work out the proper strategy.3.  A shopping agent in an environment in which there are costs of    gathering information.4.  Reasoning about public key cryptography, which rests on the    intractability of certain computational problems.Exercise 24 The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:1.  Partial knowledge adversary games, such as card games. Here one    player wants to reason about what his opponent knows about the state    of the game.2.  Chess with a clock. Here the player may wish to reason about the    limits of his opponent’s or his own ability to find the best move in    the time available. For instance, if player A has much more time    left than player B, then A will sometimes make a move that greatly    complicates the situation, in the hopes of gaining an advantage    because he has more time to work out the proper strategy.3.  A shopping agent in an environment in which there are costs of    gathering information.4.  Reasoning about public key cryptography, which rests on the    intractability of certain computational problems.Exercise 25 Translate the following description logic expression (frompage description-logic-ex) into first-order logic, and comment on the result:$$And(Man, AtLeast(3,Son), AtMost(2,Daughter), All(Son,And(Unemployed,Married, All(Spouse,Doctor ))), All(Daughter,And(Professor, Fills(Department ,Physics,Math))))$$Exercise 26 Recall that inheritance information in semantic networks can be capturedlogically by suitable implication sentences. This exercise investigatesthe efficiency of using such sentences for inheritance.1.  Consider the information in a used-car catalog such as Kelly’s Blue    Book—for example, that 1973 Dodge vans are (or perhaps were once)    worth 575. Suppose all this information (for 11,000 models) is    encoded as logical sentences, as suggested in the chapter. Write    down three such sentences, including that for 1973 Dodge vans. How    would you use the sentences to find the value of a    particular car, given a backward-chaining theorem    prover such as Prolog?2.  Compare the time efficiency of the backward-chaining method for    solving this problem with the inheritance method used in    semantic nets.3.  Explain how forward chaining allows a logic-based system to solve    the same problem efficiently, assuming that the KB contains only the    11,000 sentences about prices.4.  Describe a situation in which neither forward nor backward chaining    on the sentences will allow the price query for an individual car to    be handled efficiently.5.  Can you suggest a solution enabling this type of query to be solved    efficiently in all cases in logic systems? Hint:    Remember that two cars of the same year and model have the    same price.)Exercise 27 (natural-stupidity-exercise) One might suppose that the syntacticdistinction between unboxed links and singly boxed links in semanticnetworks is unnecessary, because singly boxed links are always attachedto categories; an inheritance algorithm could simply assume that anunboxed link attached to a category is intended to apply to all membersof that category. Show that this argument is fallacious, giving examplesof errors that would arise.Exercise 28 One part of the shopping process that was not covered in this chapter ischecking for compatibility between items. For example, if a digitalcamera is ordered, what accessory batteries, memory cards, and cases arecompatible with the camera? Write a knowledge base that can determinethe compatibility of a set of items and suggest replacements oradditional items if the shopper makes a choice that is not compatible.The knowledge base should works with at least one line of products andextend easily to other lines.Exercise 29 (shopping-grammar-exercise) A complete solution to the problem ofinexact matches to the buyer’s description in shopping is very difficultand requires a full array of natural language processing and informationretrieval techniques. (See Chapters nlp1-chapterand nlp-english-chapter.) One small step is to allow the user tospecify minimum and maximum values for various attributes. The buyermust use the following grammar for product descriptions:$$Description rightarrow Category space [Connector space Modifier]*$$$$Connector rightarrow &quot;with&quot; space | &quot;and&quot; | &quot;,&quot;$$$$Modifier rightarrow Attribute space |space Attribute space Op space Value$$$$Op rightarrow &quot;=&quot; | &quot;gt&quot; | &quot;lt&quot;$$Here, ${Category}$ names a product category, ${Attribute}$ is somefeature such as “CPU” or “price,” and ${Value}$ is the target valuefor the attribute. So the query “computer with at least a 2.5 GHz CPUfor under 500” must be re-expressed as “computer with CPU $&amp;gt;$ 2.5 GHzand price $&amp;lt;$ 500.” Implement a shopping agent that accepts descriptionsin this language.Exercise 30 (buying-exercise) Our description of Internet shopping omitted theall-important step of actually buying the product.Provide a formal logical description of buying, using event calculus.That is, define the sequence of events that occurs when a buyer submitsa credit-card purchase and then eventually gets billed and receives theproduct.Exercise 1 Show from first principles that $P(abland a) = 1$.Exercise 2 (sum-to-1-exercise) Using the axioms of probability, prove that anyprobability distribution on a discrete random variable must sum to 1.Exercise 3 For each of the following statements, either prove it is true or give acounterexample.1.  If $P(a b, c) = P(b a, c)$, then    $P(a c) = P(b c)$ 2.  If $P(a b, c) = P(a)$, then $P(b c) = P(b)$ 3.  If $P(a b) = P(a)$, then    $P(a b, c) = P(a c)$Exercise 4 Would it be rational for an agent to hold the three beliefs$P(A) = 0.4$, $P(B) = 0.3$, and$P(A lor B) = 0.5$? If so, what range of probabilities wouldbe rational for the agent to hold for $A land B$? Make up a table likethe one in Figure de-finetti-table, and show how itsupports your argument about rationality. Then draw another version ofthe table where $P(A lor B)= 0.7$. Explain why it is rational to have this probability,even though the table shows one case that is a loss and three that justbreak even. (Hint: what is Agent 1 committed to about theprobability of each of the four cases, especially the case that is aloss?)Exercise 5 (exclusive-exhaustive-exercise) This question deals with the propertiesof possible worlds, defined on page possible-worlds-page as assignments to allrandom variables. We will work with propositions that correspond toexactly one possible world because they pin down the assignments of allthe variables. In probability theory, such propositions are called atomic event. Forexample, with Boolean variables $X_1$, $X_2$, $X_3$, the proposition$x_1land lnot x_2 land lnot x_3$ fixes the assignment of thevariables; in the language of propositional logic, we would say it hasexactly one model.1.  Prove, for the case of $n$ Boolean variables, that any two distinct    atomic events are mutually exclusive; that is, their conjunction is    equivalent to ${false}$.2.  Prove that the disjunction of all possible atomic events is    logically equivalent to ${true}$.3.  Prove that any proposition is logically equivalent to the    disjunction of the atomic events that entail its truth.Exercise 6 (inclusion-exclusion-exercise) ProveEquation (kolmogorov-disjunction-equation) fromEquations basic-probability-axiom-equationand (proposition-probability-equation.Exercise 7 Consider the set of all possible five-card poker hands dealt fairly froma standard deck of fifty-two cards.1.  How many atomic events are there in the joint probability    distribution (i.e., how many five-card hands are there)?2.  What is the probability of each atomic event?3.  What is the probability of being dealt a royal straight flush? Four    of a kind?Exercise 8 Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:1.  $textbf{P}({toothache})$.2.  $textbf{P}({Cavity})$.3.  $textbf{P}({Toothache}{cavity})$.4.  $textbf{P}({Cavity}{toothache}lor {catch})$.Exercise 9 Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:1.  $textbf{P}({toothache})$.2.  $textbf{P}({Catch})$.3.  $textbf{P}({Cavity}{catch})$.4.  $textbf{P}({Cavity}{toothache}lor {catch})$.Exercise 10 (unfinished-game-exercise) In his letter of August 24, 1654, Pascalwas trying to show how a pot of money should be allocated when agambling game must end prematurely. Imagine a game where each turnconsists of the roll of a die, player E gets a point whenthe die is even, and player  O gets a point when the dieis odd. The first player to get 7 points wins the pot. Suppose the gameis interrupted with E leading 4–2. How should the moneybe fairly split in this case? What is the general formula? (Fermat andPascal made several errors before solving the problem, but you should beable to get it right the first time.)Exercise 11 Deciding to put probability theory to good use, we encounter a slotmachine with three independent wheels, each producing one of the foursymbols bar, bell, lemon, orcherry with equal probability. The slot machine has thefollowing payout scheme for a bet of 1 coin (where “?” denotes that wedon’t care what comes up for that wheel): &amp;gt; bar/bar/bar pays 20 coins&amp;gt; bell/bell/bell pays 15 coins&amp;gt; lemon/lemon/lemon pays 5 coins&amp;gt; cherry/cherry/cherry pays 3 coins&amp;gt; cherry/cherry/? pays 2 coins&amp;gt; cherry/?/? pays 1 coin1.  Compute the expected “payback” percentage of the machine. In other    words, for each coin played, what is the expected coin return?2.  Compute the probability that playing the slot machine once will    result in a win.3.  Estimate the mean and median number of plays you can expect to make    until you go broke, if you start with 10 coins. You can run a    simulation to estimate this, rather than trying to compute an    exact answer.Exercise 12 Deciding to put probability theory to good use, we encounter a slotmachine with three independent wheels, each producing one of the foursymbols bar, bell, lemon, orcherry with equal probability. The slot machine has thefollowing payout scheme for a bet of 1 coin (where “?” denotes that wedon’t care what comes up for that wheel): &amp;gt; bar/bar/bar pays 20 coins&amp;gt; bell/bell/bell pays 15 coins&amp;gt; lemon/lemon/lemon pays 5 coins&amp;gt; cherry/cherry/cherry pays 3 coins&amp;gt; cherry/cherry/? pays 2 coins&amp;gt; cherry/?/? pays 1 coin1.  Compute the expected “payback” percentage of the machine. In other    words, for each coin played, what is the expected coin return?2.  Compute the probability that playing the slot machine once will    result in a win.3.  Estimate the mean and median number of plays you can expect to make    until you go broke, if you start with 10 coins. You can run a    simulation to estimate this, rather than trying to compute an    exact answer.Exercise 13 We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon = 0.001$, $delta = 0.01$.Exercise 14 We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon0.002$, $delta0.01$.Exercise 15 (independence-exercise) Show that the three forms of independence inEquation (independence-equation) are equivalent.Exercise 16 Consider two medical tests, A and B, for a virus. Test A is 95%effective at recognizing the virus when it is present, but has a 10%false positive rate (indicating that the virus is present, when it isnot). Test B is 90% effective at recognizing the virus, but has a 5%false positive rate. The two tests use independent methods ofidentifying the virus. The virus is carried by 1% of all people. Saythat a person is tested for the virus using only one of the tests, andthat test comes back positive for carrying the virus. Which testreturning positive is more indicative of someone really carrying thevirus? Justify your answer mathematically.Exercise 17 Suppose you are given a coin that lands ${heads}$ with probability $x$and ${tails}$ with probability $1 - x$. Are the outcomes of successiveflips of the coin independent of each other given that you know thevalue of $x$? Are the outcomes of successive flips of the coinindependent of each other if you do not know the value of$x$? Justify your answer.Exercise 18 After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 10,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?Exercise 19 After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 100,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?Exercise 20 (conditional-bayes-exercise) It is quite often useful to consider theeffect of some specific propositions in the context of some generalbackground evidence that remains fixed, rather than in the completeabsence of information. The following questions ask you to prove moregeneral versions of the product rule and Bayes’ rule, with respect tosome background evidence $textbf{e}$: 1.  Prove the conditionalized version of the general product rule:    $${textbf{P}}(X,Y textbf{e}) = {textbf{P}}(XY,textbf{e}) {textbf{P}}(Ytextbf{e}) .$$ 2.  Prove the conditionalized version of Bayes’ rule in    Equation (conditional-bayes-equation). Exercise 21 (pv-xyz-exercise) Show that the statement of conditional independence$${textbf{P}}(X,Y  | Z) = {textbf{P}}(X | Z) {textbf{P}}(Y | Z)$$is equivalent to each of the statements$${textbf{P}}(X | Y,Z) = {textbf{P}}(X | Z) quadmbox{and}quad {textbf{P}}(Y | X,Z) = {textbf{P}}(Y | Z) .$$Exercise 22 Suppose you are given a bag containing $n$ unbiased coins. You are toldthat $n-1$ of these coins are normal, with heads on one side and tailson the other, whereas one coin is a fake, with heads on both sides. 1.  Suppose you reach into the bag, pick out a coin at random, flip it,    and get a head. What is the (conditional) probability that the coin    you chose is the fake coin? 2.  Suppose you continue flipping the coin for a total of $k$ times    after picking it and see $k$ heads. Now what is the conditional    probability that you picked the fake coin? 3.  Suppose you wanted to decide whether the chosen coin was fake by    flipping it $k$ times. The decision procedure returns ${fake}$ if    all $k$ flips come up heads; otherwise it returns ${normal}$. What    is the (unconditional) probability that this procedure makes an    error?Exercise 23 (normalization-exercise) In this exercise, you will complete thenormalization calculation for the meningitis example. First, make up asuitable value for $P(slnot m)$, and use it to calculateunnormalized values for $P(ms)$ and $P(lnot m s)$(i.e., ignoring the $P(s)$ term in the Bayes’ rule expression,Equation (meningitis-bayes-equation). Now normalizethese values so that they add to 1.Exercise 24 This exercise investigates the way in which conditional independencerelationships affect the amount of information needed for probabilisticcalculations.1.  Suppose we wish to calculate $P(he_1,e_2)$ and we have no    conditional independence information. Which of the following sets of    numbers are sufficient for the calculation?    1.  ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,        ${textbf{P}}(E_1H)$,        ${textbf{P}}(E_2H)$    2.  ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,        ${textbf{P}}(E_1,E_2H)$    3.  ${textbf{P}}(H)$,        ${textbf{P}}(E_1H)$,        ${textbf{P}}(E_2H)$2.  Suppose we know that    ${textbf{P}}(E_1H,E_2)={textbf{P}}(E_1H)$    for all values of $H$, $E_1$, $E_2$. Now which of the three sets are    sufficient?Exercise 25 Let $X$, $Y$, $Z$ be Boolean random variables. Label the eight entriesin the joint distribution ${textbf{P}}(X,Y,Z)$ as $a$ through$h$. Express the statement that $X$ and $Y$ are conditionallyindependent given $Z$, as a set of equations relating $a$ through $h$.How many nonredundantequations are there?Exercise 26 (Adapted from Pearl [Pearl:1988].) Suppose you are a witness to anighttime hit-and-run accident involving a taxi in Athens. All taxis inAthens are blue or green. You swear, under oath, that the taxi was blue.Extensive testing shows that, under the dim lighting conditions,discrimination between blue and green is 75% reliable. 1.  Is it possible to calculate the most likely color for the taxi?    (*Hint:* distinguish carefully between the proposition    that the taxi *is* blue and the proposition that it    *appears* blue.) 2.  What if you know that 9 out of 10 Athenian taxis are green?Exercise 27 Write out a general algorithm for answering queries of the form${textbf{P}}({Cause}textbf{e})$, using a naive Bayesdistribution. Assume that the evidence $textbf{e}$ may assign values toany subset of the effect variables.Exercise 28 (naive-bayes-retrieval-exercise) Text categorization is the task ofassigning a given document to one of a fixed set of categories on thebasis of the text it contains. Naive Bayes models are often used forthis task. In these models, the query variable is the document category,and the “effect” variables are the presence or absence of each word inthe language; the assumption is that words occur independently indocuments, with frequencies determined by the document category.1.  Explain precisely how such a model can be constructed, given as    “training data” a set of documents that have been assigned    to categories.2.  Explain precisely how to categorize a new document.3.  Is the conditional independence assumption reasonable? Discuss.Exercise 29 In our analysis of the wumpus world, we used the fact thateach square contains a pit with probability 0.2, independently of thecontents of the other squares. Suppose instead that exactly $N/5$ pitsare scattered at random among the $N$ squares other than [1,1]. Arethe variables $P_{i,j}$ and $P_{k,l}$ still independent? What is thejoint distribution ${textbf{P}}(P_{1,1},ldots,P_{4,4})$ now?Redo the calculation for the probabilities of pits in [1,3] and[2,2].Exercise 30 Redo the probability calculation for pits in [1,3] and [2,2],assuming that each square contains a pit with probability 0.01,independent of the other squares. What can you say about the relativeperformance of a logical versus a probabilistic agent in this case?Exercise 31 Implement a hybrid probabilistic agent for the wumpus world, based onthe hybrid agent inFigure hybrid-wumpus-agent-algorithm and theprobabilistic inference procedure outlined in this chapter.Exercise 1 We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 20%, 60%, and 80%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.1.  Draw the Bayesian network corresponding to this setup and define the    necessary CPTs.2.  Calculate which coin was most likely to have been drawn from the bag    if the observed flips come out heads twice and tails once.Exercise 2 We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 30%, 60%, and 75%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.1.  Draw the Bayesian network corresponding to this setup and define the    necessary CPTs.2.  Calculate which coin was most likely to have been drawn from the bag    if the observed flips come out heads twice and tails once.Exercise 3(cpt-equivalence-exercise) Equation (parameter-joint-repn-equation onpage parameter-joint-repn-equation defines the joint distribution represented by aBayesian network in terms of the parameters$theta(X_i{Parents}(X_i))$. This exercise asks you to derivethe equivalence between the parameters and the conditional probabilities${textbf{ P}}(X_i{Parents}(X_i))$ from this definition.1.  Consider a simple network $Xrightarrow Yrightarrow Z$ with three    Boolean variables. Use    Equations (conditional-probability-equation and (marginalization-equation    (pages conditional-probability-equation and marginalization-equation)    to express the conditional probability $P(zy)$ as the ratio of two sums, each over entries in the    joint distribution ${textbf{P}}(X,Y,Z)$.2.  Now use Equation (parameter-joint-repn-equation to    write this expression in terms of the network parameters    $theta(X)$, $theta(YX)$, and $theta(ZY)$.3.  Next, expand out the summations in your expression from part (b),    writing out explicitly the terms for the true and false values of    each summed variable. Assuming that all network parameters satisfy    the constraint    $sum_{x_i} theta(x_i{parents}(X_i))1$, show    that the resulting expression reduces to $theta(zy)$.4.  Generalize this derivation to show that    $theta(X_i{Parents}(X_i)) = {textbf{P}}(X_i{Parents}(X_i))$    for any Bayesian network.Exercise 4 The arc reversal operation of in a Bayesian network allows us to change the directionof an arc $Xrightarrow Y$ while preserving the joint probabilitydistribution that the network represents Shachter:1986. Arc reversalmay require introducing new arcs: all the parents of $X$ also becomeparents of $Y$, and all parents of $Y$ also become parents of $X$.1.  Assume that $X$ and $Y$ start with $m$ and $n$ parents,    respectively, and that all variables have $k$ values. By calculating    the change in size for the CPTs of $X$ and $Y$, show that the total    number of parameters in the network cannot decrease during    arc reversal. (Hint: the parents of $X$ and $Y$ need    not be disjoint.)2.  Under what circumstances can the total number remain constant?3.  Let the parents of $X$ be $textbf{U} cup textbf{V}$ and the parents of $Y$ be    $textbf{V} cup textbf{W}$, where $textbf{U}$ and $textbf{W}$ are disjoint. The formulas for the    new CPTs after arc reversal are as follows: $$begin{aligned}    {textbf{P}}(Y | textbf{U},textbf{V},textbf{W}) &amp;amp;=&amp;amp; sum_x {textbf{P}}(Y | textbf{V},textbf{W}, x) {textbf{P}}(x | textbf{U}, textbf{V})     {textbf{P}}(X | textbf{U},textbf{V},textbf{W}, Y) &amp;amp;=&amp;amp; {textbf{P}}(Y | X, textbf{V}, textbf{W}) {textbf{P}}(X | textbf{U}, textbf{V}) / {textbf{P}}(Y | textbf{U},textbf{V},textbf{W}) .end{aligned}$$    Prove that the new network expresses the same joint distribution    over all variables as the original network.Exercise 5 Consider the Bayesian network inFigure burglary-figure.1.  If no evidence is observed, are ${Burglary}$ and ${Earthquake}$    independent? Prove this from the numerical semantics and from the    topological semantics.2.  If we observe ${Alarm}{true}$, are ${Burglary}$ and    ${Earthquake}$ independent? Justify your answer by calculating    whether the probabilities involved satisfy the definition of    conditional independence.Exercise 6 Suppose that in a Bayesian network containing an unobserved variable$Y$, all the variables in the Markov blanket ${MB}(Y)$ have beenobserved.1.  Prove that removing the node $Y$ from the network will not affect    the posterior distribution for any other unobserved variable in    the network.2.  Discuss whether we can remove $Y$ if we are planning to use (i)    rejection sampling and (ii) likelihood weighting.                Three possible structures for a Bayesian network describing genetic inheritance of handedness.    Exercise 7 (handedness-exercise) Let $H_x$ be a random variable denoting thehandedness of an individual $x$, with possible values $l$ or $r$. Acommon hypothesis is that left- or right-handedness is inherited by asimple mechanism; that is, perhaps there is a gene $G_x$, also withvalues $l$ or $r$, and perhaps actual handedness turns out mostly thesame (with some probability $s$) as the gene an individual possesses.Furthermore, perhaps the gene itself is equally likely to be inheritedfrom either of an individual’s parents, with a small nonzero probability$m$ of a random mutation flipping the handedness.1.  Which of the three networks in    Figure handedness-figure claim that    $ {textbf{P}}(G_{father},G_{mother},G_{child}) = {textbf{P}}(G_{father}){textbf{P}}(G_{mother}){textbf{P}}(G_{child})$?2.  Which of the three networks make independence claims that are    consistent with the hypothesis about the inheritance of handedness?3.  Which of the three networks is the best description of the    hypothesis?4.  Write down the CPT for the $G_{child}$ node in network (a), in    terms of $s$ and $m$.5.  Suppose that    $P(G_{father}l)=P(G_{mother}l)=q$. In    network (a), derive an expression for $P(G_{child}l)$    in terms of $m$ and $q$ only, by conditioning on its parent nodes.6.  Under conditions of genetic equilibrium, we expect the distribution    of genes to be the same across generations. Use this to calculate    the value of $q$, and, given what you know about handedness in    humans, explain why the hypothesis described at the beginning of    this question must be wrong.Exercise 8 (markov-blanket-exercise) The Markovblanket of a variable is defined on page markov-blanket-page.Prove that a variable is independent of all other variables in thenetwork, given its Markov blanket and deriveEquation (markov-blanket-equation)(page markov-blanket-equation).      A Bayesian network describing some features of a car&#39;s electrical system and engine. Each variable is Boolean, and the true value indicates that the corresponding aspect of the vehicle is in working order.Exercise 9 Consider the network for car diagnosis shown inFigure car-starts-figure.1.  Extend the network with the Boolean variables ${IcyWeather}$ and    ${StarterMotor}$.2.  Give reasonable conditional probability tables for all the nodes.3.  How many independent values are contained in the joint probability    distribution for eight Boolean nodes, assuming that no conditional    independence relations are known to hold among them?4.  How many independent probability values do your network tables    contain?5.  The conditional distribution for ${Starts}$ could be described as    a noisy-AND distribution. Define this    family in general and relate it to the noisy-OR distribution.Exercise 10 Consider a simple Bayesian network with root variables ${Cold}$,${Flu}$, and ${Malaria}$ and child variable ${Fever}$, with anoisy-OR conditional distribution for ${Fever}$ as described inSection canonical-distribution-section. By addingappropriate auxiliary variables for inhibition events and fever-inducingevents, construct an equivalent Bayesian network whose CPTs (except forroot variables) are deterministic. Define the CPTs and proveequivalence.Exercise 11 (LG-exercise) Consider the family of linear Gaussian networks, asdefined on page LG-network-page.1.  In a two-variable network, let $X_1$ be the parent of $X_2$, let    $X_1$ have a Gaussian prior, and let    ${textbf{P}}(X_2X_1)$ be a linear    Gaussian distribution. Show that the joint distribution $P(X_1,X_2)$    is a multivariate Gaussian, and calculate its covariance matrix.2.  Prove by induction that the joint distribution for a general linear    Gaussian network on $X_1,ldots,X_n$ is also a    multivariate Gaussian.Exercise 12 (multivalued-probit-exercise)The probit distribution defined onpage probit-page describes the probability distribution for a Booleanchild, given a single continuous parent.1.  How might the definition be extended to cover multiple continuous    parents?2.  How might it be extended to handle a multivalued    child variable? Consider both cases where the child’s values are    ordered (as in selecting a gear while driving, depending on speed,    slope, desired acceleration, etc.) and cases where they are    unordered (as in selecting bus, train, or car to get to work).    (Hint: Consider ways to divide the possible values    into two sets, to mimic a Boolean variable.)Exercise 13 In your local nuclear power station, there is an alarm that senses whena temperature gauge exceeds a given threshold. The gauge measures thetemperature of the core. Consider the Boolean variables $A$ (alarmsounds), $F_A$ (alarm is faulty), and $F_G$ (gauge is faulty) and themultivalued nodes $G$ (gauge reading) and $T$ (actual core temperature).1.  Draw a Bayesian network for this domain, given that the gauge is    more likely to fail when the core temperature gets too high.2.  Is your network a polytree? Why or why not?3.  Suppose there are just two possible actual and measured    temperatures, normal and high; the probability that the gauge gives    the correct temperature is $x$ when it is working, but $y$ when it    is faulty. Give the conditional probability table associated with    $G$.4.  Suppose the alarm works correctly unless it is faulty, in which case    it never sounds. Give the conditional probability table associated    with $A$.5.  Suppose the alarm and gauge are working and the alarm sounds.    Calculate an expression for the probability that the temperature of    the core is too high, in terms of the various conditional    probabilities in the network.Exercise 14 (telescope-exercise) Two astronomers in different parts of the worldmake measurements $M_1$ and $M_2$ of the number of stars $N$ in somesmall region of the sky, using their telescopes. Normally, there is asmall possibility $e$ of error by up to one star in each direction. Eachtelescope can also (with a much smaller probability $f$) be badly out offocus (events $F_1$ and $F_2$), in which case the scientist willundercount by three or more stars (or if $N$ is less than 3, fail todetect any stars at all). Consider the three networks shown inFigure telescope-nets-figure.1.  Which of these Bayesian networks are correct (but not    necessarily efficient) representations of the preceding information?2.  Which is the best network? Explain.3.  Write out a conditional distribution for    ${textbf{P}}(M_1N)$, for the case where    $N{1,2,3}$ and $M_1{0,1,2,3,4}$. Each    entry in the conditional distribution should be expressed as a    function of the parameters $e$ and/or $f$.4.  Suppose $M_11$ and $M_23$. What are the    possible numbers of stars if you assume no prior    constraint on the values of $N$?5.  What is the most likely number of stars, given these    observations? Explain how to compute this, or if it is not possible    to compute, explain what additional information is needed and how it    would affect the result.Exercise 15 Consider the network shown inFigure telescope-nets-figure(ii), and assume that thetwo telescopes work identically. $N{1,2,3}$ and$M_1,M_2{0,1,2,3,4}$, with the symbolic CPTs as describedin Exercise telescope-exercise. Using the enumerationalgorithm (Figure enumeration-algorithm onpage enumeration-algorithm), calculate the probability distribution${textbf{P}}(NM_12,M_22)$.    Three possible networks for the telescope problem.Exercise 16 Consider the Bayes net shown in Figure politics-figure.1.  Which of the following are asserted by the network    structure?    1.  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.    2.  ${textbf{P}}(J|G) = {textbf{P}}(J|G,I)$.    3.  ${textbf{P}}(M|G,B,I) = {textbf{P}}(M|G,B,I,J)$.2.  Calculate the value of $P(b,i,lnot m,g,j)$.3.  Calculate the probability that someone goes to jail given that they    broke the law, have been indicted, and face a politically    motivated prosecutor.4.  A context-specific independence (see    page CSI-page) allows a variable to be independent of some of    its parents given certain values of others. In addition to the usual    conditional independences given by the graph structure, what    context-specific independences exist in the Bayes net in    Figure politics-figure?5.  Suppose we want to add the variable    $P={PresidentialPardon}$ to the network; draw the new    network and briefly explain any links you add.    A simple Bayes net with  Boolean variables B = {BrokeElectionLaw}, I = {Indicted}, M = {PoliticallyMotivatedProsecutor}, G= {FoundGuilty}, J = {Jailed}.Exercise 17 Consider the Bayes net shown in Figure politics-figure.1.  Which of the following are asserted by the network    structure?    1.  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.    2.  ${textbf{P}}(J|G) = {textbf{P}}(J|G,I)$.    3.  ${textbf{P}}(M|G,B,I) = {textbf{P}}(M|G,B,I,J)$.2.  Calculate the value of $P(b,i,lnot m,g,j)$.3.  Calculate the probability that someone goes to jail given that they    broke the law, have been indicted, and face a politically    motivated prosecutor.4.  A context-specific independence (see    page CSI-page) allows a variable to be independent of some of    its parents given certain values of others. In addition to the usual    conditional independences given by the graph structure, what    context-specific independences exist in the Bayes net in    Figure politics-figure?5.  Suppose we want to add the variable    $P={PresidentialPardon}$ to the network; draw the new    network and briefly explain any links you add.Exercise 18 (VE-exercise) Consider the variable elimination algorithm inFigure elimination-ask-algorithm (page elimination-ask-algorithm).1.  Section exact-inference-section applies variable    elimination to the query    $${textbf{P}}({Burglary}{JohnCalls}{true},{MaryCalls}{true}) .$$    Perform the calculations indicated and check that the answer    is correct.2.  Count the number of arithmetic operations performed, and compare it    with the number performed by the enumeration algorithm.3.  Suppose a network has the form of a chain: a sequence    of Boolean variables $X_1,ldots, X_n$ where    ${Parents}(X_i){X_{i-1}}$ for $i2,ldots,n$.    What is the complexity of computing    ${textbf{P}}(X_1X_n{true})$ using    enumeration? Using variable elimination?4.  Prove that the complexity of running variable elimination on a    polytree network is linear in the size of the tree for any variable    ordering consistent with the network structure.Exercise 19 (bn-complexity-exercise) Investigate the complexity of exact inferencein general Bayesian networks:1.  Prove that any 3-SAT problem can be reduced to exact inference in a    Bayesian network constructed to represent the particular problem and    hence that exact inference is NP-hard. (Hint:    Consider a network with one variable for each proposition symbol,    one for each clause, and one for the conjunction of clauses.)2.  The problem of counting the number of satisfying assignments for a    3-SAT problem is #P-complete. Show that exact inference is at least    as hard as this.Exercise 20 (primitive-sampling-exercise) Consider the problem of generating arandom sample from a specified distribution on a single variable. Assumeyou have a random number generator that returns a random numberuniformly distributed between 0 and 1.1.  Let $X$ be a discrete variable with    $P(Xx_i)p_i$ for    $i{1,ldots,k}$. The cumulative distribution of $X$ gives the probability    that $X{x_1,ldots,x_j}$ for each possible $j$. (See    also Appendix [math-appendix].) Explain how to    calculate the cumulative distribution in $O(k)$ time and how to    generate a single sample of $X$ from it. Can the latter be done in    less than $O(k)$ time?2.  Now suppose we want to generate $N$ samples of $X$, where $Ngg k$.    Explain how to do this with an expected run time per sample that is    constant (i.e., independent of $k$).3.  Now consider a continuous-valued variable with a parameterized    distribution (e.g., Gaussian). How can samples be generated from    such a distribution?4.  Suppose you want to query a continuous-valued variable and you are    using a sampling algorithm such as LIKELIHOODWEIGHTING to do the inference. How would    you have to modify the query-answering process?Exercise 21 Consider the query${textbf{P}}({Rain}{Sprinkler}{true},{WetGrass}{true})$in Figure rain-clustering-figure(a)(page rain-clustering-figure) and how Gibbs sampling can answer it.1.  How many states does the Markov chain have?2.  Calculate the transition matrix    ${textbf{Q}}$ containing    $q({textbf{y}}$ $rightarrow$ ${textbf{y}}&#39;)$    for all ${textbf{y}}$, ${textbf{y}}&#39;$.3.  What does ${textbf{ Q}}^2$, the square of the    transition matrix, represent?4.  What about ${textbf{Q}}^n$ as $nto infty$?5.  Explain how to do probabilistic inference in Bayesian networks,    assuming that ${textbf{Q}}^n$ is available. Is this a    practical way to do inference?Exercise 22 (gibbs-proof-exercise) This exercise explores the stationarydistribution for Gibbs sampling methods.1.  The convex composition $[alpha, q_1; 1-alpha, q_2]$ of $q_1$ and    $q_2$ is a transition probability distribution that first chooses    one of $q_1$ and $q_2$ with probabilities $alpha$ and $1-alpha$,    respectively, and then applies whichever is chosen. Prove that if    $q_1$ and $q_2$ are in detailed balance with $pi$, then their    convex composition is also in detailed balance with $pi$.    (Note: this result justifies a variant of GIBBS-ASK in which    variables are chosen at random rather than sampled in a    fixed sequence.)2.  Prove that if each of $q_1$ and $q_2$ has $pi$ as its stationary    distribution, then the sequential composition    $q q_1 circ q_2$ also has $pi$ as its    stationary distribution.Exercise 23 (MH-exercise) The Metropolis--Hastings algorithm is a member of the MCMC family; as such,it is designed to generate samples $textbf{x}$ (eventually) according to targetprobabilities $pi(textbf{x})$. (Typically we are interested in sampling from$pi(textbf{x})P(textbf{x}textbf{e})$.) Like simulated annealing,Metropolis–Hastings operates in two stages. First, it samples a newstate $textbf{x&#39;}$ from a proposal distribution $q(textbf{x&#39;}textbf{x})$, given the current state $textbf{x}$.Then, it probabilistically accepts or rejects $textbf{x&#39;}$ according to the acceptance probability$$alpha(textbf{x&#39;}textbf{x}) = min left(1,frac{pi(textbf{x&#39;})q(textbf{x}textbf{x&#39;})}{pi(textbf{x})q(textbf{x&#39;}textbf{x})}  right) .$$If the proposal is rejected, the state remains at $textbf{x}$.1.  Consider an ordinary Gibbs sampling step for a specific variable    $X_i$. Show that this step, considered as a proposal, is guaranteed    to be accepted by Metropolis–Hastings. (Hence, Gibbs sampling is a    special case of Metropolis–Hastings.)2.  Show that the two-step process above, viewed as a transition    probability distribution, is in detailed balance with $pi$.Exercise 24 (soccer-rpm-exercise) Three soccer teams $A$, $B$, and $C$, play eachother once. Each match is between two teams, and can be won, drawn, orlost. Each team has a fixed, unknown degree of quality—an integerranging from 0 to 3—and the outcome of a match depends probabilisticallyon the difference in quality between the two teams.1.  Construct a relational probability model to describe this domain,    and suggest numerical values for all the necessary    probability distributions.2.  Construct the equivalent Bayesian network for the three matches.3.  Suppose that in the first two matches $A$ beats $B$ and draws with    $C$. Using an exact inference algorithm of your choice, compute the    posterior distribution for the outcome of the third match.4.  Suppose there are $n$ teams in the league and we have the results    for all but the last match. How does the complexity of predicting    the last game vary with $n$?5.  Investigate the application of MCMC to this problem. How quickly    does it converge in practice and how well does it scale?Exercise 1 (state-augmentation-exercise)Show that any second-order Markovprocess can be rewritten as a first-order Markov process with anaugmented set of state variables. Can this always be doneparsimoniously, i.e., without increasing the number ofparameters needed to specify the transition model?Exercise 2 (markov-convergence-exercise) In this exercise, we examine whathappens to the probabilities in the umbrella world in the limit of longtime sequences.1.  Suppose we observe an unending sequence of days on which the    umbrella appears. Show that, as the days go by, the probability of    rain on the current day increases monotonically toward a    fixed point. Calculate this fixed point.2.  Now consider forecasting further and further into the    future, given just the first two umbrella observations. First,    compute the probability $P(r_{2+k}|u_1,u_2)$ for    $k=1 ldots 20$ and plot the results. You should see that    the probability converges towards a fixed point. Prove that the    exact value of this fixed point is 0.5.Exercise 3 (island-exercise) This exercise develops a space-efficient variant ofthe forward–backward algorithm described inFigure forward-backward-algorithm (page forward-backward-algorithm).We wish to compute $textbf{P} (textbf{X}_k|textbf{e}_{1:t})$ for$k=1,ldots ,t$. This will be done with a divide-and-conquerapproach.1.  Suppose, for simplicity, that $t$ is odd, and let the halfway point    be $h=(t+1)/2$. Show that $textbf{P} (textbf{X}_k|textbf{e}_{1:t}) $     can be computed for    $k=1,ldots ,h$ given just the initial forward message    $textbf{f}_{1:0}$, the backward message $textbf{b}_{h+1:t}$, and the evidence    $textbf{e}_{1:h}$.2.  Show a similar result for the second half of the sequence.3.  Given the results of (a) and (b), a recursive divide-and-conquer    algorithm can be constructed by first running forward along the    sequence and then backward from the end, storing just the required    messages at the middle and the ends. Then the algorithm is called on    each half. Write out the algorithm in detail.4.  Compute the time and space complexity of the algorithm as a function    of $t$, the length of the sequence. How does this change if we    divide the input into more than two pieces?Exercise 4 (flawed-viterbi-exercise) On page flawed-viterbi-page, we outlined a flawedprocedure for finding the most likely state sequence, given anobservation sequence. The procedure involves finding the most likelystate at each time step, using smoothing, and returning the sequencecomposed of these states. Show that, for some temporal probabilitymodels and observation sequences, this procedure returns an impossiblestate sequence (i.e., the posterior probability of the sequence iszero).Exercise 5 (hmm-likelihood-exercise) Equation (matrix-filtering-equation) describes thefiltering process for the matrix formulation of HMMs. Give a similarequation for the calculation of likelihoods, which was describedgenerically in Equation (forward-likelihood-equation).Exercise 6 Consider the vacuum worlds ofFigure vacuum-maze-ch4-figure (perfect sensing) andFigure vacuum-maze-hmm2-figure (noisy sensing). Supposethat the robot receives an observation sequence such that, with perfectsensing, there is exactly one possible location it could be in. Is thislocation necessarily the most probable location under noisy sensing forsufficiently small noise probability $epsilon$? Prove your claim orfind a counterexample.Exercise 7 (hmm-robust-exercise) In Section hmm-localization-section, the priordistribution over locations is uniform and the transition model assumesan equal probability of moving to any neighboring square. What if thoseassumptions are wrong? Suppose that the initial location is actuallychosen uniformly from the northwest quadrant of the room and the actionactually tends to move southeast. Keepingthe HMM model fixed, explore the effect on localization and pathaccuracy as the southeasterly tendency increases, for different valuesof $epsilon$.Exercise 8 (roomba-viterbi-exercise)Consider a version of the vacuum robot(page vacuum-maze-hmm2-figure) that has the policy of going straight for as longas it can; only when it encounters an obstacle does it change to a new(randomly selected) heading. To model this robot, each state in themodel consists of a (location, heading) pair. Implementthis model and see how well the Viterbi algorithm can track a robot withthis model. The robot’s policy is more constrained than the random-walkrobot; does that mean that predictions of the most likely path are moreaccurate?Exercise 9 We have described three policies for the vacuum robot: (1) a uniformrandom walk, (2) a bias for wandering southeast, as described inExercise hmm-robust-exercise, and (3) the policydescribed in Exercise roomba-viterbi-exercise. Supposean observer is given the observation sequence from a vacuum robot, butis not sure which of the three policies the robot is following. Whatapproach should the observer use to find the most likely path, given theobservations? Implement the approach and test it. How much does thelocalization accuracy suffer, compared to the case in which the observerknows which policy the robot is following?Exercise 10 This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .8 on each step; the robot switches to arandomly selected new heading with probability .2 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?Exercise 11 This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .7 on each step; the robot switches to arandomly selected new heading with probability .3 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?    A Bayesian network representation of a switching Kalman filter. The switching variable $S_t$ is a discrete state variable whose value determines  the transition model for the continuous state variables $textbf{X}_t$.  For any discrete state $textit{i}$, the transition model  $textbf{P}(textbf{X}_{t+1}|textbf{X}_t,S_t= i)$ is a linear Gaussian model, just as in a  regular Kalman filter. The transition model for the discrete state,  $textbf{P}(S_{t+1}|S_t)$, can be thought of as a matrix, as in a hidden  Markov model.Exercise 12 (switching-kf-exercise) Often, we wish to monitor a continuous-statesystem whose behavior switches unpredictably among a set of $k$ distinct“modes.” For example, an aircraft trying to evade a missile can executea series of distinct maneuvers that the missile may attempt to track. ABayesian network representation of such a switching Kalmanfilter model is shown inFigure switching-kf-figure.1.  Suppose that the discrete state $S_t$ has $k$ possible values and    that the prior continuous state estimate    ${textbf{P}}(textbf{X}_0)$ is a multivariate    Gaussian distribution. Show that the prediction    ${textbf{P}}(textbf{X}_1)$ is a mixture of    Gaussians—that is, a weighted sum of Gaussians such    that the weights sum to 1.2.  Show that if the current continuous state estimate    ${textbf{P}}(textbf{X}_t|textbf{e}_{1:t})$ is a mixture of $m$ Gaussians,    then in the general case the updated state estimate    ${textbf{P}}(textbf{X}_{t+1}|textbf{e}_{1:t+1})$ will be a mixture of    $km$ Gaussians.3.  What aspect of the temporal process do the weights in the Gaussian    mixture represent?The results in (a) and (b) show that the representation of the posteriorgrows without limit even for switching Kalman filters, which are amongthe simplest hybrid dynamic models.Exercise 13 (kalman-update-exercise) Complete the missing step in the derivationof Equation (kalman-one-step-equation) onpage kalman-one-step-equation, the first update step for the one-dimensional Kalmanfilter.Exercise 14 (kalman-variance-exercise)Let us examine the behavior of the varianceupdate in Equation (kalman-univariate-equation)(page kalman-univariate-equation).1.  Plot the value of $sigma_t^2$ as a function of $t$, given various    values for $sigma_x^2$ and $sigma_z^2$.2.  Show that the update has a fixed point $sigma^2$ such that    $sigma_t^2 rightarrow sigma^2$ as $t rightarrow infty$, and    calculate the value of $sigma^2$.3.  Give a qualitative explanation for what happens as    $sigma_x^2rightarrow 0$ and as $sigma_z^2rightarrow 0$.Exercise 15 (sleep1-exercise) A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:-   The prior probability of getting enough sleep, with no observations,    is 0.7.-   The probability of getting enough sleep on night $t$ is 0.8 given    that the student got enough sleep the previous night, and 0.3    if not.-   The probability of having red eyes is 0.2 if the student got enough    sleep, and 0.7 if not.-   The probability of sleeping in class is 0.1 if the student got    enough sleep, and 0.3 if not.Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.Exercise 16 A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:-   The prior probability of getting enough sleep, with no observations,    is 0.7.-   The probability of getting enough sleep on night $t$ is 0.8 given    that the student got enough sleep the previous night, and 0.3    if not.-   The probability of having red eyes is 0.2 if the student got enough    sleep, and 0.7 if not.-   The probability of sleeping in class is 0.1 if the student got    enough sleep, and 0.3 if not.Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.Exercise 17 For the DBN specified in Exercise sleep1-exercise andfor the evidence values$textbf{e}_1 = notspace redspace eyes,space notspace sleepingspace inspace class$$textbf{e}_2 = redspace eyes,space notspace sleepingspace inspace class$$textbf{e}_3 = redspace eyes,space sleepingspace inspace class$perform the following computations:1.  State estimation: Compute $P({EnoughSleep}_t | textbf{e}_{1:t})$ for each    of $t = 1,2,3$.2.  Smoothing: Compute $P({EnoughSleep}_t | textbf{e}_{1:3})$ for each of    $t = 1,2,3$.3.  Compare the filtered and smoothed probabilities for $t=1$ and $t=2$.Exercise 18 Suppose that a particular student shows up with red eyes and sleeps inclass every day. Given the model described inExercise sleep1-exercise, explain why the probabilitythat the student had enough sleep the previous night converges to afixed point rather than continuing to go down as we gather more days ofevidence. What is the fixed point? Answer this both numerically (bycomputation) and analytically.Exercise 19 (battery-sequence-exercise) This exercise analyzes in more detail thepersistent-failure model for the battery sensor inFigure battery-persistence-figure(a)(page battery-persistence-figure).1.  Figure battery-persistence-figure(b) stops at    $t=32$. Describe qualitatively what should happen as    $ttoinfty$ if the sensor continues to read 0.2.  Suppose that the external temperature affects the battery sensor in    such a way that transient failures become more likely as    temperature increases. Show how to augment the DBN structure in    Figure battery-persistence-figure(a), and explain    any required changes to the CPTs.3.  Given the new network structure, can battery readings be used by the    robot to infer the current temperature?Exercise 20 (dbn-elimination-exercise) Consider applying the variable eliminationalgorithm to the umbrella DBN unrolled for three slices, where the queryis ${textbf{P}}(R_3|u_1,u_2,u_3)$. Show that the spacecomplexity of the algorithm—the size of the largest factor—is the same,regardless of whether the rain variables are eliminated in forward orbackward order.Exercise 1 (almanac-game) (Adapted from David Heckerman.) This exercise concernsthe Almanac Game, which is used bydecision analysts to calibrate numeric estimation. For each of thequestions that follow, give your best guess of the answer, that is, anumber that you think is as likely to be too high as it is to be toolow. Also give your guess at a 25th percentile estimate, that is, anumber that you think has a 25% chance of being too high, and a 75%chance of being too low. Do the same for the 75th percentile. (Thus, youshould give three estimates in all—low, median, and high—for eachquestion.)1.  Number of passengers who flew between New York and Los Angeles    in 1989.2.  Population of Warsaw in 1992.3.  Year in which Coronado discovered the Mississippi River.4.  Number of votes received by Jimmy Carter in the 1976    presidential election.5.  Age of the oldest living tree, as of 2002.6.  Height of the Hoover Dam in feet.7.  Number of eggs produced in Oregon in 1985.8.  Number of Buddhists in the world in 1992.9.  Number of deaths due to AIDS in the United States    in 1981.10. Number of U.S. patents granted in 1901.The correct answers appear after the last exercise of this chapter. Fromthe point of view of decision analysis, the interesting thing is not howclose your median guesses came to the real answers, but rather how oftenthe real answer came within your 25% and 75% bounds. If it was abouthalf the time, then your bounds are accurate. But if you’re like mostpeople, you will be more sure of yourself than you should be, and fewerthan half the answers will fall within the bounds. With practice, youcan calibrate yourself to give realistic bounds, and thus be more usefulin supplying information for decision making. Try this second set ofquestions and see if there is any improvement:1.  Year of birth of Zsa Zsa Gabor.2.  Maximum distance from Mars to the sun in miles.3.  Value in dollars of exports of wheat from the United States in 1992.4.  Tons handled by the port of Honolulu in 1991.5.  Annual salary in dollars of the governor of California in 1993.6.  Population of San Diego in 1990.7.  Year in which Roger Williams founded Providence, Rhode Island.8.  Height of Mt. Kilimanjaro in feet.9.  Length of the Brooklyn Bridge in feet.10. Number of deaths due to automobile accidents in the United States    in 1992.Exercise 2 Chris considers four used cars before buying the one with maximumexpected utility. Pat considers ten cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?Exercise 3 Chris considers five used cars before buying the one with maximumexpected utility. Pat considers eleven cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?Exercise 4 (St-Petersburg-exercise) In 1713, Nicolas Bernoulli stated a puzzle,now called the St. Petersburg paradox, which works as follows. You havethe opportunity to play a game in which a fair coin is tossed repeatedlyuntil it comes up heads. If the first heads appears on the $n$th toss,you win $2^n$ dollars.1.  Show that the expected monetary value of this game is infinite.2.  How much would you, personally, pay to play the game?3.  Nicolas’s cousin Daniel Bernoulli resolved the apparent paradox in    1738 by suggesting that the utility of money is measured on a    logarithmic scale (i.e., $U(S_{n}) = alog_2 n +b$, where $S_n$ is    the state of having $n$). What is the expected utility of the game    under this assumption?4.  What is the maximum amount that it would be rational to pay to play    the game, assuming that one’s initial wealth is $k$?Exercise 5 Write a computer program to automate the process inExercise assessment-exercise. Try your program out onseveral people of different net worth and political outlook. Comment onthe consistency of your results, both for an individual and acrossindividuals.Exercise 6 (surprise-candy-exercise) The Surprise Candy Company makes candy intwo flavors: 75% are strawberry flavor and 25% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 70% of the strawberrycandies are round and 70% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.1.  Which network(s) can correctly represent    ${textbf{P}}(Flavor,Wrapper,Shape)$?2.  Which network is the best representation for this problem?3.  Does network (i) assert that    ${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?4.  What is the probability that your candy has a red wrapper?5.  In the box is a round candy with a red wrapper. What is the    probability that its flavor is strawberry?6.  A unwrapped strawberry candy is worth $s$ on the open market and an    unwrapped anchovy candy is worth $a$. Write an expression for the    value of an unopened candy box.7.  A new law prohibits trading of unwrapped candies, but it is still    legal to trade wrapped candies (out of the box). Is an unopened    candy box now worth more than less than, or the same as before?                Three proposed Bayes nets for the Surprise Candy      problem        Exercise 7 (surprise-candy-exercise) The Surprise Candy Company makes candy intwo flavors: 70% are strawberry flavor and 30% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 80% of the strawberrycandies are round and 80% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.1.  Which network(s) can correctly represent    ${textbf{P}}(Flavor,Wrapper,Shape)$?2.  Which network is the best representation for this problem?3.  Does network (i) assert that    ${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?4.  What is the probability that your candy has a red wrapper?5.  In the box is a round candy with a red wrapper. What is the    probability that its flavor is strawberry?6.  A unwrapped strawberry candy is worth $s$ on the open market and an    unwrapped anchovy candy is worth $a$. Write an expression for the    value of an unopened candy box.7.  A new law prohibits trading of unwrapped candies, but it is still    legal to trade wrapped candies (out of the box). Is an unopened    candy box now worth more than less than, or the same as before?Exercise 8 Prove that the judgments $B succ A$ and $C succ D$ in the Allaisparadox (page allais-page) violate the axiom of substitutability.Exercise 9 Consider the Allais paradox described on page allais-page: an agentwho prefers $B$ over $A$ (taking the sure thing), and $C$ over $D$(taking the higher EMV) is not acting rationally, according to utilitytheory. Do you think this indicates a problem for the agent, a problemfor the theory, or no problem at all? Explain.Exercise 10 Tickets to a lottery cost 1. There are two possible prizes:a 10 payoff with probability 1/50, and a 1,000,000 payoff withprobability 1/2,000,000. What is the expected monetary value of alottery ticket? When (if ever) is it rational to buy a ticket? Beprecise—show an equation involving utilities. You may assume currentwealth of $k$ and that $U(S_k)=0$. You may also assume that$U(S_{k+{10}}) = {10}times U(S_{k+1})$, but you may not make anyassumptions about $U(S_{k+1,{000},{000}})$. Sociological studies showthat people with lower income buy a disproportionate number of lotterytickets. Do you think this is because they are worse decision makers orbecause they have a different utility function? Consider the value ofcontemplating the possibility of winning the lottery versus the value ofcontemplating becoming an action hero while watching an adventure movie.Exercise 11 (assessment-exercise) Assess your own utility for different incrementalamounts of money by running a series of preference tests between somedefinite amount $M_1$ and a lottery $[p,M_2; (1-p), 0]$. Choosedifferent values of $M_1$ and $M_2$, and vary $p$ until you areindifferent between the two choices. Plot the resulting utilityfunction.Exercise 12 How much is a micromort worth to you? Devise a protocol to determinethis. Ask questions based both on paying to avoid risk and being paid toaccept risk.Exercise 13 (kmax-exercise) Let continuous variables $X_1,ldots,X_k$ beindependently distributed according to the same probability densityfunction $f(x)$. Prove that the density function for$max{X_1,ldots,X_k}$ is given by $kf(x)(F(x))^{k-1}$, where $F$ isthe cumulative distribution for $f$.Exercise 14 Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.1.  Assume Mary has an exponential utility function with $R = $500$.    Mary is given the choice between receiving $$500$ with certainty    (probability 1) or participating in a lottery which has a 60%    probability of winning $5000 and a 40% probability of    winning nothing. Assuming Marry acts rationally, which option would    she choose? Show how you derived your answer.2.  Consider the choice between receiving $$100$ with certainty    (probability 1) or participating in a lottery which has a 50%    probability of winning $$500$ and a 50% probability of winning    nothing. Approximate the value of R (to 3 significant digits) in an    exponential utility function that would cause an individual to be    indifferent to these two alternatives. (You might find it helpful to    write a short program to help you solve this problem.)Exercise 15 Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.1.  Assume Mary has an exponential utility function with $R = $400$.    Mary is given the choice between receiving $$400$ with certainty    (probability 1) or participating in a lottery which has a 60%    probability of winning $5000 and a 40% probability of    winning nothing. Assuming Marry acts rationally, which option would    she choose? Show how you derived your answer.2.  Consider the choice between receiving $$100$ with certainty    (probability 1) or participating in a lottery which has a 50%    probability of winning $500 and a 50% probability of winning    nothing. Approximate the value of R (to 3 significant digits) in an    exponential utility function that would cause an individual to be    indifferent to these two alternatives. (You might find it helpful to    write a short program to help you solve this problem.)Exercise 16 Alex is given the choice between two games. In Game 1, a fair coin isflipped and if it comes up heads, Alex receives $$100$. If the coin comesup tails, Alex receives nothing. In Game 2, a fair coin is flippedtwice. Each time the coin comes up heads, Alex receives $$50$, and Alexreceives nothing for each coin flip that comes up tails. Assuming thatAlex has a monotonically increasing utility function for money in therange [$0, $100], show mathematically that if Alex prefers Game 2 toGame 1, then Alex is risk averse (at least with respect to this range ofmonetary amounts).Show that if $X_1$ and $X_2$ are preferentially independent of $X_3$,and $X_2$ and $X_3$ are preferentially independent of $X_1$, then $X_3$and $X_1$ are preferentially independent of $X_2$.Exercise 17 (airport-au-id-exercise) Repeat Exercise airport-id-exercise, using the action-utilityrepresentation shown in Figure airport-au-id-figure.Exercise 18 For either of the airport-siting diagrams from Exercisesairport-id-exercise and airport-au-id-exercise, to whichconditional probability table entry is the utility most sensitive, giventhe available evidence?Exercise 19 Modify and extend the Bayesian network code in the code repository toprovide for creation and evaluation of decision networks and thecalculation of information value.Exercise 20 Consider a student who has the choice to buy or not buy a textbook for acourse. We’ll model this as a decision problem with one Boolean decisionnode, $B$, indicating whether the agent chooses to buy the book, and twoBoolean chance nodes, $M$, indicating whether the student has masteredthe material in the book, and $P$, indicating whether the student passesthe course. Of course, there is also a utility node, $U$. A certainstudent, Sam, has an additive utility function: 0 for not buying thebook and -$100 for buying it; and $2000 for passing the course and 0for not passing. Sam’s conditional probability estimates are as follows:$$begin{array}{ll}P(p|b,m) = 0.9              &amp;amp; P(m|b) = 0.9       P(p|b, lnot m) = 0.5       &amp;amp; P(m|lnot b) = 0.7 P(p|lnot b, m) = 0.8       &amp;amp; P(p|lnot b, lnot m) = 0.3 &amp;amp; end{array}$$You might think that $P$ would be independent of $B$ given$M$, But this course has an open-book final—so having the book helps.1.  Draw the decision network for this problem.2.  Compute the expected utility of buying the book and of not    buying it.3.  What should Sam do?Exercise 21 (airport-id-exercise) This exercise completes the analysis of theairport-siting problem in Figure airport-id-figure.1.  Provide reasonable variable domains, probabilities, and utilities    for the network, assuming that there are three possible sites.2.  Solve the decision problem.3.  What happens if changes in technology mean that each aircraft    generates half the noise?4.  What if noise avoidance becomes three times more important?5.  Calculate the VPI for ${AirTraffic}$, ${Litigation}$, and    ${Construction}$ in your model.Exercise 22 (car-vpi-exercise) (Adapted from Pearl [Pearl:1988].) A used-carbuyer can decide to carry out various tests with various costs (e.g.,kick the tires, take the car to a qualified mechanic) and then,depending on the outcome of the tests, decide which car to buy. We willassume that the buyer is deciding whether to buy car $c_1$, that thereis time to carry out at most one test, and that $t_1$ is the test of$c_1$ and costs $50.A car can be in good shape (quality $q^+$) or bad shape (quality $q^-$),and the tests might help indicate what shape the car is in. Car $c_1$costs $1,500, and its market value is $$2,000$ if it is in good shape; ifnot, $$700$ in repairs will be needed to make it in good shape. The buyer’sestimate is that $c_1$ has a 70% chance of being in good shape.1.  Draw the decision network that represents this problem.2.  Calculate the expected net gain from buying $c_1$, given no test.3.  Tests can be described by the probability that the car will pass or    fail the test given that the car is in good or bad shape. We have    the following information:    $P({pass}(c_1,t_1) | q^+(c_1)) = {0.8}$    $P({pass}(c_1,t_1) | q^-(c_1)) = {0.35}$    Use Bayes’ theorem to calculate the probability that the car will pass (or fail) its test and hence the probability that it is in good (or bad) shape given each possible test outcome.4.  Calculate the optimal decisions given either a pass or a fail, and    their expected utilities.5.  Calculate the value of information of the test, and derive an    optimal conditional plan for the buyer.Exercise 23 (nonnegative-VPI-exercise) Recall the definition of value ofinformation in Section VPI-section.1.  Prove that the value of information is nonnegative and    order independent.2.  Explain why it is that some people would prefer not to get some    information—for example, not wanting to know the sex of their baby    when an ultrasound is done.3.  A function $f$ on sets is submodular if, for any element $x$ and any sets $A$    and $B$ such that $Asubseteq B$, adding $x$ to $A$ gives a greater    increase in $f$ than adding $x$ to $B$:    $$Asubseteq B Rightarrow (f(A cup {x}) - f(A)) geq (f(Bcup {x}) - f(B)) .$$    Submodularity captures the intuitive notion of diminishing    returns. Is the value of information, viewed as a function    $f$ on sets of possible observations, submodular? Prove this or find    a counterexample.Exercise 1 (mdp-model-exercise) For the $4times 3$ world shown inFigure sequential-decision-world-figure., calculatewhich squares can be reached from (1,1) by the action sequence$[{Up},{Up},{Right},{Right},{Right}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section for ahidden Markov model.Exercise 2 (mdp-model-exercise) For the $4times 3$ world shown inFigure sequential-decision-world-figure, calculatewhich squares can be reached from (1,1) by the action sequence$[{Right},{Right},{Right},{Up},{Up}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section) for ahidden Markov model.Exercise 3 Select a specific member of the set of policies that are optimal for$R(s)&amp;gt;0$ as shown inFigure sequential-decision-policies-figure(b), andcalculate the fraction of time the agent spends in each state, in thelimit, if the policy is executed forever. (Hint:Construct the state-to-state transition probability matrix correspondingto the policy and seeExercise markov-convergence-exercise.)Exercise 4 (nonseparable-exercise)Suppose that we define the utility of a statesequence to be the maximum reward obtained in any statein the sequence. Show that this utility function does not result instationary preferences between state sequences. Is it still possible todefine a utility function on states such that MEU decision making givesoptimal behavior?Exercise 5 Can any finite search problem be translated exactly into a Markovdecision problem such that an optimal solution of the latter is also anoptimal solution of the former? If so, explain preciselyhow to translate the problem and how to translate the solution back; ifnot, explain precisely why not (i.e., give acounterexample).Exercise 6 (reward-equivalence-exercise) Sometimes MDPs are formulated with areward function $R(s,a)$ that depends on the action taken or with areward function $R(s,a,s&#39;)$ that also depends on the outcome state.1.  Write the Bellman equations for these formulations.2.  Show how an MDP with reward function $R(s,a,s&#39;)$ can be transformed    into a different MDP with reward function $R(s,a)$, such that    optimal policies in the new MDP correspond exactly to optimal    policies in the original MDP.3.  Now do the same to convert MDPs with $R(s,a)$ into MDPs with $R(s)$.Exercise 7 (threshold-cost-exercise) For the environment shown inFigure sequential-decision-world-figure, find all thethreshold values for $R(s)$ such that the optimal policy changes whenthe threshold is crossed. You will need a way to calculate the optimalpolicy and its value for fixed $R(s)$. (Hint: Prove thatthe value of any fixed policy varies linearly with $R(s)$.)Exercise 8 (vi-contraction-exercise) Equation (vi-contraction-equation) onpage vi-contraction-equation states that the Bellman operator is a contraction.1.  Show that, for any functions $f$ and $g$,    $$|max_a f(a) - max_a g(a)| leq max_a |f(a) - g(a)| .$$2.  Write out an expression for $$|(B,U_i - B,U&#39;_i)(s)|$$ and then apply    the result from (1) to complete the proof that the Bellman operator    is a contraction.Exercise 9 This exercise considers two-player MDPs that correspond to zero-sum,turn-taking games like those inChapter game-playing-chapter. Let the players be $A$and $B$, and let $R(s)$ be the reward for player $A$ in state $s$. (Thereward for $B$ is always equal and opposite.)1.  Let $U_A(s)$ be the utility of state $s$ when it is $A$’s turn to    move in $s$, and let $U_B(s)$ be the utility of state $s$ when it is    $B$’s turn to move in $s$. All rewards and utilities are calculated    from $A$’s point of view (just as in a minimax game tree). Write    down Bellman equations defining $U_A(s)$ and $U_B(s)$.2.  Explain how to do two-player value iteration with these equations,    and define a suitable termination criterion.3.  Consider the game described in    Figure line-game4-figure on page line-game4-figure.    Draw the state space (rather than the game tree), showing the moves    by $A$ as solid lines and moves by $B$ as dashed lines. Mark each    state with $R(s)$. You will find it helpful to arrange the states    $(s_A,s_B)$ on a two-dimensional grid, using $s_A$ and $s_B$ as    “coordinates.”4.  Now apply two-player value iteration to solve this game, and derive    the optimal policy.                (a) $3 times 3$ world for Exercise 3x3-mdp-exercise. The reward for each state is indicated. The upper right square is a terminal state. (b) $101 times 3$ world for Exercise 101x3-mdp-exercise (omitting 93 identical columns in the middle).      The start state has reward 0.    Exercise 10 (3x3-mdp-exercise) Consider the $3 times 3$ world shown inFigure grid-mdp-figure(a). The transition model is thesame as in the $4times 3$Figure sequential-decision-world-figure: 80% of thetime the agent goes in the direction it selects; the rest of the time itmoves at right angles to the intended direction.Implement value iteration for this world for each value of $r$ below.Use discounted rewards with a discount factor of 0.99. Show the policyobtained in each case. Explain intuitively why the value of $r$ leads toeach policy.1.  $r = -100$2.  $r = -3$3.  $r = 0$4.  $r = +3$Exercise 11 (101x3-mdp-exercise) Consider the $101 times 3$ world shown inFigure grid-mdp-figure(b). In the start state the agenthas a choice of two deterministic actions, Up orDown, but in the other states the agent has onedeterministic action, Right. Assuming a discounted rewardfunction, for what values of the discount $gamma$ should the agentchoose Up and for which Down? Compute theutility of each action as a function of $gamma$. (Note that this simpleexample actually reflects many real-world situations in which one mustweigh the value of an immediate action versus the potential continuallong-term consequences, such as choosing to dump pollutants into alake.)Exercise 12 Consider an undiscounted MDP having three states, (1, 2, 3), withrewards $-1$, $-2$, $0$, respectively. State 3 is a terminal state. Instates 1 and 2 there are two possible actions: $a$ and $b$. Thetransition model is as follows:-   In state 1, action $a$ moves the agent to state 2 with probability    0.8 and makes the agent stay put with probability 0.2.-   In state 2, action $a$ moves the agent to state 1 with probability    0.8 and makes the agent stay put with probability 0.2.-   In either state 1 or state 2, action $b$ moves the agent to state 3    with probability 0.1 and makes the agent stay put with    probability 0.9.Answer the following questions:1.  What can be determined qualitatively about the    optimal policy in states 1 and 2?2.  Apply policy iteration, showing each step in full, to determine the    optimal policy and the values of states 1 and 2. Assume that the    initial policy has action $b$ in both states.3.  What happens to policy iteration if the initial policy has action    $a$ in both states? Does discounting help? Does the optimal policy    depend on the discount factor?Exercise 13 Consider the $4times 3$ world shown inFigure sequential-decision-world-figure.1.  Implement an environment simulator for this environment, such that    the specific geography of the environment is easily altered. Some    code for doing this is already in the online code repository.2.  Create an agent that uses policy iteration, and measure its    performance in the environment simulator from various    starting states. Perform several experiments from each starting    state, and compare the average total reward received per run with    the utility of the state, as determined by your algorithm.3.  Experiment with increasing the size of the environment. How does the    run time for policy iteration vary with the size of the environment?Exercise 14 (policy-loss-exercise) How can the value determination algorithm beused to calculate the expected loss experienced by an agent using agiven set of utility estimates ${U}$ and an estimatedmodel ${P}$, compared with an agent using correct values?Exercise 15 (4x3-pomdp-exercise) Let the initial belief state $b_0$ for the$4times 3$ POMDP on page 4x3-pomdp-page be the uniform distributionover the nonterminal states, i.e.,$&amp;lt; frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},0,0 &amp;gt;$.Calculate the exact belief state $b_1$ after the agent moves and itssensor reports 1 adjacent wall. Also calculate $b_2$ assuming that thesame thing happens again.Exercise 16 What is the time complexity of $d$ steps of POMDP value iteration for asensorless environment?Exercise 17 (2state-pomdp-exercise) Consider a version of the two-state POMDP onpage 2state-pomdp-page in which the sensor is 90% reliable in state 0 butprovides no information in state 1 (that is, it reports 0 or 1 withequal probability). Analyze, either qualitatively or quantitatively, theutility function and the optimal policy for this problem.Exercise 18 (dominant-equilibrium-exercise) Show that a dominant strategyequilibrium is a Nash equilibrium, but not vice versa.Exercise 19 In the children’s game of rock–paper–scissors each player reveals at thesame time a choice of rock, paper, or scissors. Paper wraps rock, rockblunts scissors, and scissors cut paper. In the extended versionrock–paper–scissors–fire–water, fire beats rock, paper, and scissors;rock, paper, and scissors beat water; and water beats fire. Write outthe payoff matrix and find a mixed-strategy solution to this game.Exercise 20 Solve the game of three-finger Morra.Exercise 21 In the Prisoner’s Dilemma, consider the case where aftereach round, Alice and Bob have probability $X$ meeting again. Supposeboth players choose the perpetual punishment strategy (where each willchoose ${refuse}$ unless the other player has ever played${testify}$). Assume neither player has played ${testify}$ thus far.What is the expected future total payoff for choosing to ${testify}$versus ${refuse}$ when $X = .2$? How about when $X = .05$? For whatvalue of $X$ is the expected future total payoff the same whether onechooses to ${testify}$ or ${refuse}$ in the current round?Exercise 22 The following payoff matrix, from @Blinder:1983 by way of Bernstein:1996, shows a game betweenpoliticians and the Federal Reserve.$$begin{array} 	{|r|r|}hline  &amp;amp; Fed: contract &amp;amp; Fed: do nothing &amp;amp; Fed: expand  	hline		Pol: contract &amp;amp; F=7, P=1 &amp;amp; F=9, P=4 &amp;amp; F=6, P=6  		Pol: do nothing &amp;amp; F=8, P=2 &amp;amp; F=5, P=5 &amp;amp; F=4, P=9  		Pol: expand &amp;amp; F=3, P=3 &amp;amp; F=2, P=7 &amp;amp; F=1, P=8 	hline  end{array}$$Politicians can expand or contract fiscal policy, while the Fed canexpand or contract monetary policy. (And of course either side canchoose to do nothing.) Each side also has preferences for who should dowhat—neither side wants to look like the bad guys. The payoffs shown aresimply the rank orderings: 9 for first choice through 1 for last choice.Find the Nash equilibrium of the game in pure strategies. Is this aPareto-optimal solution? You might wish to analyze the policies ofrecent administrations in this light.Exercise 23 A Dutch auction is similar in an English auction, but rather thanstarting the bidding at a low price and increasing, in a Dutch auctionthe seller starts at a high price and gradually lowers the price untilsome buyer is willing to accept that price. (If multiple bidders acceptthe price, one is arbitrarily chosen as the winner.) More formally, theseller begins with a price $p$ and gradually lowers $p$ by increments of$d$ until at least one buyer accepts the price. Assuming all bidders actrationally, is it true that for arbitrarily small $d$, a Dutch auctionwill always result in the bidder with the highest value for the itemobtaining the item? If so, show mathematically why. If not, explain howit may be possible for the bidder with highest value for the item not toobtain it.Exercise 24 Imagine an auction mechanism that is just like an ascending-bid auction,except that at the end, the winning bidder, the one who bid $b_{max}$,pays only $b_{max}/2$ rather than $b_{max}$. Assuming all agents arerational, what is the expected revenue to the auctioneer for thismechanism, compared with a standard ascending-bid auction?Exercise 25 Teams in the National Hockey League historically received 2 points forwinning a game and 0 for losing. If the game is tied, an overtime periodis played; if nobody wins in overtime, the game is a tie and each teamgets 1 point. But league officials felt that teams were playing tooconservatively in overtime (to avoid a loss), and it would be moreexciting if overtime produced a winner. So in 1999 the officialsexperimented in mechanism design: the rules were changed, giving a teamthat loses in overtime 1 point, not 0. It is still 2 points for a winand 1 for a tie. 1.  Was hockey a zero-sum game before the rule change? After?2.  Suppose that at a certain time $t$ in a game, the home team has    probability $p$ of winning in regulation time, probability $0.78-p$    of losing, and probability 0.22 of going into overtime, where they    have probability $q$ of winning, $.9-q$ of losing, and .1 of tying.    Give equations for the expected value for the home and    visiting teams.3.  Imagine that it were legal and ethical for the two teams to enter    into a pact where they agree that they will skate to a tie in    regulation time, and then both try in earnest to win in overtime.    Under what conditions, in terms of $p$ and $q$, would it be rational    for both teams to agree to this pact?4.  Longley+Sankaran:2005 report that since the rule change, the percentage of games with a    winner in overtime went up 18.2%, as desired, but the percentage of    overtime games also went up 3.6%. What does that suggest about    possible collusion or conservative play after the rule change?Exercise 1 (infant-language-exercise) Consider the problem faced by an infantlearning to speak and understand a language. Explain how this processfits into the general learning model. Describe the percepts and actionsof the infant, and the types of learning the infant must do. Describethe subfunctions the infant is trying to learn in terms of inputs andoutputs, and available example data.Exercise 2 Repeat Exercise infant-language-exercise for the caseof learning to play tennis (or some other sport with which you arefamiliar). Is this supervised learning or reinforcement learning?Exercise 3 Draw a decision tree for the problem of deciding whether to move forwardat a road intersection, given that the light has just turned green.Exercise 4 We never test the same attribute twice along one path in a decisiontree. Why not?Exercise 5 Suppose we generate a training set from a decision tree and then applydecision-tree learning to that training set. Is it the case that thelearning algorithm will eventually return the correct tree as thetraining-set size goes to infinity? Why or why not?Exercise 6 (leaf-classification-exercise) In the recursive construction ofdecision trees, it sometimes happens that a mixed set of positive andnegative examples remains at a leaf node, even after all the attributeshave been used. Suppose that we have $p$ positive examples and $n$negative examples.1.  Show that the solution used by DECISION-TREE-LEARNING, which picks the majority    classification, minimizes the absolute error over the set of    examples at the leaf.2.  Show that the class probability $p/(p+n)$ minimizes the sum of squared errors.Exercise 7 (nonnegative-gain-exercise) Suppose that an attribute splits the set ofexamples $E$ into subsets $E_k$ and that each subset has $p_k$positive examples and $n_k$ negative examples. Show that theattribute has strictly positive information gain unless the ratio$p_k/(p_k+n_k)$ is the same for all $k$.Exercise 8 Consider the following data set comprised of three binary inputattributes ($A_1, A_2$, and $A_3$) and one binary output:$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; Outputspace y  	hline textbf{x}_1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  	textbf{x}_2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  	 textbf{x}_3 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	 textbf{x}_4 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_5 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1  	hline  end{array}$$Use the algorithm in Figure DTL-algorithm(page DTL-algorithm) to learn a decision tree for these data. Show thecomputations made to determine the attribute to split at each node.Exercise 9 Construct a data set (set of examples with attributes andclassifications) that would cause the decision-tree learning algorithmto find a non-minimal-sized tree. Show the tree constructed by thealgorithm and the minimal-sized tree that you can generate by hand.Exercise 10 A decision graph is a generalization of a decision treethat allows nodes (i.e., attributes used for splits) to have multipleparents, rather than just a single parent. The resulting graph muststill be acyclic. Now, consider the XOR function of threebinary input attributes, which produces the value 1 if and only if anodd number of the three input attributes has value 1.1.  Draw a minimal-sized decision tree for the    three-input XOR function.2.  Draw a minimal-sized decision graph for the    three-input XOR function.Exercise 11 (pruning-DTL-exercise) This exercise considers $chi^2$ pruning ofdecision trees (Section chi-squared-section.1.  Create a data set with two input attributes, such that the    information gain at the root of the tree for both attributes is    zero, but there is a decision tree of depth 2 that is consistent    with all the data. What would $chi^2$ pruning do on this data set    if applied bottom up? If applied top down?2.  Modify DECISION-TREE-LEARNING to include $chi^2$-pruning. You might wish to consult    Quinlan [Quinlan:1986] or [Kearns+Mansour:1998] for details.Exercise 12 (missing-value-DTL-exercise) The standard DECISION-TREE-LEARNING algorithm described in thechapter does not handle cases in which some examples have missingattribute values.1.  First, we need to find a way to classify such examples, given a    decision tree that includes tests on the attributes for which values    can be missing. Suppose that an example $textbf{x}$ has a missing value for    attribute $A$ and that the decision tree tests for $A$ at a node    that $textbf{x}$ reaches. One way to handle this case is to pretend that    the example has all possible values for the    attribute, but to weight each value according to its frequency among    all of the examples that reach that node in the decision tree. The    classification algorithm should follow all branches at any node for    which a value is missing and should multiply the weights along each    path. Write a modified classification algorithm for decision trees    that has this behavior.2.  Now modify the information-gain calculation so that in any given    collection of examples $C$ at a given node in the tree during the    construction process, the examples with missing values for any of    the remaining attributes are given “as-if” values according to the    frequencies of those values in the set $C$.Exercise 13 (gain-ratio-DTL-exercise) InSection broadening-decision-tree-section, we noted thatattributes with many different possible values can cause problems withthe gain measure. Such attributes tend to split the examples intonumerous small classes or even singleton classes, thereby appearing tobe highly relevant according to the gain measure. Thegain-ratio criterion selects attributesaccording to the ratio between their gain and their intrinsicinformation content—that is, the amount of information contained in theanswer to the question, “What is the value of this attribute?” Thegain-ratio criterion therefore tries to measure how efficiently anattribute provides information on the correct classification of anexample. Write a mathematical expression for the information content ofan attribute, and implement the gain ratio criterion in DECISION-TREE-LEARNING.Exercise 14 Suppose you are running a learning experiment on a new algorithm forBoolean classification. You have a data set consisting of 100 positiveand 100 negative examples. You plan to use leave-one-outcross-validation and compare your algorithm to a baseline function, asimple majority classifier. (A majority classifier is given a set oftraining data and then always outputs the class that is in the majorityin the training set, regardless of the input.) You expect the majorityclassifier to score about 50% on leave-one-out cross-validation, but toyour surprise, it scores zero every time. Can you explain why?Exercise 15 Suppose that a learning algorithm is trying to find a consistenthypothesis when the classifications of examples are actually random.There are $n$ Boolean attributes, and examples are drawn uniformly fromthe set of $2^n$ possible examples. Calculate the number of examplesrequired before the probability of finding a contradiction in the datareaches 0.5.Exercise 16 Construct a decision list to classify the data below.Select tests to be as small as possible (in terms of attributes),breaking ties among tests with the same number of attributes byselecting the one that classifies the greatest number of examplescorrectly. If multiple tests have the same number of attributes andclassify the same number of examples, then break the tie usingattributes with lower index numbers (e.g., select $A_1$ over $A_2$).$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; A_4 &amp;amp; y  	hline textbf{x}_1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1  	textbf{x}_2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_3 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1  	 textbf{x}_4 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	 textbf{x}_5 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_6 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  	 textbf{x}_7 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  	 textbf{x}_8 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  	hline  end{array}$$Exercise 17 Prove that a decision list can represent the same function as a decisiontree while using at most as many rules as there are leaves in thedecision tree for that function. Give an example of a functionrepresented by a decision list using strictly fewer rules than thenumber of leaves in a minimal-sized decision tree for that samefunction.Exercise 18 (DL-expressivity-exercise) This exercise concerns the expressiveness ofdecision lists (Section learning-theory-section).1.  Show that decision lists can represent any Boolean function, if the    size of the tests is not limited.2.  Show that if the tests can contain at most $k$ literals each, then    decision lists can represent any function that can be represented by    a decision tree of depth $k$.Exercise 19 (knn-mean-mode) Suppose a $7$-nearest-neighbors regression searchreturns $ {7, 6, 8, 4, 7, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.Exercise 20 (knn-mean-mode) Suppose a $7$-nearest-neighbors regression searchreturns $ {4, 2, 8, 4, 9, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.Exercise 21 (svm-ellipse-exercise) Figure kernel-machine-figureshowed how a circle at the origin can be linearly separated by mappingfrom the features $(x_1, x_2)$ to the two dimensions $(x_1^2, x_2^2)$.But what if the circle is not located at the origin? What if it is anellipse, not a circle? The general equation for a circle (and hence thedecision boundary) is $(x_1-a)^2 +(x_2-b)^2 - r^20$, and the general equation for an ellipse is$c(x_1-a)^2 + d(x_2-b)^2 - 1 0$.1.  Expand out the equation for the circle and show what the weights    $w_i$ would be for the decision boundary in the four-dimensional    feature space $(x_1, x_2, x_1^2, x_2^2)$. Explain why this means    that any circle is linearly separable in this space.2.  Do the same for ellipses in the five-dimensional feature space    $(x_1, x_2, x_1^2, x_2^2, x_1 x_2)$.Exercise 22 (svm-exercise) Construct a support vector machine that computes thexor function. Use values of +1 and –1 (instead of 1 and 0)for both inputs and outputs, so that an example looks like $([-1, 1],1)$ or $([-1, -1], -1)$. Map the input $[x_1,x_2]$ into a spaceconsisting of $x_1$ and $x_1,x_2$. Draw the four input points in thisspace, and the maximal margin separator. What is the margin? Now drawthe separating line back in the original Euclidean input space.Exercise 23 (ensemble-error-exercise) Consider an ensemble learning algorithm thatuses simple majority voting among $K$ learned hypotheses.Suppose that each hypothesis has error $epsilon$ and that the errorsmade by each hypothesis are independent of the others’. Calculate aformula for the error of the ensemble algorithm in terms of $K$and $epsilon$, and evaluate it for the cases where$K=5$, 10, and 20 and $epsilon={0.1}$, 0.2,and 0.4. If the independence assumption is removed, is it possible forthe ensemble error to be worse than $epsilon$?Exercise 24 Construct by hand a neural network that computes the xorfunction of two inputs. Make sure to specify what sort of units you areusing.Exercise 25 A simple perceptron cannot represent xor (or, generally,the parity function of its inputs). Describe what happens to the weightsof a four-input, hard-threshold perceptron, beginning with all weightsset to 0.1, as examples of the parity function arrive.Exercise 26 (linear-separability-exercise) Recall fromChapter concept-learning-chapter that there are$2^{2^n}$ distinct Boolean functions of $n$ inputs. How many ofthese are representable by a threshold perceptron?Exercise 27 Consider the following set of examples, each with six inputs and onetarget output:$$begin{array} 	{|r|r|}hline textbf{Example} &amp;amp; A_1 &amp;amp; A_2 &amp;amp; A_3 &amp;amp; A_4 &amp;amp; A_5 &amp;amp; A_6 &amp;amp; A_7 &amp;amp; A_8 &amp;amp; A_9 &amp;amp; A_{10} &amp;amp; A_{11} &amp;amp; A_{12} &amp;amp; A_{13} &amp;amp; A_{14}  	hline 	textbf{x}_1  &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 0 	textbf{x}_2  &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 	textbf{x}_3  &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 	textbf{x}_4  &amp;amp; 0 &amp;amp; 1  &amp;amp; 0  &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 1 	textbf{x}_5  &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  &amp;amp; 0  &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 	textbf{x}_6  &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 0 	textbf{T}   &amp;amp; 1 &amp;amp; 1  &amp;amp; 1  &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0  &amp;amp; 1  &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0  &amp;amp; 0  &amp;amp; 0 	hline  end{array}$$1.  Run the perceptron learning rule on these data and show the    final weights.2.  Run the decision tree learning rule, and show the resulting    decision tree.3.  Comment on your results.Exercise 28 (perceptron-ML-gradient-exercise) Section logistic-regression-section(page logistic-regression-section) noted that the output of the logistic functioncould be interpreted as a probability $p$ assigned by themodel to the proposition that $f(textbf{x})1$; the probability that$f(textbf{x})0$ is therefore $1-p$. Write down the probability $p$as a function of $textbf{x}$ and calculate the derivative of $log p$ withrespect to each weight $w_i$. Repeat the process for $log (1-p)$. Thesecalculations give a learning rule for minimizing thenegative-log-likelihood loss function for a probabilistic hypothesis.Comment on any resemblance to other learning rules in the chapter.Exercise 29 (linear-nn-exercise) Suppose you had a neural network with linearactivation functions. That is, for each unit the output is some constant$c$ times the weighted sum of the inputs.1.  Assume that the network has one hidden layer. For a given assignment    to the weights $textbf{w}$, write down equations for the value of the    units in the output layer as a function of $textbf{w}$ and the input layer    $textbf{x}$, without any explicit mention of the output of the    hidden layer. Show that there is a network with no hidden units that    computes the same function.2.  Repeat the calculation in part (a), but this time do it for a    network with any number of hidden layers.3.  Suppose a network with one hidden layer and linear activation    functions has $n$ input and output nodes and $h$ hidden nodes. What    effect does the transformation in part (a) to a network with no    hidden layers have on the total number of weights? Discuss in    particular the case $h ll n$.Exercise 30 Implement a data structure for layered, feed-forward neural networks,remembering to provide the information needed for both forwardevaluation and backward propagation. Using this data structure, write afunction NEURAL-NETWORK-OUTPUT that takes an example and a network and computes theappropriate output values.Exercise 31 Suppose that a training set contains only a single example, repeated 100times. In 80 of the 100 cases, the single output value is 1; in theother 20, it is 0. What will a back-propagation network predict for thisexample, assuming that it has been trained and reaches a global optimum?(Hint: to find the global optimum, differentiate theerror function and set it to zero.)Exercise 32 The neural network whose learning performance is measured inFigure restaurant-back-prop-figure has four hiddennodes. This number was chosen somewhat arbitrarily. Use across-validation method to find the best number of hidden nodes.Exercise 33 (embedding-separability-exercise) Consider the problem of separating$N$ data points into positive and negative examples using a linearseparator. Clearly, this can always be done for $N2$ pointson a line of dimension $d1$, regardless of how the points arelabeled or where they are located (unless the points are in the sameplace).1.  Show that it can always be done for $N3$ points on a    plane of dimension $d2$, unless they are collinear.2.  Show that it cannot always be done for $N4$ points on a    plane of dimension $d2$.3.  Show that it can always be done for $N4$ points in a    space of dimension $d3$, unless they are coplanar.4.  Show that it cannot always be done for $N5$ points in a    space of dimension $d3$.5.  The ambitious student may wish to prove that $N$ points in general    position (but not $N+1$) are linearly separable in a space of    dimension $N-1$.Exercise 1 (dbsig-exercise) Show, by translating into conjunctive normal form andapplying resolution, that the conclusion drawn on page dbsig-pageconcerning Brazilians is sound.Exercise 2 For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):1.  Design and denomination determine the mass of a coin.2.  For a given program, input determines output.3.  Climate, food intake, exercise, and metabolism determine weight gain    and loss.4.  Baldness is determined by the baldness (or lack thereof) of one’s    maternal grandfather. Exercise 3 For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):1.  Zip code determines the state (U.S.).2.  Design and denomination determine the mass of a coin.3.  Climate, food intake, exercise, and metabolism determine weight gain    and loss.4.  Baldness is determined by the baldness (or lack thereof) of one’s    maternal grandfather.Exercise 4 Would a probabilistic version of determinations be useful? Suggest adefinition.Exercise 5 (ir-step-exercise) Fill in the missing values for the clauses $C_1$ or$C_2$ (or both) in the following sets of clauses, given that $C$ is theresolvent of $C_1$ and $C_2$:1.  $C = {True} Rightarrow P(A,B)$,    $C_1 = P(x,y) Rightarrow Q(x,y)$, $C_2    = ??$.2.  $C = {True} Rightarrow P(A,B)$, $C_1 = ??$,    $C_2 = ??$.3.  $C = P(x,y) Rightarrow P(x,f(y))$, $C_1 = ??$,    $C_2 = ??$.If there is more than one possible solution, provide one example of eachdifferent kind.Exercise 6 (prolog-ir-exercise) Suppose one writes a logic program that carriesout a resolution inference step. That is, let ${Resolve}(c_1,c_2,c)$succeed if $c$ is the result of resolving $c_1$ and $c_2$. Normally,${Resolve}$ would be used as part of a theorem prover by calling itwith $c_1$ and $c_2$ instantiated to particular clauses, therebygenerating the resolvent $c$. Now suppose instead that we call it with$c$ instantiated and $c_1$ and $c_2$ uninstantiated. Will this succeedin generating the appropriate results of an inverse resolution step?Would you need any special modifications to the logic programming systemfor this to work?Exercise 7 (foil-literals-exercise) Suppose that is considering adding a literalto a clause using a binary predicate $P$ and that previous literals(including the head of the clause) contain five different variables.1.  How many functionally different literals can be generated? Two    literals are functionally identical if they differ only in the names    of the *new* variables that they contain.2.  Can you find a general formula for the number of different literals    with a predicate of arity $r$ when there are $n$ variables    previously used?3.  Why does not allow literals that contain no previously used    variables?Exercise 8 Using the data from the family tree inFigure family2-figure, or a subset thereof, apply thealgorithm to learn a definition for the ${Ancestor}$ predicate.Exercise 1 (bayes-candy-exercise) The data used forFigure bayes-candy-figure on page bayes-candy-figure can beviewed as being generated by $h_5$. For each of the other fourhypotheses, generate a data set of length 100 and plot the correspondinggraphs for $P(h_i|d_1,ldots,d_N)$ and$P(D_{N+1}=lime|d_1,ldots,d_N)$. Comment onyour results.Exercise 2 Repeat Exercise bayes-candy-exercise, this timeplotting the values of$P(D_{N+1}=lime|h_{MAP})$ and$P(D_{N+1}=lime|h_{ML})$.Exercise 3 (candy-trade-exercise) Suppose that Ann’s utilities for cherry andlime candies are $c_A$ and $ell_A$, whereas Bob’s utilities are $c_B$and $ell_B$. (But once Ann has unwrapped a piece of candy, Bob won’tbuy it.) Presumably, if Bob likes lime candies much more than Ann, itwould be wise for Ann to sell her bag of candies once she issufficiently sure of its lime content. On the other hand, if Ann unwrapstoo many candies in the process, the bag will be worth less. Discuss theproblem of determining the optimal point at which to sell the bag.Determine the expected utility of the optimal procedure, given the priordistribution from Section statistical-learning-section.Exercise 4 Two statisticians go to the doctor and are both given the sameprognosis: A 40% chance that the problem is the deadly disease $A$, anda 60% chance of the fatal disease $B$. Fortunately, there are anti-$A$and anti-$B$ drugs that are inexpensive, 100% effective, and free ofside-effects. The statisticians have the choice of taking one drug,both, or neither. What will the first statistician (an avid Bayesian)do? How about the second statistician, who always uses the maximumlikelihood hypothesis?The doctor does some research and discovers that disease $B$ actuallycomes in two versions, dextro-$B$ and levo-$B$, which are equally likelyand equally treatable by the anti-$B$ drug. Now that there are threehypotheses, what will the two statisticians do?Exercise 5 (BNB-exercise) Explain how to apply the boosting method ofChapter concept-learning-chapter to naive Bayeslearning. Test the performance of the resulting algorithm on therestaurant learning problem.Exercise 6 (linear-regression-exercise) Consider $N$ data points $(x_j,y_j)$,where the $y_j$s are generated from the $x_j$s according to the linearGaussian model inEquation (linear-gaussian-likelihood-equation). Findthe values of $theta_1$, $theta_2$, and $sigma$ that maximize theconditional log likelihood of the data.Exercise 7 (noisy-OR-ML-exercise) Consider the noisy-OR model for fever describedin Section canonical-distribution-section. Explain howto apply maximum-likelihood learning to fit the parameters of such amodel to a set of complete data. (Hint: use the chainrule for partial derivatives.)Exercise 8 (beta-integration-exercise) This exercise investigates properties ofthe Beta distribution defined inEquation (beta-equation).1.  By integrating over the range $[0,1]$, show that the normalization    constant for the distribution $[a,b]$ is given by    $alpha = Gamma(a+b)/Gamma(a)Gamma(b)$ where $Gamma(x)$ is the Gamma function,    defined by $Gamma(x+1)xcdotGamma(x)$ and    $Gamma(1)1$. (For integer $x$,    $Gamma(x+1)x!$.)2.  Show that the mean is $a/(a+b)$.3.  Find the mode(s) (the most likely value(s) of $theta$).4.  Describe the distribution $[epsilon,epsilon]$ for very    small $epsilon$. What happens as such a distribution is updated?Exercise 9 (ML-parents-exercise) Consider an arbitrary Bayesian network, acomplete data set for that network, and the likelihood for the data setaccording to the network. Give a simple proof that the likelihood of thedata cannot decrease if we add a new link to the network and recomputethe maximum-likelihood parameter values.Exercise 10 Consider a single Boolean random variable $Y$ (the “classification”).Let the prior probability $P(Y=true)$ be $pi$. Let’s try tofind $pi$, given a training set $D=(y_1,ldots,y_N)$ with $N$independent samples of $Y$. Furthermore, suppose $p$ of the $N$ arepositive and $n$ of the $N$ are negative.1.  Write down an expression for the likelihood of $D$ (i.e., the    probability of seeing this particular sequence of examples, given a    fixed value of $pi$) in terms of $pi$, $p$, and $n$.2.  By differentiating the log likelihood $L$, find the value of $pi$    that maximizes the likelihood.3.  Now suppose we add in $k$ Boolean random variables    $X_1, X_2,ldots,X_k$ (the “attributes”) that describe each sample,    and suppose we assume that the attributes are conditionally    independent of each other given the goal $Y$. Draw the Bayes net    corresponding to this assumption.4.  Write down the likelihood for the data including the attributes,    using the following additional notation:    -   $alpha_i$ is $P(X_i=true | Y=true)$.    -   $beta_i$ is $P(X_i=true | Y=false)$.    -   $p_i^+$ is the count of samples for which $X_i=true$        and $Y=true$.    -   $n_i^+$ is the count of samples for which $X_i=false$        and $Y=true$.    -   $p_i^-$ is the count of samples for which $X_i=true$        and $Y=false$.    -   $n_i^-$ is the count of samples for which $X_i=false$        and $Y=false$.    [Hint: consider first the probability of seeing a    single example with specified values for $X_1, X_2,ldots,X_k$ and    $Y$.]5.  By differentiating the log likelihood $L$, find the values of    $alpha_i$ and $beta_i$ (in terms of the various counts) that    maximize the likelihood and say in words what these    values represent.6.  Let $k = 2$, and consider a data set with 4 all four possible    examples of thexor function. Compute the maximum    likelihood estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,    and $beta_2$.7.  Given these estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,    and $beta_2$, what are the posterior probabilities    $P(Y=true | x_1,x_2)$ for each example?Exercise 11 Consider the application of EM to learn the parameters for the networkin Figure mixture-networks-figure(a), given the trueparameters in Equation (candy-true-equation).1.  Explain why the EM algorithm would not work if there were just two    attributes in the model rather than three.2.  Show the calculations for the first iteration of EM starting from    Equation (candy-64-equation).3.  What happens if we start with all the parameters set to the same    value $p$? (Hint: you may find it helpful to    investigate this empirically before deriving the general result.)4.  Write out an expression for the log likelihood of the tabulated    candy data on page candy-counts-page in terms of the parameters,    calculate the partial derivatives with respect to each parameter,    and investigate the nature of the fixed point reached in part (c).Exercise 1 Implement a passive learning agent in a simple environment, such as the$4times 3$ world. For the case of an initially unknown environmentmodel, compare the learning performance of the direct utilityestimation, TD, and ADP algorithms. Do the comparison for the optimalpolicy and for several random policies. For which do the utilityestimates converge faster? What happens when the size of the environmentis increased? (Try environments with and without obstacles.)Exercise 2 Chapter complex-decisions-chapter defined aproper policy for an MDP as one that isguaranteed to reach a terminal state. Show that it is possible for apassive ADP agent to learn a transition model for which its policy $pi$is improper even if $pi$ is proper for the true MDP; with such models,the POLICY-EVALUATION step may fail if $gamma1$. Show that this problem cannotarise if POLICY-EVALUATION is applied to the learned model only at the end of a trial.Exercise 3 (prioritized-sweeping-exercise) Starting with the passive ADP agent,modify it to use an approximate ADP algorithm as discussed in the text.Do this in two steps:1.  Implement a priority queue for adjustments to the utility estimates.    Whenever a state is adjusted, all of its predecessors also become    candidates for adjustment and should be added to the queue. The    queue is initialized with the state from which the most recent    transition took place. Allow only a fixed number of adjustments.2.  Experiment with various heuristics for ordering the priority queue,    examining their effect on learning rates and computation time.Exercise 4 The direct utility estimation method inSection passive-rl-section uses distinguished terminalstates to indicate the end of a trial. How could it be modified forenvironments with discounted rewards and no terminal states?Exercise 5 Write out the parameter update equations for TD learning with$$hat{U}(x,y) = theta_0 + theta_1 x + theta_2 y + theta_3,sqrt{(x-x_g)^2 + (y-y_g)^2} .$$Exercise 6 Adapt the vacuum world (Chapter agents-chapter forreinforcement learning by including rewards for squares being clean.Make the world observable by providing suitable percepts. Now experimentwith different reinforcement learning agents. Is function approximationnecessary for success? What sort of approximator works for thisapplication?Exercise 7 (approx-LMS-exercise) Implement an exploring reinforcement learningagent that uses direct utility estimation. Make two versions—one with atabular representation and one using the function approximator inEquation (4x3-linear-approx-equation). Compare theirperformance in three environments:1.  The $4times 3$ world described in the chapter.2.  A ${10}times {10}$ world with no obstacles and a +1 reward    at (10,10).3.  A ${10}times {10}$ world with no obstacles and a +1 reward    at (5,5).Exercise 8 Devise suitable features for reinforcement learning in stochastic gridworlds (generalizations of the $4times 3$ world) that contain multipleobstacles and multiple terminal states with rewards of $+1$ or $-1$.Exercise 9 Extend the standard game-playing environment(Chapter game-playing-chapter) to incorporate a rewardsignal. Put two reinforcement learning agents into the environment (theymay, of course, share the agent program) and have them play against eachother. Apply the generalized TD update rule(Equation (generalized-td-equation)) to update theevaluation function. You might wish to start with a simple linearweighted evaluation function and a simple game, such as tic-tac-toe.Exercise 10 (10x10-exercise) Compute the true utility function and the best linearapproximation in $x$ and $y$ (as inEquation (4x3-linear-approx-equation)) for thefollowing environments:1.  A ${10}times {10}$ world with a single $+1$ terminal state    at (10,10).2.  As in (a), but add a $-1$ terminal state at (10,1).3.  As in (b), but add obstacles in 10 randomly selected squares.4.  As in (b), but place a wall stretching from (5,2) to (5,9).5.  As in (a), but with the terminal state at (5,5).The actions are deterministic moves in the four directions. In eachcase, compare the results using three-dimensional plots. For eachenvironment, propose additional features (besides $x$ and $y$) thatwould improve the approximation and show the results.Exercise 11 Implement the REINFORCE and PEGASUS algorithms and apply them to the $4times 3$ world,using a policy family of your own choosing. Comment on the results.Exercise 12 Investigate the application of reinforcement learning ideas to themodeling of human and animal behavior.Exercise 13 Is reinforcement learning an appropriate abstract model for evolution?What connection exists, if any, between hardwired reward signals andevolutionary fitness?Exercise 1 This exercise explores the quality of the $n$-gram model of language.Find or create a monolingual corpus of 100,000 words or more. Segment itinto words, and compute the frequency of each word. How many distinctwords are there? Also count frequencies of bigrams (two consecutivewords) and trigrams (three consecutive words). Now use those frequenciesto generate language: from the unigram, bigram, and trigram models, inturn, generate a 100-word text by making random choices according to thefrequency counts. Compare the three generated texts with actuallanguage. Finally, calculate the perplexity of each model.Exercise 2 Write a program to do segmentation ofwords without spaces. Given a string, such as the URL“thelongestlistofthelongeststuffatthelongestdomainnameatlonglast.com,”return a list of component words: [“the,” “longest,” “list,”$ldots$]. This task is useful for parsing URLs, for spellingcorrection when words runtogether, and for languages such as Chinesethat do not have spaces between words. It can be solved with a unigramor bigram word model and a dynamic programming algorithm similar to theViterbi algorithm.Exercise 3 Zipf’s law of word distribution states the following:Take a large corpus of text, count the frequency of every word in thecorpus, and then rank these frequencies in decreasing order. Let $f_{I}$be the $I$th largest frequency in this list; that is, $f_{1}$ is thefrequency of the most common word (usually “the”), $f_{2}$ is thefrequency of the second most common word, and so on. Zipf’s law statesthat $f_{I}$ is approximately equal to $alpha / I$ for some constant$alpha$. The law tends to be highly accurate except for very small andvery large values of $I$.Exercise 4 Choose a corpus of at least 20,000 words of online text, and verifyZipf’s law experimentally. Define an error measure and find the value of$alpha$ where Zipf’s law best matches your experimental data. Create alog–log graph plotting $f_{I}$ vs. $I$ and $alpha/I$ vs. $I$. (On alog–log graph, the function $alpha/I$ is a straight line.) In carryingout the experiment, be sure to eliminate any formatting tokens (e.g.,HTML tags) and normalize upper and lower case.Exercise 5 (Adapted from Jurafsky+Martin:2000.) In this exercise you will develop a classifier forauthorship: given a text, the classifier predicts which of two candidateauthors wrote the text. Obtain samples of text from two differentauthors. Separate them into training and test sets. Now train a languagemodel on the training set. You can choose what features to use;$n$-grams of words or letters are the easiest, but you can addadditional features that you think may help. Then compute theprobability of the text under each language model and chose the mostprobable model. Assess the accuracy of this technique. How does accuracychange as you alter the set of features? This subfield of linguistics iscalled stylometry; its successes include the identification of the author of thedisputed Federalist Papers Mosteller+Wallace:1964 andsome disputed works of Shakespeare Hope:1994. Khmelev+Tweedie:2001 produce good results witha simple letter bigram model.Exercise 6 This exercise concerns the classification of spam email.Create a corpus of spam email and one of non-spam mail. Examine eachcorpus and decide what features appear to be useful for classification:unigram words? bigrams? message length, sender, time of arrival? Thentrain a classification algorithm (decision tree, naive Bayes, SVM,logistic regression, or some other algorithm of your choosing) on atraining set and report its accuracy on a test set.Exercise 7 Create a test set of ten queries, and pose them to three major Websearch engines. Evaluate each one for precision at 1, 3, and 10documents. Can you explain the differences between engines?Exercise 8 Try to ascertain which of the search engines from the previous exerciseare using case folding, stemming, synonyms, and spelling correction.Exercise 9 Estimate how much storage space is necessary for the index to a 100billion-page corpus of Web pages. Show the assumptions you made.Exercise 10 Write a regular expression or a short program to extract company names.Test it on a corpus of business news articles. Report your recall andprecision.Exercise 11 Consider the problem of trying to evaluate the quality of an IR systemthat returns a ranked list of answers (like most Web search engines).The appropriate measure of quality depends on the presumed model of whatthe searcher is trying to achieve, and what strategy she employs. Foreach of the following models, propose a corresponding numeric measure.1.  The searcher will look at the first twenty answers returned, with    the objective of getting as much relevant information as possible.2.  The searcher needs only one relevant document, and will go down the    list until she finds the first one.3.  The searcher has a fairly narrow query and is able to examine all    the answers retrieved. She wants to be sure that she has seen    everything in the document collection that is relevant to her query.    (E.g., a lawyer wants to be sure that she has found    all relevant precedents, and is willing to spend    considerable resources on that.)4.  The searcher needs just one document relevant to the query, and can    afford to pay a research assistant for an hour’s work looking    through the results. The assistant can look through 100 retrieved    documents in an hour. The assistant will charge the searcher for the    full hour regardless of whether he finds it immediately or at the    end of the hour.5.  The searcher will look through all the answers. Examining a document    has cost $ A; finding a relevant document has value $ B; failing    to find a relevant document has cost $ C for each relevant    document not found.6.  The searcher wants to collect as many relevant documents as    possible, but needs steady encouragement. She looks through the    documents in order. If the documents she has looked at so far are    mostly good, she will continue; otherwise, she will stop.Exercise 1 (washing-clothes-exercise) Read the following text once forunderstanding, and remember as much of it as you can. There will be atest later.&amp;gt; The procedure is actually quite simple. First you arrange things intodifferent groups. Of course, one pile may be sufficient depending on howmuch there is to do. If you have to go somewhere else due to lack offacilities that is the next step, otherwise you are pretty well set. Itis important not to overdo things. That is, it is better to do too fewthings at once than too many. In the short run this may not seemimportant but complications can easily arise. A mistake is expensive aswell. At first the whole procedure will seem complicated. Soon, however,it will become just another facet of life. It is difficult to foreseeany end to the necessity for this task in the immediate future, but thenone can never tell. After the procedure is completed one arranges thematerial into different groups again. Then they can be put into theirappropriate places. Eventually they will be used once more and the wholecycle will have to be repeated. However, this is part of life.Exercise 2 An HMM grammar is essentially a standard HMM whose statevariable is $N$ (nonterminal, with values such as $Det$, $Adjective$,$Noun$ and so on) and whose evidence variable is $W$ (word, with valuessuch as $is$, $duck$, and so on). The HMM model includes a prior${textbf{P}}(N_0)$, a transition model${textbf{P}}(N_{t+1}|N_t)$, and a sensor model${textbf{P}}(W_t|N_t)$. Show that every HMM grammar can bewritten as a PCFG. [Hint: start by thinking about how the HMM prior canbe represented by PCFG rules for the sentence symbol. You may find ithelpful to illustrate for the particular HMM with values $A$, $B$ for$N$ and values $x$, $y$ for $W$.]Exercise 3 Consider the following PCFG for simple verb phrases:&amp;gt; 0.1: VP $rightarrow$ Verb&amp;gt; 0.2: VP $rightarrow$ Copula Adjective&amp;gt; 0.5: VP $rightarrow$ Verb the Noun&amp;gt; 0.2: VP $rightarrow$ VP Adverb&amp;gt; 0.5: Verb $rightarrow$ is&amp;gt; 0.5: Verb $rightarrow$ shoots&amp;gt; 0.8: Copula $rightarrow$ is&amp;gt; 0.2: Copula $rightarrow$ seems&amp;gt; 0.5: Adjective $rightarrow$ unwell&amp;gt; 0.5: Adjective $rightarrow$ well&amp;gt; 0.5: Adverb $rightarrow$ well&amp;gt; 0.5: Adverb $rightarrow$ badly&amp;gt; 0.6: Noun $rightarrow$ duck&amp;gt; 0.4: Noun $rightarrow$ well1.  Which of the following have a nonzero probability as a VP? (i)    shoots the duck well well well(ii) seems the well well(iii) shoots    the unwell well badly2.  What is the probability of generating “is well well”?3.  What types of ambiguity are exhibited by the phrase in (b)?4.  Given any PCFG, is it possible to calculate the probability that the    PCFG generates a string of exactly 10 words?Exercise 4 Consider the following simple PCFG for noun phrases:&amp;gt; 0.6: NP $rightarrow$ Det AdjString Noun&amp;gt; 0.4: NP $rightarrow$ Det NounNounCompound&amp;gt; 0.5: AdjString $rightarrow$ Adj AdjString&amp;gt; 0.5: AdjString $rightarrow$ $Lambda$&amp;gt; 1.0: NounNounCompound $rightarrow$ Noun&amp;gt; 0.8: Det $rightarrow$ the&amp;gt; 0.2: Det $rightarrow$ a&amp;gt; 0.5: Adj $rightarrow$ small&amp;gt; 0.5: Adj $rightarrow$ green&amp;gt; 0.6: Noun $rightarrow$ village&amp;gt; 0.4: Noun $rightarrow$ greenwhere $Lambda$ denotes the empty string.1.  What is the longest NP that can be generated by this grammar? (i)    three words(ii) four words(iii) infinitely many words2.  Which of the following have a nonzero probability of being generated    as complete NPs? (i) a small green village(ii) a green    green green(iii) a small village green3.  What is the probability of generating “the green green”?4.  What types of ambiguity are exhibited by the phrase in (c)?5.  Given any PCFG and any finite word sequence, is it possible to    calculate the probability that the sequence was generated by the    PCFG?Exercise 5 Outline the major differences between Java (or any other computerlanguage with which you are familiar) and English, commenting on the“understanding” problem in each case. Think about such things asgrammar, syntax, semantics, pragmatics, compositionality,context-dependence, lexical ambiguity, syntactic ambiguity, referencefinding (including pronouns), background knowledge, and what it means to“understand” in the first place.Exercise 6 This exercise concerns grammars for very simple languages.1.  Write a context-free grammar for the language $a^n b^n$.2.  Write a context-free grammar for the palindrome language: the set of    all strings whose second half is the reverse of the first half.3.  Write a context-sensitive grammar for the duplicate language: the    set of all strings whose second half is the same as the first half.Exercise 7 Consider the sentence “Someone walked slowly to the supermarket” and alexicon consisting of the following words:$Pronoun rightarrow textbf{someone} quad Verb rightarrow textbf{walked}$$Adv rightarrow textbf{slowly} quad Prep rightarrow textbf{to}$$Article rightarrow textbf{the} quad Noun rightarrow textbf{supermarket}$Which of the following three grammars, combined with the lexicon,generates the given sentence? Show the corresponding parse tree(s).$$quadquadquadquad (A):quadquadquadquad  quadquadquadquad(B):quadquadquadquad  quadquadquadquad(C):quadquadquadquad S rightarrow NP space VP quadquadquadquad quadquadquadquad Srightarrow NPspace VP quadquadquadquad Srightarrow NPspace VPquadquadquadquad NPrightarrow Pronoun quadquadquadquad  NPrightarrow Pronoun quadquadquadquad  NPrightarrow Pronounquadquadquadquad NPrightarrow Articlespace Noun quadquadquadquad  NPrightarrow Noun quadquadquadquad  NPrightarrow Articlespace NPquadquadquadquad VPrightarrow VPspace PP quadquadquadquad NPrightarrow Articlespace NP quadquadquadquad  VPrightarrow Verbspace Advquadquadquadquad  VPrightarrow VPspace Advspace Adv quadquadquadquad  VPrightarrow Verbspace Vmod quadquadquadquad  Advrightarrow Advspace Advquadquadquadquad  VPrightarrow Verb quadquadquadquad  Vmodrightarrow Advspace Vmod quadquadquadquad   Advrightarrow PPquadquadquadquad PPrightarrow Prepspace NP quadquadquadquad Vmodrightarrow Adv quadquadquadquad PPrightarrow Prepspace NPquadquadquadquad NPrightarrow Noun quadquadquadquad Advrightarrow PP quadquadquadquad NPrightarrow Nounquadquadquadquadquad quadquadquadquad PPrightarrow Prepspace NP quadquadquadquad quadquadquadquad$$For each of the preceding three grammars, write down three sentences ofEnglish and three sentences of non-English generated by the grammar.Each sentence should be significantly different, should be at least sixwords long, and should include some new lexical entries (which youshould define). Suggest ways to improve each grammar to avoid generatingthe non-English sentences.Exercise 8 Collect some examples of time expressions, such as “two o’clock,”“midnight,” and “12:46.” Also think up some examples that areungrammatical, such as “thirteen o’clock” or “half past two fifteen.”Write a grammar for the time language.Exercise 9 Some linguists have argued as follows: Children learning a language hear only positive examples of the language and no negative examples. Therefore, the hypothesis that “every possible sentence is in the language” is consistent with all the observed examples. Moreover, this is the simplest consistent hypothesis. Furthermore, all grammars for languages that are supersets of the true language are also consistent with the observed data. Yet children do induce (more or less) the right grammar. It follows that they begin with very strong innate grammatical constraints that rule out all of these more general hypotheses a priori.Comment on the weak point(s) in this argument from a statisticallearning viewpoint.Exercise 10 (chomsky-form-exercise) In this exercise you will transform $large varepsilon_0$  intoChomsky Normal Form (CNF). There are five steps: (a) Add a new startsymbol, (b) Eliminate $epsilon$ rules, (c) Eliminate multiple words onright-hand sides, (d) Eliminate rules of the form(${it X} rightarrow$${it Y}$),(e) Convert long right-hand sides into binary rules.1.  The start symbol, $S$, can occur only on the left-hand side in CNF.    Replace ${it S}$ everywhere by a new symbol    ${it S&#39;}$ and add a rule of the form    ${it S}$    $rightarrow$${it S&#39;}$.2.  The empty string, $epsilon$ cannot appear on the right-hand side    in CNF. $large varepsilon_0$ does not have any rules with $epsilon$, so this is not    an issue.3.  A word can appear on the right-hand side in a rule only of the form    (${it X}$    $rightarrow$word).    Replace each rule of the form (${it X}$    $rightarrow$…word …)    with (${it X}$    $rightarrow$…${it W&#39;}$ …)    and (${it W&#39;}$    $rightarrow$word),    using a new symbol ${it W&#39;}$.4.  A rule (${it X}$    $rightarrow$${it Y}$)    is not allowed in CNF; it must be (${it X}$    $rightarrow$${it Y}$    ${it Z}$) or (${it X}$    $rightarrow$word).    Replace each rule of the form (${it X}$    $rightarrow$${it Y}$)    with a set of rules of the form (${it X}$    $rightarrow$…), one    for each rule (${it Y}$    $rightarrow$…),    where (…) indicates one or more symbols.5.  Replace each rule of the form (${it X}$    $rightarrow$${it Y}$    ${it Z}$ …) with two rules, (${it X}$    $rightarrow$${it Y}$    ${it Z&#39;}$) and (${it Z&#39;}$    $rightarrow$${it Z}$    …), where ${it Z&#39;}$ is a new symbol.Show each step of the process and the final set of rules.Exercise 11 Consider the following toy grammar:&amp;gt; $S rightarrow NPspace VP$&amp;gt; $NP rightarrow Noun$&amp;gt; $NP rightarrow NPspace andspace NP$&amp;gt; $NP rightarrow NPspace PP$&amp;gt; $VP rightarrow Verb$&amp;gt; $VP rightarrow VPspace and space VP$&amp;gt; $VP rightarrow VPspace PP$&amp;gt; $PP rightarrow Prepspace NP$&amp;gt; $Noun rightarrow Sallyspace; poolsspace; streamsspace; swims$&amp;gt; $Prep rightarrow in$&amp;gt; $Verb rightarrow poolsspace; streamsspace; swims$1.  Show all the parse trees in this grammar for the sentence “Sally    swims in streams and pools.”2.  Show all the table entries that would be made by    a (non-probabalistic) CYK parser on this sentence.Exercise 12(exercise-subj-verb-agree) Using DCG notation, write a grammar for alanguage that is just like $large varepsilon_1$, except that it enforces agreement betweenthe subject and verb of a sentence and thus does not generateungrammatical sentences such as “I smells the wumpus.”Exercise 13 Consider the following PCFG:&amp;gt; $S rightarrow NP space VP[1.0] $&amp;gt; $NP rightarrow textit{Noun}[0.6] space|space textit{Pronoun}[0.4] $&amp;gt; $VP rightarrow textit{Verb} space NP[0.8] space|space textit{Modal}space textit{Verb}[0.2]$&amp;gt; $textit{Noun} rightarrow textbf{can}[0.1] space|space textbf{fish}[0.3] space|space ...$&amp;gt; $textit{Pronoun} rightarrow textbf{I}[0.4] space|space ...$&amp;gt; $textit{Verb} rightarrow textbf{can}[0.01] space|space textbf{fish}[0.1] space|space ...$&amp;gt; $textit{Modal} rightarrow textbf{can}[0.3] space|space ...$The sentence “I can fish” has two parse trees with this grammar. Showthe two trees, their prior probabilities, and their conditionalprobabilities, given the sentence.Exercise 14 An augmented context-free grammar can represent languages that a regularcontext-free grammar cannot. Show an augmented context-free grammar forthe language $a^nb^nc^n$. The allowable values for augmentationvariables are 1 and $SUCCESSOR(n)$, where $n$ is a value. The rule for a sentencein this language is$$S(n) rightarrow A(n) B(n) C(n)  .$$Show the rule(s) for each of ${it A}$,${it B}$, and ${it C}$.Exercise 15 Augment the $large varepsilon_1$ grammar so that it handles article–noun agreement. That is,make sure that “agents” and “an agent” are ${it NP}$s, but“agent” and “an agents” are not.Exercise 16 Consider the following sentence (from The New York Times,July 28, 2008):&amp;gt; Banks struggling to recover from multibillion-dollar loans on real&amp;gt; estate are curtailing loans to American businesses, depriving even&amp;gt; healthy companies of money for expansion and hiring.1.  Which of the words in this sentence are lexically ambiguous?2.  Find two cases of syntactic ambiguity in this sentence (there are    more than two.)3.  Give an instance of metaphor in this sentence.4.  Can you find semantic ambiguity?Exercise 17 (washing-clothes2-exercise) Without looking back atExercise washing-clothes-exercise, answer the followingquestions:1.  What are the four steps that are mentioned?2.  What step is left out?3.  What is “the material” that is mentioned in the text?4.  What kind of mistake would be expensive?5.  Is it better to do too few things or too many? Why?Exercise 18 Select five sentences and submit them to an online translation service.Translate them from English to another language and back to English.Rate the resulting sentences for grammaticality and preservation ofmeaning. Repeat the process; does the second round of iteration giveworse results or the same results? Does the choice of intermediatelanguage make a difference to the quality of the results? If you know aforeign language, look at the translation of one paragraph into thatlanguage. Count and describe the errors made, and conjecture why theseerrors were made.Exercise 19 The $D_i$ values for the sentence inFigure mt-alignment-figure sum to 0. Will that be trueof every translation pair? Prove it or give a counterexample.Exercise 20 (Adapted from [Knight:1999].) Our translation model assumes that, after the phrasetranslation model selects phrases and the distortion model permutesthem, the language model can unscramble the permutation. This exerciseinvestigates how sensible that assumption is. Try to unscramble theseproposed lists of phrases into the correct order:1.  have, programming, a, seen, never, I, language, better2.  loves, john, mary3.  is the, communication, exchange of, intentional, information    brought, by, about, the production, perception of, and signs, from,    drawn, a, of, system, signs, conventional, shared4.  created, that, we hold these, to be, all men, truths, are, equal,    self-evidentWhich ones could you do? What type of knowledge did you draw upon? Traina bigram model from a training corpus, and use it to find thehighest-probability permutation of some sentences from a test corpus.Report on the accuracy of this model.Exercise 21 Calculate the most probable path through the HMM inFigure sr-hmm-figure for the output sequence$[C_1,C_2,C_3,C_4,C_4,C_6,C_7]$. Also give its probability.Exercise 22 We forgot to mention that the text inExercise washing-clothes-exercise is entitled “WashingClothes.” Reread the text and answer the questions inExercise washing-clothes2-exercise. Did you do betterthis time? Bransford and Johnson [Bransford+Johnson:1973] used thistext in a controlled experiment and found that the title helpedsignificantly. What does this tell you about how language and memoryworks?Exercise 1 In the shadow of a tree with a dense, leafy canopy, one sees a number oflight spots. Surprisingly, they all appear to be circular. Why? Afterall, the gaps between the leaves through which the sun shines are notlikely to be circular.Exercise 2 Consider a picture of a white sphere floating in front of a blackbackdrop. The image curve separating white pixels from black pixels issometimes called the “outline” of the sphere. Show that the outline of asphere, viewed in a perspective camera, can be an ellipse. Why dospheres not look like ellipses to you?Exercise 3 Consider an infinitely long cylinder of radius $r$ oriented with itsaxis along the $y$-axis. The cylinder has a Lambertian surface and isviewed by a camera along the positive $z$-axis. What will you expect tosee in the image if the cylinder is illuminated by a point source atinfinity located on the positive $x$-axis? Draw the contours of constantbrightness in the projected image. Are the contours of equal brightnessuniformly spaced?Exercise 4 Edges in an image can correspond to a variety of events in a scene.Consider Figure illuminationfigure(page illuminationfigure, and assume that it is a picture of a realthree-dimensional scene. Identify ten different brightness edges in theimage, and for each, state whether it corresponds to a discontinuity in(a) depth, (b) surface orientation, (c) reflectance, or (d)illumination.Exercise 5 A stereoscopic system is being contemplated for terrain mapping. It willconsist of two CCD cameras, each having ${512}times {512}$ pixels on a10 cm $times$ 10 cm square sensor. The lenses to be used have a focallength of 16 cm, with the focus fixed at infinity. For correspondingpoints ($u_1,v_1$) in the left image and ($u_2,v_2$) in the right image,$v_1=v_2$ because the $x$-axes in the two image planes are parallel tothe epipolar lines—the lines from the object to the camera. The opticalaxes of the two cameras are parallel. The baseline between the camerasis 1 meter.1.  If the nearest distance to be measured is 16 meters, what is the    largest disparity that will occur (in pixels)?2.  What is the distance resolution at 16 meters, due to the pixel    spacing?3.  What distance corresponds to a disparity of one pixel?Exercise 6 Which of the following are true, and which are false?1.  Finding corresponding points in stereo images is the easiest phase    of the stereo depth-finding process.2.  Shape-from-texture can be done by projecting a grid of light-stripes    onto the scene.3.  Lines with equal lengths in the scene always project to equal    lengths in the image.4.  Straight lines in the image necessarily correspond to straight lines    in the scene.Exercise 7 Which of the following are true, and which are false?1.  Finding corresponding points in stereo images is the easiest phase    of the stereo depth-finding process.2.  In stereo views of the same scene, greater accuracy is obtained in    the depth calculations if the two camera positions are    farther apart.3.  Lines with equal lengths in the scene always project to equal    lengths in the image.4.  Straight lines in the image necessarily correspond to straight lines    in the scene.                Top view of      a two-camera vision system observing a bottle with a wall behind it.    Exercise 8 (Courtesy of Pietro Perona.) Figure bottle-figure showstwo cameras at X and Y observing a scene. Draw the image seen at eachcamera, assuming that all named points are in the same horizontal plane.What can be concluded from these two images about the relative distancesof points A, B, C, D, and E from the camera baseline, and on what basis?Exercise 1 (mcl-biasdness-exercise) Monte Carlo localization isbiased for any finite sample size—i.e., the expectedvalue of the location computed by the algorithm differs from the trueexpected value—because of the way particle filtering works. In thisquestion, you are asked to quantify this bias.To simplify, consider a world with four possible robot locations:$X={x_1,x_2,x_3,x_4}$. Initially, wedraw $Ngeq $ samples uniformly from among those locations. Asusual, it is perfectly acceptable if more than one sample is generatedfor any of the locations $X$. Let $Z$ be a Boolean sensor variablecharacterized by the following conditional probabilities:$$begin{aligned}P(z | x_1) = 0.8 qquadqquad P(z | x_1) = 0.2  P(z | x_2) = 0.4 qquadqquad P(z | x_2) = 0.6  P(z | x_3) = 0.1 qquadqquad P(z | x_3) = 0.9  P(z | x_4) = 0.1 qquadqquad P(z | x_4) = 0.9 end{aligned}$$MCL uses these probabilities to generate particle weights, which aresubsequently normalized and used in the resampling process. Forsimplicity, let us assume we generate only one new sample in theresampling process, regardless of $N$. This sample might correspond toany of the four locations in $X$. Thus, the sampling process defines aprobability distribution over $X$.1.  What is the resulting probability distribution over $X$ for this new    sample? Answer this question separately for    $N=1,ldots,10$, and for $N=infty$.2.  The difference between two probability distributions $P$ and $Q$ can    be measured by the KL divergence, which is defined as    $${KL}(P,Q) = sum_i P(x_i)logfrac{P(x_i)}{Q(x_i)} .$$ What are    the KL divergences between the distributions in (a) and the true    posterior?3.  What modification of the problem formulation (not the algorithm!)    would guarantee that the specific estimator above is unbiased even    for finite values of $N$? Provide at least two such modifications    (each of which should be sufficient).Exercise 2 (mcl-implement-exercise)Implement Monte Carlo localization for asimulated robot with range sensors. A grid map and range data areavailable from the code repository ataima.cs.berkeley.edu. You should demonstratesuccessful global localization of the robot.    A Robot manipulator in two of its possible configurations.Exercise 3 (AB-manipulator-ex)Consider a robot with two simple manipulators, asshown in figure figRobot2. Manipulator A is a square block of side 2which can slide back and on a rod that runs along the x-axis fromx=$-$10 to x=10. Manipulator B is a square block of side 2 which canslide back and on a rod that runs along the y-axis from y=-10 to y=10.The rods lie outside the plane of manipulation, so the rods do notinterfere with the movement of the blocks. A configuration is then apair ${langle}x,y{rangle}$ where $x$ is the x-coordinate of the centerof manipulator A and where $y$ is the y-coordinate of the center ofmanipulator B. Draw the configuration space for this robot, indicatingthe permitted and excluded zones.Exercise 4 Suppose that you are working with the robot inExercise AB-manipulator-ex and you are given theproblem of finding a path from the starting configuration offigure figRobot2 to the ending configuration. Consider a potentialfunction $$D(A, {Goal})^2 + D(B, {Goal})^2 + frac{1}{D(A, B)^2}$$where $D(A,B)$ is the distance between the closest points of A and B.1.  Show that hill climbing in this potential field will get stuck in a    local minimum.2.  Describe a potential field where hill climbing will solve this    particular problem. You need not work out the exact numerical    coefficients needed, just the general form of the solution. (Hint:    Add a term that “rewards&quot; the hill climber for moving A out of B’s    way, even in a case like this where this does not reduce the    distance from A to B in the above sense.)Exercise 5 (inverse-kinematics-exercise) Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is60cm long and that its upper arm and forearm are each 40cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?Exercise 6 (inverse-kinematics-exercise) Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is70cm long and that its upper arm and forearm are each 50cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?Exercise 7 (voronoi-exercise) Implement an algorithm for calculating the Voronoidiagram of an arbitrary 2D environment, described by an $ntimes n$Boolean array. Illustrate your algorithm by plotting the Voronoi diagramfor 10 interesting maps. What is the complexity of your algorithm?Exercise 8 (confspace-exercise) This exercise explores the relationship betweenworkspace and configuration space using the examples shown inFigure FigEx2.1.  Consider the robot configurations shown in    Figure FigEx2(a) through (c), ignoring the obstacle    shown in each of the diagrams. Draw the corresponding arm    configurations in configuration space. (Hint: Each    arm configuration maps to a single point in configuration space, as    illustrated in Figure FigArm1(b).)2.  Draw the configuration space for each of the workspace diagrams in    Figure FigEx2(a)–(c). (Hint: The    configuration spaces share with the one shown in    Figure FigEx2(a) the region that corresponds to    self-collision, but differences arise from the lack of enclosing    obstacles and the different locations of the obstacles in these    individual figures.)3.  For each of the black dots in Figure FigEx2(e)–(f),    draw the corresponding configurations of the robot arm in workspace.    Please ignore the shaded regions in this exercise.4.  The configuration spaces shown in    Figure FigEx2(e)–(f) have all been generated by a    single workspace obstacle (dark shading), plus the constraints    arising from the self-collision constraint (light shading). Draw,    for each diagram, the workspace obstacle that corresponds to the    darkly shaded area.5.  Figure FigEx2(d) illustrates that a single planar    obstacle can decompose the workspace into two disconnected regions.    What is the maximum number of disconnected regions that can be    created by inserting a planar obstacle into an obstacle-free,    connected workspace, for a 2DOF robot? Give an example, and argue    why no larger number of disconnected regions can be created. How    about a non-planar obstacle?                (a)                    (b)                    (c)                    (d)                    (e)                    (f)    Exercise 9 Consider a mobile robot moving on a horizontal surface. Suppose that therobot can execute two kinds of motions:-   Rolling forward a specified distance.-   Rotating in place through a specified angle.The state of such a robot can be characterized in terms of threeparameters ${langle}x,y,phi$, the x-coordinate and y-coordinate of therobot (more precisely, of its center of rotation) and the robot’sorientation expressed as the angle from the positive x direction. Theaction “$Roll(D)$” has the effect of changing state ${langle}x,y,phi$to ${langle}x+D cos(phi), y+D sin(phi), phi {rangle}$, and theaction $Rotate(theta)$ has the effect of changing state${langle}x,y,phi {rangle}$ to${langle}x,y, phi + theta {rangle}$.1.  Suppose that the robot is initially at ${langle}0,0,0 {rangle}$    and then executes the actions $Rotate(60^{circ})$, $Roll(1)$,    $Rotate(25^{circ})$, $Roll(2)$. What is the final state of the    robot?2.  Now suppose that the robot has imperfect control of its own    rotation, and that, if it attempts to rotate by $theta$, it may    actually rotate by any angle between $theta-10^{circ}$ and    $theta+10^{circ}$. In that case, if the robot attempts to carry    out the sequence of actions in (A), there is a range of possible    ending states. What are the minimal and maximal values of the    x-coordinate, the y-coordinate and the orientation in the final    state?3.  Let us modify the model in (B) to a probabilistic model in which,    when the robot attempts to rotate by $theta$, its actual angle of    rotation follows a Gaussian distribution with mean $theta$ and    standard deviation $10^{circ}$. Suppose that the robot executes the    actions $Rotate(90^{circ})$, $Roll(1)$. Give a simple argument    that (a) the expected value of the location at the end is not equal    to the result of rotating exactly $90^{circ}$ and then rolling    forward 1 unit, and (b) that the distribution of locations at the    end does not follow a Gaussian. (Do not attempt to calculate the    true mean or the true distribution.)    The point of this exercise is that rotational uncertainty quickly    gives rise to a lot of positional uncertainty and that dealing with    rotational uncertainty is painful, whether uncertainty is treated in    terms of hard intervals or probabilistically, due to the fact that    the relation between orientation and position is both non-linear    and non-monotonic.      Simplified robot in a maze. See Exercise robot-exploration-exerciseExercise 10 (robot-exploration-exercise) Consider the simplified robot shown inFigure FigEx3. Suppose the robot’s Cartesiancoordinates are known at all times, as are those of its goal location.However, the locations of the obstacles are unknown. The robot can senseobstacles in its immediate proximity, as illustrated in this figure. Forsimplicity, let us assume the robot’s motion is noise-free, and thestate space is discrete. Figure FigEx3 is only oneexample; in this exercise you are required to address all possible gridworlds with a valid path from the start to the goal location.1.  Design a deliberate controller that guarantees that the robot always    reaches its goal location if at all possible. The deliberate    controller can memorize measurements in the form of a map that is    being acquired as the robot moves. Between individual moves, it may    spend arbitrary time deliberating.2.  Now design a reactive controller for the same task.    This controller may not memorize past sensor measurements. (It may    not build a map!) Instead, it has to make all decisions based on the    current measurement, which includes knowledge of its own location    and that of the goal. The time to make a decision must be    independent of the environment size or the number of past    time steps. What is the maximum number of steps that it may take for    your robot to arrive at the goal?3.  How will your controllers from (a) and (b) perform if any of the    following six conditions apply: continuous state space, noise in    perception, noise in motion, noise in both perception and motion,    unknown location of the goal (the goal can be detected only when    within sensor range), or moving obstacles. For each condition and    each controller, give an example of a situation where the robot    fails (or explain why it cannot fail).Exercise 11 (subsumption-exercise) In Figure Fig5(b) onpage Fig5, we encountered an augmented finite state machine forthe control of a single leg of a hexapod robot. In this exercise, theaim is to design an AFSM that, when combined with six copies of theindividual leg controllers, results in efficient, stable locomotion. Forthis purpose, you have to augment the individual leg controller to passmessages to your new AFSM and to wait until other messages arrive. Arguewhy your controller is efficient, in that it does not unnecessarilywaste energy (e.g., by sliding legs), and in that it propels the robotat reasonably high speeds. Prove that your controller satisfies thedynamic stability condition given on page polygon-stability-condition-page.Exercise 12 (human-robot-exercise)(This exercise was first devised by MichaelGenesereth and Nils Nilsson. It works for first graders through graduatestudents.) Humans are so adept at basic household tasks that they oftenforget how complex these tasks are. In this exercise you will discoverthe complexity and recapitulate the last 30 years of developments inrobotics. Consider the task of building an arch out of three blocks.Simulate a robot with four humans as follows:Brain. The Brain direct the hands in the execution of aplan to achieve the goal. The Brain receives input from the Eyes, butcannot see the scene directly. The brain is the only onewho knows what the goal is.Eyes. The Eyes report a brief description of the sceneto the Brain: “There is a red box standing on top of a green box, whichis on its side” Eyes can also answer questions from the Brain such as,“Is there a gap between the Left Hand and the red box?” If you have avideo camera, point it at the scene and allow the eyes to look at theviewfinder of the video camera, but not directly at the scene.Left hand and right hand. One personplays each Hand. The two Hands stand next to each other, each wearing anoven mitt on one hand, Hands execute only simple commands from theBrain—for example, “Left Hand, move two inches forward.” They cannotexecute commands other than motions; for example, they cannot becommanded to “Pick up the box.” The Hands must beblindfolded. The only sensory capability they have is theability to tell when their path is blocked by an immovable obstacle suchas a table or the other Hand. In such cases, they can beep to inform theBrain of the difficulty.            Exercise 1                                Go through Turing’s list of alleged“disabilities” of machines, identifying which have been achieved, whichare achievable in principle by a program, and which are stillproblematic because they require conscious mental states.                Exercise 2                                Find and analyze an account in the popular media of one or more of thearguments to the effect that AI is impossible.                Exercise 3                                Attempt to write definitions of the terms “intelligence,” “thinking,”and “consciousness.” Suggest some possible objections to yourdefinitions.                Exercise 4                                Does a refutation of the Chinese room argument necessarily prove thatappropriately programmed computers have mental states? Does anacceptance of the argument necessarily mean that computers cannot havemental states?                Exercise 5 (brain-prosthesis-exercise)                                In the brain replacement argument, it isimportant to be able to restore the subject’s brain to normal, such thatits external behavior is as it would have been if the operation had nottaken place. Can the skeptic reasonably object that this would requireupdating those neurophysiological properties of the neurons relating toconscious experience, as distinct from those involved in the functionalbehavior of the neurons?                Exercise 6                                Suppose that a Prolog program containing many clauses about the rules ofBritish citizenship is compiled and run on an ordinary computer. Analyzethe “brain states” of the computer under wide and narrow content.                Exercise 7                                Alan Perlis [Perlis:1982] wrote, “A year spent in artificialintelligence is enough to make one believe in God”. He also wrote, in aletter to Philip Davis, that one of the central dreams of computerscience is that “through the performance of computers and their programswe will remove all doubt that there is only a chemical distinctionbetween the living and nonliving world.” To what extent does theprogress made so far in artificial intelligence shed light on theseissues? Suppose that at some future date, the AI endeavor has beencompletely successful; that is, we have build intelligent agents capableof carrying out any human cognitive task at human levels of ability. Towhat extent would that shed light on these issues?                Exercise 8                                Compare the social impact of artificial intelligence in the last fiftyyears with the social impact of the introduction of electric appliancesand the internal combustion engine in the fifty years between 1890 and1940.                Exercise 9                                I. J. Good claims that intelligence is the most important quality, andthat building ultraintelligent machines will change everything. Asentient cheetah counters that “Actually speed is more important; if wecould build ultrafast machines, that would change everything,” and asentient elephant claims “You’re both wrong; what we need is ultrastrongmachines.” What do you think of these arguments?                Exercise 10                                Analyze the potential threats from AI technology to society. Whatthreats are most serious, and how might they be combated? How do theycompare to the potential benefits?                Exercise 11                                How do the potential threats from AI technology compare with those fromother computer science technologies, and to bio-, nano-, and nucleartechnologies?                Exercise 12                                Some critics object that AI is impossible, while others object that itis too possible and that ultraintelligent machines pose athreat. Which of these objections do you think is more likely? Would itbe a contradiction for someone to hold both positions?    ",
        "url": " /question_bank/"
      }
    
  
    
  
}