{
  "_":{
	"title":"",
	"content":"",
	"url":""  	
  }	
  
    
  
    
  
    
  
    ,
      "decision-theory-exercises-ex-3":  {
        "title": "Exercise 16.3",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.3Chris considers five used cars before buying the one with maximumexpected utility. Pat considers eleven cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?",
        "url": " /decision-theory-exercises/ex_3/"
      }
    
  
    ,
      "decision-theory-exercises-ex-11":  {
        "title": "Exercise 16.11",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.11 [assessment-exercise]Assess your own utility for different incrementalamounts of money by running a series of preference tests between somedefinite amount $M_1$ and a lottery $[p,M_2; (1-p), 0]$. Choosedifferent values of $M_1$ and $M_2$, and vary $p$ until you areindifferent between the two choices. Plot the resulting utilityfunction.",
        "url": " /decision-theory-exercises/ex_11/"
      }
    
  
    ,
      "decision-theory-exercises-ex-14":  {
        "title": "Exercise 16.14",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.14Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.      Assume Mary has an exponential utility function with .Mary is given the choice between receiving  with certainty(probability 1) or participating in a lottery which has a 60%probability of winning $5000 and a 40% probability ofwinning nothing. Assuming Marry acts rationally, which option wouldshe choose? Show how you derived your answer.        Consider the choice between receiving  with certainty(probability 1) or participating in a lottery which has a 50%probability of winning  and a 50% probability of winningnothing. Approximate the value of R (to 3 significant digits) in anexponential utility function that would cause an individual to beindifferent to these two alternatives. (You might find it helpful towrite a short program to help you solve this problem.)  ",
        "url": " /decision-theory-exercises/ex_14/"
      }
    
  
    ,
      "decision-theory-exercises-ex-4":  {
        "title": "Exercise 16.4",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.4 [St-Petersburg-exercise]In 1713, Nicolas Bernoulli stated a puzzle,now called the St. Petersburg paradox, which works as follows. You havethe opportunity to play a game in which a fair coin is tossed repeatedlyuntil it comes up heads. If the first heads appears on the $n$th toss,you win $2^n$ dollars.      Show that the expected monetary value of this game is infinite.        How much would you, personally, pay to play the game?        Nicolas’s cousin Daniel Bernoulli resolved the apparent paradox in1738 by suggesting that the utility of money is measured on alogarithmic scale (i.e., $U(S_{n}) = alog_2 n +b$, where $S_n$ isthe state of having $n$). What is the expected utility of the gameunder this assumption?        What is the maximum amount that it would be rational to pay to playthe game, assuming that one’s initial wealth is $k$?  ",
        "url": " /decision-theory-exercises/ex_4/"
      }
    
  
    ,
      "decision-theory-exercises-ex-23":  {
        "title": "Exercise 16.24",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.23 [nonnegative-VPI-exercise]Recall the definition of value ofinformation in Section VPI-section.      Prove that the value of information is nonnegative andorder independent.        Explain why it is that some people would prefer not to get someinformation—for example, not wanting to know the sex of their babywhen an ultrasound is done.        A function $f$ on sets is submodular if, for any element $x$ and any sets $A$and $B$ such that $Asubseteq B$, adding $x$ to $A$ gives a greaterincrease in $f$ than adding $x$ to $B$:Submodularity captures the intuitive notion of diminishingreturns. Is the value of information, viewed as a function$f$ on sets of possible observations, submodular? Prove this or finda counterexample.  ",
        "url": " /decision-theory-exercises/ex_23/"
      }
    
  
    ,
      "decision-theory-exercises-ex-20":  {
        "title": "Exercise 16.20",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.20Consider a student who has the choice to buy or not buy a textbook for acourse. We’ll model this as a decision problem with one Boolean decisionnode, $B$, indicating whether the agent chooses to buy the book, and twoBoolean chance nodes, $M$, indicating whether the student has masteredthe material in the book, and $P$, indicating whether the student passesthe course. Of course, there is also a utility node, $U$. A certainstudent, Sam, has an additive utility function: 0 for not buying thebook and -$100 for buying it; and $2000 for passing the course and 0for not passing. Sam’s conditional probability estimates are as follows:You might think that $P$ would be independent of $B$ given$M$, But this course has an open-book final—so having the book helps.      Draw the decision network for this problem.        Compute the expected utility of buying the book and of notbuying it.        What should Sam do?  ",
        "url": " /decision-theory-exercises/ex_20/"
      }
    
  
    ,
      "decision-theory-exercises-ex-7":  {
        "title": "Exercise 16.7",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.7 [surprise-candy-exercise]The Surprise Candy Company makes candy intwo flavors: 70% are strawberry flavor and 30% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 80% of the strawberrycandies are round and 80% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.      Which network(s) can correctly represent${textbf{P}}(Flavor,Wrapper,Shape)$?        Which network is the best representation for this problem?        Does network (i) assert that${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?        What is the probability that your candy has a red wrapper?        In the box is a round candy with a red wrapper. What is theprobability that its flavor is strawberry?        A unwrapped strawberry candy is worth $s$ on the open market and anunwrapped anchovy candy is worth $a$. Write an expression for thevalue of an unopened candy box.        A new law prohibits trading of unwrapped candies, but it is stilllegal to trade wrapped candies (out of the box). Is an unopenedcandy box now worth more than less than, or the same as before?  ",
        "url": " /decision-theory-exercises/ex_7/"
      }
    
  
    ,
      "decision-theory-exercises-ex-17":  {
        "title": "Exercise 16.17",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.17 [airport-au-id-exercise]Repeat Exercise airport-id-exercise, using the action-utilityrepresentation shown in Figure airport-au-id-figure.",
        "url": " /decision-theory-exercises/ex_17/"
      }
    
  
    ,
      "decision-theory-exercises-ex-5":  {
        "title": "Exercise 16.5",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.5Write a computer program to automate the process inExercise assessment-exercise. Try your program out onseveral people of different net worth and political outlook. Comment onthe consistency of your results, both for an individual and acrossindividuals.",
        "url": " /decision-theory-exercises/ex_5/"
      }
    
  
    ,
      "decision-theory-exercises-ex-10":  {
        "title": "Exercise 16.10",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.10Tickets to a lottery cost 1. There are two possible prizes:a 10 payoff with probability 1/50, and a 1,000,000 payoff withprobability 1/2,000,000. What is the expected monetary value of alottery ticket? When (if ever) is it rational to buy a ticket? Beprecise—show an equation involving utilities. You may assume currentwealth of $k$ and that $U(S_k)=0$. You may also assume that$U(S_{k+{10}}) = {10}times U(S_{k+1})$, but you may not make anyassumptions about $U(S_{k+1,{000},{000}})$. Sociological studies showthat people with lower income buy a disproportionate number of lotterytickets. Do you think this is because they are worse decision makers orbecause they have a different utility function? Consider the value ofcontemplating the possibility of winning the lottery versus the value ofcontemplating becoming an action hero while watching an adventure movie.",
        "url": " /decision-theory-exercises/ex_10/"
      }
    
  
    ,
      "decision-theory-exercises-ex-22":  {
        "title": "Exercise 16.22",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.22 [car-vpi-exercise](Adapted from Pearl [@Pearl:1988].) A used-carbuyer can decide to carry out various tests with various costs (e.g.,kick the tires, take the car to a qualified mechanic) and then,depending on the outcome of the tests, decide which car to buy. We willassume that the buyer is deciding whether to buy car $c_1$, that thereis time to carry out at most one test, and that $t_1$ is the test of$c_1$ and costs $50.A car can be in good shape (quality ) or bad shape (quality $q^-$),and the tests might help indicate what shape the car is in. Car $c_1$costs $1,500, and its market value is  if it is in good shape; ifnot,  in repairs will be needed to make it in good shape. The buyer’sestimate is that $c_1$ has a 70% chance of being in good shape.      Draw the decision network that represents this problem.        Calculate the expected net gain from buying $c_1$, given no test.        Tests can be described by the probability that the car will pass orfail the test given that the car is in good or bad shape. We havethe following information:            Use Bayes’ theorem to calculate the probability that the car will pass (or fail) its test and hence the probability that it is in good (or bad) shape given each possible test outcome.        Calculate the optimal decisions given either a pass or a fail, andtheir expected utilities.        Calculate the value of information of the test, and derive anoptimal conditional plan for the buyer.  ",
        "url": " /decision-theory-exercises/ex_22/"
      }
    
  
    ,
      "decision-theory-exercises-ex-18":  {
        "title": "Exercise 16.18",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.18For either of the airport-siting diagrams from Exercises[airport-id-exercise] and [airport-au-id-exercise], to whichconditional probability table entry is the utility most sensitive, giventhe available evidence?",
        "url": " /decision-theory-exercises/ex_18/"
      }
    
  
    ,
      "decision-theory-exercises-ex-15":  {
        "title": "Exercise 16.15",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.15Economists often make use of an exponential utility function for money:$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing anindividual’s risk tolerance. Risk tolerance reflects how likely anindividual is to accept a lottery with a particular expected monetaryvalue (EMV) versus some certain payoff. As $R$ (which is measured in thesame units as $x$) becomes larger, the individual becomes lessrisk-averse.      Assume Mary has an exponential utility function with $R = $400$.Mary is given the choice between receiving  with certainty(probability 1) or participating in a lottery which has a 60%probability of winning $5000 and a 40% probability ofwinning nothing. Assuming Marry acts rationally, which option wouldshe choose? Show how you derived your answer.        Consider the choice between receiving  with certainty(probability 1) or participating in a lottery which has a 50%probability of winning $500 and a 50% probability of winningnothing. Approximate the value of R (to 3 significant digits) in anexponential utility function that would cause an individual to beindifferent to these two alternatives. (You might find it helpful towrite a short program to help you solve this problem.)  ",
        "url": " /decision-theory-exercises/ex_15/"
      }
    
  
    ,
      "decision-theory-exercises-ex-16":  {
        "title": "Exercise 16.16",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.16Alex is given the choice between two games. In Game 1, a fair coin isflipped and if it comes up heads, Alex receives . If the coin comesup tails, Alex receives nothing. In Game 2, a fair coin is flippedtwice. Each time the coin comes up heads, Alex receives , and Alexreceives nothing for each coin flip that comes up tails. Assuming thatAlex has a monotonically increasing utility function for money in therange [$0, $100], show mathematically that if Alex prefers Game 2 toGame 1, then Alex is risk averse (at least with respect to this range ofmonetary amounts).Show that if $X_1$ and $X_2$ are preferentially independent of $X_3$,and $X_2$ and $X_3$ are preferentially independent of $X_1$, then $X_3$and $X_1$ are preferentially independent of $X_2$.",
        "url": " /decision-theory-exercises/ex_16/"
      }
    
  
    ,
      "decision-theory-exercises-ex-8":  {
        "title": "Exercise 16.8",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.8Prove that the judgments $B succ A$ and $C succ D$ in the Allaisparadox (page allais-page) violate the axiom of substitutability.",
        "url": " /decision-theory-exercises/ex_8/"
      }
    
  
    ,
      "decision-theory-exercises-ex-2":  {
        "title": "Exercise 16.2",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.2Chris considers four used cars before buying the one with maximumexpected utility. Pat considers ten cars and does the same. All otherthings being equal, which one is more likely to have the better car?Which is more likely to be disappointed with their car’s quality? By howmuch (in terms of standard deviations of expected quality)?",
        "url": " /decision-theory-exercises/ex_2/"
      }
    
  
    ,
      "decision-theory-exercises-ex-9":  {
        "title": "Exercise 16.9",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.9Consider the Allais paradox described on page allais-page: an agentwho prefers $B$ over $A$ (taking the sure thing), and $C$ over $D$(taking the higher EMV) is not acting rationally, according to utilitytheory. Do you think this indicates a problem for the agent, a problemfor the theory, or no problem at all? Explain.",
        "url": " /decision-theory-exercises/ex_9/"
      }
    
  
    ,
      "decision-theory-exercises-ex-19":  {
        "title": "Exercise 16.19",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.19Modify and extend the Bayesian network code in the code repository toprovide for creation and evaluation of decision networks and thecalculation of information value.",
        "url": " /decision-theory-exercises/ex_19/"
      }
    
  
    ,
      "decision-theory-exercises-ex-6":  {
        "title": "Exercise 16.6",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.6 [surprise-candy-exercise]The Surprise Candy Company makes candy intwo flavors: 75% are strawberry flavor and 25% are anchovy flavor. Eachnew piece of candy starts out with a round shape; as it moves along theproduction line, a machine randomly selects a certain percentage to betrimmed into a square; then, each piece is wrapped in a wrapper whosecolor is chosen randomly to be red or brown. 70% of the strawberrycandies are round and 70% have a red wrapper, while 90% of the anchovycandies are square and 90% have a brown wrapper. All candies are soldindividually in sealed, identical, black boxes.Now you, the customer, have just bought a Surprise candy at the storebut have not yet opened the box. Consider the three Bayes nets inFigure 3candy-figure.      Which network(s) can correctly represent${textbf{P}}(Flavor,Wrapper,Shape)$?        Which network is the best representation for this problem?        Does network (i) assert that${textbf{P}}(Wrapper|Shape){textbf{P}}(Wrapper)$?        What is the probability that your candy has a red wrapper?        In the box is a round candy with a red wrapper. What is theprobability that its flavor is strawberry?        A unwrapped strawberry candy is worth $s$ on the open market and anunwrapped anchovy candy is worth $a$. Write an expression for thevalue of an unopened candy box.        A new law prohibits trading of unwrapped candies, but it is stilllegal to trade wrapped candies (out of the box). Is an unopenedcandy box now worth more than less than, or the same as before?  Figure [3candy-figure] Three proposed Bayes nets for the Surprise Candyproblem",
        "url": " /decision-theory-exercises/ex_6/"
      }
    
  
    ,
      "decision-theory-exercises-ex-21":  {
        "title": "Exercise 16.21",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.21 [airport-id-exercise]This exercise completes the analysis of theairport-siting problem in Figure airport-id-figure.      Provide reasonable variable domains, probabilities, and utilitiesfor the network, assuming that there are three possible sites.        Solve the decision problem.        What happens if changes in technology mean that each aircraftgenerates half the noise?        What if noise avoidance becomes three times more important?        Calculate the VPI for ${AirTraffic}$, ${Litigation}$, and${Construction}$ in your model.  ",
        "url": " /decision-theory-exercises/ex_21/"
      }
    
  
    ,
      "decision-theory-exercises-ex-1":  {
        "title": "Exercise 16.1",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.1 [almanac-game](Adapted from David Heckerman.) This exercise concernsthe Almanac Game, which is used bydecision analysts to calibrate numeric estimation. For each of thequestions that follow, give your best guess of the answer, that is, anumber that you think is as likely to be too high as it is to be toolow. Also give your guess at a 25th percentile estimate, that is, anumber that you think has a 25% chance of being too high, and a 75%chance of being too low. Do the same for the 75th percentile. (Thus, youshould give three estimates in all—low, median, and high—for eachquestion.)      Number of passengers who flew between New York and Los Angelesin 1989.        Population of Warsaw in 1992.        Year in which Coronado discovered the Mississippi River.        Number of votes received by Jimmy Carter in the 1976presidential election.        Age of the oldest living tree, as of 2002.        Height of the Hoover Dam in feet.        Number of eggs produced in Oregon in 1985.        Number of Buddhists in the world in 1992.        Number of deaths due to AIDS in the United Statesin 1981.        Number of U.S. patents granted in 1901.  The correct answers appear after the last exercise of this chapter. Fromthe point of view of decision analysis, the interesting thing is not howclose your median guesses came to the real answers, but rather how oftenthe real answer came within your 25% and 75% bounds. If it was abouthalf the time, then your bounds are accurate. But if you’re like mostpeople, you will be more sure of yourself than you should be, and fewerthan half the answers will fall within the bounds. With practice, youcan calibrate yourself to give realistic bounds, and thus be more usefulin supplying information for decision making. Try this second set ofquestions and see if there is any improvement:      Year of birth of Zsa Zsa Gabor.        Maximum distance from Mars to the sun in miles.        Value in dollars of exports of wheat from the United States in 1992.        Tons handled by the port of Honolulu in 1991.        Annual salary in dollars of the governor of California in 1993.        Population of San Diego in 1990.        Year in which Roger Williams founded Providence, Rhode Island.        Height of Mt. Kilimanjaro in feet.        Length of the Brooklyn Bridge in feet.        Number of deaths due to automobile accidents in the United Statesin 1992.  ",
        "url": " /decision-theory-exercises/ex_1/"
      }
    
  
    ,
      "decision-theory-exercises-ex-13":  {
        "title": "Exercise 16.13",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.13 [kmax-exercise]Let continuous variables $X_1,ldots,X_k$ beindependently distributed according to the same probability densityfunction $f(x)$. Prove that the density function for$max{X_1,ldots,X_k}$ is given by $kf(x)(F(x))^{k-1}$, where $F$ isthe cumulative distribution for $f$.",
        "url": " /decision-theory-exercises/ex_13/"
      }
    
  
    ,
      "decision-theory-exercises-ex-12":  {
        "title": "Exercise 16.12",
        "breadcrumb": "16-Making-Simple-Decisions",
      	"content"  : "Exercise 16.12How much is a micromort worth to you? Devise a protocol to determinethis. Ask questions based both on paying to avoid risk and being paid toaccept risk.",
        "url": " /decision-theory-exercises/ex_12/"
      }
    
  
    
  
    ,
      "probability-exercises-ex-28":  {
        "title": "Exercise 13.28",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.28 [naive-bayes-retrieval-exercise]Text categorization is the task ofassigning a given document to one of a fixed set of categories on thebasis of the text it contains. Naive Bayes models are often used forthis task. In these models, the query variable is the document category,and the “effect” variables are the presence or absence of each word inthe language; the assumption is that words occur independently indocuments, with frequencies determined by the document category.      Explain precisely how such a model can be constructed, given as“training data” a set of documents that have been assignedto categories.        Explain precisely how to categorize a new document.        Is the conditional independence assumption reasonable? Discuss.  ",
        "url": " /probability-exercises/ex_28/"
      }
    
  
    ,
      "probability-exercises-ex-29":  {
        "title": "Exercise 13.29",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.29In our analysis of the wumpus world, we used the fact thateach square contains a pit with probability 0.2, independently of thecontents of the other squares. Suppose instead that exactly $N/5$ pitsare scattered at random among the $N$ squares other than [1,1]. Arethe variables $P_{i,j}$ and $P_{k,l}$ still independent? What is thejoint distribution ${textbf{P}}(P_{1,1},ldots,P_{4,4})$ now?Redo the calculation for the probabilities of pits in [1,3] and[2,2].",
        "url": " /probability-exercises/ex_29/"
      }
    
  
    ,
      "probability-exercises-ex-3":  {
        "title": "Exercise 13.3",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.3For each of the following statements, either prove it is true or give acounterexample.      If $P(a b, c) = P(b a, c)$, then$P(a c) = P(b c)$        If $P(a b, c) = P(a)$, then $P(b c) = P(b)$        If $P(a b) = P(a)$, then$P(a b, c) = P(a c)$  ",
        "url": " /probability-exercises/ex_3/"
      }
    
  
    ,
      "probability-exercises-ex-11":  {
        "title": "Exercise 13.11",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.11Deciding to put probability theory to good use, we encounter a slotmachine with three independent wheels, each producing one of the foursymbols bar, bell, lemon, orcherry with equal probability. The slot machine has thefollowing payout scheme for a bet of 1 coin (where “?” denotes that wedon’t care what comes up for that wheel):  bar/bar/bar pays 20 coins  bell/bell/bell pays 15 coins  lemon/lemon/lemon pays 5 coins  cherry/cherry/cherry pays 3 coins  cherry/cherry/? pays 2 coins  cherry/?/? pays 1 coin      Compute the expected “payback” percentage of the machine. In otherwords, for each coin played, what is the expected coin return?        Compute the probability that playing the slot machine once willresult in a win.        Estimate the mean and median number of plays you can expect to makeuntil you go broke, if you start with 10 coins. You can run asimulation to estimate this, rather than trying to compute anexact answer.  ",
        "url": " /probability-exercises/ex_11/"
      }
    
  
    ,
      "probability-exercises-ex-14":  {
        "title": "Exercise 13.14",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.14We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon0.002$, $delta0.01$.",
        "url": " /probability-exercises/ex_14/"
      }
    
  
    ,
      "probability-exercises-ex-4":  {
        "title": "Exercise 13.4",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.4Would it be rational for an agent to hold the three beliefs$P(A) {0.4}$, $P(B) {0.3}$, and$P(A lor B) {0.5}$? If so, what range of probabilities wouldbe rational for the agent to hold for $A land B$? Make up a table likethe one in Figure de-finetti-table, and show how itsupports your argument about rationality. Then draw another version ofthe table where $P(A lor B){0.7}$. Explain why it is rational to have this probability,even though the table shows one case that is a loss and three that justbreak even. (Hint: what is Agent 1 committed to about theprobability of each of the four cases, especially the case that is aloss?)",
        "url": " /probability-exercises/ex_4/"
      }
    
  
    ,
      "probability-exercises-ex-23":  {
        "title": "Exercise 13.23",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.23 [normalization-exercise]In this exercise, you will complete thenormalization calculation for the meningitis example. First, make up asuitable value for $P(slnot m)$, and use it to calculateunnormalized values for $P(ms)$ and $P(lnot m s)$(i.e., ignoring the $P(s)$ term in the Bayes’ rule expression,Equation (meningitis-bayes-equation)). Now normalizethese values so that they add to 1.",
        "url": " /probability-exercises/ex_23/"
      }
    
  
    ,
      "probability-exercises-ex-20":  {
        "title": "Exercise 13.20",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.20 [conditional-bayes-exercise]It is quite often useful to consider theeffect of some specific propositions in the context of some generalbackground evidence that remains fixed, rather than in the completeabsence of information. The following questions ask you to prove moregeneral versions of the product rule and Bayes’ rule, with respect tosome background evidence $textbf{e}$:      Prove the conditionalized version of the general product rule:        Prove the conditionalized version of Bayes’ rule inEquation (conditional-bayes-equation).  ",
        "url": " /probability-exercises/ex_20/"
      }
    
  
    ,
      "probability-exercises-ex-7":  {
        "title": "Exercise 13.7",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.7Consider the set of all possible five-card poker hands dealt fairly froma standard deck of fifty-two cards.      How many atomic events are there in the joint probabilitydistribution (i.e., how many five-card hands are there)?        What is the probability of each atomic event?        What is the probability of being dealt a royal straight flush? Fourof a kind?  ",
        "url": " /probability-exercises/ex_7/"
      }
    
  
    ,
      "probability-exercises-ex-17":  {
        "title": "Exercise 13.17",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.17Suppose you are given a coin that lands ${heads}$ with probability $x$and ${tails}$ with probability $1 - x$. Are the outcomes of successiveflips of the coin independent of each other given that you know thevalue of $x$? Are the outcomes of successive flips of the coinindependent of each other if you do not know the value of$x$? Justify your answer.",
        "url": " /probability-exercises/ex_17/"
      }
    
  
    ,
      "probability-exercises-ex-5":  {
        "title": "Exercise 13.5",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.5 [exclusive-exhaustive-exercise]This question deals with the propertiesof possible worlds, defined on page possible-worlds-page as assignments to allrandom variables. We will work with propositions that correspond toexactly one possible world because they pin down the assignments of allthe variables. In probability theory, such propositions are called atomic event. Forexample, with Boolean variables $X_1$, $X_2$, $X_3$, the proposition$x_1land lnot x_2 land lnot x_3$ fixes the assignment of thevariables; in the language of propositional logic, we would say it hasexactly one model.      Prove, for the case of $n$ Boolean variables, that any two distinctatomic events are mutually exclusive; that is, their conjunction isequivalent to ${false}$.        Prove that the disjunction of all possible atomic events islogically equivalent to ${true}$.        Prove that any proposition is logically equivalent to thedisjunction of the atomic events that entail its truth.  ",
        "url": " /probability-exercises/ex_5/"
      }
    
  
    ,
      "probability-exercises-ex-25":  {
        "title": "Exercise 13.25",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.25Let $X$, $Y$, $Z$ be Boolean random variables. Label the eight entriesin the joint distribution ${textbf{P}}(X,Y,Z)$ as $a$ through$h$. Express the statement that $X$ and $Y$ are conditionallyindependent given $Z$, as a set of equations relating $a$ through $h$.How many nonredundant equations are there?",
        "url": " /probability-exercises/ex_25/"
      }
    
  
    ,
      "probability-exercises-ex-10":  {
        "title": "Exercise 13.10",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.10 [unfinished-game-exercise]In his letter of August 24, 1654, Pascalwas trying to show how a pot of money should be allocated when agambling game must end prematurely. Imagine a game where each turnconsists of the roll of a die, player E gets a point whenthe die is even, and player  O gets a point when the dieis odd. The first player to get 7 points wins the pot. Suppose the gameis interrupted with E leading 4–2. How should the moneybe fairly split in this case? What is the general formula? (Fermat andPascal made several errors before solving the problem, but you should beable to get it right the first time.)",
        "url": " /probability-exercises/ex_10/"
      }
    
  
    ,
      "probability-exercises-ex-22":  {
        "title": "Exercise 13.22",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.22Suppose you are given a bag containing $n$ unbiased coins. You are toldthat $n-1$ of these coins are normal, with heads on one side and tailson the other, whereas one coin is a fake, with heads on both sides.      Suppose you reach into the bag, pick out a coin at random, flip it,and get a head. What is the (conditional) probability that the coinyou chose is the fake coin?        Suppose you continue flipping the coin for a total of $k$ timesafter picking it and see $k$ heads. Now what is the conditionalprobability that you picked the fake coin?        Suppose you wanted to decide whether the chosen coin was fake byflipping it $k$ times. The decision procedure returns ${fake}$ ifall $k$ flips come up heads; otherwise it returns ${normal}$. Whatis the (unconditional) probability that this procedure makes anerror?  ",
        "url": " /probability-exercises/ex_22/"
      }
    
  
    ,
      "probability-exercises-ex-18":  {
        "title": "Exercise 13.18",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.18After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 10,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?",
        "url": " /probability-exercises/ex_18/"
      }
    
  
    ,
      "probability-exercises-ex-31":  {
        "title": "Exercise 13.31",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.31Implement a hybrid probabilistic agent for the wumpus world, based onthe hybrid agent inFigure hybrid-wumpus-agent-algorithm and theprobabilistic inference procedure outlined in this chapter.",
        "url": " /probability-exercises/ex_31/"
      }
    
  
    ,
      "probability-exercises-ex-24":  {
        "title": "Exercise 13.24",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.24This exercise investigates the way in which conditional independencerelationships affect the amount of information needed for probabilisticcalculations.      Suppose we wish to calculate $P(he_1,e_2)$ and we have noconditional independence information. Which of the following sets ofnumbers are sufficient for the calculation?                  ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,${textbf{P}}(E_1H)$,${textbf{P}}(E_2H)$                    ${textbf{P}}(E_1,E_2)$, ${textbf{P}}(H)$,${textbf{P}}(E_1,E_2H)$                    ${textbf{P}}(H)$,${textbf{P}}(E_1H)$,${textbf{P}}(E_2H)$                  Suppose we know that${textbf{P}}(E_1H,E_2)={textbf{P}}(E_1H)$for all values of $H$, $E_1$, $E_2$. Now which of the three sets aresufficient?  ",
        "url": " /probability-exercises/ex_24/"
      }
    
  
    ,
      "probability-exercises-ex-15":  {
        "title": "Exercise 13.15",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.15 [independence-exercise]Show that the three forms of independence inEquation (independence-equation) are equivalent.",
        "url": " /probability-exercises/ex_15/"
      }
    
  
    ,
      "probability-exercises-ex-16":  {
        "title": "Exercise 13.16",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.16Consider two medical tests, A and B, for a virus. Test A is 95%effective at recognizing the virus when it is present, but has a 10%false positive rate (indicating that the virus is present, when it isnot). Test B is 90% effective at recognizing the virus, but has a 5%false positive rate. The two tests use independent methods ofidentifying the virus. The virus is carried by 1% of all people. Saythat a person is tested for the virus using only one of the tests, andthat test comes back positive for carrying the virus. Which testreturning positive is more indicative of someone really carrying thevirus? Justify your answer mathematically.",
        "url": " /probability-exercises/ex_16/"
      }
    
  
    ,
      "probability-exercises-ex-30":  {
        "title": "Exercise 13.30",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.30Redo the probability calculation for pits in [1,3] and [2,2],assuming that each square contains a pit with probability 0.01,independent of the other squares. What can you say about the relativeperformance of a logical versus a probabilistic agent in this case?",
        "url": " /probability-exercises/ex_30/"
      }
    
  
    ,
      "probability-exercises-ex-8":  {
        "title": "Exercise 13.8",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.8Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:      $textbf{P}({toothache})$.        $textbf{P}({Cavity})$.        $textbf{P}({Toothache}{cavity})$.        $textbf{P}({Cavity}{toothache}lor {catch})$.  ",
        "url": " /probability-exercises/ex_8/"
      }
    
  
    ,
      "probability-exercises-ex-2":  {
        "title": "Exercise 13.2",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.2 [sum-to-1-exercise]Using the axioms of probability, prove that anyprobability distribution on a discrete random variable must sum to 1.",
        "url": " /probability-exercises/ex_2/"
      }
    
  
    ,
      "probability-exercises-ex-9":  {
        "title": "Exercise 13.9",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.9Given the full joint distribution shown inFigure dentist-joint-table, calculate the following:      $textbf{P}({toothache})$.        $textbf{P}({Catch})$.        $textbf{P}({Cavity}{catch})$.        $textbf{P}({Cavity}{toothache}lor {catch})$.  ",
        "url": " /probability-exercises/ex_9/"
      }
    
  
    ,
      "probability-exercises-ex-19":  {
        "title": "Exercise 13.19",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.19After your yearly checkup, the doctor has bad news and good news. Thebad news is that you tested positive for a serious disease and that thetest is 99% accurate (i.e., the probability of testing positive when youdo have the disease is 0.99, as is the probability of testing negativewhen you don’t have the disease). The good news is that this is a raredisease, striking only 1 in 100,000 people of your age. Why is it goodnews that the disease is rare? What are the chances that you actuallyhave the disease?",
        "url": " /probability-exercises/ex_19/"
      }
    
  
    ,
      "probability-exercises-ex-27":  {
        "title": "Exercise 13.27",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.27Write out a general algorithm for answering queries of the form${textbf{P}}({Cause}textbf{e})$, using a naive Bayesdistribution. Assume that the evidence $textbf{e}$ may assign values toany subset of the effect variables.",
        "url": " /probability-exercises/ex_27/"
      }
    
  
    ,
      "probability-exercises-ex-6":  {
        "title": "Exercise 13.6",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.6 [inclusion-exclusion-exercise]ProveEquation (kolmogorov-disjunction-equation) fromEquations (basic-probability-axiom-equation)and (proposition-probability-equation).",
        "url": " /probability-exercises/ex_6/"
      }
    
  
    ,
      "probability-exercises-ex-26":  {
        "title": "Exercise 13.26",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.26(Adapted from Pearl [-@Pearl:1988].) Suppose you are a witness to anighttime hit-and-run accident involving a taxi in Athens. All taxis inAthens are blue or green. You swear, under oath, that the taxi was blue.Extensive testing shows that, under the dim lighting conditions,discrimination between blue and green is 75% reliable.      Is it possible to calculate the most likely color for the taxi?(Hint: distinguish carefully between the propositionthat the taxi is blue and the proposition that itappears blue.)        What if you know that 9 out of 10 Athenian taxis are green?  ",
        "url": " /probability-exercises/ex_26/"
      }
    
  
    ,
      "probability-exercises-ex-21":  {
        "title": "Exercise 13.21",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.21 [pv-xyz-exercise]Show that the statement of conditional independenceis equivalent to each of the statements",
        "url": " /probability-exercises/ex_21/"
      }
    
  
    ,
      "probability-exercises-ex-1":  {
        "title": "Exercise 13.1",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.1Show from first principles that $P(abland a) = 1$.",
        "url": " /probability-exercises/ex_1/"
      }
    
  
    ,
      "probability-exercises-ex-13":  {
        "title": "Exercise 13.13",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.13We wish to transmit an $n$-bit message to a receiving agent. The bits inthe message are independently corrupted (flipped) during transmissionwith $epsilon$ probability each. With an extra parity bit sent alongwith the original information, a message can be corrected by thereceiver if at most one bit in the entire message (including the paritybit) has been corrupted. Suppose we want to ensure that the correctmessage is received with probability at least $1-delta$. What is themaximum feasible value of $n$? Calculate this value for the case$epsilon0.001$, $delta0.01$.",
        "url": " /probability-exercises/ex_13/"
      }
    
  
    ,
      "probability-exercises-ex-12":  {
        "title": "Exercise 13.12",
        "breadcrumb": "13-Quantifying-Uncertainity",
      	"content"  : "Exercise 13.12Deciding to put our knowledge of probability to good use, we encounter aslot machine with three independently turning reels, each producing oneof the four symbols bar, bell,lemon, or cherry with equal probability. Theslot machine has the following payout scheme for a bet of 1 coin (where“?” denotes that we don’t care what comes up for that wheel):  bar/bar/bar pays 21 coins  bell/bell/bell pays 16 coins  lemon/lemon/lemon pays 5 coins  cherry/cherry/cherry pays 3 coins  cherry/cherry/? pays 2 coins  cherry/?/? pays 1 coin      Compute the expected “payback” percentage of the machine. In otherwords, for each coin played, what is the expected coin return?        Compute the probability that playing the slot machine once willresult in a win.        Estimate the mean and median number of plays you can expect to makeuntil you go broke, if you start with 8 coins. You can run asimulation to estimate this, rather than trying to compute anexact answer.  ",
        "url": " /probability-exercises/ex_12/"
      }
    
  
    
  
    ,
      "kr-exercises-ex-28":  {
        "title": "Exercise 12.28",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.28One part of the shopping process that was not covered in this chapter ischecking for compatibility between items. For example, if a digitalcamera is ordered, what accessory batteries, memory cards, and cases arecompatible with the camera? Write a knowledge base that can determinethe compatibility of a set of items and suggest replacements oradditional items if the shopper makes a choice that is not compatible.The knowledge base should works with at least one line of products andextend easily to other lines.",
        "url": " /kr-exercises/ex_28/"
      }
    
  
    ,
      "kr-exercises-ex-29":  {
        "title": "Exercise 12.29",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.29 [shopping-grammar-exercise]A complete solution to the problem ofinexact matches to the buyer’s description in shopping is very difficultand requires a full array of natural language processing and informationretrieval techniques. (See Chapters nlp1-chapterand nlp-english-chapter.) One small step is to allow the user tospecify minimum and maximum values for various attributes. The buyermust use the following grammar for product descriptions:Here, ${Category}$ names a product category, ${Attribute}$ is somefeature such as “CPU” or “price,” and ${Value}$ is the target valuefor the attribute. So the query “computer with at least a 2.5 GHz CPUfor under 500” must be re-expressed as “computer with CPU $&amp;gt;$ 2.5 GHzand price $&amp;lt;$ 500.” Implement a shopping agent that accepts descriptionsin this language.",
        "url": " /kr-exercises/ex_29/"
      }
    
  
    ,
      "kr-exercises-ex-3":  {
        "title": "Exercise 12.3",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.3Figure ontology-figure shows the top levels of ahierarchy for everything. Extend it to include as many real categoriesas possible. A good way to do this is to cover all the things in youreveryday life. This includes objects and events. Start with waking up,and proceed in an orderly fashion noting everything that you see, touch,do, and think about. For example, a random sampling produces music,news, milk, walking, driving, gas, Soda Hall, carpet, talking, ProfessorFateman, chicken curry, tongue, $ 7, sun, the daily newspaper, and so on.You should produce both a single hierarchy chart (on a large sheet ofpaper) and a listing of objects and categories with the relationssatisfied by members of each category. Every object should be in acategory, and every category should be in the hierarchy.",
        "url": " /kr-exercises/ex_3/"
      }
    
  
    ,
      "kr-exercises-ex-11":  {
        "title": "Exercise 12.11",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.11 [alt-measure-exercise]An alternative scheme for representing measuresinvolves applying the units function to an abstract length object. Insuch a scheme, one would write ${Inches}({Length}(L_1)) = {1.5}$.How does this scheme compare with the one in the chapter? Issues includeconversion axioms, names for abstract quantities (such as “50 dollars”),and comparisons of abstract measures in different units (50 inches ismore than 50 centimeters).",
        "url": " /kr-exercises/ex_11/"
      }
    
  
    ,
      "kr-exercises-ex-14":  {
        "title": "Exercise 12.14",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.14Write event calculus axioms to describe the actions in the wumpus world.",
        "url": " /kr-exercises/ex_14/"
      }
    
  
    ,
      "kr-exercises-ex-4":  {
        "title": "Exercise 12.4",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.4 [windows-exercise]Develop a representational system for reasoningabout windows in a window-based computer interface. In particular, yourrepresentation should be able to describe:      The state of a window: minimized, displayed, or nonexistent.        Which window (if any) is the active window.        The position of every window at a given time.        The order (front to back) of overlapping windows.        The actions of creating, destroying, resizing, and moving windows;changing the state of a window; and bringing a window to the front.Treat these actions as atomic; that is, do not deal with the issueof relating them to mouse actions. Give axioms describing theeffects of actions on fluents. You may use either event orsituation calculus.  Assume an ontology containing situations,actions, integers (for $x$ and $y$coordinates) and windows. Define a language over thisontology; that is, a list of constants, function symbols, and predicateswith an English description of each. If you need to add more categoriesto the ontology (e.g., pixels), you may do so, but be sure to specifythese in your write-up. You may (and should) use symbols defined in thetext, but be sure to list these explicitly.",
        "url": " /kr-exercises/ex_4/"
      }
    
  
    ,
      "kr-exercises-ex-23":  {
        "title": "Exercise 12.23",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.23The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:      Partial knowledge adversary games, such as card games. Here oneplayer wants to reason about what his opponent knows about the stateof the game.        Chess with a clock. Here the player may wish to reason about thelimits of his opponent’s or his own ability to find the best move inthe time available. For instance, if player A has much more timeleft than player B, then A will sometimes make a move that greatlycomplicates the situation, in the hopes of gaining an advantagebecause he has more time to work out the proper strategy.        A shopping agent in an environment in which there are costs ofgathering information.        Reasoning about public key cryptography, which rests on theintractability of certain computational problems.  ",
        "url": " /kr-exercises/ex_23/"
      }
    
  
    ,
      "kr-exercises-ex-20":  {
        "title": "Exercise 12.20",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.20Describe the event of trading something for something else. Describebuying as a kind of trading in which one of the objects traded is a sumof money.",
        "url": " /kr-exercises/ex_20/"
      }
    
  
    ,
      "kr-exercises-ex-7":  {
        "title": "Exercise 12.7",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.7(Adapted from an example by Doug Lenat.) Your mission is to capture, inlogical form, enough knowledge to answer a series of questions about thefollowing simple scenario:  Yesterday John went to the North Berkeley Safeway supermarket andbought two pounds of tomatoes and a pound of ground beef.Start by trying to represent the content of the sentence as a series ofassertions. You should write sentences that have straightforward logicalstructure (e.g., statements that objects have certain properties, thatobjects are related in certain ways, that all objects satisfying oneproperty satisfy another). The following might help you get started:      Which classes, objects, and relations would you need? What are theirparents, siblings and so on? (You will need events and temporalordering, among other things.)        Where would they fit in a more general hierarchy?        What are the constraints and interrelationships among them?        How detailed must you be about each of the various concepts?  To answer the questions below, your knowledge base must includebackground knowledge. You’ll have to deal with what kind of things areat a supermarket, what is involved with purchasing the things oneselects, what the purchases will be used for, and so on. Try to makeyour representation as general as possible. To give a trivial example:don’t say “People buy food from Safeway,” because that won’t help youwith those who shop at another supermarket. Also, don’t turn thequestions into answers; for example, question (c) asks “Did John buy anymeat?”—not “Did John buy a pound of ground beef?”Sketch the chains of reasoning that would answer the questions. Ifpossible, use a logical reasoning system to demonstrate the sufficiencyof your knowledge base. Many of the things you write might be onlyapproximately correct in reality, but don’t worry too much; the idea isto extract the common sense that lets you answer these questions at all.A truly complete answer to this question is extremelydifficult, probably beyond the state of the art of current knowledgerepresentation. But you should be able to put together a consistent setof axioms for the limited questions posed here.      Is John a child or an adult? [Adult]        Does John now have at least two tomatoes? [Yes]        Did John buy any meat? [Yes]        If Mary was buying tomatoes at the same time as John, did he seeher? [Yes]        Are the tomatoes made in the supermarket? [No]        What is John going to do with the tomatoes? [Eat them]        Does Safeway sell deodorant? [Yes]        Did John bring some money or a credit card to the supermarket?[Yes]        Does John have less money after going to the supermarket? [Yes]  ",
        "url": " /kr-exercises/ex_7/"
      }
    
  
    ,
      "kr-exercises-ex-17":  {
        "title": "Exercise 12.17",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.17Investigate ways to extend the event calculus to handlesimultaneous events. Is it possible to avoid acombinatorial explosion of axioms?",
        "url": " /kr-exercises/ex_17/"
      }
    
  
    ,
      "kr-exercises-ex-5":  {
        "title": "Exercise 12.5",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.5State the following in the language you developed for the previousexercise:      In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out onthe left and right. Do not state exact coordinatesfor these; describe the general situation.        If a window is displayed, then its top edge is higher than itsbottom edge.        After you create a window $w$, it is displayed.        A window can be minimized if it is displayed.  ",
        "url": " /kr-exercises/ex_5/"
      }
    
  
    ,
      "kr-exercises-ex-25":  {
        "title": "Exercise 12.25",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.25Translate the following description logic expression (frompage description-logic-ex) into first-order logic, and comment on the result:",
        "url": " /kr-exercises/ex_25/"
      }
    
  
    ,
      "kr-exercises-ex-10":  {
        "title": "Exercise 12.10",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.10 [part-decomposition-exercise]Write definitions for the following:      ${ExhaustivePartDecomposition}$        ${PartPartition}$        ${PartwiseDisjoint}$  These should be analogous to the definitions for${ExhaustiveDecomposition}$, ${Partition}$, and ${Disjoint}$. Isit the case that ${PartPartition}(s,{BunchOf}(s))$? If so, prove it;if not, give a counterexample and define sufficient conditions underwhich it does hold.",
        "url": " /kr-exercises/ex_10/"
      }
    
  
    ,
      "kr-exercises-ex-22":  {
        "title": "Exercise 12.22",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.22 [card-on-forehead-exercise](Adapted from @Fagin+al:1995.) Consider a game playedwith a deck of just 8 cards, 4 aces and 4 kings. The three players,Alice, Bob, and Carlos, are dealt two cards each. Without looking atthem, they place the cards on their foreheads so that the other playerscan see them. Then the players take turns either announcing that theyknow what cards are on their own forehead, thereby winning the game, orsaying “I don’t know.” Everyone knows the players are truthful and areperfect at reasoning about beliefs.      Game 1. Alice and Bob have both said “I don’t know.” Carlos seesthat Alice has two aces (A-A) and Bob has two kings (K-K). Whatshould Carlos say? (Hint: consider all three possiblecases for Carlos: A-A, K-K, A-K.)        Describe each step of Game 1 using the notation of modal logic.        Game 2. Carlos, Alice, and Bob all said “I don’t know” on theirfirst turn. Alice holds K-K and Bob holds A-K. What should Carlossay on his second turn?        Game 3. Alice, Carlos, and Bob all say “I don’t know” on their firstturn, as does Alice on her second turn. Alice and Bob both hold A-K.What should Carlos say?        Prove that there will always be a winner to this game.  ",
        "url": " /kr-exercises/ex_22/"
      }
    
  
    ,
      "kr-exercises-ex-18":  {
        "title": "Exercise 12.18",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.18 [exchange-rates-exercise]Construct a representation for exchange ratesbetween currencies that allows for daily fluctuations.",
        "url": " /kr-exercises/ex_18/"
      }
    
  
    ,
      "kr-exercises-ex-24":  {
        "title": "Exercise 12.24",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.24The assumption of logical omniscience, discussed onpage logical-omniscience, is of course not true of any actual reasoners.Rather, it is an idealization of the reasoning processthat may be more or less acceptable depending on the applications.Discuss the reasonableness of the assumption for each of the followingapplications of reasoning about knowledge:      Chess with a clock. Here the player may wish to reason about thelimits of his opponent’s or his own ability to find the best move inthe time available. For instance, if player A has much more timeleft than player B, then A will sometimes make a move that greatlycomplicates the situation, in the hopes of gaining an advantagebecause he has more time to work out the proper strategy.        A shopping agent in an environment in which there are costs ofgathering information.        An automated tutoring program for math, which reasons about whatstudents understand.        Reasoning about public key cryptography, which rests on theintractability of certain computational problems.  ",
        "url": " /kr-exercises/ex_24/"
      }
    
  
    ,
      "kr-exercises-ex-15":  {
        "title": "Exercise 12.15",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.15State the interval-algebra relation that holds between every pair of thefollowing real-world events:  $LK$: The life of President Kennedy.  $IK$: The infancy of President Kennedy.  $PK$: The presidency of President Kennedy.  $LJ$: The life of President Johnson.  $PJ$: The presidency of President Johnson.  $LO$: The life of President Obama.",
        "url": " /kr-exercises/ex_15/"
      }
    
  
    ,
      "kr-exercises-ex-16":  {
        "title": "Exercise 12.16",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.16This exercise concerns the problem of planning a route for a robot totake from one city to another. The basic action taken by the robot is${Go}(x,y)$, which takes it from city $x$ to city $y$ if there is aroute between those cities. ${Road}(x, y)$ is true if and only ifthere is a road connecting cities $x$ and $y$; if there is, then${Distance}(x, y)$ gives the length of the road. See the map onpage romania-distances-figure for an example. The robot begins in Arad and mustreach Bucharest.      Write a suitable logical description of the initial situation ofthe robot.        Write a suitable logical query whose solutions provide possiblepaths to the goal.        Write a sentence describing the ${Go}$ action.        Now suppose that the robot consumes fuel at the rate of .02 gallonsper mile. The robot starts with 20 gallons of fuel. Augment yourrepresentation to include these considerations.        Now suppose some of the cities have gas stations at which the robotcan fill its tank. Extend your representation and write all therules needed to describe gas stations, including the${Fillup}$ action.  ",
        "url": " /kr-exercises/ex_16/"
      }
    
  
    ,
      "kr-exercises-ex-30":  {
        "title": "Exercise 12.30",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.30 [buying-exercise]Our description of Internet shopping omitted theall-important step of actually buying the product.Provide a formal logical description of buying, using event calculus.That is, define the sequence of events that occurs when a buyer submitsa credit-card purchase and then eventually gets billed and receives theproduct.",
        "url": " /kr-exercises/ex_30/"
      }
    
  
    ,
      "kr-exercises-ex-8":  {
        "title": "Exercise 12.8",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.8Make the necessary additions or changes to your knowledge base from theprevious exercise so that the questions that follow can be answered.Include in your report a discussion of your changes, explaining why theywere needed, whether they were minor or major, and what kinds ofquestions would necessitate further changes.      Are there other people in Safeway while John is there?[Yes—staff!]        Is John a vegetarian? [No]        Who owns the deodorant in Safeway? [Safeway Corporation]        Did John have an ounce of ground beef? [Yes]        Does the Shell station next door have any gas? [Yes]        Do the tomatoes fit in John’s car trunk? [Yes]  ",
        "url": " /kr-exercises/ex_8/"
      }
    
  
    ,
      "kr-exercises-ex-2":  {
        "title": "Exercise 12.2",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.2You are to create a system for advising computer science undergraduateson what courses to take over an extended period in order to satisfy theprogram requirements. (Use whatever requirements are appropriate foryour institution.) First, decide on a vocabulary for representing allthe information, and then represent it; then formulate a query to thesystem that will return a legal program of study as a solution. Youshould allow for some tailoring to individual students, in that yoursystem should ask what courses or equivalents the student has alreadytaken, and not generate programs that repeat those courses.Suggest ways in which your system could be improved—for example to takeinto account knowledge about student preferences, the workload, good andbad instructors, and so on. For each kind of knowledge, explain how itcould be expressed logically. Could your system easily incorporate thisinformation to find all feasible programs of study for a student? Couldit find the best program?",
        "url": " /kr-exercises/ex_2/"
      }
    
  
    ,
      "kr-exercises-ex-9":  {
        "title": "Exercise 12.9",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.9Represent the following seven sentences using and extending therepresentations developed in the chapter:      Water is a liquid between 0 and 100 degrees.        Water boils at 100 degrees.        The water in John’s water bottle is frozen.        Perrier is a kind of water.        John has Perrier in his water bottle.        All liquids have a freezing point.        A liter of water weighs more than a liter of alcohol.  ",
        "url": " /kr-exercises/ex_9/"
      }
    
  
    ,
      "kr-exercises-ex-19":  {
        "title": "Exercise 12.19",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.19 [fixed-definition-exercise]Define the predicate ${Fixed}$, where${Fixed}({Location}(x))$ means that the location of object $x$ isfixed over time.",
        "url": " /kr-exercises/ex_19/"
      }
    
  
    ,
      "kr-exercises-ex-27":  {
        "title": "Exercise 12.27",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.27 [natural-stupidity-exercise]One might suppose that the syntacticdistinction between unboxed links and singly boxed links in semanticnetworks is unnecessary, because singly boxed links are always attachedto categories; an inheritance algorithm could simply assume that anunboxed link attached to a category is intended to apply to all membersof that category. Show that this argument is fallacious, giving examplesof errors that would arise.",
        "url": " /kr-exercises/ex_27/"
      }
    
  
    ,
      "kr-exercises-ex-6":  {
        "title": "Exercise 12.6",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.6State the following in the language you developed for the previousexercise:      In situation $S_0$, window $W_1$ is behind $W_2$ but sticks out onthe top and bottom. Do not state exact coordinatesfor these; describe the general situation.        If a window is displayed, then its top edge is higher than itsbottom edge.        After you create a window $w$, it is displayed.        A window can be minimized only if it is displayed.  ",
        "url": " /kr-exercises/ex_6/"
      }
    
  
    ,
      "kr-exercises-ex-26":  {
        "title": "Exercise 12.26",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.26Recall that inheritance information in semantic networks can be capturedlogically by suitable implication sentences. This exercise investigatesthe efficiency of using such sentences for inheritance.      Consider the information in a used-car catalog such as Kelly’s BlueBook—for example, that 1973 Dodge vans are (or perhaps were once)worth 575. Suppose all this information (for 11,000 models) isencoded as logical sentences, as suggested in the chapter. Writedown three such sentences, including that for 1973 Dodge vans. Howwould you use the sentences to find the value of aparticular car, given a backward-chaining theoremprover such as Prolog?        Compare the time efficiency of the backward-chaining method forsolving this problem with the inheritance method used insemantic nets.        Explain how forward chaining allows a logic-based system to solvethe same problem efficiently, assuming that the KB contains only the11,000 sentences about prices.        Describe a situation in which neither forward nor backward chainingon the sentences will allow the price query for an individual car tobe handled efficiently.        Can you suggest a solution enabling this type of query to be solvedefficiently in all cases in logic systems? (Hint:Remember that two cars of the same year and model have thesame price.)  ",
        "url": " /kr-exercises/ex_26/"
      }
    
  
    ,
      "kr-exercises-ex-21":  {
        "title": "Exercise 12.21",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.21The two preceding exercises assume a fairly primitive notion ofownership. For example, the buyer starts by owning thedollar bills. This picture begins to break down when, for example, one’smoney is in the bank, because there is no longer any specific collectionof dollar bills that one owns. The picture is complicated still furtherby borrowing, leasing, renting, and bailment. Investigate the variouscommonsense and legal concepts of ownership, and propose a scheme bywhich they can be represented formally.",
        "url": " /kr-exercises/ex_21/"
      }
    
  
    ,
      "kr-exercises-ex-1":  {
        "title": "Exercise 12.1",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.1Define an ontology in first-order logic for tic-tac-toe. The ontologyshould contain situations, actions, squares, players, marks (X, O, orblank), and the notion of winning, losing, or drawing a game. Alsodefine the notion of a forced win (or draw): a position from which aplayer can force a win (or draw) with the right sequence of actions.Write axioms for the domain. (Note: The axioms that enumerate thedifferent squares and that characterize the winning positions are ratherlong. You need not write these out in full, but indicate clearly whatthey look like.)",
        "url": " /kr-exercises/ex_1/"
      }
    
  
    ,
      "kr-exercises-ex-13":  {
        "title": "Exercise 12.13",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.13 [namematch-exercise]Add sentences to extend the definition of thepredicate ${Name}(s, c)$ so that a string such as “laptop computer”matches the appropriate category names from a variety of stores. Try tomake your definition general. Test it by looking at ten online stores,and at the category names they give for three different categories. Forexample, for the category of laptops, we found the names “Notebooks,”“Laptops,” “Notebook Computers,” “Notebook,” “Laptops and Notebooks,”and “Notebook PCs.” Some of these can be covered by explicit ${Name}$facts, while others could be covered by sentences for handling plurals,conjunctions, etc.",
        "url": " /kr-exercises/ex_13/"
      }
    
  
    ,
      "kr-exercises-ex-12":  {
        "title": "Exercise 12.12",
        "breadcrumb": "12-Knowledge-Representation",
      	"content"  : "Exercise 12.12Write a set of sentences that allows one to calculate the price of anindividual tomato (or other object), given the price per pound. Extendthe theory to allow the price of a bag of tomatoes to be calculated.",
        "url": " /kr-exercises/ex_12/"
      }
    
  
    
  
    ,
      "reinforcement-learning-exercises-ex-3":  {
        "title": "Exercise 21.3",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.3 [prioritized-sweeping-exercise]Starting with the passive ADP agent,modify it to use an approximate ADP algorithm as discussed in the text.Do this in two steps:      Implement a priority queue for adjustments to the utility estimates.Whenever a state is adjusted, all of its predecessors also becomecandidates for adjustment and should be added to the queue. Thequeue is initialized with the state from which the most recenttransition took place. Allow only a fixed number of adjustments.        Experiment with various heuristics for ordering the priority queue,examining their effect on learning rates and computation time.  ",
        "url": " /reinforcement-learning-exercises/ex_3/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-11":  {
        "title": "Exercise 21.11",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.11Implement the REINFORCE and PEGASUS algorithms and apply them to the $4times 3$ world,using a policy family of your own choosing. Comment on the results.",
        "url": " /reinforcement-learning-exercises/ex_11/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-4":  {
        "title": "Exercise 21.4",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.4The direct utility estimation method inSection passive-rl-section uses distinguished terminalstates to indicate the end of a trial. How could it be modified forenvironments with discounted rewards and no terminal states?",
        "url": " /reinforcement-learning-exercises/ex_4/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-7":  {
        "title": "Exercise 21.7",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.7 [approx-LMS-exercise]Implement an exploring reinforcement learningagent that uses direct utility estimation. Make two versions—one with atabular representation and one using the function approximator inEquation (4x3-linear-approx-equation). Compare theirperformance in three environments:      The $4times 3$ world described in the chapter.        A ${10}times {10}$ world with no obstacles and a +1 rewardat (10,10).        A ${10}times {10}$ world with no obstacles and a +1 rewardat (5,5).  ",
        "url": " /reinforcement-learning-exercises/ex_7/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-5":  {
        "title": "Exercise 21.5",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.5Write out the parameter update equations for TD learning with",
        "url": " /reinforcement-learning-exercises/ex_5/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-10":  {
        "title": "Exercise 21.10",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.10 [10x10-exercise]Compute the true utility function and the best linearapproximation in $x$ and $y$ (as inEquation (4x3-linear-approx-equation)) for thefollowing environments:      A ${10}times {10}$ world with a single $+1$ terminal stateat (10,10).        As in (a), but add a $-1$ terminal state at (10,1).        As in (b), but add obstacles in 10 randomly selected squares.        As in (b), but place a wall stretching from (5,2) to (5,9).        As in (a), but with the terminal state at (5,5).  The actions are deterministic moves in the four directions. In eachcase, compare the results using three-dimensional plots. For eachenvironment, propose additional features (besides $x$ and $y$) thatwould improve the approximation and show the results.",
        "url": " /reinforcement-learning-exercises/ex_10/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-8":  {
        "title": "Exercise 21.8",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.8Devise suitable features for reinforcement learning in stochastic gridworlds (generalizations of the $4times 3$ world) that contain multipleobstacles and multiple terminal states with rewards of $+1$ or $-1$.",
        "url": " /reinforcement-learning-exercises/ex_8/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-2":  {
        "title": "Exercise 21.2",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.2Chapter complex-decisions-chapter defined aproper policy for an MDP as one that isguaranteed to reach a terminal state. Show that it is possible for apassive ADP agent to learn a transition model for which its policy $pi$is improper even if $pi$ is proper for the true MDP; with such models,the POLICY-EVALUATION step may fail if $gamma1$. Show that this problem cannotarise if POLICY-EVALUATION is applied to the learned model only at the end of a trial.",
        "url": " /reinforcement-learning-exercises/ex_2/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-9":  {
        "title": "Exercise 21.9",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.9Extend the standard game-playing environment(Chapter game-playing-chapter) to incorporate a rewardsignal. Put two reinforcement learning agents into the environment (theymay, of course, share the agent program) and have them play against eachother. Apply the generalized TD update rule(Equation (generalized-td-equation)) to update theevaluation function. You might wish to start with a simple linearweighted evaluation function and a simple game, such as tic-tac-toe.",
        "url": " /reinforcement-learning-exercises/ex_9/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-6":  {
        "title": "Exercise 21.6",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.6Adapt the vacuum world (Chapter agents-chapter) forreinforcement learning by including rewards for squares being clean.Make the world observable by providing suitable percepts. Now experimentwith different reinforcement learning agents. Is function approximationnecessary for success? What sort of approximator works for thisapplication?",
        "url": " /reinforcement-learning-exercises/ex_6/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-1":  {
        "title": "Exercise 21.1",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.1Implement a passive learning agent in a simple environment, such as the$4times 3$ world. For the case of an initially unknown environmentmodel, compare the learning performance of the direct utilityestimation, TD, and ADP algorithms. Do the comparison for the optimalpolicy and for several random policies. For which do the utilityestimates converge faster? What happens when the size of the environmentis increased? (Try environments with and without obstacles.)",
        "url": " /reinforcement-learning-exercises/ex_1/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-13":  {
        "title": "Exercise 21.13",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.13Is reinforcement learning an appropriate abstract model for evolution?What connection exists, if any, between hardwired reward signals andevolutionary fitness?",
        "url": " /reinforcement-learning-exercises/ex_13/"
      }
    
  
    ,
      "reinforcement-learning-exercises-ex-12":  {
        "title": "Exercise 21.12",
        "breadcrumb": "21-Reinforcement-Learning",
      	"content"  : "Exercise 21.12Investigate the application of reinforcement learning ideas to themodeling of human and animal behavior.",
        "url": " /reinforcement-learning-exercises/ex_12/"
      }
    
  
    
  
    ,
      "perception-exercises-ex-3":  {
        "title": "Exercise 24.3",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.3Consider an infinitely long cylinder of radius $r$ oriented with itsaxis along the $y$-axis. The cylinder has a Lambertian surface and isviewed by a camera along the positive $z$-axis. What will you expect tosee in the image if the cylinder is illuminated by a point source atinfinity located on the positive $x$-axis? Draw the contours of constantbrightness in the projected image. Are the contours of equal brightnessuniformly spaced?",
        "url": " /perception-exercises/ex_3/"
      }
    
  
    ,
      "perception-exercises-ex-4":  {
        "title": "Exercise 24.4",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.4Edges in an image can correspond to a variety of events in a scene.Consider Figure illuminationfigure(page illuminationfigure), and assume that it is a picture of a realthree-dimensional scene. Identify ten different brightness edges in theimage, and for each, state whether it corresponds to a discontinuity in(a) depth, (b) surface orientation, (c) reflectance, or (d)illumination.",
        "url": " /perception-exercises/ex_4/"
      }
    
  
    ,
      "perception-exercises-ex-7":  {
        "title": "Exercise 24.7",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.7Which of the following are true, and which are false?      Finding corresponding points in stereo images is the easiest phaseof the stereo depth-finding process.        In stereo views of the same scene, greater accuracy is obtained inthe depth calculations if the two camera positions arefarther apart.        Lines with equal lengths in the scene always project to equallengths in the image.        Straight lines in the image necessarily correspond to straight linesin the scene.  Figure [bottle-figure] Top view ofa two-camera vision system observing a bottle with a wall behind it.",
        "url": " /perception-exercises/ex_7/"
      }
    
  
    ,
      "perception-exercises-ex-5":  {
        "title": "Exercise 24.5",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.5A stereoscopic system is being contemplated for terrain mapping. It willconsist of two CCD cameras, each having ${512}times {512}$ pixels on a10 cm $times$ 10 cm square sensor. The lenses to be used have a focallength of 16 cm, with the focus fixed at infinity. For correspondingpoints ($u_1,v_1$) in the left image and ($u_2,v_2$) in the right image,$v_1=v_2$ because the $x$-axes in the two image planes are parallel tothe epipolar lines—the lines from the object to the camera. The opticalaxes of the two cameras are parallel. The baseline between the camerasis 1 meter.      If the nearest distance to be measured is 16 meters, what is thelargest disparity that will occur (in pixels)?        What is the distance resolution at 16 meters, due to the pixelspacing?        What distance corresponds to a disparity of one pixel?  ",
        "url": " /perception-exercises/ex_5/"
      }
    
  
    ,
      "perception-exercises-ex-8":  {
        "title": "Exercise 24.8",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.8(Courtesy of Pietro Perona.) Figure bottle-figure showstwo cameras at X and Y observing a scene. Draw the image seen at eachcamera, assuming that all named points are in the same horizontal plane.What can be concluded from these two images about the relative distancesof points A, B, C, D, and E from the camera baseline, and on what basis?",
        "url": " /perception-exercises/ex_8/"
      }
    
  
    ,
      "perception-exercises-ex-2":  {
        "title": "Exercise 24.2",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.2Consider a picture of a white sphere floating in front of a blackbackdrop. The image curve separating white pixels from black pixels issometimes called the “outline” of the sphere. Show that the outline of asphere, viewed in a perspective camera, can be an ellipse. Why dospheres not look like ellipses to you?",
        "url": " /perception-exercises/ex_2/"
      }
    
  
    ,
      "perception-exercises-ex-6":  {
        "title": "Exercise 24.6",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.6Which of the following are true, and which are false?      Finding corresponding points in stereo images is the easiest phaseof the stereo depth-finding process.        Shape-from-texture can be done by projecting a grid of light-stripesonto the scene.        Lines with equal lengths in the scene always project to equallengths in the image.        Straight lines in the image necessarily correspond to straight linesin the scene.  ",
        "url": " /perception-exercises/ex_6/"
      }
    
  
    ,
      "perception-exercises-ex-1":  {
        "title": "Exercise 24.1",
        "breadcrumb": "24-Perception",
      	"content"  : "Exercise 24.1In the shadow of a tree with a dense, leafy canopy, one sees a number oflight spots. Surprisingly, they all appear to be circular. Why? Afterall, the gaps between the leaves through which the sun shines are notlikely to be circular.",
        "url": " /perception-exercises/ex_1/"
      }
    
  
    
  
    ,
      "robotics-exercises-ex-3":  {
        "title": "Exercise 25.3",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.3 [AB-manipulator-ex]Consider a robot with two simple manipulators, asshown in figure figRobot2. Manipulator A is a square block of side 2which can slide back and on a rod that runs along the x-axis fromx=$-$10 to x=10. Manipulator B is a square block of side 2 which canslide back and on a rod that runs along the y-axis from y=-10 to y=10.The rods lie outside the plane of manipulation, so the rods do notinterfere with the movement of the blocks. A configuration is then apair ${langle}x,y{rangle}$ where $x$ is the x-coordinate of the centerof manipulator A and where $y$ is the y-coordinate of the center ofmanipulator B. Draw the configuration space for this robot, indicatingthe permitted and excluded zones.",
        "url": " /robotics-exercises/ex_3/"
      }
    
  
    ,
      "robotics-exercises-ex-11":  {
        "title": "Exercise 25.11",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.11 [subsumption-exercise]In Figure Fig5(b) onpage Fig5, we encountered an augmented finite state machine forthe control of a single leg of a hexapod robot. In this exercise, theaim is to design an AFSM that, when combined with six copies of theindividual leg controllers, results in efficient, stable locomotion. Forthis purpose, you have to augment the individual leg controller to passmessages to your new AFSM and to wait until other messages arrive. Arguewhy your controller is efficient, in that it does not unnecessarilywaste energy (e.g., by sliding legs), and in that it propels the robotat reasonably high speeds. Prove that your controller satisfies thedynamic stability condition given on page polygon-stability-condition-page.",
        "url": " /robotics-exercises/ex_11/"
      }
    
  
    ,
      "robotics-exercises-ex-4":  {
        "title": "Exercise 25.4",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.4Suppose that you are working with the robot inExercise AB-manipulator-ex and you are given theproblem of finding a path from the starting configuration offigure figRobot2 to the ending configuration. Consider a potentialfunction where $D(A,B)$ is the distance between the closest points of A and B.      Show that hill climbing in this potential field will get stuck in alocal minimum.        Describe a potential field where hill climbing will solve thisparticular problem. You need not work out the exact numericalcoefficients needed, just the general form of the solution. (Hint:Add a term that “rewards” the hill climber for moving A out of B’sway, even in a case like this where this does not reduce thedistance from A to B in the above sense.)  ",
        "url": " /robotics-exercises/ex_4/"
      }
    
  
    ,
      "robotics-exercises-ex-7":  {
        "title": "Exercise 25.7",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.7 [voronoi-exercise]Implement an algorithm for calculating the Voronoidiagram of an arbitrary 2D environment, described by an $ntimes n$Boolean array. Illustrate your algorithm by plotting the Voronoi diagramfor 10 interesting maps. What is the complexity of your algorithm?",
        "url": " /robotics-exercises/ex_7/"
      }
    
  
    ,
      "robotics-exercises-ex-5":  {
        "title": "Exercise 25.5",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.5 [inverse-kinematics-exercise]Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is60cm long and that its upper arm and forearm are each 40cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?",
        "url": " /robotics-exercises/ex_5/"
      }
    
  
    ,
      "robotics-exercises-ex-10":  {
        "title": "Exercise 25.10",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.10 [robot-exploration-exercise]Consider the simplified robot shown inFigure FigEx3. Suppose the robot’s Cartesiancoordinates are known at all times, as are those of its goal location.However, the locations of the obstacles are unknown. The robot can senseobstacles in its immediate proximity, as illustrated in this figure. Forsimplicity, let us assume the robot’s motion is noise-free, and thestate space is discrete. Figure FigEx3 is only oneexample; in this exercise you are required to address all possible gridworlds with a valid path from the start to the goal location.      Design a deliberate controller that guarantees that the robot alwaysreaches its goal location if at all possible. The deliberatecontroller can memorize measurements in the form of a map that isbeing acquired as the robot moves. Between individual moves, it mayspend arbitrary time deliberating.        Now design a reactive controller for the same task.This controller may not memorize past sensor measurements. (It maynot build a map!) Instead, it has to make all decisions based on thecurrent measurement, which includes knowledge of its own locationand that of the goal. The time to make a decision must beindependent of the environment size or the number of pasttime steps. What is the maximum number of steps that it may take foryour robot to arrive at the goal?        How will your controllers from (a) and (b) perform if any of thefollowing six conditions apply: continuous state space, noise inperception, noise in motion, noise in both perception and motion,unknown location of the goal (the goal can be detected only whenwithin sensor range), or moving obstacles. For each condition andeach controller, give an example of a situation where the robotfails (or explain why it cannot fail).  ",
        "url": " /robotics-exercises/ex_10/"
      }
    
  
    ,
      "robotics-exercises-ex-8":  {
        "title": "Exercise 25.8",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.8 [confspace-exercise]This exercise explores the relationship betweenworkspace and configuration space using the examples shown inFigure FigEx2.      Consider the robot configurations shown inFigure FigEx2(a) through (c), ignoring the obstacleshown in each of the diagrams. Draw the corresponding armconfigurations in configuration space. (Hint: Eacharm configuration maps to a single point in configuration space, asillustrated in Figure FigArm1(b).)        Draw the configuration space for each of the workspace diagrams inFigure FigEx2(a)–(c). (Hint: Theconfiguration spaces share with the one shown inFigure FigEx2(a) the region that corresponds toself-collision, but differences arise from the lack of enclosingobstacles and the different locations of the obstacles in theseindividual figures.)        For each of the black dots in Figure FigEx2(e)–(f),draw the corresponding configurations of the robot arm in workspace.Please ignore the shaded regions in this exercise.        The configuration spaces shown inFigure FigEx2(e)–(f) have all been generated by asingle workspace obstacle (dark shading), plus the constraintsarising from the self-collision constraint (light shading). Draw,for each diagram, the workspace obstacle that corresponds to thedarkly shaded area.        Figure FigEx2(d) illustrates that a single planarobstacle can decompose the workspace into two disconnected regions.What is the maximum number of disconnected regions that can becreated by inserting a planar obstacle into an obstacle-free,connected workspace, for a 2DOF robot? Give an example, and arguewhy no larger number of disconnected regions can be created. Howabout a non-planar obstacle?  Figure [FigEx2] Diagrams for Exercise [confspace-exercise](#/).            $quadquadquadquadquadquad$      $quadquadquadquadquadquad$      $quadquadquadquadquadquad$                                            (a)      (b)      (c)                                        (d)      (e)      (f)      ",
        "url": " /robotics-exercises/ex_8/"
      }
    
  
    ,
      "robotics-exercises-ex-2":  {
        "title": "Exercise 25.2",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.2 [mcl-implement-exercise]Implement Monte Carlo localization for asimulated robot with range sensors. A grid map and range data areavailable from the code repository ataima.cs.berkeley.edu. You should demonstratesuccessful global localization of the robot.Figure [figRobot2] A Robot manipulator in two of its possible configurations.",
        "url": " /robotics-exercises/ex_2/"
      }
    
  
    ,
      "robotics-exercises-ex-9":  {
        "title": "Exercise 25.9",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.9Consider a mobile robot moving on a horizontal surface. Suppose that therobot can execute two kinds of motions:      Rolling forward a specified distance.        Rotating in place through a specified angle.  The state of such a robot can be characterized in terms of threeparameters ${langle}x,y,phi$, the x-coordinate and y-coordinate of therobot (more precisely, of its center of rotation) and the robot’sorientation expressed as the angle from the positive x direction. Theaction “$Roll(D)$” has the effect of changing state ${langle}x,y,phi$to ${langle}x+D cos(phi), y+D sin(phi), phi {rangle}$, and theaction $Rotate(theta)$ has the effect of changing state${langle}x,y,phi {rangle}$ to${langle}x,y, phi + theta {rangle}$.      Suppose that the robot is initially at ${langle}0,0,0 {rangle}$and then executes the actions $Rotate(60^{circ})$, $Roll(1)$,$Rotate(25^{circ})$, $Roll(2)$. What is the final state of therobot?        Now suppose that the robot has imperfect control of its ownrotation, and that, if it attempts to rotate by $theta$, it mayactually rotate by any angle between $theta-10^{circ}$ and$theta+10^{circ}$. In that case, if the robot attempts to carryout the sequence of actions in (A), there is a range of possibleending states. What are the minimal and maximal values of thex-coordinate, the y-coordinate and the orientation in the finalstate?        Let us modify the model in (B) to a probabilistic model in which,when the robot attempts to rotate by $theta$, its actual angle ofrotation follows a Gaussian distribution with mean $theta$ andstandard deviation $10^{circ}$. Suppose that the robot executes theactions $Rotate(90^{circ})$, $Roll(1)$. Give a simple argumentthat (a) the expected value of the location at the end is not equalto the result of rotating exactly $90^{circ}$ and then rollingforward 1 unit, and (b) that the distribution of locations at theend does not follow a Gaussian. (Do not attempt to calculate thetrue mean or the true distribution.)    The point of this exercise is that rotational uncertainty quicklygives rise to a lot of positional uncertainty and that dealing withrotational uncertainty is painful, whether uncertainty is treated interms of hard intervals or probabilistically, due to the fact thatthe relation between orientation and position is both non-linearand non-monotonic.  Figure [FigEx3] Simplified robot in a maze. See Exercise [robot-exploration-exercise](#/)",
        "url": " /robotics-exercises/ex_9/"
      }
    
  
    ,
      "robotics-exercises-ex-6":  {
        "title": "Exercise 25.6",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.6 [inverse-kinematics-exercise]Consider the robot arm shown inFigure FigArm1. Assume that the robot’s base element is70cm long and that its upper arm and forearm are each 50cm long. Asargued on page inverse-kinematics-not-unique, the inverse kinematics of a robot is oftennot unique. State an explicit closed-form solution of the inversekinematics for this arm. Under what exact conditions is the solutionunique?",
        "url": " /robotics-exercises/ex_6/"
      }
    
  
    ,
      "robotics-exercises-ex-1":  {
        "title": "Exercise 25.1",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.1 [mcl-biasdness-exercise]Monte Carlo localization isbiased for any finite sample size—i.e., the expectedvalue of the location computed by the algorithm differs from the trueexpected value—because of the way particle filtering works. In thisquestion, you are asked to quantify this bias.To simplify, consider a world with four possible robot locations:$X={x_,x_,x_,x_}$. Initially, wedraw $Ngeq $ samples uniformly from among those locations. Asusual, it is perfectly acceptable if more than one sample is generatedfor any of the locations $X$. Let $Z$ be a Boolean sensor variablecharacterized by the following conditional probabilities:MCL uses these probabilities to generate particle weights, which aresubsequently normalized and used in the resampling process. Forsimplicity, let us assume we generate only one new sample in theresampling process, regardless of $N$. This sample might correspond toany of the four locations in $X$. Thus, the sampling process defines aprobability distribution over $X$.      What is the resulting probability distribution over $X$ for this newsample? Answer this question separately for$N=,ldots,}$, and for $N=infty$.        The difference between two probability distributions $P$ and $Q$ canbe measured by the KL divergence, which is defined as What arethe KL divergences between the distributions in (a) and the trueposterior?        What modification of the problem formulation (not the algorithm!)would guarantee that the specific estimator above is unbiased evenfor finite values of $N$? Provide at least two such modifications(each of which should be sufficient).  ",
        "url": " /robotics-exercises/ex_1/"
      }
    
  
    ,
      "robotics-exercises-ex-12":  {
        "title": "Exercise 25.12",
        "breadcrumb": "25-Robotics",
      	"content"  : "Exercise 25.12 [human-robot-exercise](This exercise was first devised by MichaelGenesereth and Nils Nilsson. It works for first graders through graduatestudents.) Humans are so adept at basic household tasks that they oftenforget how complex these tasks are. In this exercise you will discoverthe complexity and recapitulate the last 30 years of developments inrobotics. Consider the task of building an arch out of three blocks.Simulate a robot with four humans as follows:Brain. The Brain direct the hands in the execution of aplan to achieve the goal. The Brain receives input from the Eyes, butcannot see the scene directly. The brain is the only onewho knows what the goal is.Eyes. The Eyes report a brief description of the sceneto the Brain: “There is a red box standing on top of a green box, whichis on its side” Eyes can also answer questions from the Brain such as,“Is there a gap between the Left Hand and the red box?” If you have avideo camera, point it at the scene and allow the eyes to look at theviewfinder of the video camera, but not directly at the scene.Left hand and right hand. One personplays each Hand. The two Hands stand next to each other, each wearing anoven mitt on one hand, Hands execute only simple commands from theBrain—for example, “Left Hand, move two inches forward.” They cannotexecute commands other than motions; for example, they cannot becommanded to “Pick up the box.” The Hands must beblindfolded. The only sensory capability they have is theability to tell when their path is blocked by an immovable obstacle suchas a table or the other Hand. In such cases, they can beep to inform theBrain of the difficulty.",
        "url": " /robotics-exercises/ex_12/"
      }
    
  
    
  
    ,
      "advanced-planning-exercises-ex-3":  {
        "title": "Exercise 11.3",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.3 [HLA-unique-exercise]Suppose that a high-level action has exactly oneimplementation as a sequence of primitive actions. Give an algorithm forcomputing its preconditions and effects, given the complete refinementhierarchy and schemas for the primitive actions.",
        "url": " /advanced-planning-exercises/ex_3/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-11":  {
        "title": "Exercise 11.11",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.11 [alt-vacuum-exercise]Conditional effects were illustrated for the${Suck}$ action in the vacuum world—which square becomes clean dependson which square the robot is in. Can you think of a new set ofpropositional variables to define states of the vacuum world, such that${Suck}$ has an unconditional description? Write outthe descriptions of ${Suck}$, ${Left}$, and ${Right}$, using yourpropositions, and demonstrate that they suffice to describe all possiblestates of the world.",
        "url": " /advanced-planning-exercises/ex_11/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-14":  {
        "title": "Exercise 11.14",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.14Consider the following problem: A patient arrives at the doctor’s officewith symptoms that could have been caused either by dehydration or bydisease $D$ (but not both). There are two possible actions: ${Drink}$,which unconditionally cures dehydration, and ${Medicate}$, which curesdisease $D$ but has an undesirable side effect if taken when the patientis dehydrated. Write the problem description, and diagram a sensorlessplan that solves the problem, enumerating all relevant possible worlds.",
        "url": " /advanced-planning-exercises/ex_14/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-4":  {
        "title": "Exercise 11.4",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.4Suppose that the optimistic reachable set of a high-level plan is asuperset of the goal set; can anything be concluded about whether theplan achieves the goal? What if the pessimistic reachable set doesn’tintersect the goal set? Explain.",
        "url": " /advanced-planning-exercises/ex_4/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-7":  {
        "title": "Exercise 11.7",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.7Some of the operations in standard programming languages can be modeledas actions that change the state of the world. For example, theassignment operation changes the contents of a memory location, and theprint operation changes the state of the output stream. A programconsisting of these operations can also be considered as a plan, whosegoal is given by the specification of the program. Therefore, planningalgorithms can be used to construct programs that achieve a givenspecification.      Write an action schema for the assignment operator (assigning thevalue of one variable to another). Remember that the original valuewill be overwritten!        Show how object creation can be used by a planner to produce a planfor exchanging the values of two variables by using atemporary variable.  ",
        "url": " /advanced-planning-exercises/ex_7/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-5":  {
        "title": "Exercise 11.5",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.5 [HLA-progression-exercise]Write an algorithm that takes an initialstate (specified by a set of propositional literals) and a sequence ofHLAs (each defined by preconditions and angelic specifications ofoptimistic and pessimistic reachable sets) and computes optimistic andpessimistic descriptions of the reachable set of the sequence.",
        "url": " /advanced-planning-exercises/ex_5/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-10":  {
        "title": "Exercise 11.10",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.10In the blocks world we were forced to introduce two action schemas,${Move}$ and ${MoveToTable}$, in order to maintain the ${Clear}$predicate properly. Show how conditional effects can be used torepresent both of these cases with a single action.",
        "url": " /advanced-planning-exercises/ex_10/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-15":  {
        "title": "Exercise 11.15",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.15To the medication problem in the previous exercise, add a ${Test}$action that has the conditional effect ${CultureGrowth}$ when${Disease}$ is true and in any case has the perceptual effect${Known}({CultureGrowth})$. Diagram a conditional plan that solvesthe problem and minimizes the use of the ${Medicate}$ action.",
        "url": " /advanced-planning-exercises/ex_15/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-8":  {
        "title": "Exercise 11.8",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.8Consider the following argument: In a framework that allows uncertaininitial states, nondeterministic effectsare just a notational convenience, not a source of additionalrepresentational power. For any action schema $a$ with nondeterministiceffect $P lor Q$, we could always replace it with the conditionaleffects ${~R{:}~P} land{~lnot R{:}~Q}$, which in turn can bereduced to two regular actions. The proposition $R$ stands for a randomproposition that is unknown in the initial state and for which there areno sensing actions. Is this argument correct? Consider separately twocases, one in which only one instance of action schema $a$ is in theplan, the other in which more than one instance is.",
        "url": " /advanced-planning-exercises/ex_8/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-2":  {
        "title": "Exercise 11.2",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.2You have a number of trucks with which to deliver a set of packages.Each package starts at some location on a grid map, and has adestination somewhere else. Each truck is directly controlled by movingforward and turning. Construct a hierarchy of high-level actions forthis problem. What knowledge about the solution does your hierarchyencode?",
        "url": " /advanced-planning-exercises/ex_2/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-9":  {
        "title": "Exercise 11.9",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.9 [conformant-flip-literal-exercise]Suppose the ${Flip}$ actionalways changes the truth value of variable $L$. Show how to define itseffects by using an action schema with conditional effects. Show that,despite the use of conditional effects, a 1-CNF belief staterepresentation remains in 1-CNF after a ${Flip}$.",
        "url": " /advanced-planning-exercises/ex_9/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-6":  {
        "title": "Exercise 11.6",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.6In Figure jobshop-cpm-figure we showed how to describeactions in a scheduling problem by using separate fields for , , and .Now suppose we wanted to combine scheduling with nondeterministicplanning, which requires nondeterministic and conditional effects.Consider each of the three fields and explain if they should remainseparate fields, or if they should become effects of the action. Give anexample for each of the three.",
        "url": " /advanced-planning-exercises/ex_6/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-1":  {
        "title": "Exercise 11.1",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.1The goals we have considered so far all ask the planner to make theworld satisfy the goal at just one time step. Not all goals can beexpressed this way: you do not achieve the goal of suspending achandelier above the ground by throwing it in the air. More seriously,you wouldn’t want your spacecraft life-support system to supply oxygenone day but not the next. A maintenance goal is achievedwhen the agent’s plan causes a condition to hold continuously from agiven state onward. Describe how to extend the formalism of this chapterto support maintenance goals.",
        "url": " /advanced-planning-exercises/ex_1/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-13":  {
        "title": "Exercise 11.13",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.13The following quotes are from the backs of shampoo bottles. Identifyeach as an unconditional, conditional, or execution-monitoring plan. (a)“Lather. Rinse. Repeat.” (b) “Apply shampoo to scalp and let it remainfor several minutes. Rinse and repeat if necessary.” (c) “See a doctorif problems persist.”",
        "url": " /advanced-planning-exercises/ex_13/"
      }
    
  
    ,
      "advanced-planning-exercises-ex-12":  {
        "title": "Exercise 11.12",
        "breadcrumb": "11-Planning-And-Acting-In-The-Real-World",
      	"content"  : "Exercise 11.12Find a suitably dirty carpet, free of obstacles, and vacuum it. Draw thepath taken by the vacuum cleaner as accurately as you can. Explain it,with reference to the forms of planning discussed in this chapter.",
        "url": " /advanced-planning-exercises/ex_12/"
      }
    
  
    
  
    ,
      "logical-inference-exercises-ex-28":  {
        "title": "Exercise 9.28",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.28From “Sheep are animals,” it follows that “The head of a sheep is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:      Translate the premise and the conclusion into the language offirst-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning“$h$ is the head of $x$”), ${Sheep}(x)$, and ${Animal}(x)$.        Negate the conclusion, and convert the premise and the negatedconclusion into conjunctive normal form.        Use resolution to show that the conclusion follows from the premise.  ",
        "url": " /logical-inference-exercises/ex_28/"
      }
    
  
    ,
      "logical-inference-exercises-ex-29":  {
        "title": "Exercise 9.29",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.29 [quantifier-order-exercise]Here are two sentences in the language offirst-order logic:      (A)${forall,x;;} {exists,y;;} ( x geq y )$        (B)${exists,y;;} {forall,x;;} ( x geq y )$        Assume that the variables range over all the natural numbers$0,1,2,ldots, infty$ and that the “$geq$” predicate means “isgreater than or equal to.” Under this interpretation, translate (A)and (B) into English.        Is (A) true under this interpretation?        Is (B) true under this interpretation?        Does (A) logically entail (B)?        Does (B) logically entail (A)?        Using resolution, try to prove that (A) follows from (B). Do thiseven if you think that (B) does not logically entail (A); continueuntil the proof breaks down and you cannot proceed (if it doesbreak down). Show the unifying substitution for each resolutionstep. If the proof fails, explain exactly where, how, and why itbreaks down.        Now try to prove that (B) follows from (A).  ",
        "url": " /logical-inference-exercises/ex_29/"
      }
    
  
    ,
      "logical-inference-exercises-ex-3":  {
        "title": "Exercise 9.3",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.3Suppose a knowledge base contains just one sentence,$exists,x {AsHighAs}(x,{Everest})$. Which of the following arelegitimate results of applying Existential Instantiation?      ${AsHighAs}({Everest},{Everest})$.        ${AsHighAs}({Kilimanjaro},{Everest})$.        ${AsHighAs}({Kilimanjaro},{Everest}) land {AsHighAs}({BenNevis},{Everest})$(after two applications).  ",
        "url": " /logical-inference-exercises/ex_3/"
      }
    
  
    ,
      "logical-inference-exercises-ex-11":  {
        "title": "Exercise 9.11",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.11Suppose you are given the following axioms:      $0 leq 3$.    $7 leq 9$.    ${forall,x;;} ; ; x leq x$.    ${forall,x;;} ; ; x leq x+0$.    ${forall,x;;} ; ; x+0 leq x$.    ${forall,x,y;;} ; ; x+y leq y+x$.    ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z$ ${:;{Rightarrow}:;}$ $w+x leq y+z$.    ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$        Give a backward-chaining proof of the sentence $7 leq 3+9$. (Besure, of course, to use only the axioms given here, not anythingelse you may know about arithmetic.) Show only the steps that leadsto success, not the irrelevant steps.        Give a forward-chaining proof of the sentence $7 leq 3+9$. Again,show only the steps that lead to success.  ",
        "url": " /logical-inference-exercises/ex_11/"
      }
    
  
    ,
      "logical-inference-exercises-ex-14":  {
        "title": "Exercise 9.14",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.14Suppose we put into a logical knowledge base a segment of theU.S. census data listing the age, city of residence, date of birth, andmother of every person, using social security numbers as identifyingconstants for each person. Thus, George’s age is given by${Age}(mbox443-{65}-{1282}}, {56})$. Which of the followingindexing schemes S1–S5 enable an efficient solution for which of thequeries Q1–Q4 (assuming normal backward chaining)?  S1: an index for each atom in each position.  S2: an index for each first argument.  S3: an index for each predicate atom.  S4: an index for each combination of predicate and first argument.  S5: an index for each combination of predicate and second argument and an index for each first argument.  Q1: ${Age}(mbox 443-44-4321,x)$  Q2: ${ResidesIn}(x,{Houston})$  Q3: ${Mother}(x,y)$  Q4: ${Age}(x,{34}) land {ResidesIn}(x,{TinyTownUSA})$",
        "url": " /logical-inference-exercises/ex_14/"
      }
    
  
    ,
      "logical-inference-exercises-ex-4":  {
        "title": "Exercise 9.4",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.4For each pair of atomic sentences, give the most general unifier if itexists:      $P(A,B,B)$, $P(x,y,z)$.        $Q(y,G(A,B))$, $Q(G(x,x),y)$.        ${Older}({Father}(y),y)$, ${Older}({Father}(x),{John})$.        ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.  ",
        "url": " /logical-inference-exercises/ex_4/"
      }
    
  
    ,
      "logical-inference-exercises-ex-23":  {
        "title": "Exercise 9.23",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.23Suppose a knowledge base contains just the following first-order Hornclauses:Consider a forward chaining algorithm that, on the $j$th iteration,terminates if the KB contains a sentence that unifies with the query,else adds to the KB every atomic sentence that can be inferred from thesentences already in the KB after iteration $j-1$.      For each of the following queries, say whether the algorithmwill (1) give an answer (if so, write down that answer); or (2)terminate with no answer; or (3) never terminate.                  $Ancestor(Mother(y),John)$                    $Ancestor(Mother(Mother(y)),John)$                    $Ancestor(Mother(Mother(Mother(y))),Mother(y))$                    $Ancestor(Mother(John),Mother(Mother(John)))$                  Can a resolution algorithm prove the sentence$lnot Ancestor(John,John)$ from the original knowledge base?Explain how, or why not.        Suppose we add the assertion that $lnot(Mother(x)x)$ andaugment the resolution algorithm with inference rules for equality.Now what is the answer to (b)?  ",
        "url": " /logical-inference-exercises/ex_23/"
      }
    
  
    ,
      "logical-inference-exercises-ex-20":  {
        "title": "Exercise 9.20",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.20This exercise looks at sorting in Prolog.      Write Prolog clauses that define the predicatesorted(L), which is true if and only if listL is sorted in ascending order.        Write a Prolog definition for the predicate perm(L,M),which is true if and only if L is a permutation ofM.        Define sort(L,M) (M is a sorted version ofL) using perm and sorted.        Run sort on longer and longer lists until you losepatience. What is the time complexity of your program?        Write a faster sorting algorithm, such as insertion sort orquicksort, in Prolog.  ",
        "url": " /logical-inference-exercises/ex_20/"
      }
    
  
    ,
      "logical-inference-exercises-ex-7":  {
        "title": "Exercise 9.7",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.7 [fol-horses-exercise]Write down logical representations for thefollowing sentences, suitable for use with Generalized Modus Ponens:      Horses, cows, and pigs are mammals.        An offspring of a horse is a horse.        Bluebeard is a horse.        Bluebeard is Charlie’s parent.        Offspring and parent are inverse relations.        Every mammal has a parent.  ",
        "url": " /logical-inference-exercises/ex_7/"
      }
    
  
    ,
      "logical-inference-exercises-ex-17":  {
        "title": "Exercise 9.17",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.17 [bc-trace-exercise]Trace the execution of the backward-chainingalgorithm in Figure backward-chaining-algorithm(page backward-chaining-algorithm) when it is applied to solve the crime problem(page west-problem-page). Show the sequence of values taken on by the${goals}$ variable, and arrange them into a tree.",
        "url": " /logical-inference-exercises/ex_17/"
      }
    
  
    ,
      "logical-inference-exercises-ex-5":  {
        "title": "Exercise 9.5",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.5For each pair of atomic sentences, give the most general unifier if itexists:      $P(A,A,B)$, $P(x,y,z)$.        $Q(y,G(A,B))$, $Q(G(x,x),y)$.        ${Older}({Father}(y),y)$, ${Older}({Father}(x),{Jerry})$.        ${Knows}({Father}(y),y)$, ${Knows}(x,x)$.  ",
        "url": " /logical-inference-exercises/ex_5/"
      }
    
  
    ,
      "logical-inference-exercises-ex-25":  {
        "title": "Exercise 9.25",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.25How can resolution be used to show that a sentence is valid?Unsatisfiable?",
        "url": " /logical-inference-exercises/ex_25/"
      }
    
  
    ,
      "logical-inference-exercises-ex-10":  {
        "title": "Exercise 9.10",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.10 [csp-clause-exercise]Explain how to write any given 3-SAT problem ofarbitrary size using a single first-order definite clause and no morethan 30 ground facts.",
        "url": " /logical-inference-exercises/ex_10/"
      }
    
  
    ,
      "logical-inference-exercises-ex-22":  {
        "title": "Exercise 9.22",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.22This exercise considers the implementation of search algorithms inProlog. Suppose that successor(X,Y) is true when stateY is a successor of state X; and thatgoal(X) is true when X is a goal state. Writea definition for solve(X,P), which means thatP is a path (list of states) beginning with X,ending in a goal state, and consisting of a sequence of legal steps asdefined by successor. You will find that depth-first searchis the easiest way to do this. How easy would it be to add heuristicsearch control?",
        "url": " /logical-inference-exercises/ex_22/"
      }
    
  
    ,
      "logical-inference-exercises-ex-18":  {
        "title": "Exercise 9.18",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.18The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)    P(X,[X|Y]).    P(X,[Y|Z]) :- P(X,Z).      Show proof trees and solutions for the queriesP(A,[2,1,3]) and P(2,[1,A,3]).        What standard list operation does P represent?  ",
        "url": " /logical-inference-exercises/ex_18/"
      }
    
  
    ,
      "logical-inference-exercises-ex-31":  {
        "title": "Exercise 9.31",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.31We said in this chapter that resolution cannot be used to generate alllogical consequences of a set of sentences. Can any algorithm do this?",
        "url": " /logical-inference-exercises/ex_31/"
      }
    
  
    ,
      "logical-inference-exercises-ex-24":  {
        "title": "Exercise 9.24",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.24Let $cal L$ be the first-order language with a single predicate$S(p,q)$, meaning “$p$ shaves  $q$.” Assume a domain of people.      Consider the sentence “There exists a person $P$ who shaves everyone who does not shave themselves, and only people that do notshave themselves.” Express this in $cal L$.        Convert the sentence in (a) to clausal form.        Construct a resolution proof to show that the clauses in (b) areinherently inconsistent. (Note: you do not need anyadditional axioms.)  ",
        "url": " /logical-inference-exercises/ex_24/"
      }
    
  
    ,
      "logical-inference-exercises-ex-15":  {
        "title": "Exercise 9.15",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.15 [standardize-failure-exercise]One might suppose that we can avoid theproblem of variable conflict in unification during backward chaining bystandardizing apart all of the sentences in the knowledge base once andfor all. Show that, for some sentences, this approach cannot work.(Hint: Consider a sentence in which one part unifies withanother.)",
        "url": " /logical-inference-exercises/ex_15/"
      }
    
  
    ,
      "logical-inference-exercises-ex-16":  {
        "title": "Exercise 9.16",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.16In this exercise, use the sentences you wrote inExercise fol-horses-exercise to answer a question byusing a backward-chaining algorithm.      Draw the proof tree generated by an exhaustive backward-chainingalgorithm for the query ${exists,h;;}{Horse}(h)$, whereclauses are matched in the order given.        What do you notice about this domain?        How many solutions for $h$ actually follow from your sentences?        Can you think of a way to find all of them? (Hint:See @Smith+al:1986.)  ",
        "url": " /logical-inference-exercises/ex_16/"
      }
    
  
    ,
      "logical-inference-exercises-ex-30":  {
        "title": "Exercise 9.30",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.30Resolution can produce nonconstructive proofs for queries withvariables, so we had to introduce special mechanisms to extract definiteanswers. Explain why this issue does not arise with knowledge basescontaining only definite clauses.",
        "url": " /logical-inference-exercises/ex_30/"
      }
    
  
    ,
      "logical-inference-exercises-ex-8":  {
        "title": "Exercise 9.8",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.8These questions concern concern issues with substitution andSkolemization.      Given the premise ${forall,x;;} {exists,y;;} P(x,y)$, it isnot valid to conclude that ${exists,q;;} P(q,q)$. Give anexample of a predicate $P$ where the first is true but the secondis false.        Suppose that an inference engine is incorrectly written with theoccurs check omitted, so that it allows a literal like $P(x,F(x))$to be unified with $P(q,q)$. (As mentioned, most standardimplementations of Prolog actually do allow this.) Show that such aninference engine will allow the conclusion ${exists,y;;} P(q,q)$to be inferred from the premise${forall,x;;} {exists,y;;} P(x,y)$.        Suppose that a procedure that converts first-order logic to clausalform incorrectly Skolemizes${forall,x;;} {exists,y;;} P(x,y)$ to $P(x,Sk0)$—that is, itreplaces $y$ by a Skolem constant rather than by a Skolem functionof $x$. Show that an inference engine that uses such a procedurewill likewise allow ${exists,q;;} P(q,q)$ to be inferred fromthe premise ${forall,x;;} {exists,y;;} P(x,y)$.        A common error among students is to suppose that, in unification,one is allowed to substitute a term for a Skolem constant instead offor a variable. For instance, they will say that the formulas$P(Sk1)$ and $P(A)$ can be unified under the substitution${ Sk1/A }$. Give an example where this leads to aninvalid inference.  ",
        "url": " /logical-inference-exercises/ex_8/"
      }
    
  
    ,
      "logical-inference-exercises-ex-2":  {
        "title": "Exercise 9.2",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.2From ${Likes}({Jerry},{IceCream})$ it seems reasonable to infer${exists,x;;}{Likes}(x,{IceCream})$. Write down a general inference rule, , thatsanctions this inference. State carefully the conditions that must besatisfied by the variables and terms involved.",
        "url": " /logical-inference-exercises/ex_2/"
      }
    
  
    ,
      "logical-inference-exercises-ex-9":  {
        "title": "Exercise 9.9",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.9This question considers Horn KBs, such as the following: Let FC be a breadth-first forward-chaining algorithm thatrepeatedly adds all consequences of currently satisfied rules; let BC bea depth-first left-to-right backward-chaining algorithm that triesclauses in the order given in the KB. Which of the following are true?      FC will infer the literal $Q(A)$.        FC will infer the literal $P(B)$.        If FC has failed to infer a given literal, then it is not entailedby the KB.        BC will return ${true}$ given the query $P(B)$.        If BC does not return ${true}$ given a query literal, then it isnot entailed by the KB.  ",
        "url": " /logical-inference-exercises/ex_9/"
      }
    
  
    ,
      "logical-inference-exercises-ex-19":  {
        "title": "Exercise 9.19",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.19The following Prolog code defines a predicate P. (Rememberthat uppercase terms are variables, not constants, in Prolog.)    P(X,[X|Y]).    P(X,[Y|Z]) :- P(X,Z).      Show proof trees and solutions for the queriesP(A,[1,2,3]) and P(2,[1,A,3]).        What standard list operation does P represent?  ",
        "url": " /logical-inference-exercises/ex_19/"
      }
    
  
    ,
      "logical-inference-exercises-ex-27":  {
        "title": "Exercise 9.27",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.27From “Horses are animals,” it follows that “The head of a horse is thehead of an animal.” Demonstrate that this inference is valid by carryingout the following steps:      Translate the premise and the conclusion into the language offirst-order logic. Use three predicates: ${HeadOf}(h,x)$ (meaning“$h$ is the head of $x$”), ${Horse}(x)$, and ${Animal}(x)$.        Negate the conclusion, and convert the premise and the negatedconclusion into conjunctive normal form.        Use resolution to show that the conclusion follows from the premise.  ",
        "url": " /logical-inference-exercises/ex_27/"
      }
    
  
    ,
      "logical-inference-exercises-ex-6":  {
        "title": "Exercise 9.6",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.6 [subsumption-lattice-exercise]Consider the subsumption lattices shownin Figure subsumption-lattice-figure(page subsumption-lattice-figure).      Construct the lattice for the sentence${Employs}({Mother}({John}),{Father}({Richard}))$.        Construct the lattice for the sentence ${Employs}({IBM},y)$(“Everyone works for IBM”). Remember to include every kind of querythat unifies with the sentence.        Assume that indexes each sentence under every node in itssubsumption lattice. Explain how should work when some of thesesentences contain variables; use as examples the sentences in (a)and (b) and the query ${Employs}(x,{Father}(x))$.  ",
        "url": " /logical-inference-exercises/ex_6/"
      }
    
  
    ,
      "logical-inference-exercises-ex-26":  {
        "title": "Exercise 9.26",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.26Construct an example of two clauses that can be resolved together in twodifferent ways giving two different outcomes.",
        "url": " /logical-inference-exercises/ex_26/"
      }
    
  
    ,
      "logical-inference-exercises-ex-21":  {
        "title": "Exercise 9.21",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.21 [diff-simplify-exercise]This exercise looks at the recursiveapplication of rewrite rules, using logic programming. A rewrite rule(or demodulator in terminology) is anequation with a specified direction. For example, the rewrite rule$x+0 rightarrow x$ suggests replacing any expression that matches $x+0$with the expression $x$. Rewrite rules are a key component of equationalreasoning systems. Use the predicate rewrite(X,Y) torepresent rewrite rules. For example, the earlier rewrite rule iswritten as rewrite(X+0,X). Some terms areprimitive and cannot be further simplified; thus, wewrite primitive(0) to say that 0 is a primitive term.      Write a definition of a predicate simplify(X,Y), thatis true when Y is a simplified version ofX—that is, when no further rewrite rules apply to anysubexpression of Y.        Write a collection of rules for the simplification of expressionsinvolving arithmetic operators, and apply your simplificationalgorithm to some sample expressions.        Write a collection of rewrite rules for symbolic differentiation,and use them along with your simplification rules to differentiateand simplify expressions involving arithmetic expressions,including exponentiation.  ",
        "url": " /logical-inference-exercises/ex_21/"
      }
    
  
    ,
      "logical-inference-exercises-ex-1":  {
        "title": "Exercise 9.1",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.1Prove that Universal Instantiation is sound and that ExistentialInstantiation produces an inferentially equivalent knowledge base.",
        "url": " /logical-inference-exercises/ex_1/"
      }
    
  
    ,
      "logical-inference-exercises-ex-13":  {
        "title": "Exercise 9.13",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.13A popular children’s riddle is “Brothers and sisters have I none, butthat man’s father is my father’s son.” Use the rules of the familydomain (Section kinship-domain-section onpage kinship-domain-section) to show who that man is. You may apply any of theinference methods described in this chapter. Why do you think that thisriddle is difficult?",
        "url": " /logical-inference-exercises/ex_13/"
      }
    
  
    ,
      "logical-inference-exercises-ex-12":  {
        "title": "Exercise 9.12",
        "breadcrumb": "9-Inference-In-First-Order-Logic",
      	"content"  : "Exercise 9.12Suppose you are given the following axioms:      $0 leq 4$.        $5 leq 9$.        ${forall,x;;} ; ; x leq x$.        ${forall,x;;} ; ; x leq x+0$.        ${forall,x;;} ; ; x+0 leq x$.        ${forall,x,y;;} ; ; x+y leq y+x$.        ${forall,w,x,y,z;;} ; ; w leq y$ $wedge$ $x leq z {:;{Rightarrow}:;}$ $w+x leq y+z$.        ${forall,x,y,z;;} ; ; x leq y wedge y leq z : {:;{Rightarrow}:;}: x leq z$        Give a backward-chaining proof of the sentence $5 leq 4+9$. (Besure, of course, to use only the axioms given here, not anythingelse you may know about arithmetic.) Show only the steps that leadsto success, not the irrelevant steps.        Give a forward-chaining proof of the sentence $5 leq 4+9$. Again,show only the steps that lead to success.  ",
        "url": " /logical-inference-exercises/ex_12/"
      }
    
  
    
  
    ,
      "dbn-exercises-ex-3":  {
        "title": "Exercise 15.3",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.3 [island-exercise]This exercise develops a space-efficient variant ofthe forward–backward algorithm described inFigure forward-backward-algorithm (page forward-backward-algorithm).We wish to compute  for. This will be done with a divide-and-conquerapproach.      Suppose, for simplicity, that $t$ is odd, and let the halfway pointbe $h=(t+1)/2$. Show that  can be computed for$k=1,ldots ,h$ given just the initial forward message, the backward message , and the evidence.        Show a similar result for the second half of the sequence.        Given the results of (a) and (b), a recursive divide-and-conqueralgorithm can be constructed by first running forward along thesequence and then backward from the end, storing just the requiredmessages at the middle and the ends. Then the algorithm is called oneach half. Write out the algorithm in detail.        Compute the time and space complexity of the algorithm as a functionof $t$, the length of the sequence. How does this change if wedivide the input into more than two pieces?  ",
        "url": " /dbn-exercises/ex_3/"
      }
    
  
    ,
      "dbn-exercises-ex-11":  {
        "title": "Exercise 15.11",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.11This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .7 on each step; the robot switches to arandomly selected new heading with probability .3 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?Figure [switching-kf-figure] A Bayesian network representation of a switching Kalman filter. The switching variable $S_t$ is a discrete state variable whose value determinesthe transition model for the continuous state variables $textbf{X}_t$.For any discrete state $textit{i}$, the transition model$textbf{P}(textbf{X}_{t+1}|textbf{X}_t,S_t= i)$ is a linear Gaussian model, just as in aregular Kalman filter. The transition model for the discrete state,$textbf{P}(S_{t+1}|S_t)$, can be thought of as a matrix, as in a hiddenMarkov model.",
        "url": " /dbn-exercises/ex_11/"
      }
    
  
    ,
      "dbn-exercises-ex-14":  {
        "title": "Exercise 15.14",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.14 [kalman-variance-exercise]Let us examine the behavior of the varianceupdate in Equation (kalman-univariate-equation)(page kalman-univariate-equation).      Plot the value of $sigma_t^2$ as a function of $t$, given variousvalues for $sigma_x^2$ and $sigma_z^2$.        Show that the update has a fixed point $sigma^2$ such that$sigma_t^2 rightarrow sigma^2$ as $t rightarrow infty$, andcalculate the value of $sigma^2$.        Give a qualitative explanation for what happens as$sigma_x^2rightarrow 0$ and as $sigma_z^2rightarrow 0$.  ",
        "url": " /dbn-exercises/ex_14/"
      }
    
  
    ,
      "dbn-exercises-ex-4":  {
        "title": "Exercise 15.4",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.4 [flawed-viterbi-exercise]On page flawed-viterbi-page, we outlined a flawedprocedure for finding the most likely state sequence, given anobservation sequence. The procedure involves finding the most likelystate at each time step, using smoothing, and returning the sequencecomposed of these states. Show that, for some temporal probabilitymodels and observation sequences, this procedure returns an impossiblestate sequence (i.e., the posterior probability of the sequence iszero).",
        "url": " /dbn-exercises/ex_4/"
      }
    
  
    ,
      "dbn-exercises-ex-20":  {
        "title": "Exercise 15.20",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.20 [dbn-elimination-exercise]Consider applying the variable eliminationalgorithm to the umbrella DBN unrolled for three slices, where the queryis ${textbf{P}}(R_3|u_1,u_2,u_3)$. Show that the spacecomplexity of the algorithm—the size of the largest factor—is the same,regardless of whether the rain variables are eliminated in forward orbackward order.",
        "url": " /dbn-exercises/ex_20/"
      }
    
  
    ,
      "dbn-exercises-ex-7":  {
        "title": "Exercise 15.7",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.7 [hmm-robust-exercise]In Section hmm-localization-section, the priordistribution over locations is uniform and the transition model assumesan equal probability of moving to any neighboring square. What if thoseassumptions are wrong? Suppose that the initial location is actuallychosen uniformly from the northwest quadrant of the room and the actionactually tends to move southeast[hmm-robot-southeast-page]. Keepingthe HMM model fixed, explore the effect on localization and pathaccuracy as the southeasterly tendency increases, for different valuesof $epsilon$.",
        "url": " /dbn-exercises/ex_7/"
      }
    
  
    ,
      "dbn-exercises-ex-17":  {
        "title": "Exercise 15.17",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.17For the DBN specified in Exercise sleep1-exercise andfor the evidence valuesperform the following computations:      State estimation: Compute  for eachof $t = 1,2,3$.        Smoothing: Compute  for each of$t = 1,2,3$.        Compare the filtered and smoothed probabilities for $t=1$ and $t=2$.  ",
        "url": " /dbn-exercises/ex_17/"
      }
    
  
    ,
      "dbn-exercises-ex-5":  {
        "title": "Exercise 15.5",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.5 [hmm-likelihood-exercise]Equation (matrix-filtering-equation) describes thefiltering process for the matrix formulation of HMMs. Give a similarequation for the calculation of likelihoods, which was describedgenerically in Equation (forward-likelihood-equation).",
        "url": " /dbn-exercises/ex_5/"
      }
    
  
    ,
      "dbn-exercises-ex-10":  {
        "title": "Exercise 15.10",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.10This exercise is concerned with filtering in an environment with nolandmarks. Consider a vacuum robot in an empty room, represented by an$n times m$ rectangular grid. The robot’s location is hidden; the onlyevidence available to the observer is a noisy location sensor that givesan approximation to the robot’s location. If the robot is at location$(x, y)$ then with probability .1 the sensor gives the correct location,with probability .05 each it reports one of the 8 locations immediatelysurrounding $(x, y)$, with probability .025 each it reports one of the16 locations that surround those 8, and with the remaining probabilityof .1 it reports “no reading.” The robot’s policy is to pick a directionand follow it with probability .8 on each step; the robot switches to arandomly selected new heading with probability .2 (or with probability 1if it encounters a wall). Implement this as an HMM and do filtering totrack the robot. How accurately can we track the robot’s path?",
        "url": " /dbn-exercises/ex_10/"
      }
    
  
    ,
      "dbn-exercises-ex-18":  {
        "title": "Exercise 15.18",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.18Suppose that a particular student shows up with red eyes and sleeps inclass every day. Given the model described inExercise sleep1-exercise, explain why the probabilitythat the student had enough sleep the previous night converges to afixed point rather than continuing to go down as we gather more days ofevidence. What is the fixed point? Answer this both numerically (bycomputation) and analytically.",
        "url": " /dbn-exercises/ex_18/"
      }
    
  
    ,
      "dbn-exercises-ex-15":  {
        "title": "Exercise 15.15",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.15 [sleep1-exercise]A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:      The prior probability of getting enough sleep, with no observations,is 0.7.        The probability of getting enough sleep on night $t$ is 0.8 giventhat the student got enough sleep the previous night, and 0.3if not.        The probability of having red eyes is 0.2 if the student got enoughsleep, and 0.7 if not.        The probability of sleeping in class is 0.1 if the student gotenough sleep, and 0.3 if not.  Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.",
        "url": " /dbn-exercises/ex_15/"
      }
    
  
    ,
      "dbn-exercises-ex-16":  {
        "title": "Exercise 15.16",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.16 [sleep1-exercise]A professor wants to know if students are gettingenough sleep. Each day, the professor observes whether the studentssleep in class, and whether they have red eyes. The professor has thefollowing domain theory:      The prior probability of getting enough sleep, with no observations,is 0.6.        The probability of getting enough sleep on night $t$ is 0.8 giventhat the student got enough sleep the previous night, and 0.2if not.        The probability of having red eyes is 0.2 if the student got enoughsleep, and 0.7 if not.        The probability of sleeping in class is 0.1 if the student gotenough sleep, and 0.3 if not.  Formulate this information as a dynamic Bayesian network that theprofessor could use to filter or predict from a sequence ofobservations. Then reformulate it as a hidden Markov model that has onlya single observation variable. Give the complete probability tables forthe model.",
        "url": " /dbn-exercises/ex_16/"
      }
    
  
    ,
      "dbn-exercises-ex-8":  {
        "title": "Exercise 15.8",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.8 [roomba-viterbi-exercise]Consider a version of the vacuum robot(page vacuum-maze-hmm2-figure) that has the policy of going straight for as longas it can; only when it encounters an obstacle does it change to a new(randomly selected) heading. To model this robot, each state in themodel consists of a (location, heading) pair. Implementthis model and see how well the Viterbi algorithm can track a robot withthis model. The robot’s policy is more constrained than the random-walkrobot; does that mean that predictions of the most likely path are moreaccurate?",
        "url": " /dbn-exercises/ex_8/"
      }
    
  
    ,
      "dbn-exercises-ex-2":  {
        "title": "Exercise 15.2",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.2 [markov-convergence-exercise]In this exercise, we examine whathappens to the probabilities in the umbrella world in the limit of longtime sequences.      Suppose we observe an unending sequence of days on which theumbrella appears. Show that, as the days go by, the probability ofrain on the current day increases monotonically toward afixed point. Calculate this fixed point.        Now consider forecasting further and further into thefuture, given just the first two umbrella observations. First,compute the probability $P(r_{2+k}|u_1,u_2)$ for$k=1 ldots 20$ and plot the results. You should see thatthe probability converges towards a fixed point. Prove that theexact value of this fixed point is 0.5.  ",
        "url": " /dbn-exercises/ex_2/"
      }
    
  
    ,
      "dbn-exercises-ex-9":  {
        "title": "Exercise 15.9",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.9We have described three policies for the vacuum robot: (1) a uniformrandom walk, (2) a bias for wandering southeast, as described inExercise hmm-robust-exercise, and (3) the policydescribed in Exercise roomba-viterbi-exercise. Supposean observer is given the observation sequence from a vacuum robot, butis not sure which of the three policies the robot is following. Whatapproach should the observer use to find the most likely path, given theobservations? Implement the approach and test it. How much does thelocalization accuracy suffer, compared to the case in which the observerknows which policy the robot is following?",
        "url": " /dbn-exercises/ex_9/"
      }
    
  
    ,
      "dbn-exercises-ex-19":  {
        "title": "Exercise 15.19",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.19 [battery-sequence-exercise]This exercise analyzes in more detail thepersistent-failure model for the battery sensor inFigure battery-persistence-figure(a)(page battery-persistence-figure).      Figure battery-persistence-figure(b) stops at$t=32$. Describe qualitatively what should happen as$ttoinfty$ if the sensor continues to read 0.        Suppose that the external temperature affects the battery sensor insuch a way that transient failures become more likely astemperature increases. Show how to augment the DBN structure inFigure battery-persistence-figure(a), and explainany required changes to the CPTs.        Given the new network structure, can battery readings be used by therobot to infer the current temperature?  ",
        "url": " /dbn-exercises/ex_19/"
      }
    
  
    ,
      "dbn-exercises-ex-6":  {
        "title": "Exercise 15.6",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.6Consider the vacuum worlds ofFigure vacuum-maze-ch4-figure (perfect sensing) andFigure vacuum-maze-hmm2-figure (noisy sensing). Supposethat the robot receives an observation sequence such that, with perfectsensing, there is exactly one possible location it could be in. Is thislocation necessarily the most probable location under noisy sensing forsufficiently small noise probability $epsilon$? Prove your claim orfind a counterexample.",
        "url": " /dbn-exercises/ex_6/"
      }
    
  
    ,
      "dbn-exercises-ex-1":  {
        "title": "Exercise 15.1",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.1 [state-augmentation-exercise]Show that any second-order Markovprocess can be rewritten as a first-order Markov process with anaugmented set of state variables. Can this always be doneparsimoniously, i.e., without increasing the number ofparameters needed to specify the transition model?",
        "url": " /dbn-exercises/ex_1/"
      }
    
  
    ,
      "dbn-exercises-ex-13":  {
        "title": "Exercise 15.13",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.13 [kalman-update-exercise]Complete the missing step in the derivationof Equation (kalman-one-step-equation) onpage kalman-one-step-equation, the first update step for the one-dimensional Kalmanfilter.",
        "url": " /dbn-exercises/ex_13/"
      }
    
  
    ,
      "dbn-exercises-ex-12":  {
        "title": "Exercise 15.12",
        "breadcrumb": "15-Probabilistic-Reasoning-Over-Time",
      	"content"  : "Exercise 15.12 [switching-kf-exercise]Often, we wish to monitor a continuous-statesystem whose behavior switches unpredictably among a set of $k$ distinct“modes.” For example, an aircraft trying to evade a missile can executea series of distinct maneuvers that the missile may attempt to track. ABayesian network representation of such a switching Kalmanfilter model is shown inFigure switching-kf-figure.      Suppose that the discrete state $S_t$ has $k$ possible values andthat the prior continuous state estimate is a multivariateGaussian distribution. Show that the prediction is a mixture ofGaussians—that is, a weighted sum of Gaussians suchthat the weights sum to 1.        Show that if the current continuous state estimate is a mixture of $m$ Gaussians,then in the general case the updated state estimate will be a mixture of$km$ Gaussians.        What aspect of the temporal process do the weights in the Gaussianmixture represent?  The results in (a) and (b) show that the representation of the posteriorgrows without limit even for switching Kalman filters, which are amongthe simplest hybrid dynamic models.",
        "url": " /dbn-exercises/ex_12/"
      }
    
  
    
  
    ,
      "agents-exercises-ex-3":  {
        "title": "Exercise 2.3",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.3Write an essay on the relationship between evolution and one or more ofautonomy, intelligence, and learning.",
        "url": " /agents-exercises/ex_3/"
      }
    
  
    ,
      "agents-exercises-ex-11":  {
        "title": "Exercise 2.11",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.11Implement a simple reflex agent for the vacuum environment inExercise vacuum-start-exercise. Run the environmentwith this agent for all possible initial dirt configurations and agentlocations. Record the performance score for each configuration and theoverall average score.",
        "url": " /agents-exercises/ex_11/"
      }
    
  
    ,
      "agents-exercises-ex-14":  {
        "title": "Exercise 2.14",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.14 [vacuum-bump-exercise]Repeat Exercise vacuum-unknown-geog-exercise for the case inwhich the location sensor is replaced with a “bump” sensor that detectsthe agent’s attempts to move into an obstacle or to cross the boundariesof the environment. Suppose the bump sensor stops working; how shouldthe agent behave?",
        "url": " /agents-exercises/ex_14/"
      }
    
  
    ,
      "agents-exercises-ex-4":  {
        "title": "Exercise 2.4",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.4For each of the following assertions, say whether it is true or falseand support your answer with examples or counterexamples whereappropriate.      An agent that senses only partial information about the state cannotbe perfectly rational.        There exist task environments in which no pure reflex agent canbehave rationally.        There exists a task environment in which every agent is rational.        The input to an agent program is the same as the input to theagent function.        Every agent function is implementable by someprogram/machine combination.        Suppose an agent selects its action uniformly at random from the setof possible actions. There exists a deterministic task environmentin which this agent is rational.        It is possible for a given agent to be perfectly rational in twodistinct task environments.        Every agent is rational in an unobservable environment.        A perfectly rational poker-playing agent never loses.  Exercise 2.4 [PEAS-exercise]For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection.      Playing soccer.        Exploring the subsurface oceans of Titan.        Shopping for used AI books on the Internet.        Playing a tennis match.        Practicing tennis against a wall.        Performing a high jump.        Knitting a sweater.        Bidding on an item at an auction.  ",
        "url": " /agents-exercises/ex_4/"
      }
    
  
    ,
      "agents-exercises-ex-7":  {
        "title": "Exercise 2.7",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.7 [agent-fn-prog-exercise]This exercise explores the differences betweenagent functions and agent programs.      Can there be more than one agent program that implements a givenagent function? Give an example, or show why one is not possible.        Are there agent functions that cannot be implemented by any agentprogram?        Given a fixed machine architecture, does each agent programimplement exactly one agent function?        Given an architecture with $n$ bits of storage, how many differentpossible agent programs are there?        Suppose we keep the agent program fixed but speed up the machine bya factor of two. Does that change the agent function?  ",
        "url": " /agents-exercises/ex_7/"
      }
    
  
    ,
      "agents-exercises-ex-5":  {
        "title": "Exercise 2.5",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.5 [PEAS-exercise] For each of the following activities, give a PEASdescription of the task environment and characterize it in terms of theproperties listed in Section env-properties-subsection.      Performing a gymnastics floor routine.        Exploring the subsurface oceans of Titan.        Playing soccer.        Shopping for used AI books on the Internet.        Practicing tennis against a wall.        Performing a high jump.        Bidding on an item at an auction.  ",
        "url": " /agents-exercises/ex_5/"
      }
    
  
    ,
      "agents-exercises-ex-10":  {
        "title": "Exercise 2.10",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.10 [vacuum-start-exercise]Implement a performance-measuring environmentsimulator for the vacuum-cleaner world depicted inFigure vacuum-world-figure and specified onpage vacuum-rationality-page. Your implementation should be modular so that thesensors, actuators, and environment characteristics (size, shape, dirtplacement, etc.) can be changed easily. (Note: for somechoices of programming language and operating system there are alreadyimplementations in the online code repository.)",
        "url": " /agents-exercises/ex_10/"
      }
    
  
    ,
      "agents-exercises-ex-15":  {
        "title": "Exercise 2.15",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.15 [vacuum-finish-exercise]The vacuum environments in the precedingexercises have all been deterministic. Discuss possible agent programsfor each of the following stochastic versions:      Murphy’s law: twenty-five percent of the time, the Suck actionfails to clean the floor if it is dirty and deposits dirt onto thefloor if the floor is clean. How is your agent program affected ifthe dirt sensor gives the wrong answer 10% of the time?        Small children: At each time step, each clean square has a 10%chance of becoming dirty. Can you come up with a rational agentdesign for this case?  ",
        "url": " /agents-exercises/ex_15/"
      }
    
  
    ,
      "agents-exercises-ex-8":  {
        "title": "Exercise 2.8",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.8Write pseudocode agent programs for the goal-based and utility-basedagents.",
        "url": " /agents-exercises/ex_8/"
      }
    
  
    ,
      "agents-exercises-ex-2":  {
        "title": "Exercise 2.2",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.2 [vacuum-rationality-exercise]Let us examine the rationality of variousvacuum-cleaner agent functions.      Show that the simple vacuum-cleaner agent function described inFigure vacuum-agent-function-table is indeedrational under the assumptions listed on page vacuum-rationality-page.        Describe a rational agent function for the case in which eachmovement costs one point. Does the corresponding agent programrequire internal state?        Discuss possible agent designs for the cases in which clean squarescan become dirty and the geography of the environment is unknown.Does it make sense for the agent to learn from its experience inthese cases? If so, what should it learn? If not, why not?  ",
        "url": " /agents-exercises/ex_2/"
      }
    
  
    ,
      "agents-exercises-ex-9":  {
        "title": "Exercise 2.9",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.9Consider a simple thermostat that turns on a furnace when thetemperature is at least 3 degrees below the setting, and turns off afurnace when the temperature is at least 3 degrees above the setting. Isa thermostat an instance of a simple reflex agent, a model-based reflexagent, or a goal-based agent?",
        "url": " /agents-exercises/ex_9/"
      }
    
  
    ,
      "agents-exercises-ex-6":  {
        "title": "Exercise 2.6",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.6Define in your own words the following terms: agent, agent function,agent program, rationality, autonomy, reflex agent, model-based agent,goal-based agent, utility-based agent, learning agent.",
        "url": " /agents-exercises/ex_6/"
      }
    
  
    ,
      "agents-exercises-ex-1":  {
        "title": "Exercise 2.1",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.1Suppose that the performance measure is concerned with just the first$T$ time steps of the environment and ignores everything thereafter.Show that a rational agent’s action may depend not just on the state ofthe environment but also on the time step it has reached.",
        "url": " /agents-exercises/ex_1/"
      }
    
  
    ,
      "agents-exercises-ex-13":  {
        "title": "Exercise 2.13",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.13 [vacuum-unknown-geog-exercise]consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the geography of the environment—its extent, boundaries, andobstacles—is unknown, as is the initial dirt configuration. (The agentcan go Up and Down as well as Left and Right.)      Can a simple reflex agent be perfectly rational for thisenvironment? Explain.        Can a simple reflex agent with a randomized agentfunction outperform a simple reflex agent? Design such an agent andmeasure its performance on several environments.        Can you design an environment in which your randomized agent willperform poorly? Show your results.        Can a reflex agent with state outperform a simple reflex agent?Design such an agent and measure its performance on severalenvironments. Can you design a rational agent of this type?  ",
        "url": " /agents-exercises/ex_13/"
      }
    
  
    ,
      "agents-exercises-ex-12":  {
        "title": "Exercise 2.12",
        "breadcrumb": "2-Intelligent-Agent",
      	"content"  : "Exercise 2.12 [vacuum-motion-penalty-exercise]Consider a modified version of thevacuum environment in Exercise vacuum-start-exercise,in which the agent is penalized one point for each movement.      Can a simple reflex agent be perfectly rational for thisenvironment? Explain.        What about a reflex agent with state? Design such an agent.        How do your answers to 1 and 2change if the agent’s percepts give it the clean/dirty status ofevery square in the environment?  ",
        "url": " /agents-exercises/ex_12/"
      }
    
  
    
  
    ,
      "fol-exercises-ex-28":  {
        "title": "Exercise 8.28",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.28Translate into first-order logic the sentence “Everyone’s DNA is uniqueand is derived from their parents’ DNA.” You must specify the preciseintended meaning of your vocabulary terms. (Hint: Do notuse the predicate ${Unique}(x)$, since uniqueness is not really aproperty of an object in itself!)",
        "url": " /fol-exercises/ex_28/"
      }
    
  
    ,
      "fol-exercises-ex-29":  {
        "title": "Exercise 8.29",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.29For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it.  Any apartment in London has lower rent than some apartmentsin Paris.  There is exactly one apartment in Paris with rent below $1000.  If an apartment is more expensive than all apartments in London, itmust be in Moscow.",
        "url": " /fol-exercises/ex_29/"
      }
    
  
    ,
      "fol-exercises-ex-3":  {
        "title": "Exercise 8.3",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.3Is the sentence ${exists,x,y;;} xy$ valid? Explain.",
        "url": " /fol-exercises/ex_3/"
      }
    
  
    ,
      "fol-exercises-ex-36":  {
        "title": "Exercise 8.36",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.36Consider a first-order logical knowledge base that describes worldscontaining people, songs, albums (e.g., “Meet the Beatles”) and disks(i.e., particular physical instances of CDs). The vocabulary containsthe following symbols:  ${CopyOf}(d,a)$: Predicate. Disk $d$ is a copy of album $a$.  ${Owns}(p,d)$: Predicate. Person $p$ owns disk $d$.  ${Sings}(p,s,a)$: Album $a$ includes a recording of song $s$ sung by person $p$.  ${Wrote}(p,s)$: Person $p$ wrote song $s$.  ${McCartney}$, ${Gershwin}$, ${BHoliday}$, ${Joe}$, ${EleanorRigby}$, ${TheManILove}$, ${Revolver}$: Constants with the obvious meanings.Express the following statements in first-order logic:      Gershwin wrote “The Man I Love.”        Gershwin did not write “Eleanor Rigby.”        Either Gershwin or McCartney wrote “The Man I Love.”        Joe has written at least one song.        Joe owns a copy of Revolver.        Every song that McCartney sings on Revolver waswritten by McCartney.        Gershwin did not write any of the songs on Revolver.        Every song that Gershwin wrote has been recorded on some album.(Possibly different songs are recorded on different albums.)        There is a single album that contains every song that Joehas written.        Joe owns a copy of an album that has Billie Holiday singing “The ManI Love.”        Joe owns a copy of every album that has a song sung by McCartney.(Of course, each different album is instantiated in a differentphysical CD.)        Joe owns a copy of every album on which all the songs are sung byBillie Holiday.  ",
        "url": " /fol-exercises/ex_36/"
      }
    
  
    ,
      "fol-exercises-ex-11":  {
        "title": "Exercise 8.11",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.11Consider a vocabulary with the following symbols:  ${Occupation}(p,o)$: Predicate. Person $p$ has occupation $o$.  ${Customer}(p1,p2)$: Predicate. Person $p1$ is a customer of person $p2$.  ${Boss}(p1,p2)$: Predicate. Person $p1$ is a boss of person $p2$.  ${Doctor}$, $ {Surgeon}$, $ {Lawyer}$, $ {Actor}$: Constants denoting occupations.  ${Emily}$, $ {Joe}$: Constants denoting people.Use these symbols to write the following assertions in first-orderlogic:      Emily is either a surgeon or a lawyer.        Joe is an actor, but he also holds another job.        All surgeons are doctors.        Joe does not have a lawyer (i.e., is not a customer of any lawyer).        Emily has a boss who is a lawyer.        There exists a lawyer all of whose customers are doctors.        Every surgeon has a lawyer.  ",
        "url": " /fol-exercises/ex_11/"
      }
    
  
    ,
      "fol-exercises-ex-14":  {
        "title": "Exercise 8.14",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.14True or false? Explain.      ${exists,x;;} x{Rumpelstiltskin}$ is a valid(necessarily true) sentence of first-order logic.        Every existentially quantified sentence in first-order logic is truein any model that contains exactly one object.        ${forall,x,y;;} xy$is satisfiable.  ",
        "url": " /fol-exercises/ex_14/"
      }
    
  
    ,
      "fol-exercises-ex-4":  {
        "title": "Exercise 8.4",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.4Write down a logical sentence such that every world in which it is truecontains exactly one object.",
        "url": " /fol-exercises/ex_4/"
      }
    
  
    ,
      "fol-exercises-ex-23":  {
        "title": "Exercise 8.23",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.23Assuming predicates ${Parent}(p,q)$ and ${Female}(p)$ and constants${Joan}$ and ${Kevin}$, with the obvious meanings, express each ofthe following sentences in first-order logic. (You may use theabbreviation $exists^{1}$ to mean “there exists exactly one.”)      Joan has a daughter (possibly more than one, and possibly sonsas well).        Joan has exactly one daughter (but may have sons as well).        Joan has exactly one child, a daughter.        Joan and Kevin have exactly one child together.        Joan has at least one child with Kevin, and no children withanyone else.  ",
        "url": " /fol-exercises/ex_23/"
      }
    
  
    ,
      "fol-exercises-ex-20":  {
        "title": "Exercise 8.20",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.20 [list-representation-exercise]Using the set axioms as examples, writeaxioms for the list domain, including all the constants, functions, andpredicates mentioned in the chapter.",
        "url": " /fol-exercises/ex_20/"
      }
    
  
    ,
      "fol-exercises-ex-33":  {
        "title": "Exercise 8.33",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.33 [4bit-adder-exercise]Extend the vocabulary fromSection circuits-section to define addition for $n$-bitbinary numbers. Then encode the description of the four-bit adder inFigure 4bit-adder-figure, and pose the queries neededto verify that it is in fact correct.Figure [adder-figure] A four-bit adder. Each ${Ad}_i$ is a one-bit adder, as in figure [adder-figure](#adder-figure) on page [adder-figure](#/)",
        "url": " /fol-exercises/ex_33/"
      }
    
  
    ,
      "fol-exercises-ex-7":  {
        "title": "Exercise 8.7",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.7 [nqueens-size-exercise]Which of the following are valid (necessarily true) sentences?      $(exists x xx) {:;{Rightarrow}:;}({forall,y;;} exists z yz)$.        ${forall,x;;} P(x) lor lnot P(x)$.        ${forall,x;;} {Smart}(x) lor (xx)$.  ",
        "url": " /fol-exercises/ex_7/"
      }
    
  
    ,
      "fol-exercises-ex-17":  {
        "title": "Exercise 8.17",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.17 [kinship-exercise]Write axioms describing the predicates${Grandchild}$, ${Greatgrandparent}$, ${Ancestor}$, ${Brother}$,${Sister}$, ${Daughter}$, ${Son}$, ${FirstCousin}$,${BrotherInLaw}$, ${SisterInLaw}$, ${Aunt}$, and ${Uncle}$. Findout the proper definition of $m$th cousin $n$ times removed, and writethe definition in first-order logic. Now write down the basic factsdepicted in the family tree in Figure family1-figure.Using a suitable logical reasoning system, it all the sentences you havewritten down, and it who are Elizabeth’s grandchildren, Diana’sbrothers-in-law, Zara’s great-grandparents, and Eugenie’s ancestors.Figure [family1-figure] A typical family tree. The symbol $bowtie$ connects spouses and arrows point to children.",
        "url": " /fol-exercises/ex_17/"
      }
    
  
    ,
      "fol-exercises-ex-5":  {
        "title": "Exercise 8.5",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.5 [two-friends-exercise]Write down a logical sentence such that every world in which it is truecontains exactly two objects.",
        "url": " /fol-exercises/ex_5/"
      }
    
  
    ,
      "fol-exercises-ex-25":  {
        "title": "Exercise 8.25",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.25In Chapter csp-chapter, we used equality to indicatethe relation between a variable and its value. For instance, we wrote${WA}{red}$ to mean that Western Australia is coloredred. Representing this in first-order logic, we must write moreverbosely ${ColorOf}({WA}){red}$. What incorrectinference could be drawn if we wrote sentences such as${WA}{red}$ directly as logical assertions?",
        "url": " /fol-exercises/ex_25/"
      }
    
  
    ,
      "fol-exercises-ex-10":  {
        "title": "Exercise 8.10",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.10This exercise uses the function ${MapColor}$ and predicates${In}(x,y)$, ${Borders}(x,y)$, and ${Country}(x)$, whose argumentsare geographical regions, along with constant symbols for variousregions. In each of the following we give an English sentence and anumber of candidate logical expressions. For each of the logicalexpressions, state whether it (1) correctly expresses the Englishsentence; (2) is syntactically invalid and therefore meaningless; or (3)is syntactically valid but does not express the meaning of the Englishsentence.      Paris and Marseilles are both in France.                  ${In}({Paris} land {Marseilles}, {France})$.                    ${In}({Paris},{France}) land {In}({Marseilles},{France})$.                    ${In}({Paris},{France}) lor {In}({Marseilles},{France})$.                  There is a country that borders both Iraq and Pakistan.                  ${exists,c;;}$${Country}(c) land {Border}(c,{Iraq}) land {Border}(c,{Pakistan})$.                    ${exists,c;;}$${Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.                    $[{exists,c;;}$${Country}(c)] {:;{Rightarrow}:;}[{Border}(c,{Iraq}) land {Border}(c,{Pakistan})]$.                    ${exists,c;;}$${Border}({Country}(c),{Iraq} land {Pakistan})$.                  All countries that border Ecuador are in South America.                  ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.                    ${forall,c;;}  {Country}(c) {:;{Rightarrow}:;}[{Border}(c,{Ecuador}) {:;{Rightarrow}:;}{In}(c,{SouthAmerica})]$.                    ${forall,c;;}  [{Country}(c) {:;{Rightarrow}:;}{Border}(c,{Ecuador})] {:;{Rightarrow}:;}{In}(c,{SouthAmerica})$.                    ${forall,c;;}  Country(c) land {Border}(c,{Ecuador}) land {In}(c,{SouthAmerica})$.                  No region in South America borders any region in Europe.                  $lnot [{exists,c,d;;}  {In}(c,{SouthAmerica}) land {In}(d,{Europe}) land {Borders}(c,d)]$.                    ${forall,c,d;;}  [{In}(c,{SouthAmerica}) land {In}(d,{Europe})] {:;{Rightarrow}:;}lnot {Borders}(c,d)]$.                    $lnot {forall,c;;}  {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{exists,d;;} {In}(d,{Europe}) landlnot {Borders}(c,d)$.                    ${forall,c;;} {In}(c,{SouthAmerica}) {:;{Rightarrow}:;}{forall,d;;} {In}(d,{Europe}) {:;{Rightarrow}:;}lnot {Borders}(c,d)$.                  No two adjacent countries have the same map color.                  ${forall,x,y;;} lnot {Country}(x) lor lnot {Country}(y) lor lnot {Borders}(x,y) lor {}$$lnot ({MapColor}(x) = {MapColor}(y))$.                    ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) land lnot(x=y)) {:;{Rightarrow}:;}{}$$lnot ({MapColor}(x) = {MapColor}(y))$.                    ${forall,x,y;;} {Country}(x) land {Country}(y) land {Borders}(x,y) land {}$$lnot ({MapColor}(x) = {MapColor}(y))$.                    ${forall,x,y;;} ({Country}(x) land {Country}(y) land {Borders}(x,y) ) {:;{Rightarrow}:;}{MapColor}(xneq y)$.            ",
        "url": " /fol-exercises/ex_10/"
      }
    
  
    ,
      "fol-exercises-ex-22":  {
        "title": "Exercise 8.22",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.22Write out the axioms required for reasoning about the wumpus’s location,using a constant symbol ${Wumpus}$ and a binary predicate${At}({Wumpus}, {Location})$. Remember that there is only onewumpus.",
        "url": " /fol-exercises/ex_22/"
      }
    
  
    ,
      "fol-exercises-ex-18":  {
        "title": "Exercise 8.18",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.18Write down a sentence asserting that + is a commutative function. Doesyour sentence follow from the Peano axioms? If so, explain why; if not,give a model in which the axioms are true and your sentence is false.",
        "url": " /fol-exercises/ex_18/"
      }
    
  
    ,
      "fol-exercises-ex-31":  {
        "title": "Exercise 8.31",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.31Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):      Some students took French in spring 2009.        Every student who takes French passes it.        Only one student took Greek in spring 2009.        The best score in Greek is always lower than the best scorein French.        Every person who buys a policy is smart.        There is an agent who sells policies only to people who arenot insured.        There is a barber who shaves all men in town who do notshave themselves.        A person born in the UK, each of whose parents is a UK citizen or aUK resident, is a UK citizen by birth.        A person born outside the UK, one of whose parents is a UK citizenby birth, is a UK citizen by descent.        Politicians can fool some of the people all of the time, and theycan fool all of the people some of the time, but they can’t fool allof the people all of the time.        All Greeks speak the same language. (Use ${Speaks}(x,l)$ to meanthat person $x$ speaks language $l$.)  ",
        "url": " /fol-exercises/ex_31/"
      }
    
  
    ,
      "fol-exercises-ex-24":  {
        "title": "Exercise 8.24",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.24Arithmetic assertions can be written in first-order logic with thepredicate symbol $&amp;lt;$, the function symbols ${+}$ and ${times}$, and theconstant symbols 0 and 1. Additional predicates can also be defined withbiconditionals.      Represent the property “$x$ is an even number.”        Represent the property “$x$ is prime.”        Goldbach’s conjecture is the conjecture (unproven as yet) that everyeven number is equal to the sum of two primes. Represent thisconjecture as a logical sentence.  ",
        "url": " /fol-exercises/ex_24/"
      }
    
  
    ,
      "fol-exercises-ex-34":  {
        "title": "Exercise 8.34",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.34The circuit representation in the chapter is more detailed thannecessary if we care only about circuit functionality. A simplerformulation describes any $m$-input, $n$-output gate or circuit using apredicate with $m+n$ arguments, such that the predicate is true exactlywhen the inputs and outputs are consistent. For example, NOT gates aredescribed by the binary predicate ${NOT}(i,o)$, for which${NOT}(0,1)$ and ${NOT}(1,0)$ are known. Compositions of gates aredefined by conjunctions of gate predicates in which shared variablesindicate direct connections. For example, a NAND circuit can be composedfrom ${AND}$s and ${NOT}$s:Using this representation, define the one-bit adder inFigure adder-figure and the four-bit adder inFigure 4bit-adder-figure, and explain what queries youwould use to verify the designs. What kinds of queries arenot supported by this representation thatare supported by the representation inSection circuits-section?",
        "url": " /fol-exercises/ex_34/"
      }
    
  
    ,
      "fol-exercises-ex-15":  {
        "title": "Exercise 8.15",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.15 [Peano-completion-exercise]Rewrite the first two Peano axioms inSection Peano-section as a single axiom that defines${NatNum}(x)$ so as to exclude the possibility of natural numbersexcept for those generated by the successor function.",
        "url": " /fol-exercises/ex_15/"
      }
    
  
    ,
      "fol-exercises-ex-16":  {
        "title": "Exercise 8.16",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.16 [wumpus-diagnostic-exercise]Equation (pit-biconditional-equation) onpage pit-biconditional-equation defines the conditions under which a square isbreezy. Here we consider two other ways to describe this aspect of thewumpus world.      We can write [diagnostic rule] leading from observed effects to hidden causes. Forfinding pits, the obvious diagnostic rules say that if a square isbreezy, some adjacent square must contain a pit; and if a square isnot breezy, then no adjacent square contains a pit. Write these tworules in first-order logic and show that their conjunction islogically equivalent toEquation (pit-biconditional-equation).        We can write [causal rule] leading from cause to effect. One obvious causal ruleis that a pit causes all adjacent squares to be breezy. Write thisrule in first-order logic, explain why it is incomplete compared toEquation (pit-biconditional-equation), and supplythe missing axiom.  ",
        "url": " /fol-exercises/ex_16/"
      }
    
  
    ,
      "fol-exercises-ex-32":  {
        "title": "Exercise 8.32",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.32Write a general set of facts and axioms to represent the assertion“Wellington heard about Napoleon’s death” and to correctly answer thequestion “Did Napoleon hear about Wellington’s death?”",
        "url": " /fol-exercises/ex_32/"
      }
    
  
    ,
      "fol-exercises-ex-30":  {
        "title": "Exercise 8.30",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.30Represent the following sentences in first-order logic, using aconsistent vocabulary (which you must define):      Some students took French in spring 2001.        Every student who takes French passes it.        Only one student took Greek in spring 2001.        The best score in Greek is always higher than the best scorein French.        Every person who buys a policy is smart.        No person buys an expensive policy.        There is an agent who sells policies only to people who arenot insured.        There is a barber who shaves all men in town who do notshave themselves.        A person born in the UK, each of whose parents is a UK citizen or aUK resident, is a UK citizen by birth.        A person born outside the UK, one of whose parents is a UK citizenby birth, is a UK citizen by descent.        Politicians can fool some of the people all of the time, and theycan fool all of the people some of the time, but they can’t fool allof the people all of the time.        All Greeks speak the same language. (Use ${Speaks}(x,l)$ to meanthat person $x$ speaks language $l$.)  ",
        "url": " /fol-exercises/ex_30/"
      }
    
  
    ,
      "fol-exercises-ex-8":  {
        "title": "Exercise 8.8",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.8 [empty-universe-exercise]Consider a version of the semantics forfirst-order logic in which models with empty domains are allowed. Giveat least two examples of sentences that are valid according to thestandard semantics but not according to the new semantics. Discuss whichoutcome makes more intuitive sense for your examples.",
        "url": " /fol-exercises/ex_8/"
      }
    
  
    ,
      "fol-exercises-ex-2":  {
        "title": "Exercise 8.2",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.2Consider a knowledge base containing just two sentences: $P(a)$ and$P(b)$. Does this knowledge base entail $forall,x P(x)$? Explain youranswer in terms of models.",
        "url": " /fol-exercises/ex_2/"
      }
    
  
    ,
      "fol-exercises-ex-9":  {
        "title": "Exercise 8.9",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.9 [hillary-exercise]Does the fact$lnot {Spouse}({George},{Laura})$ follow from the facts${Jim}neq {George}$ and ${Spouse}({Jim},{Laura})$? If so,give a proof; if not, supply additional axioms as needed. What happensif we use ${Spouse}$ as a unary function symbol instead of a binarypredicate?",
        "url": " /fol-exercises/ex_9/"
      }
    
  
    ,
      "fol-exercises-ex-35":  {
        "title": "Exercise 8.35",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.35Obtain a passport application for your country, identify the rulesdetermining eligibility for a passport, and translate them intofirst-order logic, following the steps outlined inSection circuits-section.",
        "url": " /fol-exercises/ex_35/"
      }
    
  
    ,
      "fol-exercises-ex-19":  {
        "title": "Exercise 8.19",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.19Explain what is wrong with the following proposed definition of the setmembership predicate $$",
        "url": " /fol-exercises/ex_19/"
      }
    
  
    ,
      "fol-exercises-ex-27":  {
        "title": "Exercise 8.27",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.27For each of the following sentences in English, decide if theaccompanying first-order logic sentence is a good translation. If not,explain why not and correct it. (Some sentences may have more than oneerror!)      No two people have the same social security number.        John’s social security number is the same as Mary’s.        Everyone’s social security number has nine digits.        Rewrite each of the above (uncorrected) sentences using a functionsymbol ${SS}#$ instead of the predicate ${HasSS}#$.  ",
        "url": " /fol-exercises/ex_27/"
      }
    
  
    ,
      "fol-exercises-ex-6":  {
        "title": "Exercise 8.6",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.6 [8puzzle-parity-exercise][fol-model-count-exercise] Consider a symbol vocabulary that contains$c$ constant symbols, $p_k$ predicate symbols of each arity $k$, and$f_k$ function symbols of each arity $k$, where $1leq kleq A$. Let thedomain size be fixed at $D$. For any given model, each predicate orfunction symbol is mapped onto a relation or function, respectively, ofthe same arity. You may assume that the functions in the model allowsome input tuples to have no value for the function (i.e., the value isthe invisible object). Derive a formula for the number of possiblemodels for a domain with $D$ elements. Don’t worry about eliminatingredundant combinations.",
        "url": " /fol-exercises/ex_6/"
      }
    
  
    ,
      "fol-exercises-ex-26":  {
        "title": "Exercise 8.26",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.26Write in first-order logic the assertion that every key and at least oneof every pair of socks will eventually be lost forever, using only thefollowing vocabulary: ${Key}(x)$, $x$ is a key; ${Sock}(x)$, $x$ isa sock; ${Pair}(x,y)$, $x$ and $y$ are a pair; ${Now}$, the currenttime; ${Before}(t_1,t_2)$, time $t_1$ comes before time $t_2$;${Lost}(x,t)$, object $x$ is lost at time $t$.",
        "url": " /fol-exercises/ex_26/"
      }
    
  
    ,
      "fol-exercises-ex-21":  {
        "title": "Exercise 8.21",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.21 [adjacency-exercise]Explain what is wrong with the following proposeddefinition of adjacent squares in the wumpus world:",
        "url": " /fol-exercises/ex_21/"
      }
    
  
    ,
      "fol-exercises-ex-1":  {
        "title": "Exercise 8.1",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.1A logical knowledge base represents the world using a set of sentenceswith no explicit structure. An analogicalrepresentation, on the other hand, has physical structure thatcorresponds directly to the structure of the thing represented. Considera road map of your country as an analogical representation of factsabout the country—it represents facts with a map language. Thetwo-dimensional structure of the map corresponds to the two-dimensionalsurface of the area.      Give five examples of symbols in the map language.        An explicit sentence is a sentence that the creatorof the representation actually writes down. Animplicit sentence is a sentence that results fromexplicit sentences because of properties of the analogicalrepresentation. Give three examples each of implicitand explicit sentences in the map language.        Give three examples of facts about the physical structure of yourcountry that cannot be represented in the map language.        Give two examples of facts that are much easier to express in themap language than in first-order logic.        Give two other examples of useful analogical representations. Whatare the advantages and disadvantages of each of these languages?  ",
        "url": " /fol-exercises/ex_1/"
      }
    
  
    ,
      "fol-exercises-ex-13":  {
        "title": "Exercise 8.13",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.13 [language-determination-exercise]Complete the following exercisesabout logical sentences:  Translate into good, natural English (no $x$s or $y$s!):  Explain why this sentence is entailed by the sentence      Translate into first-order logic the following sentences:                  Understanding leads to friendship.                    Friendship is transitive.              Remember to define all predicates, functions, and constants you use.  ",
        "url": " /fol-exercises/ex_13/"
      }
    
  
    ,
      "fol-exercises-ex-12":  {
        "title": "Exercise 8.12",
        "breadcrumb": "8-First-Order-Logic",
      	"content"  : "Exercise 8.12In each of the following we give an English sentence and a number ofcandidate logical expressions. For each of the logical expressions,state whether it (1) correctly expresses the English sentence; (2) issyntactically invalid and therefore meaningless; or (3) is syntacticallyvalid but does not express the meaning of the English sentence.      Every cat loves its mother or father.                  ${forall,x;;} {Cat}(x) {:;{Rightarrow}:;}{Loves}(x,{Mother}(x)lor {Father}(x))$.                    ${forall,x;;} lnot {Cat}(x) lor {Loves}(x,{Mother}(x)) lor {Loves}(x,{Father}(x))$.                    ${forall,x;;} {Cat}(x) land ({Loves}(x,{Mother}(x))lor {Loves}(x,{Father}(x)))$.                  Every dog who loves one of its brothers is happy.                  ${forall,x;;} {Dog}(x) land (exists y {Brother}(y,x) land {Loves}(x,y)) {:;{Rightarrow}:;}{Happy}(x)$.                    ${forall,x,y;;} {Dog}(x) land {Brother}(y,x) land {Loves}(x,y) {:;{Rightarrow}:;}{Happy}(x)$.                    ${forall,x;;} {Dog}(x) land [{forall,y;;} {Brother}(y,x) {;;{Leftrightarrow};;}{Loves}(x,y)] {:;{Rightarrow}:;}{Happy}(x)$.                  No dog bites a child of its owner.                  ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}lnot {Bites}(x,{Child}({Owner}(x)))$.                    $lnot {exists,x,y;;} {Dog}(x) land {Child}(y,{Owner}(x)) land {Bites}(x,y)$.                    ${forall,x;;} {Dog}(x) {:;{Rightarrow}:;}({forall,y;;} {Child}(y,{Owner}(x)) {:;{Rightarrow}:;}lnot {Bites}(x,y))$.                    $lnot {exists,x;;} {Dog}(x) {:;{Rightarrow}:;}({exists,y;;} {Child}(y,{Owner}(x)) land {Bites}(x,y))$.                  Everyone’s zip code within a state has the same first digit.                  ${forall,x,s,z_1;;} [{State}(s) land {LivesIn}(x,s) land {Zip}(x)z_1] {:;{Rightarrow}:;}{}$$[{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 {:;{Rightarrow}:;}{Digit}(1,z_1) {Digit}(1,z_2) ]$.                    ${forall,x,s;;} [{State}(s) land {LivesIn}(x,s) land {exists,z_1;;} {Zip}(x)z_1] {:;{Rightarrow}:;}{}$$ [{forall,y,z_2;;} {LivesIn}(y,s) land {Zip}(y)z_2 land {Digit}(1,z_1) {Digit}(1,z_2) ]$.                    ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{Digit}(1,{Zip}(x){Zip}(y))$.                    ${forall,x,y,s;;} {State}(s) land {LivesIn}(x,s) land {LivesIn}(y,s) {:;{Rightarrow}:;}{}$${Digit}(1,{Zip}(x)) {Digit}(1,{Zip}(y))$.            ",
        "url": " /fol-exercises/ex_12/"
      }
    
  
    
  
    
  
    ,
      "complex-decisions-exercises-ex-3":  {
        "title": "Exercise 17.3",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.3Select a specific member of the set of policies that are optimal for$R(s)&amp;gt;0$ as shown inFigure sequential-decision-policies-figure(b), andcalculate the fraction of time the agent spends in each state, in thelimit, if the policy is executed forever. (Hint:Construct the state-to-state transition probability matrix correspondingto the policy and seeExercise markov-convergence-exercise.)",
        "url": " /complex-decisions-exercises/ex_3/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-11":  {
        "title": "Exercise 17.11",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.11 [101x3-mdp-exercise]Consider the $101 times 3$ world shown inFigure grid-mdp-figure(b). In the start state the agenthas a choice of two deterministic actions, Up orDown, but in the other states the agent has onedeterministic action, Right. Assuming a discounted rewardfunction, for what values of the discount $gamma$ should the agentchoose Up and for which Down? Compute theutility of each action as a function of $gamma$. (Note that this simpleexample actually reflects many real-world situations in which one mustweigh the value of an immediate action versus the potential continuallong-term consequences, such as choosing to dump pollutants into alake.)",
        "url": " /complex-decisions-exercises/ex_11/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-14":  {
        "title": "Exercise 17.14",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.14 [policy-loss-exercise]How can the value determination algorithm beused to calculate the expected loss experienced by an agent using agiven set of utility estimates ${U}$ and an estimatedmodel ${P}$, compared with an agent using correct values?",
        "url": " /complex-decisions-exercises/ex_14/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-4":  {
        "title": "Exercise 17.4",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.4 [nonseparable-exercise]Suppose that we define the utility of a statesequence to be the maximum reward obtained in any statein the sequence. Show that this utility function does not result instationary preferences between state sequences. Is it still possible todefine a utility function on states such that MEU decision making givesoptimal behavior?",
        "url": " /complex-decisions-exercises/ex_4/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-23":  {
        "title": "Exercise 17.23",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.23A Dutch auction is similar in an English auction, but rather thanstarting the bidding at a low price and increasing, in a Dutch auctionthe seller starts at a high price and gradually lowers the price untilsome buyer is willing to accept that price. (If multiple bidders acceptthe price, one is arbitrarily chosen as the winner.) More formally, theseller begins with a price $p$ and gradually lowers $p$ by increments of$d$ until at least one buyer accepts the price. Assuming all bidders actrationally, is it true that for arbitrarily small $d$, a Dutch auctionwill always result in the bidder with the highest value for the itemobtaining the item? If so, show mathematically why. If not, explain howit may be possible for the bidder with highest value for the item not toobtain it.",
        "url": " /complex-decisions-exercises/ex_23/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-20":  {
        "title": "Exercise 17.20",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.20Solve the game of three-finger Morra.",
        "url": " /complex-decisions-exercises/ex_20/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-7":  {
        "title": "Exercise 17.7",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.7 [threshold-cost-exercise]For the environment shown inFigure sequential-decision-world-figure, find all thethreshold values for $R(s)$ such that the optimal policy changes whenthe threshold is crossed. You will need a way to calculate the optimalpolicy and its value for fixed $R(s)$. (Hint: Prove thatthe value of any fixed policy varies linearly with $R(s)$.)",
        "url": " /complex-decisions-exercises/ex_7/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-17":  {
        "title": "Exercise 17.17",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.17 [2state-pomdp-exercise]Consider a version of the two-state POMDP onpage 2state-pomdp-page in which the sensor is 90% reliable in state 0 butprovides no information in state 1 (that is, it reports 0 or 1 withequal probability). Analyze, either qualitatively or quantitatively, theutility function and the optimal policy for this problem.",
        "url": " /complex-decisions-exercises/ex_17/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-5":  {
        "title": "Exercise 17.5",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.5Can any finite search problem be translated exactly into a Markovdecision problem such that an optimal solution of the latter is also anoptimal solution of the former? If so, explain preciselyhow to translate the problem and how to translate the solution back; ifnot, explain precisely why not (i.e., give acounterexample).",
        "url": " /complex-decisions-exercises/ex_5/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-25":  {
        "title": "Exercise 17.25",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.25Teams in the National Hockey League historically received 2 points forwinning a game and 0 for losing. If the game is tied, an overtime periodis played; if nobody wins in overtime, the game is a tie and each teamgets 1 point. But league officials felt that teams were playing tooconservatively in overtime (to avoid a loss), and it would be moreexciting if overtime produced a winner. So in 1999 the officialsexperimented in mechanism design: the rules were changed, giving a teamthat loses in overtime 1 point, not 0. It is still 2 points for a winand 1 for a tie.      Was hockey a zero-sum game before the rule change? After?        Suppose that at a certain time $t$ in a game, the home team hasprobability $p$ of winning in regulation time, probability $0.78-p$of losing, and probability 0.22 of going into overtime, where theyhave probability $q$ of winning, $.9-q$ of losing, and .1 of tying.Give equations for the expected value for the home andvisiting teams.        Imagine that it were legal and ethical for the two teams to enterinto a pact where they agree that they will skate to a tie inregulation time, and then both try in earnest to win in overtime.Under what conditions, in terms of $p$ and $q$, would it be rationalfor both teams to agree to this pact?        @Longley+Sankaran:2005 report that since the rule change, the percentage of games with awinner in overtime went up 18.2%, as desired, but the percentage ofovertime games also went up 3.6%. What does that suggest aboutpossible collusion or conservative play after the rule change?  ",
        "url": " /complex-decisions-exercises/ex_25/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-10":  {
        "title": "Exercise 17.10",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.10 [3x3-mdp-exercise]Consider the $3 times 3$ world shown inFigure grid-mdp-figure(a). The transition model is thesame as in the $4times 3$Figure sequential-decision-world-figure: 80% of thetime the agent goes in the direction it selects; the rest of the time itmoves at right angles to the intended direction.Implement value iteration for this world for each value of $r$ below.Use discounted rewards with a discount factor of 0.99. Show the policyobtained in each case. Explain intuitively why the value of $r$ leads toeach policy.      $r = -100$        $r = -3$        $r = 0$        $r = +3$  ",
        "url": " /complex-decisions-exercises/ex_10/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-22":  {
        "title": "Exercise 17.22",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.22The following payoff matrix, from @Blinder:1983 by way of @Bernstein:1996, shows a game betweenpoliticians and the Federal Reserve.                   Fed: contract      Fed: do nothing      Fed: expand                  Pol: contract      $F=7, P=1$      $F=9,P=4$      $F=6,P=6$              Pol: do nothing      $F=8, P=2$      $F=5,P=5$      $F=4,P=9$              Pol: expand      $F=3, P=3$      $F=2,P=7$      $F=1,P=8$      Politicians can expand or contract fiscal policy, while the Fed canexpand or contract monetary policy. (And of course either side canchoose to do nothing.) Each side also has preferences for who should dowhat—neither side wants to look like the bad guys. The payoffs shown aresimply the rank orderings: 9 for first choice through 1 for last choice.Find the Nash equilibrium of the game in pure strategies. Is this aPareto-optimal solution? You might wish to analyze the policies ofrecent administrations in this light.",
        "url": " /complex-decisions-exercises/ex_22/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-18":  {
        "title": "Exercise 17.18",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.18 [dominant-equilibrium-exercise]Show that a dominant strategyequilibrium is a Nash equilibrium, but not vice versa.",
        "url": " /complex-decisions-exercises/ex_18/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-24":  {
        "title": "Exercise 17.24",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.24Imagine an auction mechanism that is just like an ascending-bid auction,except that at the end, the winning bidder, the one who bid $b_{max}$,pays only $b_{max}/2$ rather than $b_{max}$. Assuming all agents arerational, what is the expected revenue to the auctioneer for thismechanism, compared with a standard ascending-bid auction?",
        "url": " /complex-decisions-exercises/ex_24/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-15":  {
        "title": "Exercise 17.15",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.15 [4x3-pomdp-exercise]Let the initial belief state $b_0$ for the$4times 3$ POMDP on page 4x3-pomdp-page be the uniform distributionover the nonterminal states, i.e.,$&amp;lt; frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},frac{1}{9},0,0 &amp;gt;$.Calculate the exact belief state $b_1$ after the agent moves and itssensor reports 1 adjacent wall. Also calculate $b_2$ assuming that thesame thing happens again.",
        "url": " /complex-decisions-exercises/ex_15/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-16":  {
        "title": "Exercise 17.16",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.16What is the time complexity of $d$ steps of POMDP value iteration for asensorless environment?",
        "url": " /complex-decisions-exercises/ex_16/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-8":  {
        "title": "Exercise 17.8",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.8 [vi-contraction-exercise]Equation (vi-contraction-equation) onpage vi-contraction-equation states that the Bellman operator is a contraction.      Show that, for any functions $f$ and $g$,        Write out an expression for  and then applythe result from (1) to complete the proof that the Bellman operatoris a contraction.  ",
        "url": " /complex-decisions-exercises/ex_8/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-2":  {
        "title": "Exercise 17.2",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.2 [mdp-model-exercise]For the $4times 3$ world shown inFigure sequential-decision-world-figure, calculatewhich squares can be reached from (1,1) by the action sequence$[{Right},{Right},{Right},{Up},{Up}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section) for ahidden Markov model.",
        "url": " /complex-decisions-exercises/ex_2/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-9":  {
        "title": "Exercise 17.9",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.9This exercise considers two-player MDPs that correspond to zero-sum,turn-taking games like those inChapter game-playing-chapter. Let the players be $A$and $B$, and let $R(s)$ be the reward for player $A$ in state $s$. (Thereward for $B$ is always equal and opposite.)      Let $U_A(s)$ be the utility of state $s$ when it is $A$’s turn tomove in $s$, and let $U_B(s)$ be the utility of state $s$ when it is$B$’s turn to move in $s$. All rewards and utilities are calculatedfrom $A$’s point of view (just as in a minimax game tree). Writedown Bellman equations defining $U_A(s)$ and $U_B(s)$.        Explain how to do two-player value iteration with these equations,and define a suitable termination criterion.        Consider the game described inFigure line-game4-figure on page line-game4-figure.Draw the state space (rather than the game tree), showing the movesby $A$ as solid lines and moves by $B$ as dashed lines. Mark eachstate with $R(s)$. You will find it helpful to arrange the states$(s_A,s_B)$ on a two-dimensional grid, using $s_A$ and $s_B$ as“coordinates.”        Now apply two-player value iteration to solve this game, and derivethe optimal policy.  Figure [grid-mdp-figure] (a) $3 times 3$ world for Exercise [3x3-mdp-exercise](#/). The reward for each state is indicated. The upper right square is a terminal state. (b) $101 times 3$ world for Exercise [101x3-mdp-exercise](#/) (omitting 93 identical columns in the middle). The start state has reward 0.",
        "url": " /complex-decisions-exercises/ex_9/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-19":  {
        "title": "Exercise 17.19",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.19In the children’s game of rock–paper–scissors each player reveals at thesame time a choice of rock, paper, or scissors. Paper wraps rock, rockblunts scissors, and scissors cut paper. In the extended versionrock–paper–scissors–fire–water, fire beats rock, paper, and scissors;rock, paper, and scissors beat water; and water beats fire. Write outthe payoff matrix and find a mixed-strategy solution to this game.",
        "url": " /complex-decisions-exercises/ex_19/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-6":  {
        "title": "Exercise 17.6",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.6 [reward-equivalence-exercise]Sometimes MDPs are formulated with areward function $R(s,a)$ that depends on the action taken or with areward function $R(s,a,s’)$ that also depends on the outcome state.      Write the Bellman equations for these formulations.        Show how an MDP with reward function $R(s,a,s’)$ can be transformedinto a different MDP with reward function $R(s,a)$, such thatoptimal policies in the new MDP correspond exactly to optimalpolicies in the original MDP.        Now do the same to convert MDPs with $R(s,a)$ into MDPs with $R(s)$.  ",
        "url": " /complex-decisions-exercises/ex_6/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-21":  {
        "title": "Exercise 17.21",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.21In the Prisoner’s Dilemma, consider the case where aftereach round, Alice and Bob have probability $X$ meeting again. Supposeboth players choose the perpetual punishment strategy (where each willchoose ${refuse}$ unless the other player has ever played${testify}$). Assume neither player has played ${testify}$ thus far.What is the expected future total payoff for choosing to ${testify}$versus ${refuse}$ when $X = .2$? How about when $X = .05$? For whatvalue of $X$ is the expected future total payoff the same whether onechooses to ${testify}$ or ${refuse}$ in the current round?",
        "url": " /complex-decisions-exercises/ex_21/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-1":  {
        "title": "Exercise 17.1",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.1 [mdp-model-exercise]For the $4times 3$ world shown inFigure sequential-decision-world-figure, calculatewhich squares can be reached from (1,1) by the action sequence$[{Up},{Up},{Right},{Right},{Right}]$ and with whatprobabilities. Explain how this computation is related to the predictiontask (see Section general-filtering-section) for ahidden Markov model.",
        "url": " /complex-decisions-exercises/ex_1/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-13":  {
        "title": "Exercise 17.13",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.13Consider the $4times 3$ world shown inFigure sequential-decision-world-figure.      Implement an environment simulator for this environment, such thatthe specific geography of the environment is easily altered. Somecode for doing this is already in the online code repository.        Create an agent that uses policy iteration, and measure itsperformance in the environment simulator from variousstarting states. Perform several experiments from each startingstate, and compare the average total reward received per run withthe utility of the state, as determined by your algorithm.        Experiment with increasing the size of the environment. How does therun time for policy iteration vary with the size of the environment?  ",
        "url": " /complex-decisions-exercises/ex_13/"
      }
    
  
    ,
      "complex-decisions-exercises-ex-12":  {
        "title": "Exercise 17.12",
        "breadcrumb": "17-Making-Complex-Decision",
      	"content"  : "Exercise 17.12Consider an undiscounted MDP having three states, (1, 2, 3), withrewards $-1$, $-2$, $0$, respectively. State 3 is a terminal state. Instates 1 and 2 there are two possible actions: $a$ and $b$. Thetransition model is as follows:      In state 1, action $a$ moves the agent to state 2 with probability0.8 and makes the agent stay put with probability 0.2.        In state 2, action $a$ moves the agent to state 1 with probability0.8 and makes the agent stay put with probability 0.2.        In either state 1 or state 2, action $b$ moves the agent to state 3with probability 0.1 and makes the agent stay put withprobability 0.9.  Answer the following questions:      What can be determined qualitatively about theoptimal policy in states 1 and 2?        Apply policy iteration, showing each step in full, to determine theoptimal policy and the values of states 1 and 2. Assume that theinitial policy has action $b$ in both states.        What happens to policy iteration if the initial policy has action$a$ in both states? Does discounting help? Does the optimal policydepend on the discount factor?  ",
        "url": " /complex-decisions-exercises/ex_12/"
      }
    
  
    
  
    ,
      "search-exercises-ex-28":  {
        "title": "Exercise 3.28",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.28Sometimes there is no good evaluation function for a problem but thereis a good comparison method: a way to tell whether one node is betterthan another without assigning numerical values to either. Show thatthis is enough to do a best-first search. Is there an analog of A forthis setting?",
        "url": " /search-exercises/ex_28/"
      }
    
  
    ,
      "search-exercises-ex-29":  {
        "title": "Exercise 3.29",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.29 [a*-failure-exercise]Devise a state space in which A using returns asuboptimal solution with an $h(n)$ function that is admissible butinconsistent.",
        "url": " /search-exercises/ex_29/"
      }
    
  
    ,
      "search-exercises-ex-3":  {
        "title": "Exercise 3.3",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.3Your goal is to navigate a robot out of a maze. The robot starts in thecenter of the maze facing north. You can turn the robot to face north,east, south, or west. You can direct the robot to move forward a certaindistance, although it will stop before hitting a wall.      Formulate this problem. How large is the state space?        In navigating a maze, the only place we need to turn is at theintersection of two or more corridors. Reformulate this problemusing this observation. How large is the state space now?        From each point in the maze, we can move in any of the fourdirections until we reach a turning point, and this is the onlyaction we need to do. Reformulate the problem using these actions.Do we need to keep track of the robot’s orientation now?        In our initial description of the problem we already abstracted fromthe real world, restricting actions and removing details. List threesuch simplifications we made.  ",
        "url": " /search-exercises/ex_3/"
      }
    
  
    ,
      "search-exercises-ex-36":  {
        "title": "Exercise 3.36",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.36Invent a heuristic function for the 8-puzzle that sometimesoverestimates, and show how it can lead to a suboptimal solution on aparticular problem. (You can use a computer to help if you want.) Provethat if $h$ never overestimates by more than $c$, A using $h$ returns asolution whose cost exceeds that of the optimal solution by no more than$c$.",
        "url": " /search-exercises/ex_36/"
      }
    
  
    ,
      "search-exercises-ex-11":  {
        "title": "Exercise 3.11",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.11 [mc-problem]The problem is usually stated as follows. Threemissionaries and three cannibals are on one side of a river, along witha boat that can hold one or two people. Find a way to get everyone tothe other side without ever leaving a group of missionaries in one placeoutnumbered by the cannibals in that place. This problem is famous in AIbecause it was the subject of the first paper that approached problemformulation from an analytical viewpoint @Amarel:1968.      Formulate the problem precisely, making only those distinctionsnecessary to ensure a valid solution. Draw a diagram of the completestate space.        Implement and solve the problem optimally using an appropriatesearch algorithm. Is it a good idea to check for repeated states?        Why do you think people have a hard time solving this puzzle, giventhat the state space is so simple?  ",
        "url": " /search-exercises/ex_11/"
      }
    
  
    ,
      "search-exercises-ex-14":  {
        "title": "Exercise 3.14",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.14An action such as really consists of a long sequence of finer-grainedactions: turn on the car, release the brake, accelerate forward, etc.Having composite actions of this kind reduces the number of steps in asolution sequence, thereby reducing the search time. Suppose we takethis to the logical extreme, by making super-composite actions out ofevery possible sequence of actions. Then every problem instance issolved by a single super-composite action, such as . Explain how searchwould work in this formulation. Is this a practical approach forspeeding up problem solving?",
        "url": " /search-exercises/ex_14/"
      }
    
  
    ,
      "search-exercises-ex-4":  {
        "title": "Exercise 3.4",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.4You have a $9 times 9$ grid of squares, each of which can be coloredred or blue. The grid is initially colored all blue, but you can changethe color of any square any number of times. Imagining the grid dividedinto nine $3 times 3$ sub-squares, you want each sub-square to be allone color but neighboring sub-squares to be different colors.      Formulate this problem in the straightforward way. Compute the sizeof the state space.        You need color a square only once. Reformulate, and compute the sizeof the state space. Would breadth-first graph search perform fasteron this problem than on the one in (a)? How about iterativedeepening tree search?        Given the goal, we need consider only colorings where eachsub-square is uniformly colored. Reformulate the problem and computethe size of the state space.        How many solutions does this problem have?        Parts (b) and (c) successively abstracted the original problem (a).Can you give a translation from solutions in problem (c) intosolutions in problem (b), and from solutions in problem (b) intosolutions for problem (a)?  ",
        "url": " /search-exercises/ex_4/"
      }
    
  
    ,
      "search-exercises-ex-37":  {
        "title": "Exercise 3.37",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.37[consistent-heuristic-exercise]Prove that if a heuristic isconsistent, it must be admissible. Construct an admissible heuristicthat is not consistent.",
        "url": " /search-exercises/ex_37/"
      }
    
  
    ,
      "search-exercises-ex-23":  {
        "title": "Exercise 3.23",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.23Write a program that will take as input two Web page URLs and find apath of links from one to the other. What is an appropriate searchstrategy? Is bidirectional search a good idea? Could a search engine beused to implement a predecessor function?",
        "url": " /search-exercises/ex_23/"
      }
    
  
    ,
      "search-exercises-ex-20":  {
        "title": "Exercise 3.20",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.20Implement two versions of the function for the 8-puzzle: one that copiesand edits the data structure for the parent node $s$ and one thatmodifies the parent state directly (undoing the modifications asneeded). Write versions of iterative deepening depth-first search thatuse these functions and compare their performance.",
        "url": " /search-exercises/ex_20/"
      }
    
  
    ,
      "search-exercises-ex-33":  {
        "title": "Exercise 3.33",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.33$n$ vehicles occupy squares $(1,1)$ through $(n,1)$ (i.e., the bottomrow) of an $ntimes n$ grid. The vehicles must be moved to the top rowbut in reverse order; so the vehicle $i$ that starts in $(i,1)$ must endup in $(n-i+1,n)$. On each time step, every one of the $n$ vehicles canmove one square up, down, left, or right, or stay put; but if a vehiclestays put, one other adjacent vehicle (but not more than one) can hopover it. Two vehicles cannot occupy the same square.      Calculate the size of the state space as a function of $n$.        Calculate the branching factor as a function of $n$.        Suppose that vehicle $i$ is at $(x_i,y_i)$; write a nontrivialadmissible heuristic $h_i$ for the number of moves it will requireto get to its goal location $(n-i+1,n)$, assuming no other vehiclesare on the grid.        Which of the following heuristics are admissible for the problem ofmoving all $n$ vehicles to their destinations? Explain.                  $sum_{i= 1}^{n} h_i$.                    $max{h_1,ldots,h_n}$.                    $min{h_1,ldots,h_n}$.            ",
        "url": " /search-exercises/ex_33/"
      }
    
  
    ,
      "search-exercises-ex-39":  {
        "title": "Exercise 3.39",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.39 [Gaschnig-h-exercise]On page Gaschnig-h-page , we defined the relaxation of the 8-puzzle inwhich a tile can move from square A to square B if B is blank. The exactsolution of this problem defines Gaschnig’s heuristic @Gaschnig:1979. Explain why Gaschnig’sheuristic is at least as accurate as $h_1$ (misplaced tiles), and showcases where it is more accurate than both $h_1$ and $h_2$ (Manhattandistance). Explain how to calculate Gaschnig’s heuristic efficiently.",
        "url": " /search-exercises/ex_39/"
      }
    
  
    ,
      "search-exercises-ex-7":  {
        "title": "Exercise 3.7",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.7 [nqueens-size-exercise]Consider the $n$-queens problem using the“efficient” incremental formulation given on page nqueens-page. Explain why the statespace has at least $sqrt[3]{n!}$ states and estimate the largest $n$for which exhaustive exploration is feasible. (Hint:Derive a lower bound on the branching factor by considering the maximumnumber of squares that a queen can attack in any column.)",
        "url": " /search-exercises/ex_7/"
      }
    
  
    ,
      "search-exercises-ex-38":  {
        "title": "Exercise 3.38",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.38[tsp-mst-exercise]The traveling salesperson problem (TSP) can besolved with the minimum-spanning-tree (MST) heuristic, which estimatesthe cost of completing a tour, given that a partial tour has alreadybeen constructed. The MST cost of a set of cities is the smallest sum ofthe link costs of any tree that connects all the cities.      Show how this heuristic can be derived from a relaxed version ofthe TSP.        Show that the MST heuristic dominates straight-line distance.        Write a problem generator for instances of the TSP where cities arerepresented by random points in the unit square.        Find an efficient algorithm in the literature for constructing theMST, and use it with A graph search to solve instances of the TSP.  ",
        "url": " /search-exercises/ex_38/"
      }
    
  
    ,
      "search-exercises-ex-17":  {
        "title": "Exercise 3.17",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.17Which of the following are true and which are false? Explain youranswers.      Depth-first search always expands at least as many nodes as A searchwith an admissible heuristic.        $h(n)=0$ is an admissible heuristic for the 8-puzzle.        A is of no use in robotics because percepts, states, and actionsare continuous.        Breadth-first search is complete even if zero step costsare allowed.        Assume that a rook can move on a chessboard any number of squares ina straight line, vertically or horizontally, but cannot jump overother pieces. Manhattan distance is an admissible heuristic for theproblem of moving the rook from square A to square B in the smallestnumber of moves.  ",
        "url": " /search-exercises/ex_17/"
      }
    
  
    ,
      "search-exercises-ex-5":  {
        "title": "Exercise 3.5",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.5 [two-friends-exercise]Suppose two friends live in different cities ona map, such as the Romania map shown in . On every turn, we cansimultaneously move each friend to a neighboring city on the map. Theamount of time needed to move from city $i$ to neighbor $j$ is equal tothe road distance $d(i,j)$ between the cities, but on each turn thefriend that arrives first must wait until the other one arrives (andcalls the first on his/her cell phone) before the next turn can begin.We want the two friends to meet as quickly as possible.      Write a detailed formulation for this search problem. (You will findit helpful to define some formal notation here.)        Let $D(i,j)$ be the straight-line distance between cities $i$ and$j$. Which of the following heuristic functions are admissible? (i)$D(i,j)$; (ii) $2cdot D(i,j)$; (iii) $D(i,j)/2$.        Are there completely connected maps for which no solution exists?        Are there maps in which all solutions require one friend to visitthe same city twice?  ",
        "url": " /search-exercises/ex_5/"
      }
    
  
    ,
      "search-exercises-ex-25":  {
        "title": "Exercise 3.25",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.25 [search-special-case-exercise]Prove each of the following statements,or give a counterexample:      Breadth-first search is a special case of uniform-cost search.        Depth-first search is a special case of best-first tree search.        Uniform-cost search is a special case of A search.  ",
        "url": " /search-exercises/ex_25/"
      }
    
  
    ,
      "search-exercises-ex-10":  {
        "title": "Exercise 3.10",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.10 [negative-g-exercise]On page non-negative-g, we said that we would not consider problemswith negative path costs. In this exercise, we explore this decision inmore depth.      Suppose that actions can have arbitrarily large negative costs;explain why this possibility would force any optimal algorithm toexplore the entire state space.        Does it help if we insist that step costs must be greater than orequal to some negative constant $c$? Consider both trees and graphs.        Suppose that a set of actions forms a loop in the state space suchthat executing the set in some order results in no net change tothe state. If all of these actions have negative cost, what doesthis imply about the optimal behavior for an agent in such anenvironment?        One can easily imagine actions with high negative cost, even indomains such as route finding. For example, some stretches of roadmight have such beautiful scenery as to far outweigh the normalcosts in terms of time and fuel. Explain, in precise terms, withinthe context of state-space search, why humans do not drive aroundscenic loops indefinitely, and explain how to define the state spaceand actions for route finding so that artificial agents can alsoavoid looping.        Can you think of a real domain in which step costs are such as tocause looping?  ",
        "url": " /search-exercises/ex_10/"
      }
    
  
    ,
      "search-exercises-ex-22":  {
        "title": "Exercise 3.22",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.22Describe a state space in which iterative deepening search performs muchworse than depth-first search (for example, $O(n^{2})$ vs. $O(n)$).",
        "url": " /search-exercises/ex_22/"
      }
    
  
    ,
      "search-exercises-ex-18":  {
        "title": "Exercise 3.18",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.18Consider a state space where the start state is number 1 and each state$k$ has two successors: numbers $2k$ and $2k+1$.      Draw the portion of the state space for states 1 to 15.        Suppose the goal state is 11. List the order in which nodes will bevisited for breadth-first search, depth-limited search with limit 3,and iterative deepening search.        How well would bidirectional search work on this problem? What isthe branching factor in each direction of the bidirectional search?        Does the answer to (c) suggest a reformulation of the problem thatwould allow you to solve the problem of getting from state 1 to agiven goal state with almost no search?        Call the action going from $k$ to $2k$ Left, and the action going to$2k+1$ Right. Can you find an algorithm that outputs the solution tothis problem without any search at all?  ",
        "url": " /search-exercises/ex_18/"
      }
    
  
    ,
      "search-exercises-ex-31":  {
        "title": "Exercise 3.31",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.31The heuristic path algorithm @Pohl:1977 is a best-first search in which the evaluation functionis $f(n) =(2-w)g(n) + wh(n)$. For what values of $w$ is this complete? For whatvalues is it optimal, assuming that $h$ is admissible? What kind ofsearch does this perform for $w=0$, $w=1$, and $w=2$?",
        "url": " /search-exercises/ex_31/"
      }
    
  
    ,
      "search-exercises-ex-24":  {
        "title": "Exercise 3.24",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.24 [vacuum-search-exercise]Consider the vacuum-world problem defined in .      Which of the algorithms defined in this chapter would be appropriatefor this problem? Should the algorithm use tree search or graphsearch?        Apply your chosen algorithm to compute an optimal sequence ofactions for a $3times 3$ world whose initial state has dirt in thethree top squares and the agent in the center.        Construct a search agent for the vacuum world, and evaluate itsperformance in a set of $3times 3$ worlds with probability 0.2 ofdirt in each square. Include the search cost as well as path cost inthe performance measure, using a reasonable exchange rate.        Compare your best search agent with a simple randomized reflex agentthat sucks if there is dirt and otherwise moves randomly.        Consider what would happen if the world were enlarged to$n times n$. How does the performance of the search agent and ofthe reflex agent vary with $n$?  ",
        "url": " /search-exercises/ex_24/"
      }
    
  
    ,
      "search-exercises-ex-34":  {
        "title": "Exercise 3.34",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.34Consider the problem of moving $k$ knights from $k$ starting squares$s_1,ldots,s_k$ to $k$ goal squares $g_1,ldots,g_k$, on an unboundedchessboard, subject to the rule that no two knights can land on the samesquare at the same time. Each action consists of moving upto $k$ knights simultaneously. We would like to complete themaneuver in the smallest number of actions.      What is the maximum branching factor in this state space, expressedas a function of $k$?        Suppose $h_i$ is an admissible heuristic for the problem of movingknight $i$ to goal $g_i$ by itself. Which of the followingheuristics are admissible for the $k$-knight problem? Of those,which is the best?                  $min{h_1,ldots,h_k}$.                    $max{h_1,ldots,h_k}$.                    $sum_{i= 1}^{k} h_i$.                  Repeat (b) for the case where you are allowed to move only oneknight at a time.  ",
        "url": " /search-exercises/ex_34/"
      }
    
  
    ,
      "search-exercises-ex-15":  {
        "title": "Exercise 3.15",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.15Does a finite state space always lead to a finite search tree? How abouta finite state space that is a tree? Can you be more precise about whattypes of state spaces always lead to finite search trees? (Adapted from, 1996.)",
        "url": " /search-exercises/ex_15/"
      }
    
  
    ,
      "search-exercises-ex-16":  {
        "title": "Exercise 3.16",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.16 [graph-separation-property-exercise]Prove that satisfies the graphseparation property illustrated in . (Hint: Begin byshowing that the property holds at the start, then show that if it holdsbefore an iteration of the algorithm, it holds afterwards.) Describe asearch algorithm that violates the property.",
        "url": " /search-exercises/ex_16/"
      }
    
  
    ,
      "search-exercises-ex-32":  {
        "title": "Exercise 3.32",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.32Consider the unbounded version of the regular 2D grid shown in . Thestart state is at the origin, (0,0), and the goal state is at $(x,y)$.      What is the branching factor $b$ in this state space?        How many distinct states are there at depth $k$ (for $k&amp;gt;0$)?        What is the maximum number of nodes expanded by breadth-first treesearch?        What is the maximum number of nodes expanded by breadth-first graphsearch?        Is $h = |u-x| + |v-y|$ an admissible heuristic for a state at$(u,v)$? Explain.        How many nodes are expanded by A graph search using $h$?        Does $h$ remain admissible if some links are removed?        Does $h$ remain admissible if some links are added betweennonadjacent states?  ",
        "url": " /search-exercises/ex_32/"
      }
    
  
    ,
      "search-exercises-ex-40":  {
        "title": "Exercise 3.40",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.40We gave two simple heuristics for the 8-puzzle: Manhattan distance andmisplaced tiles. Several heuristics in the literature purport to improveon this—see, for example, @Nilsson:1971,@Mostow+Prieditis:1989, and @Hansson+al:1992. Test these claims by implementingthe heuristics and comparing the performance of the resultingalgorithms.",
        "url": " /search-exercises/ex_40/"
      }
    
  
    ,
      "search-exercises-ex-30":  {
        "title": "Exercise 3.30",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.30Accurate heuristics don’t necessarily reduce search time in the worstcase. Given any depth $d$, define a search problem with a goal node atdepth $d$, and write a heuristic function such that $|h(n) - h^*(n)|  le O(log h^*(n))$ but $A^*$ expands all nodes of depth lessthan $d$.",
        "url": " /search-exercises/ex_30/"
      }
    
  
    ,
      "search-exercises-ex-8":  {
        "title": "Exercise 3.8",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.8Give a complete problem formulation for each of the following. Choose aformulation that is precise enough to be implemented.      Using only four colors, you have to color a planar map in such a waythat no two adjacent regions have the same color.        A 3-foot-tall monkey is in a room where some bananas are suspendedfrom the 8-foot ceiling. He would like to get the bananas. The roomcontains two stackable, movable, climbable 3-foot-high crates.        You have a program that outputs the message “illegal input record”when fed a certain file of input records. You know that processingof each record is independent of the other records. You want todiscover what record is illegal.        You have three jugs, measuring 12 gallons, 8 gallons, and 3 gallons,and a water faucet. You can fill the jugs up or empty them out fromone to another or onto the ground. You need to measure out exactlyone gallon.  ",
        "url": " /search-exercises/ex_8/"
      }
    
  
    ,
      "search-exercises-ex-2":  {
        "title": "Exercise 3.2",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.2Give a complete problem formulation for each of the following problems.Choose a formulation that is precise enough to be implemented.      There are six glass boxes in a row, each with a lock. Each of thefirst five boxes holds a key unlocking the next box in line; thelast box holds a banana. You have the key to the first box, and youwant the banana.        You start with the sequence ABABAECCEC, or in general any sequencemade from A, B, C, and E. You can transform this sequence using thefollowing equalities: AC = E, AB = BC, BB = E, and E$x$ = $x$ forany $x$. For example, ABBC can be transformed into AEC, and then AC,and then E. Your goal is to produce the sequence E.        There is an $n times n$ grid of squares, each square initiallybeing either unpainted floor or a bottomless pit. You start standingon an unpainted floor square, and can either paint the square underyou or move onto an adjacent unpainted floor square. You want thewhole floor painted.        A container ship is in port, loaded high with containers. There 13rows of containers, each 13 containers wide and 5 containers tall.You control a crane that can move to any location above the ship,pick up the container under it, and move it onto the dock. You wantthe ship unloaded.  ",
        "url": " /search-exercises/ex_2/"
      }
    
  
    ,
      "search-exercises-ex-9":  {
        "title": "Exercise 3.9",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.9 [path-planning-exercise]Consider the problem of finding the shortestpath between two points on a plane that has convex polygonal obstaclesas shown in Figure polygonal obstacles. This is an idealization of the problem that a robot has tosolve to navigate in a crowded environment.      Suppose the state space consists of all positions $(x,y)$ inthe plane. How many states are there? How many paths are there tothe goal?        Explain briefly why the shortest path from one polygon vertex to anyother in the scene must consist of straight-line segments joiningsome of the vertices of the polygons. Define a good state space now.How large is this state space?        Define the necessary functions to implement the search problem,including an function that takes a vertex as input and returns a setof vectors, each of which maps the current vertex to one of thevertices that can be reached in a straight line. (Do not forget theneighbors on the same polygon.) Use the straight-line distance forthe heuristic function.        Apply one or more of the algorithms in this chapter to solve a rangeof problems in the domain, and comment on their performance.Figure A scene with polygonal obstacles. S and G are the start and goal states.  ",
        "url": " /search-exercises/ex_9/"
      }
    
  
    ,
      "search-exercises-ex-35":  {
        "title": "Exercise 3.35",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.35We saw on page I-to-F that the straight-line distance heuristic leads greedybest-first search astray on the problem of going from Iasi to Fagaras.However, the heuristic is perfect on the opposite problem: going fromFagaras to Iasi. Are there problems for which the heuristic ismisleading in both directions?",
        "url": " /search-exercises/ex_35/"
      }
    
  
    ,
      "search-exercises-ex-19":  {
        "title": "Exercise 3.19",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.19 [brio-exercise]A basic wooden railway set contains the pieces shown in Figure wooded railway set. The task is to connect these pieces into a railway that has nooverlapping tracks and no loose ends where a train could run off ontothe floor.      Suppose that the pieces fit together exactly with noslack. Give a precise formulation of the task as a search problem.        Identify a suitable uninformed search algorithm for this task andexplain your choice.        Explain why removing any one of the “fork” pieces makes theproblem unsolvable.        Give an upper bound on the total size of the state space defined byyour formulation. (Hint: think about the maximumbranching factor for the construction process and the maximum depth,ignoring the problem of overlapping pieces and loose ends. Begin bypretending that every piece is unique.) Figure  The track pieced in a wooden railway set; each is labeled with the number of copies in the set. Note that curved pieces and “fork” pieces (“switches” or “points”) can be flipped over so they can curve in either direction. Each curve sustends 45 degrees.  ",
        "url": " /search-exercises/ex_19/"
      }
    
  
    ,
      "search-exercises-ex-27":  {
        "title": "Exercise 3.27",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.27Trace the operation of A search applied to the problem of getting toBucharest from Lugoj using the straight-line distance heuristic. Thatis, show the sequence of nodes that the algorithm will consider and the$f$, $g$, and $h$ score for each node.",
        "url": " /search-exercises/ex_27/"
      }
    
  
    ,
      "search-exercises-ex-6":  {
        "title": "Exercise 3.6",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.6 [8puzzle-parity-exercise]Show that the 8-puzzle states are dividedinto two disjoint sets, such that any state is reachable from any otherstate in the same set, while no state is reachable from any state in theother set. (Hint: See @Berlekamp+al:1982.) Devise a procedure to decidewhich set a given state is in, and explain why this is useful forgenerating random states.",
        "url": " /search-exercises/ex_6/"
      }
    
  
    ,
      "search-exercises-ex-26":  {
        "title": "Exercise 3.26",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.26Compare the performance of A and RBFS on a set of randomly generatedproblems in the 8-puzzle (with Manhattan distance) and TSP (with MST—see) domains. Discuss your results. What happens to the performance of RBFSwhen a small random number is added to the heuristic values in the8-puzzle domain?",
        "url": " /search-exercises/ex_26/"
      }
    
  
    ,
      "search-exercises-ex-21":  {
        "title": "Exercise 3.21",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.21 [iterative-lengthening-exercise]On page iterative-lengthening-page,we mentioned iterative lengthening search,an iterative analog of uniform cost search. The idea is to use increasing limits onpath cost. If a node is generated whose path cost exceeds the currentlimit, it is immediately discarded. For each new iteration, the limit isset to the lowest path cost of any node discarded in the previousiteration.      Show that this algorithm is optimal for general path costs.        Consider a uniform tree with branching factor $b$, solution depth$d$, and unit step costs. How many iterations will iterativelengthening require?        Now consider step costs drawn from the continuous range$[epsilon,1]$, where $0 &amp;lt; epsilon &amp;lt; 1$. How many iterations arerequired in the worst case?        Implement the algorithm and apply it to instances of the 8-puzzleand traveling salesperson problems. Compare the algorithm’sperformance to that of uniform-cost search, and comment onyour results.  ",
        "url": " /search-exercises/ex_21/"
      }
    
  
    ,
      "search-exercises-ex-1":  {
        "title": "Exercise 3.1",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.1Explain why problem formulation must follow goal formulation.",
        "url": " /search-exercises/ex_1/"
      }
    
  
    ,
      "search-exercises-ex-13":  {
        "title": "Exercise 3.13",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.13What’s the difference between a world state, a state description, and asearch node? Why is this distinction useful?",
        "url": " /search-exercises/ex_13/"
      }
    
  
    ,
      "search-exercises-ex-12":  {
        "title": "Exercise 3.12",
        "breadcrumb": "3-Solving-Problems-By-Searching",
      	"content"  : "Exercise 3.12Define in your own words the following terms: state, state space, searchtree, search node, goal, action, transition model, and branching factor.",
        "url": " /search-exercises/ex_12/"
      }
    
  
    
  
    ,
      "csp-exercises-ex-3":  {
        "title": "Exercise 6.3",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.3 [crossword-exercise]Consider the problem of constructing (not solving)crossword puzzles fitting words into a rectangular grid. The grid,which is given as part of the problem, specifies which squares are blankand which are shaded. Assume that a list of words (i.e., a dictionary)is provided and that the task is to fill in the blank squares by usingany subset of the list. Formulate this problem precisely in two ways:      As a general search problem. Choose an appropriate search algorithmand specify a heuristic function. Is it better to fill in blanks oneletter at a time or one word at a time?        As a constraint satisfaction problem. Should the variables be wordsor letters?  Which formulation do you think will be better? Why?",
        "url": " /csp-exercises/ex_3/"
      }
    
  
    ,
      "csp-exercises-ex-11":  {
        "title": "Exercise 6.11",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.11Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${green},V{red}$ for the problemshown in Figure australia-figure.",
        "url": " /csp-exercises/ex_11/"
      }
    
  
    ,
      "csp-exercises-ex-14":  {
        "title": "Exercise 6.14",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.14 [ac4-exercise]AC-3 puts back on the queue every arc($X_{k}, X_{i}$) whenever any value is deleted from thedomain of $X_{i}$, even if each value of $X_{k}$ is consistent withseveral remaining values of $X_{i}$. Suppose that, for every arc($X_{k}, X_{i}$), we keep track of the number of remaining values of$X_{i}$ that are consistent with each value of $X_{k}$. Explain how toupdate these numbers efficiently and hence show that arc consistency canbe enforced in total time $O(n^2d^2)$.",
        "url": " /csp-exercises/ex_14/"
      }
    
  
    ,
      "csp-exercises-ex-4":  {
        "title": "Exercise 6.4",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.4 [csp-definition-exercise]Give precise formulations for each of thefollowing as constraint satisfaction problems:      Rectilinear floor-planning: find non-overlapping places in a largerectangle for a number of smaller rectangles.        Class scheduling: There is a fixed number of professors andclassrooms, a list of classes to be offered, and a list of possibletime slots for classes. Each professor has a set of classes that heor she can teach.        Hamiltonian tour: given a network of cities connected by roads,choose an order to visit all cities in a country withoutrepeating any.  ",
        "url": " /csp-exercises/ex_4/"
      }
    
  
    ,
      "csp-exercises-ex-20":  {
        "title": "Exercise 6.20",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.20Consider the problem of tiling a surface (completely and exactlycovering it) with $n$ dominoes ($2times1$ rectangles). The surface is an arbitrary edge-connected (i.e.,adjacent along an edge, not just a corner) collection of $2n$$1times 1$ squares (e.g., a checkerboard, a checkerboard with somesquares missing, a $10times 1$ row of squares, etc.).      Formulate this problem precisely as a CSP where the dominoes arethe variables.        Formulate this problem precisely as a CSP where the squares are thevariables, keeping the state space as small as possible.(Hint: does it matter which particular domino goes ona given pair of squares?)        Construct a surface consisting of 6 squares such that your CSPformulation from part (b) has a tree-structuredconstraint graph.        Describe exactly the set of solvable instances that have atree-structured constraint graph.  ^1. @Ginsberg+al:1990 discuss several methods for constructing crossword puzzles.@Littman+al:1999 tackle the harder problem of solving them.",
        "url": " /csp-exercises/ex_20/"
      }
    
  
    ,
      "csp-exercises-ex-7":  {
        "title": "Exercise 6.7",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.7 [zebra-exercise]Consider the following logic puzzle: In five houses,each with a different color, live five persons of differentnationalities, each of whom prefers a different brand of candy, adifferent drink, and a different pet. Given the following facts, thequestions to answer are “Where does the zebra live, and in which housedo they drink water?”The Englishman lives in the red house.The Spaniard owns the dog.The Norwegian lives in the first house on the left.The green house is immediately to the right of the ivory house.The man who eats Hershey bars lives in the house next to the man withthe fox.Kit Kats are eaten in the yellow house.The Norwegian lives next to the blue house.The Smarties eater owns snails.The Snickers eater drinks orange juice.The Ukrainian drinks tea.The Japanese eats Milky Ways.Kit Kats are eaten in a house next to the house where the horse is kept.Coffee is drunk in the green house.Milk is drunk in the middle house.Discuss different representations of this problem as a CSP. Why wouldone prefer one representation over another?",
        "url": " /csp-exercises/ex_7/"
      }
    
  
    ,
      "csp-exercises-ex-17":  {
        "title": "Exercise 6.17",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.17Define in your own words the terms constraint, backtracking search, arcconsistency, backjumping, min-conflicts, and cycle cutset.",
        "url": " /csp-exercises/ex_17/"
      }
    
  
    ,
      "csp-exercises-ex-5":  {
        "title": "Exercise 6.5",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.5Solve the cryptarithmetic problem inFigure cryptarithmetic-figure by hand, using thestrategy of backtracking with forward checking and the MRV andleast-constraining-value heuristics.",
        "url": " /csp-exercises/ex_5/"
      }
    
  
    ,
      "csp-exercises-ex-10":  {
        "title": "Exercise 6.10",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.10Generate random instances of map-coloring problems as follows: scatter$n$ points on the unit square; select a point $X$ at random, connect $X$by a straight line to the nearest point $Y$ such that $X$ is not alreadyconnected to $Y$ and the line crosses no other line; repeat the previousstep until no more connections are possible. The points representregions on the map and the lines connect neighbors. Now try to find$k$-colorings of each map, for both $k3$ and$k4$, using min-conflicts, backtracking, backtracking withforward checking, and backtracking with MAC. Construct a table ofaverage run times for each algorithm for values of $n$ up to the largestyou can manage. Comment on your results.",
        "url": " /csp-exercises/ex_10/"
      }
    
  
    ,
      "csp-exercises-ex-18":  {
        "title": "Exercise 6.18",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.18Define in your own words the terms constraint, commutativity, arcconsistency, backjumping, min-conflicts, and cycle cutset.",
        "url": " /csp-exercises/ex_18/"
      }
    
  
    ,
      "csp-exercises-ex-15":  {
        "title": "Exercise 6.15",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.15The Tree-CSP-Solver (Figure tree-csp-figure) makes arcs consistentstarting at the leaves and working backwards towards the root. Why doesit do that? What would happen if it went in the opposite direction?",
        "url": " /csp-exercises/ex_15/"
      }
    
  
    ,
      "csp-exercises-ex-16":  {
        "title": "Exercise 6.16",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.16We introduced Sudoku as a CSP to be solved by search over partialassignments because that is the way people generally undertake solvingSudoku problems. It is also possible, of course, to attack theseproblems with local search over complete assignments. How well would alocal solver using the min-conflicts heuristic do on Sudoku problems?",
        "url": " /csp-exercises/ex_16/"
      }
    
  
    ,
      "csp-exercises-ex-8":  {
        "title": "Exercise 6.8",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.8Consider the graph with 8 nodes $A_1$, $A_2$, $A_3$, $A_4$, $H$, $T$,$F_1$, $F_2$. $A_i$ is connected to $A_{i+1}$ for all $i$, each $A_i$ isconnected to $H$, $H$ is connected to $T$, and $T$ is connected to each$F_i$. Find a 3-coloring of this graph by hand using the followingstrategy: backtracking with conflict-directed backjumping, the variableorder $A_1$, $H$, $A_4$, $F_1$, $A_2$, $F_2$, $A_3$, $T$, and the valueorder $R$, $G$, $B$.",
        "url": " /csp-exercises/ex_8/"
      }
    
  
    ,
      "csp-exercises-ex-2":  {
        "title": "Exercise 6.2",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.2Consider the problem of placing $k$ knights on an $ntimes n$chessboard such that no two knights are attacking each other, where $k$is given and $kleq n^2$.      Choose a CSP formulation. In your formulation, what are thevariables?        What are the possible values of each variable?        What sets of variables are constrained, and how?        Now consider the problem of putting as many knights aspossible on the board without any attacks. Explain how tosolve this with local search by defining appropriate ACTIONS and RESULT functionsand a sensible objective function.  ",
        "url": " /csp-exercises/ex_2/"
      }
    
  
    ,
      "csp-exercises-ex-9":  {
        "title": "Exercise 6.9",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.9Explain why it is a good heuristic to choose the variable that ismost constrained but the value that isleast constraining in a CSP search.",
        "url": " /csp-exercises/ex_9/"
      }
    
  
    ,
      "csp-exercises-ex-19":  {
        "title": "Exercise 6.19",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.19Suppose that a graph is known to have a cycle cutset of no more than $k$nodes. Describe a simple algorithm for finding a minimal cycle cutsetwhose run time is not much more than $O(n^k)$ for a CSP with $n$variables. Search the literature for methods for finding approximatelyminimal cycle cutsets in time that is polynomial in the size of thecutset. Does the existence of such algorithms make the cycle cutsetmethod practical?",
        "url": " /csp-exercises/ex_19/"
      }
    
  
    ,
      "csp-exercises-ex-6":  {
        "title": "Exercise 6.6",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.6 [nary-csp-exercise]Show how a single ternary constraint such as“$A + B = C$” can be turned into three binary constraints by using anauxiliary variable. You may assume finite domains. (Hint:Consider a new variable that takes on values that are pairs of othervalues, and consider constraints such as “$X$ is the first element ofthe pair $Y$.”) Next, show how constraints with more than threevariables can be treated similarly. Finally, show how unary constraintscan be eliminated by altering the domains of variables. This completesthe demonstration that any CSP can be transformed into a CSP with onlybinary constraints.",
        "url": " /csp-exercises/ex_6/"
      }
    
  
    ,
      "csp-exercises-ex-1":  {
        "title": "Exercise 6.1",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.1How many solutions are there for the map-coloring problem inFigure australia-figure? How many solutions if fourcolors are allowed? Two colors?",
        "url": " /csp-exercises/ex_1/"
      }
    
  
    ,
      "csp-exercises-ex-13":  {
        "title": "Exercise 6.13",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.13What is the worst-case complexity of running AC-3 on a tree-structuredCSP?",
        "url": " /csp-exercises/ex_13/"
      }
    
  
    ,
      "csp-exercises-ex-12":  {
        "title": "Exercise 6.12",
        "breadcrumb": "6-Constraint-Satisfaction-Problems",
      	"content"  : "Exercise 6.12Use the AC-3 algorithm to show that arc consistency can detect theinconsistency of the partial assignment${red},V{blue}$ for the problemshown in Figure australia-figure.",
        "url": " /csp-exercises/ex_12/"
      }
    
  
    
  
    ,
      "bayesian-learning-exercises-ex-3":  {
        "title": "Exercise 20.3",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.3 [candy-trade-exercise]Suppose that Ann’s utilities for cherry andlime candies are $c_A$ and $ell_A$, whereas Bob’s utilities are $c_B$and $ell_B$. (But once Ann has unwrapped a piece of candy, Bob won’tbuy it.) Presumably, if Bob likes lime candies much more than Ann, itwould be wise for Ann to sell her bag of candies once she issufficiently sure of its lime content. On the other hand, if Ann unwrapstoo many candies in the process, the bag will be worth less. Discuss theproblem of determining the optimal point at which to sell the bag.Determine the expected utility of the optimal procedure, given the priordistribution from Section statistical-learning-section.",
        "url": " /bayesian-learning-exercises/ex_3/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-11":  {
        "title": "Exercise 20.11",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.11Consider the application of EM to learn the parameters for the networkin Figure mixture-networks-figure(a), given the trueparameters in Equation (candy-true-equation).      Explain why the EM algorithm would not work if there were just twoattributes in the model rather than three.        Show the calculations for the first iteration of EM starting fromEquation (candy-64-equation).        What happens if we start with all the parameters set to the samevalue $p$? (Hint: you may find it helpful toinvestigate this empirically before deriving the general result.)        Write out an expression for the log likelihood of the tabulatedcandy data on page candy-counts-page in terms of the parameters,calculate the partial derivatives with respect to each parameter,and investigate the nature of the fixed point reached in part (c).  ",
        "url": " /bayesian-learning-exercises/ex_11/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-4":  {
        "title": "Exercise 20.4",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.4Two statisticians go to the doctor and are both given the sameprognosis: A 40% chance that the problem is the deadly disease $A$, anda 60% chance of the fatal disease $B$. Fortunately, there are anti-$A$and anti-$B$ drugs that are inexpensive, 100% effective, and free ofside-effects. The statisticians have the choice of taking one drug,both, or neither. What will the first statistician (an avid Bayesian)do? How about the second statistician, who always uses the maximumlikelihood hypothesis?The doctor does some research and discovers that disease $B$ actuallycomes in two versions, dextro-$B$ and levo-$B$, which are equally likelyand equally treatable by the anti-$B$ drug. Now that there are threehypotheses, what will the two statisticians do?",
        "url": " /bayesian-learning-exercises/ex_4/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-7":  {
        "title": "Exercise 20.7",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.7 [noisy-OR-ML-exercise]Consider the noisy-OR model for fever describedin Section canonical-distribution-section. Explain howto apply maximum-likelihood learning to fit the parameters of such amodel to a set of complete data. (Hint: use the chainrule for partial derivatives.)",
        "url": " /bayesian-learning-exercises/ex_7/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-5":  {
        "title": "Exercise 20.5",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.5 [BNB-exercise]Explain how to apply the boosting method ofChapter concept-learning-chapter to naive Bayeslearning. Test the performance of the resulting algorithm on therestaurant learning problem.",
        "url": " /bayesian-learning-exercises/ex_5/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-10":  {
        "title": "Exercise 20.10",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.10Consider a single Boolean random variable $Y$ (the “classification”).Let the prior probability $P(Y=true)$ be $pi$. Let’s try tofind $pi$, given a training set $D=(y_1,ldots,y_N)$ with $N$independent samples of $Y$. Furthermore, suppose $p$ of the $N$ arepositive and $n$ of the $N$ are negative.      Write down an expression for the likelihood of $D$ (i.e., theprobability of seeing this particular sequence of examples, given afixed value of $pi$) in terms of $pi$, $p$, and $n$.        By differentiating the log likelihood $L$, find the value of $pi$that maximizes the likelihood.        Now suppose we add in $k$ Boolean random variables$X_1, X_2,ldots,X_k$ (the “attributes”) that describe each sample,and suppose we assume that the attributes are conditionallyindependent of each other given the goal $Y$. Draw the Bayes netcorresponding to this assumption.        Write down the likelihood for the data including the attributes,using the following additional notation:                  $alpha_i$ is $P(X_i=true | Y=true)$.                    $beta_i$ is $P(X_i=true | Y=false)$.                    $p_i^+$ is the count of samples for which $X_i=true$and $Y=true$.                    $n_i^+$ is the count of samples for which $X_i=false$and $Y=true$.                    $p_i^-$ is the count of samples for which $X_i=true$and $Y=false$.                    $n_i^-$ is the count of samples for which $X_i=false$and $Y=false$.              [Hint: consider first the probability of seeing asingle example with specified values for $X_1, X_2,ldots,X_k$ and$Y$.]        By differentiating the log likelihood $L$, find the values of$alpha_i$ and $beta_i$ (in terms of the various counts) thatmaximize the likelihood and say in words what thesevalues represent.        Let $k = 2$, and consider a data set with 4 all four possibleexamples of thexor function. Compute the maximumlikelihood estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,and $beta_2$.        Given these estimates of $pi$, $alpha_1$, $alpha_2$, $beta_1$,and $beta_2$, what are the posterior probabilities$P(Y=true | x_1,x_2)$ for each example?  ",
        "url": " /bayesian-learning-exercises/ex_10/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-8":  {
        "title": "Exercise 20.8",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.8 [beta-integration-exercise]This exercise investigates properties ofthe Beta distribution defined inEquation (beta-equation).      By integrating over the range $[0,1]$, show that the normalizationconstant for the distribution $[a,b]$ is given by$alpha = Gamma(a+b)/Gamma(a)Gamma(b)$ where $Gamma(x)$ is the Gamma function,defined by $Gamma(x+1)xcdotGamma(x)$ and$Gamma(1)1$. (For integer $x$,$Gamma(x+1)x!$.)        Show that the mean is $a/(a+b)$.        Find the mode(s) (the most likely value(s) of $theta$).        Describe the distribution $[epsilon,epsilon]$ for verysmall $epsilon$. What happens as such a distribution is updated?  ",
        "url": " /bayesian-learning-exercises/ex_8/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-2":  {
        "title": "Exercise 20.2",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.2Repeat Exercise bayes-candy-exercise, this timeplotting the values of$P(D_{N+1}=lime|h_{MAP})$ and$P(D_{N+1}=lime|h_{ML})$.",
        "url": " /bayesian-learning-exercises/ex_2/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-9":  {
        "title": "Exercise 20.9",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.9 [ML-parents-exercise]Consider an arbitrary Bayesian network, acomplete data set for that network, and the likelihood for the data setaccording to the network. Give a simple proof that the likelihood of thedata cannot decrease if we add a new link to the network and recomputethe maximum-likelihood parameter values.",
        "url": " /bayesian-learning-exercises/ex_9/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-6":  {
        "title": "Exercise 20.6",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.6 [linear-regression-exercise]Consider $N$ data points $(x_j,y_j)$,where the $y_j$s are generated from the $x_j$s according to the linearGaussian model inEquation (linear-gaussian-likelihood-equation). Findthe values of $theta_1$, $theta_2$, and $sigma$ that maximize theconditional log likelihood of the data.",
        "url": " /bayesian-learning-exercises/ex_6/"
      }
    
  
    ,
      "bayesian-learning-exercises-ex-1":  {
        "title": "Exercise 20.1",
        "breadcrumb": "20-Learning-Probabilistic-Models",
      	"content"  : "Exercise 20.1 [bayes-candy-exercise]The data used forFigure bayes-candy-figure on page bayes-candy-figure can beviewed as being generated by $h_5$. For each of the other fourhypotheses, generate a data set of length 100 and plot the correspondinggraphs for $P(h_i|d_1,ldots,d_N)$ and$P(D_{N+1}=lime|d_1,ldots,d_N)$. Comment onyour results.",
        "url": " /bayesian-learning-exercises/ex_1/"
      }
    
  
    
  
    ,
      "planning-exercises-ex-3":  {
        "title": "Exercise 10.3",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.3[strips-airport-exercise]Given the action schemas and initial statefrom Figure airport-pddl-algorithm, what are all theapplicable concrete instances of ${Fly}(p,{from},{to})$ in thestate described by",
        "url": " /planning-exercises/ex_3/"
      }
    
  
    ,
      "planning-exercises-ex-11":  {
        "title": "Exercise 10.11",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.11 [graphplan-proof-exercise]Prove the following assertions aboutplanning graphs:      A literal that does not appear in the final level of the graphcannot be achieved.        The level cost of a literal in a serial graph is no greater than theactual cost of an optimal plan for achieving it.  ",
        "url": " /planning-exercises/ex_11/"
      }
    
  
    ,
      "planning-exercises-ex-14":  {
        "title": "Exercise 10.14",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.14Examine the definition of bidirectionalsearch in Chapter search-chapter.      Would bidirectional state-space search be a good idea for planning?        What about bidirectional search in the space of partial-order plans?        Devise a version of partial-order planning in which an action can beadded to a plan if its preconditions can be achieved by the effectsof actions already in the plan. Explain how to deal with conflictsand ordering constraints. Is the algorithm essentially identical toforward state-space search?  ",
        "url": " /planning-exercises/ex_14/"
      }
    
  
    ,
      "planning-exercises-ex-4":  {
        "title": "Exercise 10.4",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.4The monkey-and-bananas problem is faced by a monkey in a laboratory withsome bananas hanging out of reach from the ceiling. A box is availablethat will enable the monkey to reach the bananas if he climbs on it.Initially, the monkey is at $A$, the bananas at $B$, and the box at $C$.The monkey and box have height ${Low}$, but if the monkey climbs ontothe box he will have height ${High}$, the same as the bananas. Theactions available to the monkey include ${Go}$ from one place toanother, ${Push}$ an object from one place to another, ${ClimbUp}$onto or ${ClimbDown}$ from an object, and ${Grasp}$ or ${Ungrasp}$an object. The result of a ${Grasp}$ is that the monkey holds theobject if the monkey and object are in the same place at the sameheight.      Write down the initial state description.        Write the six action schemas.        Suppose the monkey wants to fool the scientists, who are off to tea,by grabbing the bananas, but leaving the box in its original place.Write this as a general goal (i.e., not assuming that the box isnecessarily at C) in the language of situation calculus. Can thisgoal be solved by a classical planning system?        Your schema for pushing is probably incorrect, because if the objectis too heavy, its position will remain the same when the ${Push}$schema is applied. Fix your action schema to account forheavy objects.  ",
        "url": " /planning-exercises/ex_4/"
      }
    
  
    ,
      "planning-exercises-ex-7":  {
        "title": "Exercise 10.7",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.7 [negative-effects-exercise]Explain why dropping negative effects fromevery action schema results in a relaxed problem, provided thatpreconditions and goals contain only positive literals.",
        "url": " /planning-exercises/ex_7/"
      }
    
  
    ,
      "planning-exercises-ex-17":  {
        "title": "Exercise 10.17",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.17 [strips-translation-exercise]Consider how to translate a set of actionschemas into the successor-state axioms of situation calculus.      Consider the schema for ${Fly}(p,{from},{to})$. Write alogical definition for the predicate${Poss}({Fly}(p,{from},{to}),s)$, which is true if thepreconditions for ${Fly}(p,{from},{to})$ are satisfied insituation $s$.        Next, assuming that ${Fly}(p,{from},{to})$ is the only actionschema available to the agent, write down a successor-state axiomfor ${At}(p,x,s)$ that captures the same information as theaction schema.        Now suppose there is an additional method of travel:${Teleport}(p,{from},{to})$. It has the additionalprecondition $lnot {Warped}(p)$ and the additional effect${Warped}(p)$. Explain how the situation calculus knowledge basemust be modified.        Finally, develop a general and precisely specified procedure forcarrying out the translation from a set of action schemas to a setof successor-state axioms.  ",
        "url": " /planning-exercises/ex_17/"
      }
    
  
    ,
      "planning-exercises-ex-5":  {
        "title": "Exercise 10.5",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.5The original {Strips} planner was designed to control Shakey the robot.Figure shakey-figure shows a version of Shakey’s worldconsisting of four rooms lined up along a corridor, where each room hasa door and a light switch. The actions in Shakey’s world include moving from place to place,pushing movable objects (such as boxes), climbing onto and down fromrigid objects (such as boxes), and turning light switches on and off.The robot itself could not climb on a box or toggle a switch, but theplanner was capable of finding and printing out plans that were beyondthe robot’s abilities. Shakey’s six actions are the following:      ${Go}(x,y,r)$, which requires that Shakey be ${At}$ $x$ and that$x$ and $y$ are locations ${In}$ the same room $r$. By conventiona door between two rooms is in both of them.        Push a box $b$ from location $x$ to location $y$ within the sameroom: ${Push}(b,x,y,r)$. You will need the predicate ${Box}$ andconstants for the boxes.        Climb onto a box from position $x$: ${ClimbUp}(x, b)$; climb downfrom a box to position $x$: ${ClimbDown}(b, x)$. We will need thepredicate ${On}$ and the constant ${Floor}$.        Turn a light switch on or off: ${TurnOn}(s,b)$;${TurnOff}(s,b)$. To turn a light on or off, Shakey must be on topof a box at the light switch’s location.  Write PDDL sentences for Shakey’s six actions and the initial state fromFigure shakey-figure. Construct a plan for Shakey toget ${Box}{}_2$ into ${Room}{}_2$.Figure [shakey-figure] Shakey&#39;s world. Shakey can move between landmarks within a room, can pass through the door between rooms, can climb climbable objects and push pushable objects, and can flip light switches.",
        "url": " /planning-exercises/ex_5/"
      }
    
  
    ,
      "planning-exercises-ex-10":  {
        "title": "Exercise 10.10",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.10Construct levels 0, 1, and 2 of the planning graph for the problem inFigure airport-pddl-algorithm.",
        "url": " /planning-exercises/ex_10/"
      }
    
  
    ,
      "planning-exercises-ex-18":  {
        "title": "Exercise 10.18",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.18 [disjunctive-satplan-exercise]In the $SATPlan$ algorithm inFigure satplan-agent-algorithm (page satplan-agent-algorithm),each call to the satisfiability algorithm asserts a goal $g^T$, where$T$ ranges from 0 to $T_{max}$. Suppose instead that thesatisfiability algorithm is called only once, with the goal$g^0 vee g^1 vee cdots vee g^{T_{max}}$.      Will this always return a plan if one exists with length less thanor equal to $T_{max}$?        Does this approach introduce any new spurious “solutions”?        Discuss how one might modify a satisfiability algorithm such as $WalkSAT$ sothat it finds short solutions (if they exist) when given adisjunctive goal of this form.  ",
        "url": " /planning-exercises/ex_18/"
      }
    
  
    ,
      "planning-exercises-ex-15":  {
        "title": "Exercise 10.15",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.15We contrasted forward and backward state-space searchers withpartial-order planners, saying that the latter is a plan-space searcher.Explain how forward and backward state-space search can also beconsidered plan-space searchers, and say what the plan refinementoperators are.",
        "url": " /planning-exercises/ex_15/"
      }
    
  
    ,
      "planning-exercises-ex-16":  {
        "title": "Exercise 10.16",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.16 [satplan-preconditions-exercise]Up to now we have assumed that theplans we create always make sure that an action’s preconditions aresatisfied. Let us now investigate what propositional successor-stateaxioms such as ${HaveArrow}^{t+1} {;;{Leftrightarrow};;}{}$$({HaveArrow}^tland lnot {Shoot}^t)$ have to say about actions whose preconditionsare not satisfied.      Show that the axioms predict that nothing will happen when an actionis executed in a state where its preconditions are not satisfied.        Consider a plan $p$ that contains the actions required to achieve agoal but also includes illegal actions. Is it the case that        With first-order successor-state axioms in situation calculus, is itpossible to prove that a plan containing illegal actions willachieve the goal?  ",
        "url": " /planning-exercises/ex_16/"
      }
    
  
    ,
      "planning-exercises-ex-8":  {
        "title": "Exercise 10.8",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.8 [sussman-anomaly-exercise]Figure sussman-anomaly-figure(page sussman-anomaly-figure) shows a blocks-world problem that is known as the {Sussman anomaly}.The problem was considered anomalous because the noninterleaved plannersof the early 1970s could not solve it. Write a definition of the problemand solve it, either by hand or with a planning program. Anoninterleaved planner is a planner that, when given two subgoals$G_{1}$ and $G_{2}$, produces either a plan for $G_{1}$ concatenatedwith a plan for $G_{2}$, or vice versa. Can a noninterleaved plannersolve this problem? How, or why not?",
        "url": " /planning-exercises/ex_8/"
      }
    
  
    ,
      "planning-exercises-ex-2":  {
        "title": "Exercise 10.2",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.2Describe the differences and similarities between problem solving andplanning.",
        "url": " /planning-exercises/ex_2/"
      }
    
  
    ,
      "planning-exercises-ex-9":  {
        "title": "Exercise 10.9",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.9Prove that backward search with PDDL problems is complete.",
        "url": " /planning-exercises/ex_9/"
      }
    
  
    ,
      "planning-exercises-ex-6":  {
        "title": "Exercise 10.6",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.6A finite Turing machine has a finite one-dimensional tape of cells, eachcell containing one of a finite number of symbols. One cell has a readand write head above it. There is a finite set of states the machine canbe in, one of which is the accept state. At each time step, depending onthe symbol on the cell under the head and the machine’s current state,there are a set of actions we can choose from. Each action involveswriting a symbol to the cell under the head, transitioning the machineto a state, and optionally moving the head left or right. The mappingthat determines which actions are allowed is the Turing machine’sprogram. Your goal is to control the machine into the accept state.Represent the Turing machine acceptance problem as a planning problem.If you can do this, it demonstrates that determining whether a planningproblem has a solution is at least as hard as the Turing acceptanceproblem, which is PSPACE-hard.",
        "url": " /planning-exercises/ex_6/"
      }
    
  
    ,
      "planning-exercises-ex-1":  {
        "title": "Exercise 10.1",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.1Consider a robot whose operation is described by the following PDDLoperators:      The operators allow the robot to hold more than one object. Show howto modify them with an $EmptyHand$ predicate for a robot that canhold only one object.        Assuming that these are the only actions in the world, write asuccessor-state axiom for $EmptyHand$.  ",
        "url": " /planning-exercises/ex_1/"
      }
    
  
    ,
      "planning-exercises-ex-13":  {
        "title": "Exercise 10.13",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.13The set-level heuristic (see page set-level-page) uses a planning graphto estimate the cost of achieving a conjunctive goal from the currentstate. What relaxed problem is the set-level heuristic the solution to?",
        "url": " /planning-exercises/ex_13/"
      }
    
  
    ,
      "planning-exercises-ex-12":  {
        "title": "Exercise 10.12",
        "breadcrumb": "10-Classical-Planning",
      	"content"  : "Exercise 10.12We saw that planning graphs can handle only propositional actions. Whatif we want to use planning graphs for a problem with variables in thegoal, such as ${At}(P_{1}, x)     land {At}(P_{2}, x)$, where $x$ is assumed to be bound by anexistential quantifier that ranges over a finite domain of locations?How could you encode such a problem to work with planning graphs?",
        "url": " /planning-exercises/ex_12/"
      }
    
  
    
  
    ,
      "philosophy-exercises-ex-3":  {
        "title": "Exercise 26.3",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.3Attempt to write definitions of the terms “intelligence,” “thinking,”and “consciousness.” Suggest some possible objections to yourdefinitions.",
        "url": " /philosophy-exercises/ex_3/"
      }
    
  
    ,
      "philosophy-exercises-ex-11":  {
        "title": "Exercise 26.11",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.11How do the potential threats from AI technology compare with those fromother computer science technologies, and to bio-, nano-, and nucleartechnologies?",
        "url": " /philosophy-exercises/ex_11/"
      }
    
  
    ,
      "philosophy-exercises-ex-4":  {
        "title": "Exercise 26.4",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.4Does a refutation of the Chinese room argument necessarily prove thatappropriately programmed computers have mental states? Does anacceptance of the argument necessarily mean that computers cannot havemental states?",
        "url": " /philosophy-exercises/ex_4/"
      }
    
  
    ,
      "philosophy-exercises-ex-7":  {
        "title": "Exercise 26.7",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.7Alan Perlis [@Perlis:1982] wrote, “A year spent in artificialintelligence is enough to make one believe in God”. He also wrote, in aletter to Philip Davis, that one of the central dreams of computerscience is that “through the performance of computers and their programswe will remove all doubt that there is only a chemical distinctionbetween the living and nonliving world.” To what extent does theprogress made so far in artificial intelligence shed light on theseissues? Suppose that at some future date, the AI endeavor has beencompletely successful; that is, we have build intelligent agents capableof carrying out any human cognitive task at human levels of ability. Towhat extent would that shed light on these issues?",
        "url": " /philosophy-exercises/ex_7/"
      }
    
  
    ,
      "philosophy-exercises-ex-5":  {
        "title": "Exercise 26.5",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.5 [brain-prosthesis-exercise]In the brain replacement argument, it isimportant to be able to restore the subject’s brain to normal, such thatits external behavior is as it would have been if the operation had nottaken place. Can the skeptic reasonably object that this would requireupdating those neurophysiological properties of the neurons relating toconscious experience, as distinct from those involved in the functionalbehavior of the neurons?",
        "url": " /philosophy-exercises/ex_5/"
      }
    
  
    ,
      "philosophy-exercises-ex-10":  {
        "title": "Exercise 26.10",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.10Analyze the potential threats from AI technology to society. Whatthreats are most serious, and how might they be combated? How do theycompare to the potential benefits?",
        "url": " /philosophy-exercises/ex_10/"
      }
    
  
    ,
      "philosophy-exercises-ex-8":  {
        "title": "Exercise 26.8",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.8Compare the social impact of artificial intelligence in the last fiftyyears with the social impact of the introduction of electric appliancesand the internal combustion engine in the fifty years between 1890 and1940.",
        "url": " /philosophy-exercises/ex_8/"
      }
    
  
    ,
      "philosophy-exercises-ex-2":  {
        "title": "Exercise 26.2",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.2Find and analyze an account in the popular media of one or more of thearguments to the effect that AI is impossible.",
        "url": " /philosophy-exercises/ex_2/"
      }
    
  
    ,
      "philosophy-exercises-ex-9":  {
        "title": "Exercise 26.9",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.9I. J. Good claims that intelligence is the most important quality, andthat building ultraintelligent machines will change everything. Asentient cheetah counters that “Actually speed is more important; if wecould build ultrafast machines, that would change everything,” and asentient elephant claims “You’re both wrong; what we need is ultrastrongmachines.” What do you think of these arguments?",
        "url": " /philosophy-exercises/ex_9/"
      }
    
  
    ,
      "philosophy-exercises-ex-6":  {
        "title": "Exercise 26.6",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.6Suppose that a Prolog program containing many clauses about the rules ofBritish citizenship is compiled and run on an ordinary computer. Analyzethe “brain states” of the computer under wide and narrow content.",
        "url": " /philosophy-exercises/ex_6/"
      }
    
  
    ,
      "philosophy-exercises-ex-1":  {
        "title": "Exercise 26.1",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.1 [disability-exercise]Go through Turing’s list of alleged“disabilities” of machines, identifying which have been achieved, whichare achievable in principle by a program, and which are stillproblematic because they require conscious mental states.",
        "url": " /philosophy-exercises/ex_1/"
      }
    
  
    ,
      "philosophy-exercises-ex-12":  {
        "title": "Exercise 26.12",
        "breadcrumb": "26-Philosophical-Foundations",
      	"content"  : "Exercise 26.12Some critics object that AI is impossible, while others object that itis too possible and that ultraintelligent machines pose athreat. Which of these objections do you think is more likely? Would itbe a contradiction for someone to hold both positions?",
        "url": " /philosophy-exercises/ex_12/"
      }
    
  
    
  
    ,
      "concept-learning-exercises-ex-28":  {
        "title": "Exercise 18.28",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.28 [perceptron-ML-gradient-exercise]Section logistic-regression-section(page logistic-regression-section) noted that the output of the logistic functioncould be interpreted as a probability $p$ assigned by themodel to the proposition that $f(textbf{x})1$; the probability that$f(textbf{x})0$ is therefore $1-p$. Write down the probability $p$as a function of $textbf{x}$ and calculate the derivative of $log p$ withrespect to each weight $w_i$. Repeat the process for $log (1-p)$. Thesecalculations give a learning rule for minimizing thenegative-log-likelihood loss function for a probabilistic hypothesis.Comment on any resemblance to other learning rules in the chapter.",
        "url": " /concept-learning-exercises/ex_28/"
      }
    
  
    ,
      "concept-learning-exercises-ex-29":  {
        "title": "Exercise 18.29",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.29 [linear-nn-exercise]Suppose you had a neural network with linearactivation functions. That is, for each unit the output is some constant$c$ times the weighted sum of the inputs.      Assume that the network has one hidden layer. For a given assignmentto the weights $textbf{w}$, write down equations for the value of theunits in the output layer as a function of $textbf{w}$ and the input layer$textbf{x}$, without any explicit mention of the output of thehidden layer. Show that there is a network with no hidden units thatcomputes the same function.        Repeat the calculation in part (a), but this time do it for anetwork with any number of hidden layers.        Suppose a network with one hidden layer and linear activationfunctions has $n$ input and output nodes and $h$ hidden nodes. Whateffect does the transformation in part (a) to a network with nohidden layers have on the total number of weights? Discuss inparticular the case $h ll n$.  ",
        "url": " /concept-learning-exercises/ex_29/"
      }
    
  
    ,
      "concept-learning-exercises-ex-3":  {
        "title": "Exercise 18.3",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.3Draw a decision tree for the problem of deciding whether to move forwardat a road intersection, given that the light has just turned green.",
        "url": " /concept-learning-exercises/ex_3/"
      }
    
  
    ,
      "concept-learning-exercises-ex-11":  {
        "title": "Exercise 18.11",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.11 [pruning-DTL-exercise]This exercise considers $chi^2$ pruning ofdecision trees (Section chi-squared-section).      Create a data set with two input attributes, such that theinformation gain at the root of the tree for both attributes iszero, but there is a decision tree of depth 2 that is consistentwith all the data. What would $chi^2$ pruning do on this data setif applied bottom up? If applied top down?        Modify DECISION-TREE-LEARNING to include $chi^2$-pruning. You might wish to consultQuinlan [@Quinlan:1986] or [@Kearns+Mansour:1998] for details.  ",
        "url": " /concept-learning-exercises/ex_11/"
      }
    
  
    ,
      "concept-learning-exercises-ex-14":  {
        "title": "Exercise 18.14",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.14Suppose you are running a learning experiment on a new algorithm forBoolean classification. You have a data set consisting of 100 positiveand 100 negative examples. You plan to use leave-one-outcross-validation and compare your algorithm to a baseline function, asimple majority classifier. (A majority classifier is given a set oftraining data and then always outputs the class that is in the majorityin the training set, regardless of the input.) You expect the majorityclassifier to score about 50% on leave-one-out cross-validation, but toyour surprise, it scores zero every time. Can you explain why?",
        "url": " /concept-learning-exercises/ex_14/"
      }
    
  
    ,
      "concept-learning-exercises-ex-4":  {
        "title": "Exercise 18.4",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.4We never test the same attribute twice along one path in a decisiontree. Why not?",
        "url": " /concept-learning-exercises/ex_4/"
      }
    
  
    ,
      "concept-learning-exercises-ex-23":  {
        "title": "Exercise 18.23",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.23 [ensemble-error-exercise]Consider an ensemble learning algorithm thatuses simple majority voting among $K$ learned hypotheses.Suppose that each hypothesis has error $epsilon$ and that the errorsmade by each hypothesis are independent of the others’. Calculate aformula for the error of the ensemble algorithm in terms of $K$and $epsilon$, and evaluate it for the cases where$K=5$, 10, and 20 and $epsilon={0.1}$, 0.2,and 0.4. If the independence assumption is removed, is it possible forthe ensemble error to be worse than $epsilon$?",
        "url": " /concept-learning-exercises/ex_23/"
      }
    
  
    ,
      "concept-learning-exercises-ex-20":  {
        "title": "Exercise 18.20",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.20 [knn-mean-mode]Suppose a $7$-nearest-neighbors regression searchreturns $ {4, 2, 8, 4, 9, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.",
        "url": " /concept-learning-exercises/ex_20/"
      }
    
  
    ,
      "concept-learning-exercises-ex-33":  {
        "title": "Exercise 18.33",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.33 [embedding-separability-exercise]Consider the problem of separating$N$ data points into positive and negative examples using a linearseparator. Clearly, this can always be done for $N2$ pointson a line of dimension $d1$, regardless of how the points arelabeled or where they are located (unless the points are in the sameplace).      Show that it can always be done for $N3$ points on aplane of dimension $d2$, unless they are collinear.        Show that it cannot always be done for $N4$ points on aplane of dimension $d2$.        Show that it can always be done for $N4$ points in aspace of dimension $d3$, unless they are coplanar.        Show that it cannot always be done for $N5$ points in aspace of dimension $d3$.        The ambitious student may wish to prove that $N$ points in generalposition (but not $N+1$) are linearly separable in a space ofdimension $N-1$.  ",
        "url": " /concept-learning-exercises/ex_33/"
      }
    
  
    ,
      "concept-learning-exercises-ex-7":  {
        "title": "Exercise 18.7",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.7 [nonnegative-gain-exercise][nonnegative-gain-exercise]Suppose that an attribute splits the set ofexamples $E$ into subsets $E_k$ and that each subset has $p_k$positive examples and $n_k$ negative examples. Show that theattribute has strictly positive information gain unless the ratio$p_k/(p_k+n_k)$ is the same for all $k$.",
        "url": " /concept-learning-exercises/ex_7/"
      }
    
  
    ,
      "concept-learning-exercises-ex-17":  {
        "title": "Exercise 18.17",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.17Prove that a decision list can represent the same function as a decisiontree while using at most as many rules as there are leaves in thedecision tree for that function. Give an example of a functionrepresented by a decision list using strictly fewer rules than thenumber of leaves in a minimal-sized decision tree for that samefunction.",
        "url": " /concept-learning-exercises/ex_17/"
      }
    
  
    ,
      "concept-learning-exercises-ex-5":  {
        "title": "Exercise 18.5",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.5Suppose we generate a training set from a decision tree and then applydecision-tree learning to that training set. Is it the case that thelearning algorithm will eventually return the correct tree as thetraining-set size goes to infinity? Why or why not?",
        "url": " /concept-learning-exercises/ex_5/"
      }
    
  
    ,
      "concept-learning-exercises-ex-25":  {
        "title": "Exercise 18.25",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.25A simple perceptron cannot represent xor (or, generally,the parity function of its inputs). Describe what happens to the weightsof a four-input, hard-threshold perceptron, beginning with all weightsset to 0.1, as examples of the parity function arrive.",
        "url": " /concept-learning-exercises/ex_25/"
      }
    
  
    ,
      "concept-learning-exercises-ex-10":  {
        "title": "Exercise 18.10",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.10A decision graph is a generalization of a decision treethat allows nodes (i.e., attributes used for splits) to have multipleparents, rather than just a single parent. The resulting graph muststill be acyclic. Now, consider the XOR function of threebinary input attributes, which produces the value 1 if and only if anodd number of the three input attributes has value 1.      Draw a minimal-sized decision tree for thethree-input XOR function.        Draw a minimal-sized decision graph for thethree-input XOR function.  ",
        "url": " /concept-learning-exercises/ex_10/"
      }
    
  
    ,
      "concept-learning-exercises-ex-22":  {
        "title": "Exercise 18.22",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.22 [svm-exercise]Construct a support vector machine that computes thexor function. Use values of +1 and –1 (instead of 1 and 0)for both inputs and outputs, so that an example looks like $([-1, 1],1)$ or $([-1, -1], -1)$. Map the input $[x_1,x_2]$ into a spaceconsisting of $x_1$ and $x_1,x_2$. Draw the four input points in thisspace, and the maximal margin separator. What is the margin? Now drawthe separating line back in the original Euclidean input space.",
        "url": " /concept-learning-exercises/ex_22/"
      }
    
  
    ,
      "concept-learning-exercises-ex-18":  {
        "title": "Exercise 18.18",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.18 [DL-expressivity-exercise]This exercise concerns the expressiveness ofdecision lists (Section learning-theory-section).      Show that decision lists can represent any Boolean function, if thesize of the tests is not limited.        Show that if the tests can contain at most $k$ literals each, thendecision lists can represent any function that can be represented bya decision tree of depth $k$.  ",
        "url": " /concept-learning-exercises/ex_18/"
      }
    
  
    ,
      "concept-learning-exercises-ex-31":  {
        "title": "Exercise 18.31",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.31Suppose that a training set contains only a single example, repeated 100times. In 80 of the 100 cases, the single output value is 1; in theother 20, it is 0. What will a back-propagation network predict for thisexample, assuming that it has been trained and reaches a global optimum?(Hint: to find the global optimum, differentiate theerror function and set it to zero.)",
        "url": " /concept-learning-exercises/ex_31/"
      }
    
  
    ,
      "concept-learning-exercises-ex-24":  {
        "title": "Exercise 18.24",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.24Construct by hand a neural network that computes the xorfunction of two inputs. Make sure to specify what sort of units you areusing.",
        "url": " /concept-learning-exercises/ex_24/"
      }
    
  
    ,
      "concept-learning-exercises-ex-15":  {
        "title": "Exercise 18.15",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.15Suppose that a learning algorithm is trying to find a consistenthypothesis when the classifications of examples are actually random.There are $n$ Boolean attributes, and examples are drawn uniformly fromthe set of $2^n$ possible examples. Calculate the number of examplesrequired before the probability of finding a contradiction in the datareaches 0.5.",
        "url": " /concept-learning-exercises/ex_15/"
      }
    
  
    ,
      "concept-learning-exercises-ex-16":  {
        "title": "Exercise 18.16",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.16Construct a decision list to classify the data below.Select tests to be as small as possible (in terms of attributes),breaking ties among tests with the same number of attributes byselecting the one that classifies the greatest number of examplescorrectly. If multiple tests have the same number of attributes andclassify the same number of examples, then break the tie usingattributes with lower index numbers (e.g., select $A_1$ over $A_2$).                   $quad A_1quad$      $quad A_2quad$      $quad A_3quad$      $quad A_yquad$      $quad yquad$                  $textbf{x}_1$      1      0      0      0      1              $textbf{x}_2$      1      0      1      1      1              $textbf{x}_3$      0      1      0      0      1              $textbf{x}_4$      0      1      1      0      0              $textbf{x}_5$      1      1      0      1      1              $textbf{x}_6$      0      1      0      1      0              $textbf{x}_7$      0      0      1      1      1              $textbf{x}_8$      0      0      1      0      0      ",
        "url": " /concept-learning-exercises/ex_16/"
      }
    
  
    ,
      "concept-learning-exercises-ex-32":  {
        "title": "Exercise 18.32",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.32The neural network whose learning performance is measured inFigure restaurant-back-prop-figure has four hiddennodes. This number was chosen somewhat arbitrarily. Use across-validation method to find the best number of hidden nodes.",
        "url": " /concept-learning-exercises/ex_32/"
      }
    
  
    ,
      "concept-learning-exercises-ex-30":  {
        "title": "Exercise 18.30",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.30Implement a data structure for layered, feed-forward neural networks,remembering to provide the information needed for both forwardevaluation and backward propagation. Using this data structure, write afunction NEURAL-NETWORK-OUTPUT that takes an example and a network and computes theappropriate output values.",
        "url": " /concept-learning-exercises/ex_30/"
      }
    
  
    ,
      "concept-learning-exercises-ex-8":  {
        "title": "Exercise 18.8",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.8Consider the following data set comprised of three binary inputattributes ($A_1, A_2$, and $A_3$) and one binary output:            $quad textbf{Example}$      $quad A_1quad$      $quad A_2quad$      $quad A_3quad$      $quad Outputspace y$                  $textbf{x}_1$      1      0      0      0              $textbf{x}_2$      1      0      1      0              $textbf{x}_3$      0      1      0      0              $textbf{x}_4$      1      1      1      1              $textbf{x}_5$      1      1      0      1      Use the algorithm in Figure DTL-algorithm(page DTL-algorithm) to learn a decision tree for these data. Show thecomputations made to determine the attribute to split at each node.",
        "url": " /concept-learning-exercises/ex_8/"
      }
    
  
    ,
      "concept-learning-exercises-ex-2":  {
        "title": "Exercise 18.2",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.2Repeat Exercise infant-language-exercise for the caseof learning to play tennis (or some other sport with which you arefamiliar). Is this supervised learning or reinforcement learning?",
        "url": " /concept-learning-exercises/ex_2/"
      }
    
  
    ,
      "concept-learning-exercises-ex-9":  {
        "title": "Exercise 18.9",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.9Construct a data set (set of examples with attributes andclassifications) that would cause the decision-tree learning algorithmto find a non-minimal-sized tree. Show the tree constructed by thealgorithm and the minimal-sized tree that you can generate by hand.",
        "url": " /concept-learning-exercises/ex_9/"
      }
    
  
    ,
      "concept-learning-exercises-ex-19":  {
        "title": "Exercise 18.19",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.19 [knn-mean-mode]Suppose a $7$-nearest-neighbors regression searchreturns $ {7, 6, 8, 4, 7, 11, 100} $ as the 7 nearest $y$ values for agiven $x$ value. What is the value of $hat{y}$ that minimizes the $L_1$loss function on this data? There is a common name in statistics forthis value as a function of the $y$ values; what is it? Answer the sametwo questions for the $L_2$ loss function.",
        "url": " /concept-learning-exercises/ex_19/"
      }
    
  
    ,
      "concept-learning-exercises-ex-27":  {
        "title": "Exercise 18.27",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.27Consider the following set of examples, each with six inputs and onetarget output:                                                                                                                                 $textbf{x}_1$      1      1      1      1      1      1      1      0      0      0      0      0      0      0              $textbf{x}_2$      0      0      0      1      1      0      0      1      1      0      1      0      1      1              $textbf{x}_3$      1      1      1      0      1      0      0      1      1      0      0      0      1      1              $textbf{x}_4$      0      1      0      0      1      0      0      1      0      1      1      1      0      1              $textbf{x}_5$      0      0      1      1      0      1      1      0      1      1      0      0      1      0              $textbf{x}_6$      0      0      0      1      0      1      0      1      1      0      1      1      1      0              $textbf{T}$      1      1      1      1      1      1      0      1      0      0      0      0      0      0            Run the perceptron learning rule on these data and show thefinal weights.        Run the decision tree learning rule, and show the resultingdecision tree.        Comment on your results.  ",
        "url": " /concept-learning-exercises/ex_27/"
      }
    
  
    ,
      "concept-learning-exercises-ex-6":  {
        "title": "Exercise 18.6",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.6 [leaf-classification-exercise]In the recursive construction ofdecision trees, it sometimes happens that a mixed set of positive andnegative examples remains at a leaf node, even after all the attributeshave been used. Suppose that we have $p$ positive examples and $n$negative examples.      Show that the solution used by DECISION-TREE-LEARNING, which picks the majorityclassification, minimizes the absolute error over the set ofexamples at the leaf.        Show that the class probability $p/(p+n)$ minimizes the sum of squared errors.  ",
        "url": " /concept-learning-exercises/ex_6/"
      }
    
  
    ,
      "concept-learning-exercises-ex-26":  {
        "title": "Exercise 18.26",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.26 [linear-separability-exercise]Recall fromChapter concept-learning-chapter that there are$2^{2^n}$ distinct Boolean functions of $n$ inputs. How many ofthese are representable by a threshold perceptron?",
        "url": " /concept-learning-exercises/ex_26/"
      }
    
  
    ,
      "concept-learning-exercises-ex-21":  {
        "title": "Exercise 18.21",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.21 [svm-ellipse-exercise]Figure kernel-machine-figureshowed how a circle at the origin can be linearly separated by mappingfrom the features $(x_1, x_2)$ to the two dimensions $(x_1^2, x_2^2)$.But what if the circle is not located at the origin? What if it is anellipse, not a circle? The general equation for a circle (and hence thedecision boundary) is $(x_1-a)^2 +(x_2-b)^2 - r^20$, and the general equation for an ellipse is$c(x_1-a)^2 + d(x_2-b)^2 - 1 0$.      Expand out the equation for the circle and show what the weights$w_i$ would be for the decision boundary in the four-dimensionalfeature space $(x_1, x_2, x_1^2, x_2^2)$. Explain why this meansthat any circle is linearly separable in this space.        Do the same for ellipses in the five-dimensional feature space$(x_1, x_2, x_1^2, x_2^2, x_1 x_2)$.  ",
        "url": " /concept-learning-exercises/ex_21/"
      }
    
  
    ,
      "concept-learning-exercises-ex-1":  {
        "title": "Exercise 18.1",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.1 [infant-language-exercise]Consider the problem faced by an infantlearning to speak and understand a language. Explain how this processfits into the general learning model. Describe the percepts and actionsof the infant, and the types of learning the infant must do. Describethe subfunctions the infant is trying to learn in terms of inputs andoutputs, and available example data.",
        "url": " /concept-learning-exercises/ex_1/"
      }
    
  
    ,
      "concept-learning-exercises-ex-13":  {
        "title": "Exercise 18.13",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.13 [gain-ratio-DTL-exercise]InSection broadening-decision-tree-section, we noted thatattributes with many different possible values can cause problems withthe gain measure. Such attributes tend to split the examples intonumerous small classes or even singleton classes, thereby appearing tobe highly relevant according to the gain measure. Thegain-ratio criterion selects attributesaccording to the ratio between their gain and their intrinsicinformation content—that is, the amount of information contained in theanswer to the question, “What is the value of this attribute?” Thegain-ratio criterion therefore tries to measure how efficiently anattribute provides information on the correct classification of anexample. Write a mathematical expression for the information content ofan attribute, and implement the gain ratio criterion in DECISION-TREE-LEARNING.",
        "url": " /concept-learning-exercises/ex_13/"
      }
    
  
    ,
      "concept-learning-exercises-ex-12":  {
        "title": "Exercise 18.12",
        "breadcrumb": "18-Learning-From-Examples",
      	"content"  : "Exercise 18.12 [missing-value-DTL-exercise]The standard DECISION-TREE-LEARNING algorithm described in thechapter does not handle cases in which some examples have missingattribute values.      First, we need to find a way to classify such examples, given adecision tree that includes tests on the attributes for which valuescan be missing. Suppose that an example $textbf{x}$ has a missing value forattribute $A$ and that the decision tree tests for $A$ at a nodethat $textbf{x}$ reaches. One way to handle this case is to pretend thatthe example has all possible values for theattribute, but to weight each value according to its frequency amongall of the examples that reach that node in the decision tree. Theclassification algorithm should follow all branches at any node forwhich a value is missing and should multiply the weights along eachpath. Write a modified classification algorithm for decision treesthat has this behavior.        Now modify the information-gain calculation so that in any givencollection of examples $C$ at a given node in the tree during theconstruction process, the examples with missing values for any ofthe remaining attributes are given “as-if” values according to thefrequencies of those values in the set $C$.  ",
        "url": " /concept-learning-exercises/ex_12/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-3":  {
        "title": "Exercise 22.3",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.3Zipf’s law of word distribution states the following:Take a large corpus of text, count the frequency of every word in thecorpus, and then rank these frequencies in decreasing order. Let $f_{I}$be the $I$th largest frequency in this list; that is, $f_{1}$ is thefrequency of the most common word (usually “the”), $f_{2}$ is thefrequency of the second most common word, and so on. Zipf’s law statesthat $f_{I}$ is approximately equal to $alpha / I$ for some constant$alpha$. The law tends to be highly accurate except for very small andvery large values of $I$.",
        "url": " /nlp-communicating-exercises/ex_3/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-11":  {
        "title": "Exercise 22.11",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.11Consider the problem of trying to evaluate the quality of an IR systemthat returns a ranked list of answers (like most Web search engines).The appropriate measure of quality depends on the presumed model of whatthe searcher is trying to achieve, and what strategy she employs. Foreach of the following models, propose a corresponding numeric measure.      The searcher will look at the first twenty answers returned, withthe objective of getting as much relevant information as possible.        The searcher needs only one relevant document, and will go down thelist until she finds the first one.        The searcher has a fairly narrow query and is able to examine allthe answers retrieved. She wants to be sure that she has seeneverything in the document collection that is relevant to her query.(E.g., a lawyer wants to be sure that she has foundall relevant precedents, and is willing to spendconsiderable resources on that.)        The searcher needs just one document relevant to the query, and canafford to pay a research assistant for an hour’s work lookingthrough the results. The assistant can look through 100 retrieveddocuments in an hour. The assistant will charge the searcher for thefull hour regardless of whether he finds it immediately or at theend of the hour.        The searcher will look through all the answers. Examining a documenthas cost $ A; finding a relevant document has value $ B; failingto find a relevant document has cost $ C for each relevantdocument not found.        The searcher wants to collect as many relevant documents aspossible, but needs steady encouragement. She looks through thedocuments in order. If the documents she has looked at so far aremostly good, she will continue; otherwise, she will stop.  ",
        "url": " /nlp-communicating-exercises/ex_11/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-4":  {
        "title": "Exercise 22.4",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.4Choose a corpus of at least 20,000 words of online text, and verifyZipf’s law experimentally. Define an error measure and find the value of$alpha$ where Zipf’s law best matches your experimental data. Create alog–log graph plotting $f_{I}$ vs. $I$ and $alpha/I$ vs. $I$. (On alog–log graph, the function $alpha/I$ is a straight line.) In carryingout the experiment, be sure to eliminate any formatting tokens (e.g.,HTML tags) and normalize upper and lower case.",
        "url": " /nlp-communicating-exercises/ex_4/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-7":  {
        "title": "Exercise 22.7",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.7Create a test set of ten queries, and pose them to three major Websearch engines. Evaluate each one for precision at 1, 3, and 10documents. Can you explain the differences between engines?",
        "url": " /nlp-communicating-exercises/ex_7/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-5":  {
        "title": "Exercise 22.5",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.5(Adapted from @Jurafsky+Martin:2000.) In this exercise you will develop a classifier forauthorship: given a text, the classifier predicts which of two candidateauthors wrote the text. Obtain samples of text from two differentauthors. Separate them into training and test sets. Now train a languagemodel on the training set. You can choose what features to use;$n$-grams of words or letters are the easiest, but you can addadditional features that you think may help. Then compute theprobability of the text under each language model and chose the mostprobable model. Assess the accuracy of this technique. How does accuracychange as you alter the set of features? This subfield of linguistics iscalled stylometry; its successes include the identification of the author of thedisputed Federalist Papers @Mosteller+Wallace:1964 andsome disputed works of Shakespeare @Hope:1994. @Khmelev+Tweedie:2001 produce good results witha simple letter bigram model.",
        "url": " /nlp-communicating-exercises/ex_5/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-10":  {
        "title": "Exercise 22.10",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.10Write a regular expression or a short program to extract company names.Test it on a corpus of business news articles. Report your recall andprecision.",
        "url": " /nlp-communicating-exercises/ex_10/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-8":  {
        "title": "Exercise 22.8",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.8Try to ascertain which of the search engines from the previous exerciseare using case folding, stemming, synonyms, and spelling correction.",
        "url": " /nlp-communicating-exercises/ex_8/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-2":  {
        "title": "Exercise 22.2",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.2Write a program to do segmentation ofwords without spaces. Given a string, such as the URL“thelongestlistofthelongeststuffatthelongestdomainnameatlonglast.com,”return a list of component words: [“the,” “longest,” “list,”$ldots$]. This task is useful for parsing URLs, for spellingcorrection when words runtogether, and for languages such as Chinesethat do not have spaces between words. It can be solved with a unigramor bigram word model and a dynamic programming algorithm similar to theViterbi algorithm.",
        "url": " /nlp-communicating-exercises/ex_2/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-9":  {
        "title": "Exercise 22.9",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.9Estimate how much storage space is necessary for the index to a 100billion-page corpus of Web pages. Show the assumptions you made.",
        "url": " /nlp-communicating-exercises/ex_9/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-6":  {
        "title": "Exercise 22.6",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.6This exercise concerns the classification of spam email.Create a corpus of spam email and one of non-spam mail. Examine eachcorpus and decide what features appear to be useful for classification:unigram words? bigrams? message length, sender, time of arrival? Thentrain a classification algorithm (decision tree, naive Bayes, SVM,logistic regression, or some other algorithm of your choosing) on atraining set and report its accuracy on a test set.",
        "url": " /nlp-communicating-exercises/ex_6/"
      }
    
  
    ,
      "nlp-communicating-exercises-ex-1":  {
        "title": "Exercise 22.1",
        "breadcrumb": "22-Natural-Language-Processing",
      	"content"  : "Exercise 22.1This exercise explores the quality of the $n$-gram model of language.Find or create a monolingual corpus of 100,000 words or more. Segment itinto words, and compute the frequency of each word. How many distinctwords are there? Also count frequencies of bigrams (two consecutivewords) and trigrams (three consecutive words). Now use those frequenciesto generate language: from the unigram, bigram, and trigram models, inturn, generate a 100-word text by making random choices according to thefrequency counts. Compare the three generated texts with actuallanguage. Finally, calculate the perplexity of each model.",
        "url": " /nlp-communicating-exercises/ex_1/"
      }
    
  
    
  
    ,
      "intro-exercises-ex-3":  {
        "title": "Exercise 1.3",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.3Every year the Loebner Prize is awarded to the program that comesclosest to passing a version of the Turing Test. Research and report onthe latest winner of the Loebner prize. What techniques does it use? Howdoes it advance the state of the art in AI?",
        "url": " /intro-exercises/ex_3/"
      }
    
  
    ,
      "intro-exercises-ex-11":  {
        "title": "Exercise 1.11",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.11Many of the computational models of cognitive activities that have beenproposed involve quite complex mathematical operations, such asconvolving an image with a Gaussian or finding a minimum of the entropyfunction. Most humans (and certainly all animals) never learn this kindof mathematics at all, almost no one learns it before college, andalmost no one can compute the convolution of a function with a Gaussianin their head. What sense does it make to say that the “vision system”is doing this kind of mathematics, whereas the actual person has no ideahow to do it?",
        "url": " /intro-exercises/ex_11/"
      }
    
  
    ,
      "intro-exercises-ex-14":  {
        "title": "Exercise 1.14",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.14Is AI a science, or is it engineering? Or neither or both? Explain.",
        "url": " /intro-exercises/ex_14/"
      }
    
  
    ,
      "intro-exercises-ex-4":  {
        "title": "Exercise 1.4",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.4Are reflex actions (such as flinching from a hot stove) rational? Arethey intelligent?",
        "url": " /intro-exercises/ex_4/"
      }
    
  
    ,
      "intro-exercises-ex-20":  {
        "title": "Exercise 1.20",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.20Various subfields of AI have held contests by defining a standard taskand inviting researchers to do their best. Examples include the DARPAGrand Challenge for robotic cars, the International PlanningCompetition, the Robocup robotic soccer league, the TREC informationretrieval event, and contests in machine translation and speechrecognition. Investigate five of these contests and describe theprogress made over the years. To what degree have the contests advancedthe state of the art in AI? To what degree do they hurt the field bydrawing energy away from new ideas?",
        "url": " /intro-exercises/ex_20/"
      }
    
  
    ,
      "intro-exercises-ex-7":  {
        "title": "Exercise 1.7",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.7The neural structure of the sea slug Aplysia has beenwidely studied (first by Nobel Laureate Eric Kandel) because it has onlyabout 20,000 neurons, most of them large and easily manipulated.Assuming that the cycle time for an Aplysia neuron isroughly the same as for a human neuron, how does the computationalpower, in terms of memory updates per second, compare with the high-endcomputer described in (Figure computer-brain-table)?",
        "url": " /intro-exercises/ex_7/"
      }
    
  
    ,
      "intro-exercises-ex-17":  {
        "title": "Exercise 1.17",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.17“Surely animals, humans, and computers cannot be intelligent—they can doonly what their constituent atoms are told to do by the laws ofphysics.” Is the latter statement true, and does it imply the former?",
        "url": " /intro-exercises/ex_17/"
      }
    
  
    ,
      "intro-exercises-ex-5":  {
        "title": "Exercise 1.5",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.5There are well-known classes of problems that are intractably difficultfor computers, and other classes that are provably undecidable. Doesthis mean that AI is impossible?",
        "url": " /intro-exercises/ex_5/"
      }
    
  
    ,
      "intro-exercises-ex-10":  {
        "title": "Exercise 1.10",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.10To what extent are the following computer systems instances ofartificial intelligence:      Supermarket bar code scanners.        Voice-activated telephone menus.        Spelling and grammar correction features in Microsoft Word.        Internet routing algorithms that respond dynamically to the state of the network.  ",
        "url": " /intro-exercises/ex_10/"
      }
    
  
    ,
      "intro-exercises-ex-18":  {
        "title": "Exercise 1.18",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.18Examine the AI literature to discover whether the following tasks cancurrently be solved by computers:  Playing a decent game of table tennis (Ping-Pong).  Driving in the center of Cairo, Egypt.  Driving in Victorville, California.  Buying a week’s worth of groceries at the market.  Buying a week’s worth of groceries on the Web.  Playing a decent game of bridge at a competitive level.  Discovering and proving new mathematical theorems.  Writing an intentionally funny story.  Giving competent legal advice in a specialized area of law.  Translating spoken English into spoken Swedish in real time.  Performing a complex surgical operation.",
        "url": " /intro-exercises/ex_18/"
      }
    
  
    ,
      "intro-exercises-ex-15":  {
        "title": "Exercise 1.15",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.15“Surely computers cannot be intelligent—they can do only what theirprogrammers tell them.” Is the latter statement true, and does it implythe former?",
        "url": " /intro-exercises/ex_15/"
      }
    
  
    ,
      "intro-exercises-ex-16":  {
        "title": "Exercise 1.16",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.16“Surely animals cannot be intelligent—they can do only what their genestell them.” Is the latter statement true, and does it imply the former?",
        "url": " /intro-exercises/ex_16/"
      }
    
  
    ,
      "intro-exercises-ex-8":  {
        "title": "Exercise 1.8",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.8How could introspection—reporting on one’s inner thoughts—be inaccurate?Could I be wrong about what I’m thinking? Discuss.",
        "url": " /intro-exercises/ex_8/"
      }
    
  
    ,
      "intro-exercises-ex-2":  {
        "title": "Exercise 1.2",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.2Read Turing’s original paper on AI @Turing:1950. In the paper, hediscusses several objections to his proposed enterprise and his test forintelligence. Which objections still carry weight? Are his refutationsvalid? Can you think of new objections arising from developments sincehe wrote the paper? In the paper, he predicts that, by the year 2000, acomputer will have a 30% chance of passing a five-minute Turing Testwith an unskilled interrogator. What chance do you think a computerwould have today? In another 50 years?",
        "url": " /intro-exercises/ex_2/"
      }
    
  
    ,
      "intro-exercises-ex-9":  {
        "title": "Exercise 1.9",
        "breadcrumb": "Introduction",
      	"content"  : "Exercise 1.9To what extent are the following computer systems instances ofartificial intelligence:      Supermarket bar code scanners.        Web search engines.        Voice-activated telephone menus.        Internet routing algorithms that respond dynamically to the state ofthe network.  ",
        "url": " /intro-exercises/ex_9/"
      }
    
  
    ,
      "intro-exercises-ex-19":  {
        "title": "Exercise 1.19",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.19For the currently infeasible tasks, try to find out what thedifficulties are and predict when, if ever, they will be overcome.",
        "url": " /intro-exercises/ex_19/"
      }
    
  
    ,
      "intro-exercises-ex-6":  {
        "title": "Exercise 1.6",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.6Suppose we extend Evans’s SYSTEM program so that it can score 200 on a standardIQ test. Would we then have a program more intelligent than a human?Explain.",
        "url": " /intro-exercises/ex_6/"
      }
    
  
    ,
      "intro-exercises-ex-1":  {
        "title": "Exercise 1.1",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.1Define in your own words: (a) intelligence, (b) artificial intelligence,(c) agent, (d) rationality, (e) logical reasoning.",
        "url": " /intro-exercises/ex_1/"
      }
    
  
    ,
      "intro-exercises-ex-13":  {
        "title": "Exercise 1.13",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.13Why would evolution tend to result in systems that act rationally? Whatgoals are such systems designed to achieve?",
        "url": " /intro-exercises/ex_13/"
      }
    
  
    ,
      "intro-exercises-ex-12":  {
        "title": "Exercise 1.12",
        "breadcrumb": "1-Introduction",
      	"content"  : "Exercise 1.12Some authors have claimed that perception and motor skills are the mostimportant part of intelligence, and that “higher level” capacities arenecessarily parasitic—simple add-ons to these underlying facilities.Certainly, most of evolution and a large part of the brain have beendevoted to perception and motor skills, whereas AI has found tasks suchas game playing and logical inference to be easier, in many ways, thanperceiving and acting in the real world. Do you think that AI’straditional focus on higher-level cognitive abilities is misplaced?",
        "url": " /intro-exercises/ex_12/"
      }
    
  
    
  
    ,
      "ilp-exercises-ex-3":  {
        "title": "Exercise 19.3",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.3For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):      Zip code determines the state (U.S.).        Design and denomination determine the mass of a coin.        Climate, food intake, exercise, and metabolism determine weight gainand loss.        Baldness is determined by the baldness (or lack thereof) of one’smaternal grandfather.  ",
        "url": " /ilp-exercises/ex_3/"
      }
    
  
    ,
      "ilp-exercises-ex-4":  {
        "title": "Exercise 19.4",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.4Would a probabilistic version of determinations be useful? Suggest adefinition.",
        "url": " /ilp-exercises/ex_4/"
      }
    
  
    ,
      "ilp-exercises-ex-7":  {
        "title": "Exercise 19.7",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.7 [foil-literals-exercise]Suppose that is considering adding a literalto a clause using a binary predicate $P$ and that previous literals(including the head of the clause) contain five different variables.      How many functionally different literals can be generated? Twoliterals are functionally identical if they differ only in the namesof the new variables that they contain.        Can you find a general formula for the number of different literalswith a predicate of arity $r$ when there are $n$ variablespreviously used?        Why does not allow literals that contain no previously usedvariables?  ",
        "url": " /ilp-exercises/ex_7/"
      }
    
  
    ,
      "ilp-exercises-ex-5":  {
        "title": "Exercise 19.5",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.5 [ir-step-exercise]Fill in the missing values for the clauses $C_1$ or$C_2$ (or both) in the following sets of clauses, given that $C$ is theresolvent of $C_1$ and $C_2$:      $C = {True} Rightarrow P(A,B)$,$C_1 = P(x,y) Rightarrow Q(x,y)$, $C_2= ??$.        $C = {True} Rightarrow P(A,B)$, $C_1 = ??$,$C_2 = ??$.        $C = P(x,y) Rightarrow P(x,f(y))$, $C_1 = ??$,$C_2 = ??$.  If there is more than one possible solution, provide one example of eachdifferent kind.",
        "url": " /ilp-exercises/ex_5/"
      }
    
  
    ,
      "ilp-exercises-ex-8":  {
        "title": "Exercise 19.8",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.8Using the data from the family tree inFigure family2-figure, or a subset thereof, apply thealgorithm to learn a definition for the ${Ancestor}$ predicate.",
        "url": " /ilp-exercises/ex_8/"
      }
    
  
    ,
      "ilp-exercises-ex-2":  {
        "title": "Exercise 19.2",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.2For each of the following determinations, write down the logicalrepresentation and explain why the determination is true (if it is):      Design and denomination determine the mass of a coin.        For a given program, input determines output.        Climate, food intake, exercise, and metabolism determine weight gainand loss.        Baldness is determined by the baldness (or lack thereof) of one’smaternal grandfather.  ",
        "url": " /ilp-exercises/ex_2/"
      }
    
  
    ,
      "ilp-exercises-ex-6":  {
        "title": "Exercise 19.6",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.6 [prolog-ir-exercise]Suppose one writes a logic program that carriesout a resolution inference step. That is, let ${Resolve}(c_1,c_2,c)$succeed if $c$ is the result of resolving $c_1$ and $c_2$. Normally,${Resolve}$ would be used as part of a theorem prover by calling itwith $c_1$ and $c_2$ instantiated to particular clauses, therebygenerating the resolvent $c$. Now suppose instead that we call it with$c$ instantiated and $c_1$ and $c_2$ uninstantiated. Will this succeedin generating the appropriate results of an inverse resolution step?Would you need any special modifications to the logic programming systemfor this to work?",
        "url": " /ilp-exercises/ex_6/"
      }
    
  
    ,
      "ilp-exercises-ex-1":  {
        "title": "Exercise 19.1",
        "breadcrumb": "19-Knowledge-In-Learning",
      	"content"  : "Exercise 19.1 [dbsig-exercise]Show, by translating into conjunctive normal form andapplying resolution, that the conclusion drawn on page dbsig-pageconcerning Brazilians is sound.",
        "url": " /ilp-exercises/ex_1/"
      }
    
  
    
  
    ,
      "knowledge-logic-exercises-ex-28":  {
        "title": "Exercise 7.28",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.28 [minesweeper-exercise]Minesweeper, the well-known computer game, isclosely related to the wumpus world. A minesweeper world isa rectangular grid of $N$ squares with $M$ invisible mines scatteredamong them. Any square may be probed by the agent; instant death followsif a mine is probed. Minesweeper indicates the presence of mines byrevealing, in each probed square, the number of minesthat are directly or diagonally adjacent. The goal is to probe everyunmined square.      Let $X_{i,j}$ be true iff square $[i,j]$ contains a mine. Write downthe assertion that exactly two mines are adjacent to [1,1] as asentence involving some logical combination of$X_{i,j}$ propositions.        Generalize your assertion from (a) by explaining how to construct aCNF sentence asserting that $k$ of $n$ neighbors contain mines.        Explain precisely how an agent can use {DPLL} to prove that a given squaredoes (or does not) contain a mine, ignoring the global constraintthat there are exactly $M$ mines in all.        Suppose that the global constraint is constructed from your methodfrom part (b). How does the number of clauses depend on $M$ and $N$?Suggest a way to modify {DPLL} so that the global constraint does not needto be represented explicitly.        Are any conclusions derived by the method in part (c) invalidatedwhen the global constraint is taken into account?        Give examples of configurations of probe values that inducelong-range dependencies such that the contents of agiven unprobed square would give information about the contents of afar-distant square. (Hint: consider an$Ntimes 1$ board.)  ",
        "url": " /knowledge-logic-exercises/ex_28/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-29":  {
        "title": "Exercise 7.29",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.29 [known-literal-exercise]How long does it take to prove${KB}{models}alpha$ using {DPLL} when $alpha$ is a literal alreadycontained in ${KB}$? Explain.",
        "url": " /knowledge-logic-exercises/ex_29/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-3":  {
        "title": "Exercise 7.3",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.3 [truth-value-exercise]Consider the problem of deciding whether apropositional logic sentence is true in a given model.      Write a recursive algorithm PL-True?$ (s, m )$ that returns ${true}$ if andonly if the sentence $s$ is true in the model $m$ (where $m$ assignsa truth value for every symbol in $s$). The algorithm should run intime linear in the size of the sentence. (Alternatively, use aversion of this function from the online code repository.)        Give three examples of sentences that can be determined to be trueor false in a partial model that does not specify atruth value for some of the symbols.        Show that the truth value (if any) of a sentence in a partial modelcannot be determined efficiently in general.        Modify your algorithm so that it can sometimes judge truth frompartial models, while retaining its recursive structure and linearrun time. Give three examples of sentences whose truth in a partialmodel is not detected by your algorithm.        Investigate whether the modified algorithm makes $TT-Entails?$ more efficient.  ",
        "url": " /knowledge-logic-exercises/ex_3/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-11":  {
        "title": "Exercise 7.11",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.11 [logical-equivalence-exercise]Using a method of your choice, verifyeach of the equivalences inTable [logical-equivalence-table] (page logical-equivalence-table).",
        "url": " /knowledge-logic-exercises/ex_11/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-14":  {
        "title": "Exercise 7.14",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.14 [cnf-proof-exercise]Any propositional logic sentence is logicallyequivalent to the assertion that each possible world in which it wouldbe false is not the case. From this observation, prove that any sentencecan be written in CNF.",
        "url": " /knowledge-logic-exercises/ex_14/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-4":  {
        "title": "Exercise 7.4",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.4Which of the following are correct?      ${False} models {True}$.        ${True} models {False}$.        $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.        $A{;;{Leftrightarrow};;}B models A lor B$.        $A{;;{Leftrightarrow};;}B models lnot A lor B$.        $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.        $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.        $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B)$.        $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.        $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.        $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$is satisfiable.        $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ hasthe same number of models as $(A{;;{Leftrightarrow};;}B)$ forany fixed set of proposition symbols that includes $A$, $B$, $C$.  ",
        "url": " /knowledge-logic-exercises/ex_4/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-23":  {
        "title": "Exercise 7.23",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.23Consider the following sentence:      Determine, using enumeration, whether this sentence is valid,satisfiable (but not valid), or unsatisfiable.        Convert the left-hand and right-hand sides of the main implicationinto CNF, showing each step, and explain how the results confirmyour answer to (a).        Prove your answer to (a) using resolution.  ",
        "url": " /knowledge-logic-exercises/ex_23/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-20":  {
        "title": "Exercise 7.20",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.20Explain why every nonempty propositional clause, by itself, issatisfiable. Prove rigorously that every set of five 3-SAT clauses issatisfiable, provided that each clause mentions exactly three distinctvariables. What is the smallest set of such clauses that isunsatisfiable? Construct such a set.",
        "url": " /knowledge-logic-exercises/ex_20/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-33":  {
        "title": "Exercise 7.33",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.33Suppose an agent inhabits a world with two states, $S$ and $lnot S$,and can do exactly one of two actions, $a$ and $b$. Action $a$ doesnothing and action $b$ flips from one state to the other. Let $S^t$ bethe proposition that the agent is in state $S$ at time $t$, and let$a^t$ be the proposition that the agent does action $a$ at time $t$(similarly for $b^t$).      Write a successor-state axiom for $S^{t+1}$.        Convert the sentence in (a) into CNF.        Show a resolution refutation proof that if the agent is in $lnot S$at time $t$ and does $a$, it will still be in $lnot S$ at time$t+1$.  ",
        "url": " /knowledge-logic-exercises/ex_33/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-7":  {
        "title": "Exercise 7.7",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.7Prove, or find a counterexample to, each of the following assertions:      If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then$(alphaland beta)modelsgamma$        If $(alphaland beta)modelsgamma$ then $alphamodelsgamma$ or$betamodelsgamma$ (or both).        If $alphamodels (beta lor gamma)$ then $alpha models beta$or $alpha models gamma$ (or both).  ",
        "url": " /knowledge-logic-exercises/ex_7/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-17":  {
        "title": "Exercise 7.17",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.17According to some political pundits, a person who is radical ($R$) iselectable ($E$) if he/she is conservative ($C$), but otherwise is notelectable.      Which of the following are correct representations of thisassertion?                  $(Rland E)iff C$                    $R{:;{Rightarrow}:;}(Eiff C)$                    $R{:;{Rightarrow}:;}((C{:;{Rightarrow}:;}E) lor lnot E)$                  Which of the sentences in (a) can be expressed in Horn form?  ",
        "url": " /knowledge-logic-exercises/ex_17/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-5":  {
        "title": "Exercise 7.5",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.5Which of the following are correct?      ${False} models {True}$.        ${True} models {False}$.        $(Aland B)  models (A{;;{Leftrightarrow};;}B)$.        $A{;;{Leftrightarrow};;}B models A lor B$.        $A{;;{Leftrightarrow};;}B models lnot A lor B$.        $(Alor B) land (lnot Clorlnot Dlor E) models (Alor Blor C) land (Bland Cland D{:;{Rightarrow}:;}E)$.        $(Alor B) land (lnot Clorlnot Dlor E) models (Alor B) land (lnot Dlor E)$.        $(Alor B) land lnot(A {:;{Rightarrow}:;}B)$ is satisfiable.        $(Aland B){:;{Rightarrow}:;}C models (A{:;{Rightarrow}:;}C)lor(B{:;{Rightarrow}:;}C)$.        $(Clor (lnot A land lnot B)) equiv ((A{:;{Rightarrow}:;}C) land (B {:;{Rightarrow}:;}C))$.        $(A{;;{Leftrightarrow};;}B) land (lnot A lor B)$is satisfiable.        $(A{;;{Leftrightarrow};;}B) {;;{Leftrightarrow};;}C$ hasthe same number of models as $(A{;;{Leftrightarrow};;}B)$ forany fixed set of proposition symbols that includes $A$, $B$, $C$.  ",
        "url": " /knowledge-logic-exercises/ex_5/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-25":  {
        "title": "Exercise 7.25",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.25 [convert-clausal-exercise]Convert the following set of sentences toclausal form.  S1: $A {;;{Leftrightarrow};;}(B lor E)$.  S2: $E {:;{Rightarrow}:;}D$.  S3: $C land F {:;{Rightarrow}:;}lnot B$.  S4: $E {:;{Rightarrow}:;}B$.  S5: $B {:;{Rightarrow}:;}F$.  S6: $B {:;{Rightarrow}:;}C$Give a trace of the execution of DPLL on the conjunction of theseclauses.",
        "url": " /knowledge-logic-exercises/ex_25/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-10":  {
        "title": "Exercise 7.10",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.10We have defined four binary logical connectives.      Are there any others that might be useful?        How many binary connectives can there be?        Why are some of them not very useful?  ",
        "url": " /knowledge-logic-exercises/ex_10/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-22":  {
        "title": "Exercise 7.22",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.22Prove each of the following assertions:      Every pair of propositional clauses either has no resolvents, or alltheir resolvents are logically equivalent.        There is no clause that, when resolved with itself, yields(after factoring) the clause $(lnot P lor lnot Q)$.        If a propositional clause $C$ can be resolved with a copy of itself,it must be logically equivalent to $ True $.  ",
        "url": " /knowledge-logic-exercises/ex_22/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-18":  {
        "title": "Exercise 7.18",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.18This question considers representing satisfiability (SAT) problems asCSPs.      Draw the constraint graph corresponding to the SAT problemfor the particular case $n5$.        How many solutions are there for this general SAT problem as afunction of $n$?        Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find allsolutions to a SAT CSP of the type given in (a). (To findall solutions to a CSP, we simply modify the basicalgorithm so it continues searching after each solution is found.)Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$is ordered before ${true}$. How much time will the algorithm taketo terminate? (Write an $O(cdot)$ expression as a function of $n$.)        We know that SAT problems in Horn form can be solved in linear timeby forward chaining (unit propagation). We also know that everytree-structured binary CSP with discrete, finite domains can besolved in time linear in the number of variables(Section csp-structure-section). Are these twofacts connected? Discuss.  ",
        "url": " /knowledge-logic-exercises/ex_18/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-31":  {
        "title": "Exercise 7.31",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.31Write a successor-state axiom for the ${Locked}$ predicate, whichapplies to doors, assuming the only actions available are ${Lock}$ and${Unlock}$.",
        "url": " /knowledge-logic-exercises/ex_31/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-24":  {
        "title": "Exercise 7.24",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.24 [dnf-exercise]A sentence is in disjunctive normal form(DNF) if it is the disjunction ofconjunctions of literals. For example, the sentence$(A land B land lnot C) lor (lnot A land C) lor (B land lnot C)$is in DNF.      Any propositional logic sentence is logically equivalent to theassertion that some possible world in which it would be true is infact the case. From this observation, prove that any sentence can bewritten in DNF.        Construct an algorithm that converts any sentence in propositionallogic into DNF. (Hint: The algorithm is similar tothe algorithm for conversion to CNF iven inSectio pl-resolution-section.)        Construct a simple algorithm that takes as input a sentence in DNFand returns a satisfying assignment if one exists, or reports thatno satisfying assignment exists.        Apply the algorithms in (b) and (c) to the following set ofsentences:    $A {Rightarrow} B$  $B {Rightarrow} C$  $C {Rightarrow} A$  Since the algorithm in (b) is very similar to the algorithm forconversion to CNF, and since the algorithm in (c) is much simplerthan any algorithm for solving a set of sentences in CNF, why isthis technique not used in automated reasoning?",
        "url": " /knowledge-logic-exercises/ex_24/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-34":  {
        "title": "Exercise 7.34",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.34 [ss-axiom-exercise]Section successor-state-sectionprovides some of the successor-state axioms required for the wumpusworld. Write down axioms for all remaining fluent symbols.",
        "url": " /knowledge-logic-exercises/ex_34/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-15":  {
        "title": "Exercise 7.15",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.15Use resolution to prove the sentence $lnot A land lnot B$ from theclauses in Exercise convert-clausal-exercise.",
        "url": " /knowledge-logic-exercises/ex_15/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-16":  {
        "title": "Exercise 7.16",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.16 [inf-exercise]This exercise looks into the relationship betweenclauses and implication sentences.      Show that the clause $(lnot P_1 lor cdots lor lnot P_m lor Q)$is logically equivalent to the implication sentence$(P_1 land cdots land P_m) {;{Rightarrow};}Q$.        Show that every clause (regardless of the number ofpositive literals) can be written in the form$(P_1 land cdots land P_m) {;{Rightarrow};}(Q_1 lor cdots lor Q_n)$,where the $P$s and $Q$s are proposition symbols. A knowledge baseconsisting of such sentences is in implicative normal form or Kowalskiform @Kowalski:1979.        Write down the full resolution rule for sentences in implicativenormal form.  ",
        "url": " /knowledge-logic-exercises/ex_16/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-32":  {
        "title": "Exercise 7.32",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.32Discuss what is meant by optimal behavior in the wumpusworld. Show that the {Hybrid-Wumpus-Agent} is not optimal, and suggest ways to improve it.",
        "url": " /knowledge-logic-exercises/ex_32/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-30":  {
        "title": "Exercise 7.30",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.30 [dpll-fc-exercise]Trace the behavior of {DPLL} on the knowledge base inFigure pl-horn-example-figure when trying to prove $Q$,and compare this behavior with that of the forward-chaining algorithm.",
        "url": " /knowledge-logic-exercises/ex_30/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-8":  {
        "title": "Exercise 7.8",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.8Prove, or find a counterexample to, each of the following assertions:      If $alphamodelsgamma$ or $betamodelsgamma$ (or both) then$(alphaland beta)modelsgamma$        If $alphamodels (beta land gamma)$ then $alpha models beta$and $alpha models gamma$.        If $alphamodels (beta lor gamma)$ then $alpha models beta$or $alpha models gamma$ (or both).  ",
        "url": " /knowledge-logic-exercises/ex_8/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-2":  {
        "title": "Exercise 7.2",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.2(Adapted from @Barwise+Etchemendy:1993 .) Given the following, can you prove that the unicorn ismythical? How about magical? Horned?  If the unicorn is mythical, then it is immortal, but if it is notmythical, then it is a mortal mammal. If the unicorn is eitherimmortal or a mammal, then it is horned. The unicorn is magical if itis horned.",
        "url": " /knowledge-logic-exercises/ex_2/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-9":  {
        "title": "Exercise 7.9",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.9Consider a vocabulary with only four propositions, $A$, $B$, $C$, and$D$. How many models are there for the following sentences?      $Blor C$.        $lnot Alor lnot B lor lnot C lor lnot D$.        $(A{:;{Rightarrow}:;}B) land A land lnot B land C land D$.  ",
        "url": " /knowledge-logic-exercises/ex_9/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-35":  {
        "title": "Exercise 7.35",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.35 [hybrid-wumpus-exercise]Modify the {Hybrid-Wumpus-Agent} to use the 1-CNF logical stateestimation method described on page 1cnf-belief-state-page. We noted on that pagethat such an agent will not be able to acquire, maintain, and use morecomplex beliefs such as the disjunction $P_{3,1}lor P_{2,2}$. Suggest amethod for overcoming this problem by defining additional propositionsymbols, and try it out in the wumpus world. Does it improve theperformance of the agent?",
        "url": " /knowledge-logic-exercises/ex_35/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-19":  {
        "title": "Exercise 7.19",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.19This question considers representing satisfiability (SAT) problems asCSPs.      Draw the constraint graph corresponding to the SAT problemfor the particular case $n4$.        How many solutions are there for this general SAT problem as afunction of $n$?        Suppose we apply {Backtracking-Search} (page backtracking-search-algorithm) to find allsolutions to a SAT CSP of the type given in (a). (To findall solutions to a CSP, we simply modify the basicalgorithm so it continues searching after each solution is found.)Assume that variables are ordered $X_1,ldots,X_n$ and ${false}$is ordered before ${true}$. How much time will the algorithm taketo terminate? (Write an $O(cdot)$ expression as a function of $n$.)        We know that SAT problems in Horn form can be solved in linear timeby forward chaining (unit propagation). We also know that everytree-structured binary CSP with discrete, finite domains can besolved in time linear in the number of variables(Section csp-structure-section). Are these twofacts connected? Discuss.  ",
        "url": " /knowledge-logic-exercises/ex_19/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-27":  {
        "title": "Exercise 7.27",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.27Is a randomly generated 4-CNF sentence with $n$ symbols and $m$ clausesmore or less likely to be solvable than a randomly generated 3-CNFsentence with $n$ symbols and $m$ clauses? Explain.",
        "url": " /knowledge-logic-exercises/ex_27/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-6":  {
        "title": "Exercise 7.6",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.6 [deduction-theorem-exercise]Prove each of the following assertions:      $alpha$ is valid if and only if ${True}{models}alpha$.        For any $alpha$, ${False}{models}alpha$.        $alpha{models}beta$ if and only if the sentence$(alpha {:;{Rightarrow}:;}beta)$ is valid.        $alpha equiv beta$ if and only if the sentence$(alpha{;;{Leftrightarrow};;}beta)$ is valid.        $alpha{models}beta$ if and only if the sentence$(alpha land lnot beta)$ is unsatisfiable.  ",
        "url": " /knowledge-logic-exercises/ex_6/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-26":  {
        "title": "Exercise 7.26",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.26 [convert-clausal-exercise]Convert the following set of sentences toclausal form.  S1: $A {;;{Leftrightarrow};;}(C lor E)$.  S2: $E {:;{Rightarrow}:;}D$.  S3: $B land F {:;{Rightarrow}:;}lnot C$.  S4: $E {:;{Rightarrow}:;}C$.  S5: $C {:;{Rightarrow}:;}F$.  S6: $C {:;{Rightarrow}:;}B$Give a trace of the execution of DPLL on the conjunction of theseclauses.",
        "url": " /knowledge-logic-exercises/ex_26/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-21":  {
        "title": "Exercise 7.21",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.21A propositional 2-CNF expression is a conjunction ofclauses, each containing exactly 2 literals, e.g.,      Prove using resolution that the above sentence entails $G$.        Two clauses are semantically distinct if they are notlogically equivalent. How many semantically distinct 2-CNF clausescan be constructed from $n$ proposition symbols?        Using your answer to (b), prove that propositional resolution alwaysterminates in time polynomial in $n$ given a 2-CNF sentencecontaining no more than $n$ distinct symbols.        Explain why your argument in (c) does not apply to 3-CNF.  ",
        "url": " /knowledge-logic-exercises/ex_21/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-1":  {
        "title": "Exercise 7.1",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.1Suppose the agent has progressed to the point shown inFigure wumpus-seq35-figure(a), page wumpus-seq35-figure,having perceived nothing in [1,1], a breeze in [2,1], and a stenchin [1,2], and is now concerned with the contents of [1,3], [2,2],and [3,1]. Each of these can contain a pit, and at most one cancontain a wumpus. Following the example ofFigure wumpus-entailment-figure, construct the set ofpossible worlds. (You should find 32 of them.) Mark the worlds in whichthe KB is true and those in which each of the following sentences istrue:$alpha_2$ = “There is no pit in [2,2].”$alpha_3$ = “There is a wumpus in [1,3].”Hence show that ${KB} {models}alpha_2$ and${KB} {models}alpha_3$.",
        "url": " /knowledge-logic-exercises/ex_1/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-13":  {
        "title": "Exercise 7.13",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.13 [propositional-validity-exercise]Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable [logical-equivalence-table] (page logical-equivalence-table).      ${Smoke} {:;{Rightarrow}:;}{Smoke}$        ${Smoke} {:;{Rightarrow}:;}{Fire}$        $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$        ${Smoke} lor {Fire} lor lnot {Fire}$        $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})        {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$        ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$        $({Big} land {Dumb}) lor lnot {Dumb}$  ",
        "url": " /knowledge-logic-exercises/ex_13/"
      }
    
  
    ,
      "knowledge-logic-exercises-ex-12":  {
        "title": "Exercise 7.12",
        "breadcrumb": "7-Logical-Agents",
      	"content"  : "Exercise 7.12 [propositional-validity-exercise]Decide whether each of the followingsentences is valid, unsatisfiable, or neither. Verify your decisionsusing truth tables or the equivalence rules ofTable [logical-equivalence-table] (page logical-equivalence-table).      ${Smoke} {:;{Rightarrow}:;}{Smoke}$        ${Smoke} {:;{Rightarrow}:;}{Fire}$        $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(lnot {Smoke} {:;{Rightarrow}:;}lnot {Fire})$        ${Smoke} lor {Fire} lor lnot {Fire}$        $(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire})        {;;{Leftrightarrow};;}(({Smoke} {:;{Rightarrow}:;}{Fire}) lor ({Heat} {:;{Rightarrow}:;}{Fire}))$        $({Smoke} {:;{Rightarrow}:;}{Fire}) {:;{Rightarrow}:;}(({Smoke} land {Heat}) {:;{Rightarrow}:;}{Fire}) $        ${Big} lor {Dumb} lor ({Big} {:;{Rightarrow}:;}{Dumb})$  ",
        "url": " /knowledge-logic-exercises/ex_12/"
      }
    
  
    
  
    ,
      "advanced-search-exercises-ex-3":  {
        "title": "Exercise 4.3",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.3In this exercise, we explore the use of local search methods to solveTSPs of the type defined in Exercise tsp-mst-exercise.      Implement and test a hill-climbing method to solve TSPs. Compare theresults with optimal solutions obtained from the A* algorithm withthe MST heuristic (Exercise tsp-mst-exercise).        Repeat part (a) using a genetic algorithm instead of hill climbing.You may want to consult @Larranaga+al:1999 for some suggestions for representations.  ",
        "url": " /advanced-search-exercises/ex_3/"
      }
    
  
    ,
      "advanced-search-exercises-ex-11":  {
        "title": "Exercise 4.11",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.11 [vacuum-solvable-exercise]Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${ 1,3,5,7 }$, and explain why the problemis unsolvable.",
        "url": " /advanced-search-exercises/ex_11/"
      }
    
  
    ,
      "advanced-search-exercises-ex-14":  {
        "title": "Exercise 4.14",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.14 [online-offline-exercise]Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (3,3), that the goal is at (1,1), and that the fouractions Up, Down, Left, Right have their usualeffects unless blocked by a wall. The agent does not knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before or is a new state.      Explain how this online search problem can be viewed as an offlinesearch in belief-state space, where the initial belief stateincludes all possible environment configurations. How large is theinitial belief state? How large is the space of belief states?        How many distinct percepts are possible in the initial state?        Describe the first few branches of a contingency plan for thisproblem. How large (roughly) is the complete plan?  Notice that this contingency plan is a solution for everypossible environment fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.",
        "url": " /advanced-search-exercises/ex_14/"
      }
    
  
    ,
      "advanced-search-exercises-ex-4":  {
        "title": "Exercise 4.4",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.4 [hill-climbing-exercise]Generate a large number of 8-puzzle and8-queens instances and solve them (where possible) by hill climbing(steepest-ascent and first-choice variants), hill climbing with randomrestart, and simulated annealing. Measure the search cost and percentageof solved problems and graph these against the optimal solution cost.Comment on your results.",
        "url": " /advanced-search-exercises/ex_4/"
      }
    
  
    ,
      "advanced-search-exercises-ex-7":  {
        "title": "Exercise 4.7",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.7In Section conformant-section we introduced beliefstates to solve sensorless search problems. A sequence of actions solvesa sensorless problem if it maps every physical state in the initialbelief state $b$ to a goal state. Suppose the agent knows $h^*(s)$, thetrue optimal cost of solving the physical state $s$ in the fullyobservable problem, for every state $s$ in $b$. Find an admissibleheuristic $h(b)$ for the sensorless problem in terms of these costs, andprove its admissibilty. Comment on the accuracy of this heuristic on thesensorless vacuum problem ofFigure vacuum2-sets-figure. How well does A* perform?",
        "url": " /advanced-search-exercises/ex_7/"
      }
    
  
    ,
      "advanced-search-exercises-ex-17":  {
        "title": "Exercise 4.17",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.17Relate the time complexity of LRTA* to its space complexity.",
        "url": " /advanced-search-exercises/ex_17/"
      }
    
  
    ,
      "advanced-search-exercises-ex-5":  {
        "title": "Exercise 4.5",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.5 [cond-plan-repeated-exercise]The And-Or-Graph-Search algorithm inFigure and-or-graph-search-algorithm checks forrepeated states only on the path from the root to the current state.Suppose that, in addition, the algorithm were to storeevery visited state and check against that list. (See inFigure breadth-first-search-algorithm for an example.)Determine the information that should be stored and how the algorithmshould use that information when a repeated state is found.(Hint: You will need to distinguish at least betweenstates for which a successful subplan was constructed previously andstates for which no subplan could be found.) Explain how to use labels,as defined in Section cyclic-plan-section, to avoidhaving multiple copies of subplans.",
        "url": " /advanced-search-exercises/ex_5/"
      }
    
  
    ,
      "advanced-search-exercises-ex-10":  {
        "title": "Exercise 4.10",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.10 [vacuum-solvable-exercise]Consider the sensorless version of theerratic vacuum world. Draw the belief-state space reachable from theinitial belief state ${1,2,3,4,5,6,7,8}$, and explain why theproblem is unsolvable.",
        "url": " /advanced-search-exercises/ex_10/"
      }
    
  
    ,
      "advanced-search-exercises-ex-15":  {
        "title": "Exercise 4.15",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.15 [path-planning-hc-exercise]In this exercise, we examine hill climbingin the context of robot navigation, using the environment inFigure geometric-scene-figure as an example.      Repeat Exercise path-planning-agent-exercise usinghill climbing. Does your agent ever get stuck in a local minimum? Isit possible for it to get stuck with convexobstacles?        Construct a nonconvex polygonal environment in which the agentgets stuck.        Modify the hill-climbing algorithm so that, instead of doing adepth-1 search to decide where to go next, it does adepth-$k$ search. It should find the best $k$-step path and do onestep along it, and then repeat the process.        Is there some $k$ for which the new algorithm is guaranteed toescape from local minima?        Explain how LRTA enables the agent to escape from local minima inthis case.  ",
        "url": " /advanced-search-exercises/ex_15/"
      }
    
  
    ,
      "advanced-search-exercises-ex-16":  {
        "title": "Exercise 4.16",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.16Like DFS, online DFS is incomplete for reversible state spaces withinfinite paths. For example, suppose that states are points on theinfinite two-dimensional grid and actions are unit vectors $(1,0)$,$(0,1)$, $(-1,0)$, $(0,-1)$, tried in that order. Show that online DFSstarting at $(0,0)$ will not reach $(1,-1)$. Suppose the agent canobserve, in addition to its current state, all successor states and theactions that would lead to them. Write an algorithm that is completeeven for bidirected state spaces with infinite paths. What states doesit visit in reaching $(1,-1)$?",
        "url": " /advanced-search-exercises/ex_16/"
      }
    
  
    ,
      "advanced-search-exercises-ex-8":  {
        "title": "Exercise 4.8",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.8 [belief-state-superset-exercise]This exercise exploressubset–superset relations between belief states in sensorless orpartially observable environments.      Prove that if an action sequence is a solution for a belief state$b$, it is also a solution for any subset of $b$. Can anything besaid about supersets of $b$?        Explain in detail how to modify graph search for sensorless problemsto take advantage of your answers in (a).        Explain in detail how to modify and–or search forpartially observable problems, beyond the modifications you describein (b).  ",
        "url": " /advanced-search-exercises/ex_8/"
      }
    
  
    ,
      "advanced-search-exercises-ex-2":  {
        "title": "Exercise 4.2",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.2Exercise brio-exercise considers the problem ofbuilding railway tracks under the assumption that pieces fit exactlywith no slack. Now consider the real problem, in which pieces don’t fitexactly but allow for up to 10 degrees of rotation to either side of the“proper” alignment. Explain how to formulate the problem so it could besolved by simulated annealing.",
        "url": " /advanced-search-exercises/ex_2/"
      }
    
  
    ,
      "advanced-search-exercises-ex-9":  {
        "title": "Exercise 4.9",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.9 [multivalued-sensorless-exercise]On page multivalued-sensorless-page it was assumedthat a given action would have the same cost when executed in anyphysical state within a given belief state. (This leads to abelief-state search problem with well-defined step costs.) Now considerwhat happens when the assumption does not hold. Does the notion ofoptimality still make sense in this context, or does it requiremodification? Consider also various possible definitions of the “cost”of executing an action in a belief state; for example, we could use theminimum of the physical costs; or themaximum; or a cost interval with the lowerbound being the minimum cost and the upper bound being the maximum; orjust keep the set of all possible costs for that action. For each ofthese, explore whether A* (with modifications if necessary) can returnoptimal solutions.",
        "url": " /advanced-search-exercises/ex_9/"
      }
    
  
    ,
      "advanced-search-exercises-ex-6":  {
        "title": "Exercise 4.6",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.6 [cond-loop-exercise]Explain precisely how to modify the And-Or-Graph-Search algorithm togenerate a cyclic plan if no acyclic plan exists. You will need to dealwith three issues: labeling the plan steps so that a cyclic plan canpoint back to an earlier part of the plan, modifying Or-Search so that itcontinues to look for acyclic plans after finding a cyclic plan, andaugmenting the plan representation to indicate whether a plan is cyclic.Show how your algorithm works on (a) the slippery vacuum world, and (b)the slippery, erratic vacuum world. You might wish to use a computerimplementation to check your results.",
        "url": " /advanced-search-exercises/ex_6/"
      }
    
  
    ,
      "advanced-search-exercises-ex-1":  {
        "title": "Exercise 4.1",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.1Give the name of the algorithm that results from each of the followingspecial cases:      Local beam search with $k = 1$.        Local beam search with one initial state and no limit on the numberof states retained.        Simulated annealing with $T = 0$ at all times (and omitting thetermination test).        Simulated annealing with $T=infty$ at all times.        Genetic algorithm with population size $N = 1$.  ",
        "url": " /advanced-search-exercises/ex_1/"
      }
    
  
    ,
      "advanced-search-exercises-ex-13":  {
        "title": "Exercise 4.13",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.13 [online-offline-exercise]Suppose that an agent is in a $3 times 3$maze environment like the one shown inFigure maze-3x3-figure. The agent knows that itsinitial location is (1,1), that the goal is at (3,3), and that theactions Up, Down, Left, Right have their usualeffects unless blocked by a wall. The agent does not knowwhere the internal walls are. In any given state, the agent perceivesthe set of legal actions; it can also tell whether the state is one ithas visited before.      Explain how this online search problem can be viewed as an offlinesearch in belief-state space, where the initial belief stateincludes all possible environment configurations. How large is theinitial belief state? How large is the space of belief states?        How many distinct percepts are possible in the initial state?        Describe the first few branches of a contingency plan for thisproblem. How large (roughly) is the complete plan?  Notice that this contingency plan is a solution for everypossible environment fitting the given description. Therefore,interleaving of search and execution is not strictly necessary even inunknown environments.",
        "url": " /advanced-search-exercises/ex_13/"
      }
    
  
    ,
      "advanced-search-exercises-ex-12":  {
        "title": "Exercise 4.12",
        "breadcrumb": "4-Beyond-Classical-Search",
      	"content"  : "Exercise 4.12 [path-planning-agent-exercise]We can turn the navigation problem inExercise path-planning-exercise into an environment asfollows:      The percept will be a list of the positions, relative to theagent, of the visible vertices. The percept doesnot include the position of the robot! The robot mustlearn its own position from the map; for now, you can assume thateach location has a different “view.”        Each action will be a vector describing a straight-line pathto follow. If the path is unobstructed, the action succeeds;otherwise, the robot stops at the point where its path firstintersects an obstacle. If the agent returns a zero motion vectorand is at the goal (which is fixed and known), then the environmentteleports the agent to a random location (not insidean obstacle).        The performance measure charges the agent 1 point for each unit ofdistance traversed and awards 1000 points each time the goalis reached.        Implement this environment and a problem-solving agent for it. Aftereach teleportation, the agent will need to formulate a new problem,which will involve discovering its current location.        Document your agent’s performance (by having the agent generatesuitable commentary as it moves around) and report its performanceover 100 episodes.        Modify the environment so that 30% of the time the agent ends up atan unintended destination (chosen randomly from the other visiblevertices if any; otherwise, no move at all). This is a crude modelof the motion errors of a real robot. Modify the agent so that whensuch an error is detected, it finds out where it is and thenconstructs a plan to get back to where it was and resume theold plan. Remember that sometimes getting back to where it was mightalso fail! Show an example of the agent successfully overcoming twosuccessive motion errors and still reaching the goal.        Now try two different recovery schemes after an error: (1) head forthe closest vertex on the original route; and (2) replan a route tothe goal from the new location. Compare the performance of the threerecovery schemes. Would the inclusion of search costs affect thecomparison?        Now suppose that there are locations from which the viewis identical. (For example, suppose the world is a grid withsquare obstacles.) What kind of problem does the agent now face?What do solutions look like?  ",
        "url": " /advanced-search-exercises/ex_12/"
      }
    
  
    
  
    ,
      "game-playing-exercises-ex-3":  {
        "title": "Exercise 5.3",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.3Imagine that, in Exercise [two-friends-exercise], one ofthe friends wants to avoid the other. The problem then becomes atwo-player game. We assume now that the players take turns moving. Thegame ends only when the players are on the same node; the terminalpayoff to the pursuer is minus the total time taken. (The evader “wins”by never losing.) An example is shown inFigure pursuit-evasion-game-figure.      Copy the game tree and mark the values of the terminal nodes.        Next to each internal node, write the strongest fact you can inferabout its value (a number, one or more inequalities such as“$geq 14$”, or a “?”).        Beneath each question mark, write the name of the node reached bythat branch.        Explain how a bound on the value of the nodes in (c) can be derivedfrom consideration of shortest-path lengths on the map, and derivesuch bounds for these nodes. Remember the cost to get to each leafas well as the cost to solve it.        Now suppose that the tree as given, with the leaf bounds from (d),is evaluated from left to right. Circle those “?” nodes that wouldnot need to be expanded further, given the boundsfrom part (d), and cross out those that need not be consideredat all.        Can you prove anything in general about who wins the game on a mapthat is a tree?  ",
        "url": " /game-playing-exercises/ex_3/"
      }
    
  
    ,
      "game-playing-exercises-ex-11":  {
        "title": "Exercise 5.11",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.11Develop a general game-playing program, capable of playing a variety ofgames.      Implement move generators and evaluation functions for one or moreof the following games: Kalah, Othello, checkers, and chess.        Construct a general alpha–beta game-playing agent.        Compare the effect of increasing search depth, improving moveordering, and improving the evaluation function. How close does youreffective branching factor come to the ideal case of perfect moveordering?        Implement a selective search algorithm, such as B* @Berliner:1979,conspiracy number search @McAllester:1988, or MGSS*@Russell+Wefald:1989 and compare its performance to A*.  ",
        "url": " /game-playing-exercises/ex_11/"
      }
    
  
    ,
      "game-playing-exercises-ex-14":  {
        "title": "Exercise 5.14",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.14Develop a formal proof of correctness for alpha–beta pruning. To dothis, consider the situation shown inFigure alpha-beta-proof-figure. The question is whetherto prune node $n_j$, which is a max-node and a descendant of node $n_1$.The basic idea is to prune it if and only if the minimax value of $n_1$can be shown to be independent of the value of $n_j$.      Mode $n_1$ takes on the minimum value among its children:$n_1 = min(n_2,n_21,ldots,n_{2b_2})$. Find a similarexpression for $n_2$ and hence an expression for $n_1$ in terms of$n_j$.        Let $l_i$ be the minimum (or maximum) value of the nodes to theleft of node $n_i$ at depth $i$, whose minimax valueis already known. Similarly, let $r_i$ be the minimum (or maximum)value of the unexplored nodes to the right of $n_i$ at depth $i$.Rewrite your expression for $n_1$ in terms of the $l_i$ and$r_i$ values.        Now reformulate the expression to show that in order to affect$n_1$, $n_j$ must not exceed a certain bound derived from the$l_i$ values.        Repeat the process for the case where $n_j$ is a min-node.  Figure [alpha-beta-proof-figure] Situation when considering whether to prune node $n_j$.",
        "url": " /game-playing-exercises/ex_14/"
      }
    
  
    ,
      "game-playing-exercises-ex-4":  {
        "title": "Exercise 5.4",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.4 [game-playing-chance-exercise]Describe and implement statedescriptions, move generators, terminal tests, utility functions, andevaluation functions for one or more of the following stochastic games:Monopoly, Scrabble, bridge play with a given contract, or Texas hold’empoker.",
        "url": " /game-playing-exercises/ex_4/"
      }
    
  
    ,
      "game-playing-exercises-ex-23":  {
        "title": "Exercise 5.23",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.23In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search.      Assuming that leaf values are finite but unbounded, is pruning (asin alpha–beta) ever possible in a max tree? Give an example, orexplain why not.        Is pruning ever possible in an expectimax tree under the sameconditions? Give an example, or explain why not.        If leaf values are constrained to be in the range $[0,1]$, ispruning ever possible in a max tree? Give an example, or explainwhy not.        If leaf values are constrained to be in the range $[0,1]$, ispruning ever possible in an expectimax tree? Give an example(qualitatively different from your example in (e), if any), orexplain why not.        If leaf values are constrained to be nonnegative, is pruning everpossible in a max tree? Give an example, or explain why not.        If leaf values are constrained to be nonnegative, is pruning everpossible in an expectimax tree? Give an example, or explain why not.        Consider the outcomes of a chance node in an expectimax tree. Whichof the following evaluation orders is most likely to yield pruningopportunities: (i) Lowest probability first; (ii) Highestprobability first; (iii) Doesn’t make any difference?  ",
        "url": " /game-playing-exercises/ex_23/"
      }
    
  
    ,
      "game-playing-exercises-ex-20":  {
        "title": "Exercise 5.20",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.20 [game-linear-transform]Prove that with a positive lineartransformation of leaf values (i.e., transforming a value $x$ to$ax + b$ where $a &amp;gt; 0$), the choice of move remains unchanged in a gametree, even when there are chance nodes.",
        "url": " /game-playing-exercises/ex_20/"
      }
    
  
    ,
      "game-playing-exercises-ex-7":  {
        "title": "Exercise 5.7",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.7 [minimax-optimality-exercise]Prove the following assertion: For everygame tree, the utility obtained by max using minimaxdecisions against a suboptimal min will never be lower thanthe utility obtained playing against an optimal min. Canyou come up with a game tree in which max can do stillbetter using a suboptimal strategy against a suboptimalmin?Figure [line-game4-figure] The starting position of a simple game.Player $A$ moves first. The two players take turns moving, and eachplayer must move his token to an open adjacent space in eitherdirection.  If the opponent occupies an adjacent space, then a playermay jump over the opponent to the next open space if any. (Forexample, if $A$ is on 3 and $B$ is on 2, then $A$ may move back to 1.)The game ends when one player reaches the opposite end of the board.If player $A$ reaches space 4 first, then the value of the game to $A$is $+1$; if player $B$ reaches space 1 first, then the value of thegame to $A$ is $-1$.",
        "url": " /game-playing-exercises/ex_7/"
      }
    
  
    ,
      "game-playing-exercises-ex-17":  {
        "title": "Exercise 5.17",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.17Suppose you have a chess program that can evaluate 10 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a2-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?Figure [trivial-chance-game-figure] The complete game tree for a trivial game with chance nodes.",
        "url": " /game-playing-exercises/ex_17/"
      }
    
  
    ,
      "game-playing-exercises-ex-5":  {
        "title": "Exercise 5.5",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.5Describe and implement a real-time,multiplayer game-playing environment, where time is partof the environment state and players are given fixed time allocations.",
        "url": " /game-playing-exercises/ex_5/"
      }
    
  
    ,
      "game-playing-exercises-ex-25":  {
        "title": "Exercise 5.25",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.25Consider carefully the interplay of chance events and partialinformation in each of the games inExercise [game-playing-chance-exercise].      For which is the standard expectiminimax model appropriate?Implement the algorithm and run it in your game-playing agent, withappropriate modifications to the game-playing environment.        For which would the scheme described inExercise [game-playing-monte-carlo-exercise] beappropriate?        Discuss how you might deal with the fact that in some of the games,the players do not have the same knowledge of the current state.  ",
        "url": " /game-playing-exercises/ex_25/"
      }
    
  
    ,
      "game-playing-exercises-ex-10":  {
        "title": "Exercise 5.10",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.10Consider the family of generalized tic-tac-toe games, defined asfollows. Each particular game is specified by a set $mathcal S$ ofsquares and a collection $mathcal W$ of winningpositions. Each winning position is a subset of $mathcal S$.For example, in standard tic-tac-toe, $mathcal S$ is a set of 9 squaresand $mathcal W$ is a collection of 8 subsets of $cal W$: the threerows, the three columns, and the two diagonals. In other respects, thegame is identical to standard tic-tac-toe. Starting from an empty board,players alternate placing their marks on an empty square. A player whomarks every square in a winning position wins the game. It is a tie ifall squares are marked and neither player has won.      Let $N= |{mathcal S}|$, the number of squares. Give an upper boundon the number of nodes in the complete game tree for generalizedtic-tac-toe as a function of $N$.        Give a lower bound on the size of the game tree for the worst case,where ${mathcal W} = {{,}}$.        Propose a plausible evaluation function that can be used for anyinstance of generalized tic-tac-toe. The function may depend on$mathcal S$ and $mathcal W$.        Assume that it is possible to generate a new board and check whetherit is a winning position in 100$N$ machine instructions and assume a2 gigahertz processor. Ignore memory limitations. Using yourestimate in (a), roughly how large a game tree can be completelysolved by alpha–beta in a second of CPU time? a minute? an hour?  ",
        "url": " /game-playing-exercises/ex_10/"
      }
    
  
    ,
      "game-playing-exercises-ex-22":  {
        "title": "Exercise 5.22",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.22In the following, a “max” tree consists only of max nodes, whereas an“expectimax” tree consists of a max node at the root with alternatinglayers of chance and max nodes. At chance nodes, all outcomeprobabilities are nonzero. The goal is to find the value of theroot with a bounded-depth search. For each of (a)–(f), eithergive an example or explain why this is impossible.      Assuming that leaf values are finite but unbounded, is pruning (asin alpha–beta) ever possible in a max tree?        Is pruning ever possible in an expectimax tree under the sameconditions?        If leaf values are all nonnegative, is pruning ever possible in amax tree? Give an example, or explain why not.        If leaf values are all nonnegative, is pruning ever possible in anexpectimax tree? Give an example, or explain why not.        If leaf values are all in the range $[0,1]$, is pruning everpossible in a max tree? Give an example, or explain why not.        If leaf values are all in the range $[0,1]$, is pruning everpossible in an expectimax tree?        Consider the outcomes of a chance node in an expectimax tree. Whichof the following evaluation orders is most likely to yield pruningopportunities?                  Lowest probability first                    Highest probability first                    Doesn’t make any difference            ",
        "url": " /game-playing-exercises/ex_22/"
      }
    
  
    ,
      "game-playing-exercises-ex-18":  {
        "title": "Exercise 5.18",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.18This question considers pruning in games with chance nodes.Figure trivial-chance-game-figure shows the completegame tree for a trivial game. Assume that the leaf nodes are to beevaluated in left-to-right order, and that before a leaf node isevaluated, we know nothing about its value—the range of possible valuesis $-infty$ to $infty$.      Copy the figure, mark the value of all the internal nodes, andindicate the best move at the root with an arrow.        Given the values of the first six leaves, do we need to evaluate theseventh and eighth leaves? Given the values of the first sevenleaves, do we need to evaluate the eighth leaf? Explainyour answers.        Suppose the leaf node values are known to lie between –2 and 2inclusive. After the first two leaves are evaluated, what is thevalue range for the left-hand chance node?        Circle all the leaves that need not be evaluated under theassumption in (c).  ",
        "url": " /game-playing-exercises/ex_18/"
      }
    
  
    ,
      "game-playing-exercises-ex-24":  {
        "title": "Exercise 5.24",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.24Which of the following are true and which are false? Give briefexplanations.      In a fully observable, turn-taking, zero-sum game between twoperfectly rational players, it does not help the first player toknow what strategy the second player is using—that is, what move thesecond player will make, given the first player’s move.        In a partially observable, turn-taking, zero-sum game between twoperfectly rational players, it does not help the first player toknow what move the second player will make, given the firstplayer’s move.        A perfectly rational backgammon agent never loses.  ",
        "url": " /game-playing-exercises/ex_24/"
      }
    
  
    ,
      "game-playing-exercises-ex-15":  {
        "title": "Exercise 5.15",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.15Prove that the alpha–beta algorithm takes time $O(b^{m/2})$ with optimalmove ordering, where $m$ is the maximum depth of the game tree.",
        "url": " /game-playing-exercises/ex_15/"
      }
    
  
    ,
      "game-playing-exercises-ex-16":  {
        "title": "Exercise 5.16",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.16Suppose you have a chess program that can evaluate 5 million nodes persecond. Decide on a compact representation of a game state for storagein a transposition table. About how many entries can you fit in a1-gigabyte in-memory table? Will that be enough for the three minutes ofsearch allocated for one move? How many table lookups can you do in thetime it would take to do one evaluation? Now suppose the transpositiontable is stored on disk. About how many evaluations could you do in thetime it takes to do one disk seek with standard disk hardware?",
        "url": " /game-playing-exercises/ex_16/"
      }
    
  
    ,
      "game-playing-exercises-ex-8":  {
        "title": "Exercise 5.8",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.8Consider the two-player game described inFigure line-game4-figure.      Draw the complete game tree, using the following conventions:                  Write each state as $(s_A,s_B)$, where $s_A$ and $s_B$ denotethe token locations.                    Put each terminal state in a square box and write its game valuein a circle.                    Put loop states (states that already appear onthe path to the root) in double square boxes. Since their valueis unclear, annotate each with a “?” in a circle.                  Now mark each node with its backed-up minimax value (also ina circle). Explain how you handled the “?” values and why.        Explain why the standard minimax algorithm would fail on this gametree and briefly sketch how you might fix it, drawing on your answerto (b). Does your modified algorithm give optimal decisions for allgames with loops?        This 4-square game can be generalized to $n$ squares for any$n &amp;gt; 2$. Prove that $A$ wins if $n$ is even and loses if $n$ is odd.  ",
        "url": " /game-playing-exercises/ex_8/"
      }
    
  
    ,
      "game-playing-exercises-ex-2":  {
        "title": "Exercise 5.2",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.2Consider the problem of solving two 8-puzzles.      Give a complete problem formulation in the style ofChapter search-chapter.        How large is the reachable state space? Give an exactnumerical expression.        Suppose we make the problem adversarial as follows: the two playerstake turns moving; a coin is flipped to determine the puzzle onwhich to make a move in that turn; and the winner is the first tosolve one puzzle. Which algorithm can be used to choose a move inthis setting?        Does the game eventually end, given optimal play? Explain.  Figure [pursuit-evasion-game-figure] (a) A map where the cost of every edge is 1. Initially the pursuer $P$ is atnode b and the evader $E$ is at node d (b) A partial game tree for this map.Each node is labeled with the $P,E$ positions. $P$ moves first. Branches marked &quot;?&quot; have yet to be explored.",
        "url": " /game-playing-exercises/ex_2/"
      }
    
  
    ,
      "game-playing-exercises-ex-9":  {
        "title": "Exercise 5.9",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.9This problem exercises the basic concepts of game playing, usingtic-tac-toe (noughts and crosses) as an example. We define$X_n$ as the number of rows, columns, or diagonals with exactly $n$$X$’s and no $O$’s. Similarly, $O_n$ is the number of rows, columns, ordiagonals with just $n$ $O$’s. The utility function assigns $+1$ to anyposition with $X_3=1$ and $-1$ to any position with $O_3 = 1$. All otherterminal positions have utility 0. For nonterminal positions, we use alinear evaluation function defined as ${Eval}(s) = 3X_2(s) + X_1(s) -(3O_2(s) + O_1(s))$.      Approximately how many possible games of tic-tac-toe are there?        Show the whole game tree starting from an empty board down to depth2 (i.e., one $X$ and one $O$ on the board), taking symmetryinto account.        Mark on your tree the evaluations of all the positions at depth 2.        Using the minimax algorithm, mark on your tree the backed-up valuesfor the positions at depths 1 and 0, and use those values to choosethe best starting move.        Circle the nodes at depth 2 that would not beevaluated if alpha–beta pruning were applied, assuming the nodes aregenerated in the optimal order for alpha–beta pruning.  ",
        "url": " /game-playing-exercises/ex_9/"
      }
    
  
    ,
      "game-playing-exercises-ex-19":  {
        "title": "Exercise 5.19",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.19Implement the expectiminimax algorithm and the *-alpha–beta algorithm,which is described by @Ballard:1983, for pruning game trees with chance nodes. Trythem on a game such as backgammon and measure the pruning effectivenessof *-alpha–beta.",
        "url": " /game-playing-exercises/ex_19/"
      }
    
  
    ,
      "game-playing-exercises-ex-6":  {
        "title": "Exercise 5.6",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.6Discuss how well the standard approach to game playing would apply togames such as tennis, pool, and croquet, which take place in acontinuous physical state space.",
        "url": " /game-playing-exercises/ex_6/"
      }
    
  
    ,
      "game-playing-exercises-ex-21":  {
        "title": "Exercise 5.21",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.21 [game-playing-monte-carlo-exercise]Consider the following procedurefor choosing moves in games with chance nodes:      Generate some dice-roll sequences (say, 50) down to a suitable depth(say, 8).        With known dice rolls, the game tree becomes deterministic. For eachdice-roll sequence, solve the resulting deterministic game treeusing alpha–beta.        Use the results to estimate the value of each move and to choosethe best.  Will this procedure work well? Why (or why not)?",
        "url": " /game-playing-exercises/ex_21/"
      }
    
  
    ,
      "game-playing-exercises-ex-1":  {
        "title": "Exercise 5.1",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.1Suppose you have an oracle, $OM(s)$, that correctly predicts theopponent’s move in any state. Using this, formulate the definition of agame as a (single-agent) search problem. Describe an algorithm forfinding the optimal move.",
        "url": " /game-playing-exercises/ex_1/"
      }
    
  
    ,
      "game-playing-exercises-ex-13":  {
        "title": "Exercise 5.13",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.13Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state sum to a number between constants $-k$and $k$, making the game almost zero-sum?",
        "url": " /game-playing-exercises/ex_13/"
      }
    
  
    ,
      "game-playing-exercises-ex-12":  {
        "title": "Exercise 5.12",
        "breadcrumb": "5-Adversarial-Search",
      	"content"  : "Exercise 5.12Describe how the minimax and alpha–beta algorithms change fortwo-player, non-zero-sum games in which each player has a distinctutility function and both utility functions are known to both players.If there are no constraints on the two terminal utilities, is itpossible for any node to be pruned by alpha–beta? What if the player’sutility functions on any state differ by at most a constant $k$, makingthe game almost cooperative?",
        "url": " /game-playing-exercises/ex_12/"
      }
    
  
    
  
    ,
      "bayes-nets-exercises-ex-3":  {
        "title": "Exercise 14.3",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.3 [cpt-equivalence-exercise]Equation (parameter-joint-repn-equation) onpage parameter-joint-repn-equation defines the joint distribution represented by aBayesian network in terms of the parameters$theta(X_i{Parents}(X_i))$. This exercise asks you to derivethe equivalence between the parameters and the conditional probabilities${textbf{ P}}(X_i{Parents}(X_i))$ from this definition.      Consider a simple network $Xrightarrow Yrightarrow Z$ with threeBoolean variables. UseEquations (conditional-probability-equation) and (marginalization-equation)(pages conditional-probability-equation and marginalization-equation)to express the conditional probability $P(zy)$ as the ratio of two sums, each over entries in thejoint distribution ${textbf{P}}(X,Y,Z)$.        Now use Equation (parameter-joint-repn-equation) towrite this expression in terms of the network parameters$theta(X)$, $theta(YX)$, and $theta(ZY)$.        Next, expand out the summations in your expression from part (b),writing out explicitly the terms for the true and false values ofeach summed variable. Assuming that all network parameters satisfythe constraint$sum_{x_i} theta(x_i{parents}(X_i))1$, showthat the resulting expression reduces to $theta(zy)$.        Generalize this derivation to show that$theta(X_i{Parents}(X_i)) = {textbf{P}}(X_i{Parents}(X_i))$for any Bayesian network.  ",
        "url": " /bayes-nets-exercises/ex_3/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-11":  {
        "title": "Exercise 14.11",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.11 [LG-exercise]Consider the family of linear Gaussian networks, asdefined on page LG-network-page.      In a two-variable network, let $X_1$ be the parent of $X_2$, let$X_1$ have a Gaussian prior, and let${textbf{P}}(X_2X_1)$ be a linearGaussian distribution. Show that the joint distribution $P(X_1,X_2)$is a multivariate Gaussian, and calculate its covariance matrix.        Prove by induction that the joint distribution for a general linearGaussian network on $X_1,ldots,X_n$ is also amultivariate Gaussian.  ",
        "url": " /bayes-nets-exercises/ex_11/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-14":  {
        "title": "Exercise 14.14",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.14 [telescope-exercise]Two astronomers in different parts of the worldmake measurements $M_1$ and $M_2$ of the number of stars $N$ in somesmall region of the sky, using their telescopes. Normally, there is asmall possibility $e$ of error by up to one star in each direction. Eachtelescope can also (with a much smaller probability $f$) be badly out offocus (events $F_1$ and $F_2$), in which case the scientist willundercount by three or more stars (or if $N$ is less than 3, fail todetect any stars at all). Consider the three networks shown inFigure telescope-nets-figure.      Which of these Bayesian networks are correct (but notnecessarily efficient) representations of the preceding information?        Which is the best network? Explain.        Write out a conditional distribution for${textbf{P}}(M_1N)$, for the case where$N{1,2,3}$ and $M_1{0,1,2,3,4}$. Eachentry in the conditional distribution should be expressed as afunction of the parameters $e$ and/or $f$.        Suppose $M_11$ and $M_23$. What are thepossible numbers of stars if you assume no priorconstraint on the values of $N$?        What is the most likely number of stars, given theseobservations? Explain how to compute this, or if it is not possibleto compute, explain what additional information is needed and how itwould affect the result.  ",
        "url": " /bayes-nets-exercises/ex_14/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-4":  {
        "title": "Exercise 14.4",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.4The arc reversal operation of in a Bayesian network allows us to change the directionof an arc $Xrightarrow Y$ while preserving the joint probabilitydistribution that the network represents @Shachter:1986. Arc reversalmay require introducing new arcs: all the parents of $X$ also becomeparents of $Y$, and all parents of $Y$ also become parents of $X$.      Assume that $X$ and $Y$ start with $m$ and $n$ parents,respectively, and that all variables have $k$ values. By calculatingthe change in size for the CPTs of $X$ and $Y$, show that the totalnumber of parameters in the network cannot decrease duringarc reversal. (Hint: the parents of $X$ and $Y$ neednot be disjoint.)        Under what circumstances can the total number remain constant?        Let the parents of $X$ be $textbf{U} cup textbf{V}$ and the parents of $Y$ be$textbf{V} cup textbf{W}$, where $textbf{U}$ and $textbf{W}$ are disjoint. The formulas for thenew CPTs after arc reversal are as follows: Prove that the new network expresses the same joint distributionover all variables as the original network.  ",
        "url": " /bayes-nets-exercises/ex_4/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-23":  {
        "title": "Exercise 14.23",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.23 [MH-exercise]The Metropolis–Hastings algorithm is a member of the MCMC family; as such,it is designed to generate samples $textbf{x}$ (eventually) according to targetprobabilities $pi(textbf{x})$. (Typically we are interested in sampling from$pi(textbf{x})P(textbf{x}textbf{e})$.) Like simulated annealing,Metropolis–Hastings operates in two stages. First, it samples a newstate $textbf{x’}$ from a proposal distribution $q(textbf{x’}textbf{x})$, given the current state $textbf{x}$.Then, it probabilistically accepts or rejects $textbf{x’}$ according to the acceptance probabilityIf the proposal is rejected, the state remains at $textbf{x}$.      Consider an ordinary Gibbs sampling step for a specific variable$X_i$. Show that this step, considered as a proposal, is guaranteedto be accepted by Metropolis–Hastings. (Hence, Gibbs sampling is aspecial case of Metropolis–Hastings.)        Show that the two-step process above, viewed as a transitionprobability distribution, is in detailed balance with $pi$.  ",
        "url": " /bayes-nets-exercises/ex_23/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-20":  {
        "title": "Exercise 14.20",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.20 [primitive-sampling-exercise]Consider the problem of generating arandom sample from a specified distribution on a single variable. Assumeyou have a random number generator that returns a random numberuniformly distributed between 0 and 1.      Let $X$ be a discrete variable with$P(Xx_i)p_i$ for$i{1,ldots,k}$. The cumulative distribution of $X$ gives the probabilitythat $X{x_1,ldots,x_j}$ for each possible $j$. (Seealso Appendix [math-appendix].) Explain how tocalculate the cumulative distribution in $O(k)$ time and how togenerate a single sample of $X$ from it. Can the latter be done inless than $O(k)$ time?        Now suppose we want to generate $N$ samples of $X$, where $Ngg k$.Explain how to do this with an expected run time per sample that isconstant (i.e., independent of $k$).        Now consider a continuous-valued variable with a parameterizeddistribution (e.g., Gaussian). How can samples be generated fromsuch a distribution?        Suppose you want to query a continuous-valued variable and you areusing a sampling algorithm such as LIKELIHOODWEIGHTING to do the inference. How wouldyou have to modify the query-answering process?  ",
        "url": " /bayes-nets-exercises/ex_20/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-7":  {
        "title": "Exercise 14.7",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.7 [handedness-exercise]Let $H_x$ be a random variable denoting thehandedness of an individual $x$, with possible values $l$ or $r$. Acommon hypothesis is that left- or right-handedness is inherited by asimple mechanism; that is, perhaps there is a gene $G_x$, also withvalues $l$ or $r$, and perhaps actual handedness turns out mostly thesame (with some probability $s$) as the gene an individual possesses.Furthermore, perhaps the gene itself is equally likely to be inheritedfrom either of an individual’s parents, with a small nonzero probability$m$ of a random mutation flipping the handedness.      Which of the three networks inFigure handedness-figure claim that$ {textbf{P}}(G_{father},G_{mother},G_{child}) = {textbf{P}}(G_{father}){textbf{P}}(G_{mother}){textbf{P}}(G_{child})$?        Which of the three networks make independence claims that areconsistent with the hypothesis about the inheritance of handedness?        Which of the three networks is the best description of thehypothesis?        Write down the CPT for the $G_{child}$ node in network (a), interms of $s$ and $m$.        Suppose that$P(G_{father}l)=P(G_{mother}l)=q$. Innetwork (a), derive an expression for $P(G_{child}l)$in terms of $m$ and $q$ only, by conditioning on its parent nodes.        Under conditions of genetic equilibrium, we expect the distributionof genes to be the same across generations. Use this to calculatethe value of $q$, and, given what you know about handedness inhumans, explain why the hypothesis described at the beginning ofthis question must be wrong.  ",
        "url": " /bayes-nets-exercises/ex_7/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-17":  {
        "title": "Exercise 14.17",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.17Consider the Bayes net shown in Figure politics-figure.      Which, if any, of the following are asserted by the networkstructure (ignoring the CPTs for now)?                  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.                    ${textbf{P}}(JG) = {textbf{P}}(JG,I)$.                    ${textbf{P}}(MG,B,I) = {textbf{P}}(MG,B,I,J)$.                  Calculate the value of $P(b,i,m,lnot g,j)$.        Calculate the probability that someone goes to jail given that theybroke the law, have been indicted, and face a politicallymotivated prosecutor.        A context-specific independence (seepage CSI-page) allows a variable to be independent of some ofits parents given certain values of others. In addition to the usualconditional independences given by the graph structure, whatcontext-specific independences exist in the Bayes net inFigure politics-figure?        Suppose we want to add the variable$P{PresidentialPardon}$ to the network; draw the newnetwork and briefly explain any links you add.  ",
        "url": " /bayes-nets-exercises/ex_17/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-5":  {
        "title": "Exercise 14.5",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.5Consider the Bayesian network inFigure burglary-figure.      If no evidence is observed, are ${Burglary}$ and ${Earthquake}$independent? Prove this from the numerical semantics and from thetopological semantics.        If we observe ${Alarm}{true}$, are ${Burglary}$ and${Earthquake}$ independent? Justify your answer by calculatingwhether the probabilities involved satisfy the definition ofconditional independence.  ",
        "url": " /bayes-nets-exercises/ex_5/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-10":  {
        "title": "Exercise 14.10",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.10Consider a simple Bayesian network with root variables ${Cold}$,${Flu}$, and ${Malaria}$ and child variable ${Fever}$, with anoisy-OR conditional distribution for ${Fever}$ as described inSection canonical-distribution-section. By addingappropriate auxiliary variables for inhibition events and fever-inducingevents, construct an equivalent Bayesian network whose CPTs (except forroot variables) are deterministic. Define the CPTs and proveequivalence.",
        "url": " /bayes-nets-exercises/ex_10/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-22":  {
        "title": "Exercise 14.22",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.22 [gibbs-proof-exercise]This exercise explores the stationarydistribution for Gibbs sampling methods.      The convex composition $[alpha, q_1; 1-alpha, q_2]$ of $q_1$ and$q_2$ is a transition probability distribution that first choosesone of $q_1$ and $q_2$ with probabilities $alpha$ and $1-alpha$,respectively, and then applies whichever is chosen. Prove that if$q_1$ and $q_2$ are in detailed balance with $pi$, then theirconvex composition is also in detailed balance with $pi$.(Note: this result justifies a variant of GIBBS-ASK in whichvariables are chosen at random rather than sampled in afixed sequence.)        Prove that if each of $q_1$ and $q_2$ has $pi$ as its stationarydistribution, then the sequential composition$q q_1 circ q_2$ also has $pi$ as itsstationary distribution.  ",
        "url": " /bayes-nets-exercises/ex_22/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-18":  {
        "title": "Exercise 14.18",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.18 [VE-exercise]Consider the variable elimination algorithm inFigure elimination-ask-algorithm (page elimination-ask-algorithm).      Section exact-inference-section applies variableelimination to the queryPerform the calculations indicated and check that the answeris correct.        Count the number of arithmetic operations performed, and compare itwith the number performed by the enumeration algorithm.        Suppose a network has the form of a chain: a sequenceof Boolean variables $X_1,ldots, X_n$ where${Parents}(X_i){X_{i-1}}$ for $i2,ldots,n$.What is the complexity of computing${textbf{P}}(X_1X_n{true})$ usingenumeration? Using variable elimination?        Prove that the complexity of running variable elimination on apolytree network is linear in the size of the tree for any variableordering consistent with the network structure.  ",
        "url": " /bayes-nets-exercises/ex_18/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-24":  {
        "title": "Exercise 14.24",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.24 [soccer-rpm-exercise]Three soccer teams $A$, $B$, and $C$, play eachother once. Each match is between two teams, and can be won, drawn, orlost. Each team has a fixed, unknown degree of quality—an integerranging from 0 to 3—and the outcome of a match depends probabilisticallyon the difference in quality between the two teams.      Construct a relational probability model to describe this domain,and suggest numerical values for all the necessaryprobability distributions.        Construct the equivalent Bayesian network for the three matches.        Suppose that in the first two matches $A$ beats $B$ and draws with$C$. Using an exact inference algorithm of your choice, compute theposterior distribution for the outcome of the third match.        Suppose there are $n$ teams in the league and we have the resultsfor all but the last match. How does the complexity of predictingthe last game vary with $n$?        Investigate the application of MCMC to this problem. How quicklydoes it converge in practice and how well does it scale?  ",
        "url": " /bayes-nets-exercises/ex_24/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-15":  {
        "title": "Exercise 14.15",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.15Consider the network shown inFigure telescope-nets-figure(ii), and assume that thetwo telescopes work identically. $N{1,2,3}$ and$M_1,M_2{0,1,2,3,4}$, with the symbolic CPTs as describedin Exercise telescope-exercise. Using the enumerationalgorithm (Figure enumeration-algorithm onpage enumeration-algorithm), calculate the probability distribution${textbf{P}}(NM_12,M_22)$.Figure [telescope-nets-figure] Three possible networks for the telescope problem.Figure [politics-figure] A simple Bayes net withBoolean variables B = {BrokeElectionLaw}, I = {Indicted}, M = {PoliticallyMotivatedProsecutor}, G= {FoundGuilty}, J = {Jailed}.",
        "url": " /bayes-nets-exercises/ex_15/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-16":  {
        "title": "Exercise 14.16",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.16Consider the Bayes net shown in Figure politics-figure.      Which of the following are asserted by the networkstructure?                  ${textbf{P}}(B,I,M) = {textbf{P}}(B){textbf{P}}(I){textbf{P}}(M)$.                    ${textbf{P}}(JG) = {textbf{P}}(JG,I)$.                    ${textbf{P}}(MG,B,I) = {textbf{P}}(MG,B,I,J)$.                  Calculate the value of $P(b,i,lnot m,g,j)$.        Calculate the probability that someone goes to jail given that theybroke the law, have been indicted, and face a politicallymotivated prosecutor.        A context-specific independence (seepage CSI-page) allows a variable to be independent of some ofits parents given certain values of others. In addition to the usualconditional independences given by the graph structure, whatcontext-specific independences exist in the Bayes net inFigure politics-figure?        Suppose we want to add the variable$P{PresidentialPardon}$ to the network; draw the newnetwork and briefly explain any links you add.  ",
        "url": " /bayes-nets-exercises/ex_16/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-8":  {
        "title": "Exercise 14.8",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.8 [markov-blanket-exercise]The Markovblanket of a variable is defined on page markov-blanket-page.Prove that a variable is independent of all other variables in thenetwork, given its Markov blanket and deriveEquation (markov-blanket-equation)(page markov-blanket-equation).Figure [car-starts-figure] A Bayesian network describing some features of a car&#39;s electrical system and engine. Each variable is Boolean, and the *true* value indicates that the corresponding aspect of the vehicle is in working order.",
        "url": " /bayes-nets-exercises/ex_8/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-2":  {
        "title": "Exercise 14.2",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.2We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 30%, 60%, and 75%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.      Draw the Bayesian network corresponding to this setup and define thenecessary CPTs.        Calculate which coin was most likely to have been drawn from the bagif the observed flips come out heads twice and tails once.  ",
        "url": " /bayes-nets-exercises/ex_2/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-9":  {
        "title": "Exercise 14.9",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.9Consider the network for car diagnosis shown inFigure car-starts-figure.      Extend the network with the Boolean variables ${IcyWeather}$ and${StarterMotor}$.        Give reasonable conditional probability tables for all the nodes.        How many independent values are contained in the joint probabilitydistribution for eight Boolean nodes, assuming that no conditionalindependence relations are known to hold among them?        How many independent probability values do your network tablescontain?        The conditional distribution for ${Starts}$ could be described asa noisy-AND distribution. Define thisfamily in general and relate it to the noisy-OR distribution.  ",
        "url": " /bayes-nets-exercises/ex_9/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-19":  {
        "title": "Exercise 14.19",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.19 [bn-complexity-exercise]Investigate the complexity of exact inferencein general Bayesian networks:      Prove that any 3-SAT problem can be reduced to exact inference in aBayesian network constructed to represent the particular problem andhence that exact inference is NP-hard. (Hint:Consider a network with one variable for each proposition symbol,one for each clause, and one for the conjunction of clauses.)        The problem of counting the number of satisfying assignments for a3-SAT problem is #P-complete. Show that exact inference is at leastas hard as this.  ",
        "url": " /bayes-nets-exercises/ex_19/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-6":  {
        "title": "Exercise 14.6",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.6Suppose that in a Bayesian network containing an unobserved variable$Y$, all the variables in the Markov blanket ${MB}(Y)$ have beenobserved.      Prove that removing the node $Y$ from the network will not affectthe posterior distribution for any other unobserved variable inthe network.        Discuss whether we can remove $Y$ if we are planning to use (i)rejection sampling and (ii) likelihood weighting.  Figure [handedness-figure] Three possible structures for a Bayesian network describing genetic inheritance of handedness.            $quadquadquad$      $quadquadquad$      $quadquadquad$                                            (a)      (b)      (c)      ",
        "url": " /bayes-nets-exercises/ex_6/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-21":  {
        "title": "Exercise 14.21",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.21Consider the query${textbf{P}}({Rain}{Sprinkler}{true},{WetGrass}{true})$in Figure rain-clustering-figure(a)(page rain-clustering-figure) and how Gibbs sampling can answer it.      How many states does the Markov chain have?        Calculate the transition matrix${textbf{Q}}$ containing$q({textbf{y}}$ $rightarrow$ ${textbf{y}}’)$for all ${textbf{y}}$, ${textbf{y}}’$.        What does ${textbf{ Q}}^2$, the square of thetransition matrix, represent?        What about ${textbf{Q}}^n$ as $nto infty$?        Explain how to do probabilistic inference in Bayesian networks,assuming that ${textbf{Q}}^n$ is available. Is this apractical way to do inference?  ",
        "url": " /bayes-nets-exercises/ex_21/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-1":  {
        "title": "Exercise 14.1",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.1We have a bag of three biased coins $a$, $b$, and $c$ with probabilitiesof coming up heads of 20%, 60%, and 80%, respectively. One coin is drawnrandomly from the bag (with equal likelihood of drawing each of thethree coins), and then the coin is flipped three times to generate theoutcomes $X_1$, $X_2$, and $X_3$.      Draw the Bayesian network corresponding to this setup and define thenecessary CPTs.        Calculate which coin was most likely to have been drawn from the bagif the observed flips come out heads twice and tails once.  ",
        "url": " /bayes-nets-exercises/ex_1/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-13":  {
        "title": "Exercise 14.13",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.13In your local nuclear power station, there is an alarm that senses whena temperature gauge exceeds a given threshold. The gauge measures thetemperature of the core. Consider the Boolean variables $A$ (alarmsounds), $F_A$ (alarm is faulty), and $F_G$ (gauge is faulty) and themultivalued nodes $G$ (gauge reading) and $T$ (actual core temperature).      Draw a Bayesian network for this domain, given that the gauge ismore likely to fail when the core temperature gets too high.        Is your network a polytree? Why or why not?        Suppose there are just two possible actual and measuredtemperatures, normal and high; the probability that the gauge givesthe correct temperature is $x$ when it is working, but $y$ when itis faulty. Give the conditional probability table associated with$G$.        Suppose the alarm works correctly unless it is faulty, in which caseit never sounds. Give the conditional probability table associatedwith $A$.        Suppose the alarm and gauge are working and the alarm sounds.Calculate an expression for the probability that the temperature ofthe core is too high, in terms of the various conditionalprobabilities in the network.  ",
        "url": " /bayes-nets-exercises/ex_13/"
      }
    
  
    ,
      "bayes-nets-exercises-ex-12":  {
        "title": "Exercise 14.12",
        "breadcrumb": "14-Probabilistic-Reasoning",
      	"content"  : "Exercise 14.12 [multivalued-probit-exercise]The probit distribution defined onpage probit-page describes the probability distribution for a Booleanchild, given a single continuous parent.      How might the definition be extended to cover multiple continuousparents?        How might it be extended to handle a multivaluedchild variable? Consider both cases where the child’s values areordered (as in selecting a gear while driving, depending on speed,slope, desired acceleration, etc.) and cases where they areunordered (as in selecting bus, train, or car to get to work).(Hint: Consider ways to divide the possible valuesinto two sets, to mimic a Boolean variable.)  ",
        "url": " /bayes-nets-exercises/ex_12/"
      }
    
  
    
  
    ,
      "nlp-english-exercises-ex-3":  {
        "title": "Exercise 23.3",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.3Consider the following PCFG for simple verb phrases:  0.1: VP $rightarrow$ Verb  0.2: VP $rightarrow$ Copula Adjective  0.5: VP $rightarrow$ Verb the Noun  0.2: VP $rightarrow$ VP Adverb  0.5: Verb $rightarrow$ is  0.5: Verb $rightarrow$ shoots  0.8: Copula $rightarrow$ is  0.2: Copula $rightarrow$ seems  0.5: Adjective $rightarrow$ unwell  0.5: Adjective $rightarrow$ well  0.5: Adverb $rightarrow$ well  0.5: Adverb $rightarrow$ badly  0.6: Noun $rightarrow$ duck  0.4: Noun $rightarrow$ well      Which of the following have a nonzero probability as a VP? (i)shoots the duck well well well(ii) seems the well well(iii) shootsthe unwell well badly        What is the probability of generating “is well well”?        What types of ambiguity are exhibited by the phrase in (b)?        Given any PCFG, is it possible to calculate the probability that thePCFG generates a string of exactly 10 words?  ",
        "url": " /nlp-english-exercises/ex_3/"
      }
    
  
    ,
      "nlp-english-exercises-ex-11":  {
        "title": "Exercise 23.11",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.11Consider the following toy grammar:  $S rightarrow NPspace VP$  $NP rightarrow Noun$  $NP rightarrow NPspace andspace NP$  $NP rightarrow NPspace PP$  $VP rightarrow Verb$  $VP rightarrow VPspace and space VP$  $VP rightarrow VPspace PP$  $PP rightarrow Prepspace NP$  $Noun rightarrow Sallyspace; poolsspace; streamsspace; swims$  $Prep rightarrow in$  $Verb rightarrow poolsspace; streamsspace; swims$      Show all the parse trees in this grammar for the sentence “Sallyswims in streams and pools.”        Show all the table entries that would be made bya (non-probabalistic) CYK parser on this sentence.  ",
        "url": " /nlp-english-exercises/ex_11/"
      }
    
  
    ,
      "nlp-english-exercises-ex-14":  {
        "title": "Exercise 23.14",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.14An augmented context-free grammar can represent languages that a regularcontext-free grammar cannot. Show an augmented context-free grammar forthe language $a^nb^nc^n$. The allowable values for augmentationvariables are 1 and $SUCCESSOR(n)$, where $n$ is a value. The rule for a sentencein this language isShow the rule(s) for each of ${it A}$,${it B}$, and ${it C}$.",
        "url": " /nlp-english-exercises/ex_14/"
      }
    
  
    ,
      "nlp-english-exercises-ex-4":  {
        "title": "Exercise 23.4",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.4Consider the following simple PCFG for noun phrases:  0.6: NP $rightarrow$ Det AdjString Noun  0.4: NP $rightarrow$ Det NounNounCompound  0.5: AdjString $rightarrow$ Adj AdjString  0.5: AdjString $rightarrow$ $Lambda$  1.0: NounNounCompound $rightarrow$ Noun  0.8: Det $rightarrow$ the  0.2: Det $rightarrow$ a  0.5: Adj $rightarrow$ small  0.5: Adj $rightarrow$ green  0.6: Noun $rightarrow$ village  0.4: Noun $rightarrow$ greenwhere $Lambda$ denotes the empty string.      What is the longest NP that can be generated by this grammar? (i)three words(ii) four words(iii) infinitely many words        Which of the following have a nonzero probability of being generatedas complete NPs? (i) a small green village(ii) a greengreen green(iii) a small village green        What is the probability of generating “the green green”?        What types of ambiguity are exhibited by the phrase in (c)?        Given any PCFG and any finite word sequence, is it possible tocalculate the probability that the sequence was generated by thePCFG?  ",
        "url": " /nlp-english-exercises/ex_4/"
      }
    
  
    ,
      "nlp-english-exercises-ex-20":  {
        "title": "Exercise 23.20",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.20(Adapted from [@Knight:1999].) Our translation model assumes that, after the phrasetranslation model selects phrases and the distortion model permutesthem, the language model can unscramble the permutation. This exerciseinvestigates how sensible that assumption is. Try to unscramble theseproposed lists of phrases into the correct order:      have, programming, a, seen, never, I, language, better        loves, john, mary        is the, communication, exchange of, intentional, informationbrought, by, about, the production, perception of, and signs, from,drawn, a, of, system, signs, conventional, shared        created, that, we hold these, to be, all men, truths, are, equal,self-evident  Which ones could you do? What type of knowledge did you draw upon? Traina bigram model from a training corpus, and use it to find thehighest-probability permutation of some sentences from a test corpus.Report on the accuracy of this model.",
        "url": " /nlp-english-exercises/ex_20/"
      }
    
  
    ,
      "nlp-english-exercises-ex-7":  {
        "title": "Exercise 23.7",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.7Consider the sentence “Someone walked slowly to the supermarket” and alexicon consisting of the following words:$Pronoun rightarrow textbf{someone} quad Verb rightarrow textbf{walked}$$Adv rightarrow textbf{slowly} quad Prep rightarrow textbf{to}$$Article rightarrow textbf{the} quad Noun rightarrow textbf{supermarket}$Which of the following three grammars, combined with the lexicon,generates the given sentence? Show the corresponding parse tree(s).            $quadquadquadquad (A):quadquadquadquad$      $quadquadquadquad(B):quadquadquadquad$      $quadquadquadquad(C):quadquadquadquad$                  $Srightarrow NPspace VP$      $Srightarrow NPspace VP$      $Srightarrow NPspace VP$              $NPrightarrow Pronoun$      $NPrightarrow Pronoun$      $NPrightarrow Pronoun$              $NPrightarrow Articlespace Noun $      $NPrightarrow Noun$      $NPrightarrow Articlespace NP$              $VPrightarrow VPspace PP$      $NPrightarrow Articlespace NP$      $VPrightarrow Verbspace Adv$              $VPrightarrow VPspace Advspace Adv$      $VPrightarrow Verbspace Vmod$      $Advrightarrow Advspace Adv$              $VPrightarrow Verb$      $Vmodrightarrow Advspace Vmod$      $Advrightarrow PP$              $PPrightarrow Prepspace NP$      $Vmodrightarrow Adv$      $PPrightarrow Prepspace NP$              $NPrightarrow Noun$      $Advrightarrow PP$      $NPrightarrow Noun$              $quad$      $PPrightarrow Prepspace NP$      $quad$      For each of the preceding three grammars, write down three sentences ofEnglish and three sentences of non-English generated by the grammar.Each sentence should be significantly different, should be at least sixwords long, and should include some new lexical entries (which youshould define). Suggest ways to improve each grammar to avoid generatingthe non-English sentences.",
        "url": " /nlp-english-exercises/ex_7/"
      }
    
  
    ,
      "nlp-english-exercises-ex-17":  {
        "title": "Exercise 23.17",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.17 [washing-clothes2-exercise]Without looking back atExercise washing-clothes-exercise, answer the followingquestions:      What are the four steps that are mentioned?        What step is left out?        What is “the material” that is mentioned in the text?        What kind of mistake would be expensive?        Is it better to do too few things or too many? Why?  ",
        "url": " /nlp-english-exercises/ex_17/"
      }
    
  
    ,
      "nlp-english-exercises-ex-5":  {
        "title": "Exercise 23.5",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.5Outline the major differences between Java (or any other computerlanguage with which you are familiar) and English, commenting on the“understanding” problem in each case. Think about such things asgrammar, syntax, semantics, pragmatics, compositionality,context-dependence, lexical ambiguity, syntactic ambiguity, referencefinding (including pronouns), background knowledge, and what it means to“understand” in the first place.",
        "url": " /nlp-english-exercises/ex_5/"
      }
    
  
    ,
      "nlp-english-exercises-ex-10":  {
        "title": "Exercise 23.10",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.10 [chomsky-form-exercise]In this exercise you will transform $large varepsilon_0$  intoChomsky Normal Form (CNF). There are five steps: (a) Add a new startsymbol, (b) Eliminate $epsilon$ rules, (c) Eliminate multiple words onright-hand sides, (d) Eliminate rules of the form(${it X}$$rightarrow$${it Y}$),(e) Convert long right-hand sides into binary rules.      The start symbol, $S$, can occur only on the left-hand side in CNF.Replace ${it S}$ everywhere by a new symbol${it S’}$ and add a rule of the form${it S}$$rightarrow$${it S’}$.        The empty string, $epsilon$ cannot appear on the right-hand sidein CNF. $large varepsilon_0$ does not have any rules with $epsilon$, so this is notan issue.        A word can appear on the right-hand side in a rule only of the form(${it X}$$rightarrow$word).Replace each rule of the form (${it X}$$rightarrow$…word …)with (${it X}$$rightarrow$…${it W’}$ …)and (${it W’}$$rightarrow$word),using a new symbol ${it W’}$.        A rule (${it X}$$rightarrow{it Y}$${it Z}$) or (${it X}$$rightarrow$word).Replace each rule of the form (${it X}$$rightarrow$${it Y}$)with a set of rules of the form (${it X}$$rightarrow$…), onefor each rule (${it Y}$$rightarrow$…),where (…) indicates one or more symbols.        Replace each rule of the form (${it X}$$rightarrow{it Y}$${it Z’}$) and (${it Z’}$$rightarrow$${it Z}$…), where ${it Z’}$ is a new symbol.  Show each step of the process and the final set of rules.",
        "url": " /nlp-english-exercises/ex_10/"
      }
    
  
    ,
      "nlp-english-exercises-ex-22":  {
        "title": "Exercise 23.22",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.22We forgot to mention that the text inExercise washing-clothes-exercise is entitled “WashingClothes.” Reread the text and answer the questions inExercise washing-clothes2-exercise. Did you do betterthis time? Bransford and Johnson [@Bransford+Johnson:1973] used thistext in a controlled experiment and found that the title helpedsignificantly. What does this tell you about how language and memoryworks?",
        "url": " /nlp-english-exercises/ex_22/"
      }
    
  
    ,
      "nlp-english-exercises-ex-18":  {
        "title": "Exercise 23.18",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.18Select five sentences and submit them to an online translation service.Translate them from English to another language and back to English.Rate the resulting sentences for grammaticality and preservation ofmeaning. Repeat the process; does the second round of iteration giveworse results or the same results? Does the choice of intermediatelanguage make a difference to the quality of the results? If you know aforeign language, look at the translation of one paragraph into thatlanguage. Count and describe the errors made, and conjecture why theseerrors were made.",
        "url": " /nlp-english-exercises/ex_18/"
      }
    
  
    ,
      "nlp-english-exercises-ex-15":  {
        "title": "Exercise 23.15",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.15Augment the $large varepsilon_1$ grammar so that it handles article–noun agreement. That is,make sure that “agents” and “an agent” are ${it NP}$s, but“agent” and “an agents” are not.",
        "url": " /nlp-english-exercises/ex_15/"
      }
    
  
    ,
      "nlp-english-exercises-ex-16":  {
        "title": "Exercise 23.16",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.16Consider the following sentence (from The New York Times,July 28, 2008):  Banks struggling to recover from multibillion-dollar loans on realestate are curtailing loans to American businesses, depriving evenhealthy companies of money for expansion and hiring.      Which of the words in this sentence are lexically ambiguous?        Find two cases of syntactic ambiguity in this sentence (there aremore than two.)        Give an instance of metaphor in this sentence.        Can you find semantic ambiguity?  ",
        "url": " /nlp-english-exercises/ex_16/"
      }
    
  
    ,
      "nlp-english-exercises-ex-8":  {
        "title": "Exercise 23.8",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.8Collect some examples of time expressions, such as “two o’clock,”“midnight,” and “12:46.” Also think up some examples that areungrammatical, such as “thirteen o’clock” or “half past two fifteen.”Write a grammar for the time language.",
        "url": " /nlp-english-exercises/ex_8/"
      }
    
  
    ,
      "nlp-english-exercises-ex-2":  {
        "title": "Exercise 23.2",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.2An HMM grammar is essentially a standard HMM whose statevariable is $N$ (nonterminal, with values such as $Det$, $Adjective$,$Noun$ and so on) and whose evidence variable is $W$ (word, with valuessuch as $is$, $duck$, and so on). The HMM model includes a prior${textbf{P}}(N_0)$, a transition model${textbf{P}}(N_{t+1}|N_t)$, and a sensor model${textbf{P}}(W_t|N_t)$. Show that every HMM grammar can bewritten as a PCFG. [Hint: start by thinking about how the HMM prior canbe represented by PCFG rules for the sentence symbol. You may find ithelpful to illustrate for the particular HMM with values $A$, $B$ for$N$ and values $x$, $y$ for $W$.]",
        "url": " /nlp-english-exercises/ex_2/"
      }
    
  
    ,
      "nlp-english-exercises-ex-9":  {
        "title": "Exercise 23.9",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.9Some linguists have argued as follows:  Children learning a language hear only positiveexamples of the language and no negativeexamples. Therefore, the hypothesis that “every possiblesentence is in the language” is consistent with all the observedexamples. Moreover, this is the simplest consistent hypothesis.Furthermore, all grammars for languages that are supersets of the truelanguage are also consistent with the observed data. Yet children doinduce (more or less) the right grammar. It follows that they beginwith very strong innate grammatical constraints that rule out all ofthese more general hypotheses a priori.Comment on the weak point(s) in this argument from a statisticallearning viewpoint.",
        "url": " /nlp-english-exercises/ex_9/"
      }
    
  
    ,
      "nlp-english-exercises-ex-19":  {
        "title": "Exercise 23.19",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.19The $D_i$ values for the sentence inFigure mt-alignment-figure sum to 0. Will that be trueof every translation pair? Prove it or give a counterexample.",
        "url": " /nlp-english-exercises/ex_19/"
      }
    
  
    ,
      "nlp-english-exercises-ex-6":  {
        "title": "Exercise 23.6",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.6This exercise concerns grammars for very simple languages.      Write a context-free grammar for the language $a^n b^n$.        Write a context-free grammar for the palindrome language: the set ofall strings whose second half is the reverse of the first half.        Write a context-sensitive grammar for the duplicate language: theset of all strings whose second half is the same as the first half.  ",
        "url": " /nlp-english-exercises/ex_6/"
      }
    
  
    ,
      "nlp-english-exercises-ex-21":  {
        "title": "Exercise 23.21",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.21Calculate the most probable path through the HMM inFigure sr-hmm-figure for the output sequence$[C_1,C_2,C_3,C_4,C_4,C_6,C_7]$. Also give its probability.",
        "url": " /nlp-english-exercises/ex_21/"
      }
    
  
    ,
      "nlp-english-exercises-ex-1":  {
        "title": "Exercise 23.1",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.1 [washing-clothes-exercise]Read the following text once forunderstanding, and remember as much of it as you can. There will be atest later.  The procedure is actually quite simple. First you arrange things intodifferent groups. Of course, one pile may be sufficient depending on howmuch there is to do. If you have to go somewhere else due to lack offacilities that is the next step, otherwise you are pretty well set. Itis important not to overdo things. That is, it is better to do too fewthings at once than too many. In the short run this may not seemimportant but complications can easily arise. A mistake is expensive aswell. At first the whole procedure will seem complicated. Soon, however,it will become just another facet of life. It is difficult to foreseeany end to the necessity for this task in the immediate future, but thenone can never tell. After the procedure is completed one arranges thematerial into different groups again. Then they can be put into theirappropriate places. Eventually they will be used once more and the wholecycle will have to be repeated. However, this is part of life.",
        "url": " /nlp-english-exercises/ex_1/"
      }
    
  
    ,
      "nlp-english-exercises-ex-13":  {
        "title": "Exercise 23.13",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.13Consider the following PCFG:  $S rightarrow NP space VP[1.0] $                    $NP rightarrow textit{Noun}[0.6] space        space textit{Pronoun}[0.4] $                                $VP rightarrow textit{Verb} space NP[0.8] space        space textit{Modal}space textit{Verb}[0.2]$                                $textit{Noun} rightarrow textbf{can}[0.1] space        space textbf{fish}[0.3] space        space …$                                $textit{Pronoun} rightarrow textbf{I}[0.4] space        space …$                                $textit{Verb} rightarrow textbf{can}[0.01] space        space textbf{fish}[0.1] space        space …$                                $textit{Modal} rightarrow textbf{can}[0.3] space        space …$            The sentence “I can fish” has two parse trees with this grammar. Showthe two trees, their prior probabilities, and their conditionalprobabilities, given the sentence.",
        "url": " /nlp-english-exercises/ex_13/"
      }
    
  
    ,
      "nlp-english-exercises-ex-12":  {
        "title": "Exercise 23.12",
        "breadcrumb": "23-Natural-Language-For-Communication",
      	"content"  : "Exercise 23.12 [exercise-subj-verb-agree]Using DCG notation, write a grammar for alanguage that is just like $large varepsilon_1$, except that it enforces agreement betweenthe subject and verb of a sentence and thus does not generateungrammatical sentences such as “I smells the wumpus.”",
        "url": " /nlp-english-exercises/ex_12/"
      }
    
  
    
  
    
  
    
  
    
  
}