<!DOCTYPE html>
<html>
  <head>
    <title>Main –  – </title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    
    <meta name="author" content="" />

    
    <meta property="og:title" content="Main" />
    <meta property="twitter:title" content="Main" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="https://code.jquery.com/jquery-3.3.1.js"></script>
    <script src="//www.gstatic.com/firebasejs/5.0.4/firebase.js"></script>
    <script type="text/javascript" src="//aima-exercises.firebaseapp.com/config.js"></script>
<!--     <script src="//http://www.gstatic.com/firebasejs/5.0.4/firebase-firestore.js"></script>
 -->
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title=" - " href="/feed.xml" />
<!--     <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
 -->
    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <input type="checkbox" id="toggleheader">
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <center>
            <h1>Aritificial Intelligence: A Modern Approach</h1>
            <h3>Stuart J. Russell and Peter Norvig</h3>
          </center>
        </header>
      </div>
    </div>
    <input type="checkbox" id="toggletoc">
    <div class="toc">
      <div>Table of Contents</div>
      <ul>
	<li>
		<span>Part &#x2160; Artificial Intelligence</span>
		<ol>
			<li><a href="/intro-exercises">1. Introduction</a></li>
			<li><a href="/agents-exercises">2. Intelligent Agent</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2161; Problem-solving</span>
		<ol>
			<li><a href="/search-exercises">3. Solving Problems By Searching</a></li>
			<li><a href="/advanced-search-exercises">4. Beyond Classical Search</a></li>
			<li><a href="/game-playing-exercises">5. Adversarial Search</a></li>
			<li><a href="/csp-exercises">6. Constraint Satisfaction Problems</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2162; Knowledge, reasoning, and planning</span>
		<ol>
			<li><a href="/knowledge-logic-exercises">7. Logical Agents</a></li>
			<li><a href="/fol-exercises">8. First Order Logic</a></li>
			<li><a href="/logical-inference-exercises">9. Inference In First Order Logic</a></li>
			<li><a href="/planning-exercises">10. Classical Planning</a></li>
			<li><a href="/advanced-planning-exercises">11. Planning And Acting In The Real World</a></li>
			<li><a href="/kr-exercises">12. Knowledge Representation</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2163; Uncertain knowledge and reasoning</span>
		<ol>
			<li><a href="/probability-exercises">13. Quantifying Uncertainity</a></li>
			<li><a href="/bayes-nets-exercises">14. Probabilistic Reasoning</a></li>
			<li><a href="/dbn-exercises">15. Probabilistic Reasoning Over Time</a></li>
			<li><a href="/decision-theory-exercises">16. Making Simple Decisions</a></li>
			<li><a href="/complex-decisions-exercises">17. Making Complex Decision</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2164; Learning</span>
		<ol>
			<li><a href="/concept-learning-exercises">18. Learning From Examples</a></li>
			<li><a href="/ilp-exercises">19. Knowledge In Learning</a></li>
			<li><a href="/bayesian-learning-exercises">20. Learning Probabilistic Models</a></li>
			<li><a href="/reinforcement-learning-exercises">21. Reinforcement Learning</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2165; Communicating, perceiving, and acting</span>
		<ol>
			<li><a href="/nlp-communicating-exercises">22. Natural Language Processing</a></li>
			<li><a href="/nlp-english-exercises">23. Natural Language For Communication</a></li>
			<li><a href="/perception-exercises">24. Perception</a></li>
			<li><a href="/robotics-exercises">25. Robotics</a></li>
		</ol>
	</li>
	<li>
		<span>Part &#x2166; Conclusions</span>
		<ol>
			<li><a href="/philosophy-exercises">26. Philosophical Foundations</a></li>
			<li><a href="/#/"> Future Exercises</a></li>
		</ol>
	</li>
</ul>
    </div>
    <div id="main" role="main" class="container">
      



<ul class="breadcrumb">

  <label for="toggletoc" class="toc-icon">
    <span></span>
    <span></span>
    <span></span>
  </label>

   
    <li><a class="breadcrumb-text" href="/">home</a> &nbsp; </li>
   

<label for="toggleheader" class="toggleheader" title="Toggle Header">
    &#9167;
</label>
</ul>

      <article class="post">

  <div class="entry">
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    },
    "HTML-CSS": { 
      preferredFont: "TeX", 
      availableFonts: ["STIX","TeX"], 
      styles: {".MathJax": {}} 
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h1 id="16-making-simple-decisions">16. Making Simple Decisions</h1>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_1" data-rating="0"></i></div>
<p><a href="ex_1/">Exercise 16.1 [almanac-game]</a></p>

<p>(Adapted from David Heckerman.) This exercise concerns
the <strong>Almanac Game</strong>, which is used by
decision analysts to calibrate numeric estimation. For each of the
questions that follow, give your best guess of the answer, that is, a
number that you think is as likely to be too high as it is to be too
low. Also give your guess at a 25th percentile estimate, that is, a
number that you think has a 25% chance of being too high, and a 75%
chance of being too low. Do the same for the 75th percentile. (Thus, you
should give three estimates in all—low, median, and high—for each
question.)</p>

<ol>
  <li>
    <p>Number of passengers who flew between New York and Los Angeles
in 1989.</p>
  </li>
  <li>
    <p>Population of Warsaw in 1992.</p>
  </li>
  <li>
    <p>Year in which Coronado discovered the Mississippi River.</p>
  </li>
  <li>
    <p>Number of votes received by Jimmy Carter in the 1976
presidential election.</p>
  </li>
  <li>
    <p>Age of the oldest living tree, as of 2002.</p>
  </li>
  <li>
    <p>Height of the Hoover Dam in feet.</p>
  </li>
  <li>
    <p>Number of eggs produced in Oregon in 1985.</p>
  </li>
  <li>
    <p>Number of Buddhists in the world in 1992.</p>
  </li>
  <li>
    <p>Number of deaths due to AIDS in the United States
in 1981.</p>
  </li>
  <li>
    <p>Number of U.S. patents granted in 1901.</p>
  </li>
</ol>

<p>The correct answers appear after the last exercise of this chapter. From
the point of view of decision analysis, the interesting thing is not how
close your median guesses came to the real answers, but rather how often
the real answer came within your 25% and 75% bounds. If it was about
half the time, then your bounds are accurate. But if you’re like most
people, you will be more sure of yourself than you should be, and fewer
than half the answers will fall within the bounds. With practice, you
can calibrate yourself to give realistic bounds, and thus be more useful
in supplying information for decision making. Try this second set of
questions and see if there is any improvement:</p>

<ol>
  <li>
    <p>Year of birth of Zsa Zsa Gabor.</p>
  </li>
  <li>
    <p>Maximum distance from Mars to the sun in miles.</p>
  </li>
  <li>
    <p>Value in dollars of exports of wheat from the United States in 1992.</p>
  </li>
  <li>
    <p>Tons handled by the port of Honolulu in 1991.</p>
  </li>
  <li>
    <p>Annual salary in dollars of the governor of California in 1993.</p>
  </li>
  <li>
    <p>Population of San Diego in 1990.</p>
  </li>
  <li>
    <p>Year in which Roger Williams founded Providence, Rhode Island.</p>
  </li>
  <li>
    <p>Height of Mt. Kilimanjaro in feet.</p>
  </li>
  <li>
    <p>Length of the Brooklyn Bridge in feet.</p>
  </li>
  <li>
    <p>Number of deaths due to automobile accidents in the United States
in 1992.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_2" data-rating="0"></i></div>
<p><a href="ex_2/">Exercise 16.2</a></p>

<p>Chris considers four used cars before buying the one with maximum
expected utility. Pat considers ten cars and does the same. All other
things being equal, which one is more likely to have the better car?
Which is more likely to be disappointed with their car’s quality? By how
much (in terms of standard deviations of expected quality)?</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_3" data-rating="0"></i></div>
<p><a href="ex_3/">Exercise 16.3</a></p>

<p>Chris considers five used cars before buying the one with maximum
expected utility. Pat considers eleven cars and does the same. All other
things being equal, which one is more likely to have the better car?
Which is more likely to be disappointed with their car’s quality? By how
much (in terms of standard deviations of expected quality)?</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_4" data-rating="0"></i></div>
<p><a href="ex_4/">Exercise 16.4 [St-Petersburg-exercise]</a></p>

<p>In 1713, Nicolas Bernoulli stated a puzzle,
now called the St. Petersburg paradox, which works as follows. You have
the opportunity to play a game in which a fair coin is tossed repeatedly
until it comes up heads. If the first heads appears on the $n$th toss,
you win $2^n$ dollars.</p>

<ol>
  <li>
    <p>Show that the expected monetary value of this game is infinite.</p>
  </li>
  <li>
    <p>How much would you, personally, pay to play the game?</p>
  </li>
  <li>
    <p>Nicolas’s cousin Daniel Bernoulli resolved the apparent paradox in
1738 by suggesting that the utility of money is measured on a
logarithmic scale (i.e., $U(S_{n}) = a\log_2 n +b$, where $S_n$ is
the state of having $n$). What is the expected utility of the game
under this assumption?</p>
  </li>
  <li>
    <p>What is the maximum amount that it would be rational to pay to play
the game, assuming that one’s initial wealth is $k$?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_5" data-rating="0"></i></div>
<p><a href="ex_5/">Exercise 16.5</a></p>

<p>Write a computer program to automate the process in
Exercise <a href="#/">assessment-exercise</a>. Try your program out on
several people of different net worth and political outlook. Comment on
the consistency of your results, both for an individual and across
individuals.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_6" data-rating="0"></i></div>
<p><a href="ex_6/">Exercise 16.6 [surprise-candy-exercise]</a></p>

<p>The Surprise Candy Company makes candy in
two flavors: 75% are strawberry flavor and 25% are anchovy flavor. Each
new piece of candy starts out with a round shape; as it moves along the
production line, a machine randomly selects a certain percentage to be
trimmed into a square; then, each piece is wrapped in a wrapper whose
color is chosen randomly to be red or brown. 70% of the strawberry
candies are round and 70% have a red wrapper, while 90% of the anchovy
candies are square and 90% have a brown wrapper. All candies are sold
individually in sealed, identical, black boxes.</p>

<p>Now you, the customer, have just bought a Surprise candy at the store
but have not yet opened the box. Consider the three Bayes nets in
Figure <a href="#3candy-figure">3candy-figure</a>.</p>

<ol>
  <li>
    <p>Which network(s) can correctly represent
${\textbf{P}}(Flavor,Wrapper,Shape)$?</p>
  </li>
  <li>
    <p>Which network is the best representation for this problem?</p>
  </li>
  <li>
    <p>Does network (i) assert that
${\textbf{P}}(Wrapper|Shape){\textbf{P}}(Wrapper)$?</p>
  </li>
  <li>
    <p>What is the probability that your candy has a red wrapper?</p>
  </li>
  <li>
    <p>In the box is a round candy with a red wrapper. What is the
probability that its flavor is strawberry?</p>
  </li>
  <li>
    <p>A unwrapped strawberry candy is worth $s$ on the open market and an
unwrapped anchovy candy is worth $a$. Write an expression for the
value of an unopened candy box.</p>
  </li>
  <li>
    <p>A new law prohibits trading of unwrapped candies, but it is still
legal to trade wrapped candies (out of the box). Is an unopened
candy box now worth more than less than, or the same as before?</p>
  </li>
</ol>

<center>
<b id="3candy-figure">Figure [3candy-figure]</b> Three proposed Bayes nets for the Surprise Candy
problem
</center>

<p><img src="http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/3candy.svg" alt="3candy-figure" /></p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_7" data-rating="0"></i></div>
<p><a href="ex_7/">Exercise 16.7 [surprise-candy-exercise]</a></p>

<p>The Surprise Candy Company makes candy in
two flavors: 70% are strawberry flavor and 30% are anchovy flavor. Each
new piece of candy starts out with a round shape; as it moves along the
production line, a machine randomly selects a certain percentage to be
trimmed into a square; then, each piece is wrapped in a wrapper whose
color is chosen randomly to be red or brown. 80% of the strawberry
candies are round and 80% have a red wrapper, while 90% of the anchovy
candies are square and 90% have a brown wrapper. All candies are sold
individually in sealed, identical, black boxes.</p>

<p>Now you, the customer, have just bought a Surprise candy at the store
but have not yet opened the box. Consider the three Bayes nets in
Figure <a href="#3candy-figure">3candy-figure</a>.</p>

<ol>
  <li>
    <p>Which network(s) can correctly represent
${\textbf{P}}(Flavor,Wrapper,Shape)$?</p>
  </li>
  <li>
    <p>Which network is the best representation for this problem?</p>
  </li>
  <li>
    <p>Does network (i) assert that
${\textbf{P}}(Wrapper|Shape){\textbf{P}}(Wrapper)$?</p>
  </li>
  <li>
    <p>What is the probability that your candy has a red wrapper?</p>
  </li>
  <li>
    <p>In the box is a round candy with a red wrapper. What is the
probability that its flavor is strawberry?</p>
  </li>
  <li>
    <p>A unwrapped strawberry candy is worth $s$ on the open market and an
unwrapped anchovy candy is worth $a$. Write an expression for the
value of an unopened candy box.</p>
  </li>
  <li>
    <p>A new law prohibits trading of unwrapped candies, but it is still
legal to trade wrapped candies (out of the box). Is an unopened
candy box now worth more than less than, or the same as before?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_8" data-rating="0"></i></div>
<p><a href="ex_8/">Exercise 16.8</a></p>

<p>Prove that the judgments $B \succ A$ and $C \succ D$ in the Allais
paradox (page <a href="#/">allais-page</a>) violate the axiom of substitutability.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_9" data-rating="0"></i></div>
<p><a href="ex_9/">Exercise 16.9</a></p>

<p>Consider the Allais paradox described on page <a href="#/">allais-page</a>: an agent
who prefers $B$ over $A$ (taking the sure thing), and $C$ over $D$
(taking the higher EMV) is not acting rationally, according to utility
theory. Do you think this indicates a problem for the agent, a problem
for the theory, or no problem at all? Explain.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_10" data-rating="0"></i></div>
<p><a href="ex_10/">Exercise 16.10</a></p>

<p>Tickets to a lottery cost 1. There are two possible prizes:
a 10 payoff with probability 1/50, and a 1,000,000 payoff with
probability 1/2,000,000. What is the expected monetary value of a
lottery ticket? When (if ever) is it rational to buy a ticket? Be
precise—show an equation involving utilities. You may assume current
wealth of $k$ and that $U(S_k)=0$. You may also assume that
$U(S_{k+{10}}) = {10}\times U(S_{k+1})$, but you may not make any
assumptions about $U(S_{k+1,{000},{000}})$. Sociological studies show
that people with lower income buy a disproportionate number of lottery
tickets. Do you think this is because they are worse decision makers or
because they have a different utility function? Consider the value of
contemplating the possibility of winning the lottery versus the value of
contemplating becoming an action hero while watching an adventure movie.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_11" data-rating="0"></i></div>
<p><a href="ex_11/">Exercise 16.11 [assessment-exercise]</a></p>

<p>Assess your own utility for different incremental
amounts of money by running a series of preference tests between some
definite amount $M_1$ and a lottery $[p,M_2; (1-p), 0]$. Choose
different values of $M_1$ and $M_2$, and vary $p$ until you are
indifferent between the two choices. Plot the resulting utility
function.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_12" data-rating="0"></i></div>
<p><a href="ex_12/">Exercise 16.12</a></p>

<p>How much is a micromort worth to you? Devise a protocol to determine
this. Ask questions based both on paying to avoid risk and being paid to
accept risk.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_13" data-rating="0"></i></div>
<p><a href="ex_13/">Exercise 16.13 [kmax-exercise]</a></p>

<p>Let continuous variables $X_1,\ldots,X_k$ be
independently distributed according to the same probability density
function $f(x)$. Prove that the density function for
$\max{X_1,\ldots,X_k}$ is given by $kf(x)(F(x))^{k-1}$, where $F$ is
the cumulative distribution for $f$.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_14" data-rating="0"></i></div>
<p><a href="ex_14/">Exercise 16.14</a></p>

<p>Economists often make use of an exponential utility function for money:
$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing an
individual’s risk tolerance. Risk tolerance reflects how likely an
individual is to accept a lottery with a particular expected monetary
value (EMV) versus some certain payoff. As $R$ (which is measured in the
same units as $x$) becomes larger, the individual becomes less
risk-averse.</p>

<ol>
  <li>
    <p>Assume Mary has an exponential utility function with <script type="math/tex">R = \$500</script>.
Mary is given the choice between receiving <script type="math/tex">\$500</script> with certainty
(probability 1) or participating in a lottery which has a 60%
probability of winning $5000 and a 40% probability of
winning nothing. Assuming Marry acts rationally, which option would
she choose? Show how you derived your answer.</p>
  </li>
  <li>
    <p>Consider the choice between receiving <script type="math/tex">\$100</script> with certainty
(probability 1) or participating in a lottery which has a 50%
probability of winning <script type="math/tex">\$500</script> and a 50% probability of winning
nothing. Approximate the value of R (to 3 significant digits) in an
exponential utility function that would cause an individual to be
indifferent to these two alternatives. (You might find it helpful to
write a short program to help you solve this problem.)</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_15" data-rating="0"></i></div>
<p><a href="ex_15/">Exercise 16.15</a></p>

<p>Economists often make use of an exponential utility function for money:
$U(x) = -e^{-x/R}$, where $R$ is a positive constant representing an
individual’s risk tolerance. Risk tolerance reflects how likely an
individual is to accept a lottery with a particular expected monetary
value (EMV) versus some certain payoff. As $R$ (which is measured in the
same units as $x$) becomes larger, the individual becomes less
risk-averse.</p>

<ol>
  <li>
    <p>Assume Mary has an exponential utility function with $R = $400$.
Mary is given the choice between receiving <script type="math/tex">\$400</script> with certainty
(probability 1) or participating in a lottery which has a 60%
probability of winning $5000 and a 40% probability of
winning nothing. Assuming Marry acts rationally, which option would
she choose? Show how you derived your answer.</p>
  </li>
  <li>
    <p>Consider the choice between receiving <script type="math/tex">\$100</script> with certainty
(probability 1) or participating in a lottery which has a 50%
probability of winning $500 and a 50% probability of winning
nothing. Approximate the value of R (to 3 significant digits) in an
exponential utility function that would cause an individual to be
indifferent to these two alternatives. (You might find it helpful to
write a short program to help you solve this problem.)</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_16" data-rating="0"></i></div>
<p><a href="ex_16/">Exercise 16.16</a></p>

<p>Alex is given the choice between two games. In Game 1, a fair coin is
flipped and if it comes up heads, Alex receives <script type="math/tex">\$100</script>. If the coin comes
up tails, Alex receives nothing. In Game 2, a fair coin is flipped
twice. Each time the coin comes up heads, Alex receives <script type="math/tex">\$50</script>, and Alex
receives nothing for each coin flip that comes up tails. Assuming that
Alex has a monotonically increasing utility function for money in the
range [$0, $100], show mathematically that if Alex prefers Game 2 to
Game 1, then Alex is risk averse (at least with respect to this range of
monetary amounts).</p>

<p>Show that if $X_1$ and $X_2$ are preferentially independent of $X_3$,
and $X_2$ and $X_3$ are preferentially independent of $X_1$, then $X_3$
and $X_1$ are preferentially independent of $X_2$.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_17" data-rating="0"></i></div>
<p><a href="ex_17/">Exercise 16.17 [airport-au-id-exercise]</a></p>

<p>Repeat Exercise <a href="#/">airport-id-exercise</a>, using the action-utility
representation shown in Figure <a href="#/">airport-au-id-figure</a>.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_18" data-rating="0"></i></div>
<p><a href="ex_18/">Exercise 16.18</a></p>

<p>For either of the airport-siting diagrams from Exercises
[airport-id-exercise] and [airport-au-id-exercise], to which
conditional probability table entry is the utility most sensitive, given
the available evidence?</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_19" data-rating="0"></i></div>
<p><a href="ex_19/">Exercise 16.19</a></p>

<p>Modify and extend the Bayesian network code in the code repository to
provide for creation and evaluation of decision networks and the
calculation of information value.</p>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_20" data-rating="0"></i></div>
<p><a href="ex_20/">Exercise 16.20</a></p>

<p>Consider a student who has the choice to buy or not buy a textbook for a
course. We’ll model this as a decision problem with one Boolean decision
node, $B$, indicating whether the agent chooses to buy the book, and two
Boolean chance nodes, $M$, indicating whether the student has mastered
the material in the book, and $P$, indicating whether the student passes
the course. Of course, there is also a utility node, $U$. A certain
student, Sam, has an additive utility function: 0 for not buying the
book and -$100 for buying it; and $2000 for passing the course and 0
for not passing. Sam’s conditional probability estimates are as follows:
<script type="math/tex">% <![CDATA[
\begin{array}{ll}
P(p|b,m) = 0.9              & P(m|b) = 0.9       \\
P(p|b, \lnot m) = 0.5       & P(m|\lnot b) = 0.7 \\
P(p|\lnot b, m) = 0.8       & \\
P(p|\lnot b, \lnot m) = 0.3 & \\
\end{array} %]]></script></p>

<p>You might think that $P$ would be independent of $B$ given
$M$, But this course has an open-book final—so having the book helps.</p>

<ol>
  <li>
    <p>Draw the decision network for this problem.</p>
  </li>
  <li>
    <p>Compute the expected utility of buying the book and of not
buying it.</p>
  </li>
  <li>
    <p>What should Sam do?</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_21" data-rating="0"></i></div>
<p><a href="ex_21/">Exercise 16.21 [airport-id-exercise]</a></p>

<p>This exercise completes the analysis of the
airport-siting problem in Figure <a href="#/">airport-id-figure</a>.</p>

<ol>
  <li>
    <p>Provide reasonable variable domains, probabilities, and utilities
for the network, assuming that there are three possible sites.</p>
  </li>
  <li>
    <p>Solve the decision problem.</p>
  </li>
  <li>
    <p>What happens if changes in technology mean that each aircraft
generates half the noise?</p>
  </li>
  <li>
    <p>What if noise avoidance becomes three times more important?</p>
  </li>
  <li>
    <p>Calculate the VPI for ${AirTraffic}$, ${Litigation}$, and
${Construction}$ in your model.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_22" data-rating="0"></i></div>
<p><a href="ex_22/">Exercise 16.22 [car-vpi-exercise]</a></p>

<p>(Adapted from Pearl [@Pearl:1988].) A used-car
buyer can decide to carry out various tests with various costs (e.g.,
kick the tires, take the car to a qualified mechanic) and then,
depending on the outcome of the tests, decide which car to buy. We will
assume that the buyer is deciding whether to buy car $c_1$, that there
is time to carry out at most one test, and that $t_1$ is the test of
$c_1$ and costs $50.</p>

<p>A car can be in good shape (quality <script type="math/tex">q^+</script>) or bad shape (quality $q^-$),
and the tests might help indicate what shape the car is in. Car $c_1$
costs $1,500, and its market value is <script type="math/tex">\$2,000</script> if it is in good shape; if
not, <script type="math/tex">\$700</script> in repairs will be needed to make it in good shape. The buyer’s
estimate is that $c_1$ has a 70% chance of being in good shape.</p>

<ol>
  <li>
    <p>Draw the decision network that represents this problem.</p>
  </li>
  <li>
    <p>Calculate the expected net gain from buying $c_1$, given no test.</p>
  </li>
  <li>
    <p>Tests can be described by the probability that the car will pass or
fail the test given that the car is in good or bad shape. We have
the following information:</p>

    <script type="math/tex; mode=display">P({pass}(c_1,t_1) | q^+(c_1)) = {0.8}</script>

    <script type="math/tex; mode=display">P({pass}(c_1,t_1) | q^-(c_1)) = {0.35}</script>

    <p>Use Bayes’ theorem to calculate the probability that the car will pass (or fail) its test and hence the probability that it is in good (or bad) shape given each possible test outcome.</p>
  </li>
  <li>
    <p>Calculate the optimal decisions given either a pass or a fail, and
their expected utilities.</p>
  </li>
  <li>
    <p>Calculate the value of information of the test, and derive an
optimal conditional plan for the buyer.</p>
  </li>
</ol>

<div><i class="arrow-up loader" data-chapter="decision-theory-exercises" data-exercise="ex_23" data-rating="0"></i></div>
<p><a href="ex_23/">Exercise 16.23 [nonnegative-VPI-exercise]</a></p>

<p>Recall the definition of <em>value of
information</em> in Section <a href="#/">VPI-section</a>.</p>

<ol>
  <li>
    <p>Prove that the value of information is nonnegative and
order independent.</p>
  </li>
  <li>
    <p>Explain why it is that some people would prefer not to get some
information—for example, not wanting to know the sex of their baby
when an ultrasound is done.</p>
  </li>
  <li>
    <p>A function $f$ on sets is <strong>submodular</strong> if, for any element $x$ and any sets $A$
and $B$ such that $A\subseteq B$, adding $x$ to $A$ gives a greater
increase in $f$ than adding $x$ to $B$:
<script type="math/tex">A\subseteq B \Rightarrow (f(A \cup \{x\}) - f(A)) \geq (f(B\cup \{x\}) - f(B))\ .</script>
Submodularity captures the intuitive notion of <em>diminishing
returns</em>. Is the value of information, viewed as a function
$f$ on sets of possible observations, submodular? Prove this or find
a counterexample.</p>
  </li>
</ol>

<p>The answers to Exercise <a href="#/">almanac-game</a> (where M stands
for million): First set: 3M, 1.6M, 1541, 41M, 4768, 221, 649M, 295M,
132, 25,546. Second set: 1917, 155M, 4,500M, 11M, 120,000, 1.1M, 1636,
19,340, 1,595, 41,710.</p>

  </div>

<!--   <div class="date">
    Written on 
  </div>
 -->
  

</article>

<script type="text/javascript">
var chapter  = String('/decision-theory-exercises/')
var chapterName = chapter.match(/\/([^\/]*)\//, "")[1]
$.get( "https://aima-exercises.firebaseapp.com/rating/"+chapterName, function( data ) {
  console.log(data)
  $("i[data-chapter='"+chapterName+"']").each(function(index,element){
  	ex = $(element).data("exercise")
  	if(ex in data){
  		console.log(data[ex])
  		$(element).attr("data-rating",data[ex])
  	}
    $(".arrow-up").removeClass("loader")
  })
});

$(document).on('click',"i[data-chapter]",function(e){
	ele = $(e.target)
  ele.addClass("loader")
	exerciseName = ele.data("exercise")
	$.post( "https://aima-exercises.firebaseapp.com/rating/"+chapterName+"/"+exerciseName, function( data ) {
	  console.log(data)
	  ele.attr("data-rating",data["rating"])
    ele.removeClass("loader")
	});	
})


</script>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!--            Designed by <a href="http://nalinc.github.io" style="color:#2196F3">Nalin</a> &#9889; 
           Written in <a href="#/" style="color: #2a932a">Markdown</a> &#9889; 
           Powered by <a href="http://jekyllrb.com" style="color: #d73838">Jekyll</a>    -->
          <!-- 











 -->
        </footer>
      </div>
    </div>

    


    <script type="text/javascript">
      // firestore =firebase.firestore();
      // function rateExercise(e){
      //   console.log(e.target)
      //   chapterLabel = $(e.target).data("chapter")
      //   exerciseLabel = $(e.target).data("exercise")
      //   docRef = firestore.collection("rating").doc(chapterLabel)
      //   score = 0
      //   docRef.get().then(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //      // score = myData
      //       console.log(myData)
      //       if(exerciseLabel in myData){
      //         myData[exerciseLabel] += 1
      //       }else{
      //         myData[exerciseLabel] = 1
      //       }
      //      // $(e.target).data("rating",score);
      //       docRef.set(myData).then(function(){
      //         console.log("status saved")
      //         console.log(myData[exerciseLabel])
      //         $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       })
      //     }
      //   })
      // }
      // getRealTimeUpdates = function(){
      //   docRef = firestore.collection("rating").doc("intro-exercises");
      //   docRef.onSnapshot(function(doc){
      //     if (doc && doc.exists){
      //       myData = doc.data()
      //       for(key in myData){
      //         console.log(key)  
      //         // $(e.target).attr("data-rating",myData[exerciseLabel]);
      //       }
      //     }
      //   })
      // }

      // getRealTimeUpdates()
      // $(document).on("click",".arrow-up", rateExercise)
    </script>
  </body>
</html>
