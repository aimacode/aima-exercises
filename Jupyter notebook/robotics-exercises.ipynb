{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25. Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.1** \\[mcl-biasdness-exercise\\]Monte Carlo localization is\n",
    "*biased* for any finite sample size—i.e., the expected\n",
    "value of the location computed by the algorithm differs from the true\n",
    "expected value—because of the way particle filtering works. In this\n",
    "question, you are asked to quantify this bias.\n",
    "\n",
    "To simplify, consider a world with four possible robot locations:\n",
    "$X=\\{x_{{\\rm 1}},x_{{\\rm 2}},x_{{\\rm 3}},x_{{\\rm 4}}\\}$. Initially, we\n",
    "draw $N\\geq {{\\rm 1}}$ samples uniformly from among those locations. As\n",
    "usual, it is perfectly acceptable if more than one sample is generated\n",
    "for any of the locations $X$. Let $Z$ be a Boolean sensor variable\n",
    "characterized by the following conditional probabilities:\n",
    "$$\\begin{aligned}\n",
    "P(z\\mid x_{{\\rm 1}}) &=& {{\\rm {0.8}}} \\qquad\\qquad P(\\lnot z\\mid x_{{\\rm 1}})\\;\\;=\\;\\;{{\\rm {0.2}}} \\\\\n",
    "P(z\\mid x_{{\\rm 2}}) &=& {{\\rm {0.4}}} \\qquad\\qquad P(\\lnot z\\mid x_{{\\rm 2}})\\;\\;=\\;\\;{{\\rm {0.6}}} \\\\\n",
    "P(z\\mid x_{{\\rm 3}}) &=& {{\\rm {0.1}}} \\qquad\\qquad P(\\lnot z\\mid x_{{\\rm 3}})\\;\\;=\\;\\;{{\\rm {0.9}}} \\\\\n",
    "P(z\\mid x_{{\\rm 4}}) &=& {{\\rm {0.1}}} \\qquad\\qquad P(\\lnot z\\mid x_{{\\rm 4}})\\;\\;=\\;\\;{{\\rm {0.9}}}\\ .\\end{aligned}$$\n",
    "MCL uses these probabilities to generate particle weights, which are\n",
    "subsequently normalized and used in the resampling process. For\n",
    "simplicity, let us assume we generate only one new sample in the\n",
    "resampling process, regardless of $N$. This sample might correspond to\n",
    "any of the four locations in $X$. Thus, the sampling process defines a\n",
    "probability distribution over $X$.\n",
    "\n",
    "1.  What is the resulting probability distribution over $X$ for this new\n",
    "    sample? Answer this question separately for\n",
    "    $N={{\\rm 1}},\\ldots,{{\\rm {10}}}$, and for $N=\\infty$.\n",
    "\n",
    "2.  The difference between two probability distributions $P$ and $Q$ can\n",
    "    be measured by the KL divergence, which is defined as\n",
    "    $${KL}(P,Q) = \\sum_i P(x_i)\\log\\frac{P(x_i)}{Q(x_i)}\\ .$$ What are\n",
    "    the KL divergences between the distributions in (a) and the true\n",
    "    posterior?\n",
    "\n",
    "3.  What modification of the problem formulation (not the algorithm!)\n",
    "    would guarantee that the specific estimator above is unbiased even\n",
    "    for finite values of $N$? Provide at least two such modifications\n",
    "    (each of which should be sufficient).\n",
    "\n",
    "**25.2** \\[mcl-implement-exercise\\]Implement Monte Carlo localization for a\n",
    "simulated robot with range sensors. A grid map and range data are\n",
    "available from the code repository at\n",
    "[aima.cs.berkeley.edu](http://aima.cs.berkeley.edu). You should demonstrate\n",
    "successful global localization of the robot.\n",
    "\n",
    "<center>\n",
    "<b id=\"figRobot2\">Figure [figRobot2]</b> A Robot manipulator in two of its possible configurations.\n",
    "</center>\n",
    "\n",
    "![figRobot2](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/figRobot2.svg)\n",
    "\n",
    "\n",
    "\n",
    "**25.3** \\[AB-manipulator-ex\\] Consider a robot with two simple manipulators, as\n",
    "shown in figure [figRobot2](#figRobot2). Manipulator A is a square block of side 2\n",
    "which can slide back and on a rod that runs along the x-axis from\n",
    "x=$-$10 to x=10. Manipulator B is a square block of side 2 which can\n",
    "slide back and on a rod that runs along the y-axis from y=-10 to y=10.\n",
    "The rods lie outside the plane of manipulation, so the rods do not\n",
    "interfere with the movement of the blocks. A configuration is then a\n",
    "pair ${\\langle}x,y{\\rangle}$ where $x$ is the x-coordinate of the center\n",
    "of manipulator A and where $y$ is the y-coordinate of the center of\n",
    "manipulator B. Draw the configuration space for this robot, indicating\n",
    "the permitted and excluded zones.\n",
    "\n",
    "**25.4** Suppose that you are working with the robot in\n",
    "Exercise [AB-manipulator-ex](#/) and you are given the\n",
    "problem of finding a path from the starting configuration of\n",
    "figure [figRobot2](#figRobot2) to the ending configuration. Consider a potential\n",
    "function $$D(A, {Goal})^2 + D(B, {Goal})^2 + \\frac{1}{D(A, B)^2}$$\n",
    "where $D(A,B)$ is the distance between the closest points of A and B.\n",
    "\n",
    "1.  Show that hill climbing in this potential field will get stuck in a\n",
    "    local minimum.\n",
    "\n",
    "2.  Describe a potential field where hill climbing will solve this\n",
    "    particular problem. You need not work out the exact numerical\n",
    "    coefficients needed, just the general form of the solution. (Hint:\n",
    "    Add a term that “rewards\" the hill climber for moving A out of B’s\n",
    "    way, even in a case like this where this does not reduce the\n",
    "    distance from A to B in the above sense.)\n",
    "\n",
    "**25.5** \\[inverse-kinematics-exercise\\]Consider the robot arm shown in\n",
    "Figure [FigArm1](#/). Assume that the robot’s base element is\n",
    "60cm long and that its upper arm and forearm are each 40cm long. As\n",
    "argued on page [inverse-kinematics-not-unique](#/), the inverse kinematics of a robot is often\n",
    "not unique. State an explicit closed-form solution of the inverse\n",
    "kinematics for this arm. Under what exact conditions is the solution\n",
    "unique?\n",
    "\n",
    "**25.6** \\[inverse-kinematics-exercise\\]Consider the robot arm shown in\n",
    "Figure [FigArm1](#/). Assume that the robot’s base element is\n",
    "70cm long and that its upper arm and forearm are each 50cm long. As\n",
    "argued on page [inverse-kinematics-not-unique](#/), the inverse kinematics of a robot is often\n",
    "not unique. State an explicit closed-form solution of the inverse\n",
    "kinematics for this arm. Under what exact conditions is the solution\n",
    "unique?\n",
    "\n",
    "**25.7** \\[voronoi-exercise\\]Implement an algorithm for calculating the Voronoi\n",
    "diagram of an arbitrary 2D environment, described by an $n\\times n$\n",
    "Boolean array. Illustrate your algorithm by plotting the Voronoi diagram\n",
    "for 10 interesting maps. What is the complexity of your algorithm?\n",
    "\n",
    "**25.8** \\[confspace-exercise\\]This exercise explores the relationship between\n",
    "workspace and configuration space using the examples shown in\n",
    "Figure [FigEx2](#FigEx2).\n",
    "\n",
    "1.  Consider the robot configurations shown in\n",
    "    Figure [FigEx2](#FigEx2)(a) through (c), ignoring the obstacle\n",
    "    shown in each of the diagrams. Draw the corresponding arm\n",
    "    configurations in configuration space. (*Hint:* Each\n",
    "    arm configuration maps to a single point in configuration space, as\n",
    "    illustrated in Figure [FigArm1](#FigEx2)(b).)\n",
    "\n",
    "2.  Draw the configuration space for each of the workspace diagrams in\n",
    "    Figure [FigEx2](#FigEx2)(a)–(c). (*Hint:* The\n",
    "    configuration spaces share with the one shown in\n",
    "    Figure [FigEx2](#FigEx2)(a) the region that corresponds to\n",
    "    self-collision, but differences arise from the lack of enclosing\n",
    "    obstacles and the different locations of the obstacles in these\n",
    "    individual figures.)\n",
    "\n",
    "3.  For each of the black dots in Figure [FigEx2](#/)(e)–(f),\n",
    "    draw the corresponding configurations of the robot arm in workspace.\n",
    "    Please ignore the shaded regions in this exercise.\n",
    "\n",
    "4.  The configuration spaces shown in\n",
    "    Figure [FigEx2](#FigEx2)(e)–(f) have all been generated by a\n",
    "    single workspace obstacle (dark shading), plus the constraints\n",
    "    arising from the self-collision constraint (light shading). Draw,\n",
    "    for each diagram, the workspace obstacle that corresponds to the\n",
    "    darkly shaded area.\n",
    "\n",
    "5.  Figure [FigEx2](#FigEx2)(d) illustrates that a single planar\n",
    "    obstacle can decompose the workspace into two disconnected regions.\n",
    "    What is the maximum number of disconnected regions that can be\n",
    "    created by inserting a planar obstacle into an obstacle-free,\n",
    "    connected workspace, for a 2DOF robot? Give an example, and argue\n",
    "    why no larger number of disconnected regions can be created. How\n",
    "    about a non-planar obstacle?\n",
    "    \n",
    "\n",
    "<center>\n",
    "<b id=\"FigEx2\">Figure [FigEx2]</b> Diagrams for Exercise [confspace-exercise](#/).\n",
    "</center>\n",
    "    \n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad$ |  $\\quad\\quad\\quad\\quad\\quad\\quad$ | $\\quad\\quad\\quad\\quad\\quad\\quad$\n",
    ":-------------------------:|:-------------------------:|:-------------------------:\n",
    "![exerciseRobot1](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseRobot1.svg)  |  ![exerciseRobot3](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseRobot3.svg) |  ![exerciseRobot6](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseRobot6.svg)\n",
    "(a) | (b) | (c)\n",
    "![exerciseConf2](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseConf2.svg)  |  ![exerciseConf4](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseConf4.svg) |  ![exerciseConf5](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/exerciseConf5.svg)\n",
    "(d) | (e) | (f)\n",
    "\n",
    "**25.9** Consider a mobile robot moving on a horizontal surface. Suppose that the\n",
    "robot can execute two kinds of motions:\n",
    "\n",
    "-   Rolling forward a specified distance.\n",
    "\n",
    "-   Rotating in place through a specified angle.\n",
    "\n",
    "The state of such a robot can be characterized in terms of three\n",
    "parameters ${\\langle}x,y,\\phi$, the x-coordinate and y-coordinate of the\n",
    "robot (more precisely, of its center of rotation) and the robot’s\n",
    "orientation expressed as the angle from the positive x direction. The\n",
    "action “$Roll(D)$” has the effect of changing state ${\\langle}x,y,\\phi$\n",
    "to ${\\langle}x+D \\cos(\\phi), y+D \\sin(\\phi), \\phi {\\rangle}$, and the\n",
    "action $Rotate(\\theta)$ has the effect of changing state\n",
    "${\\langle}x,y,\\phi {\\rangle}$ to\n",
    "${\\langle}x,y, \\phi + \\theta {\\rangle}$.\n",
    "\n",
    "1.  Suppose that the robot is initially at ${\\langle}0,0,0 {\\rangle}$\n",
    "    and then executes the actions $Rotate(60^{\\circ})$, $Roll(1)$,\n",
    "    $Rotate(25^{\\circ})$, $Roll(2)$. What is the final state of the\n",
    "    robot?\n",
    "\n",
    "2.  Now suppose that the robot has imperfect control of its own\n",
    "    rotation, and that, if it attempts to rotate by $\\theta$, it may\n",
    "    actually rotate by any angle between $\\theta-10^{\\circ}$ and\n",
    "    $\\theta+10^{\\circ}$. In that case, if the robot attempts to carry\n",
    "    out the sequence of actions in (A), there is a range of possible\n",
    "    ending states. What are the minimal and maximal values of the\n",
    "    x-coordinate, the y-coordinate and the orientation in the final\n",
    "    state?\n",
    "\n",
    "3.  Let us modify the model in (B) to a probabilistic model in which,\n",
    "    when the robot attempts to rotate by $\\theta$, its actual angle of\n",
    "    rotation follows a Gaussian distribution with mean $\\theta$ and\n",
    "    standard deviation $10^{\\circ}$. Suppose that the robot executes the\n",
    "    actions $Rotate(90^{\\circ})$, $Roll(1)$. Give a simple argument\n",
    "    that (a) the expected value of the location at the end is not equal\n",
    "    to the result of rotating exactly $90^{\\circ}$ and then rolling\n",
    "    forward 1 unit, and (b) that the distribution of locations at the\n",
    "    end does not follow a Gaussian. (Do not attempt to calculate the\n",
    "    true mean or the true distribution.)\n",
    "\n",
    "    The point of this exercise is that rotational uncertainty quickly\n",
    "    gives rise to a lot of positional uncertainty and that dealing with\n",
    "    rotational uncertainty is painful, whether uncertainty is treated in\n",
    "    terms of hard intervals or probabilistically, due to the fact that\n",
    "    the relation between orientation and position is both non-linear\n",
    "    and non-monotonic.\n",
    "\n",
    "<center>\n",
    "<b id=\"FigEx3\">Figure [FigEx3]</b> Simplified robot in a maze. See Exercise [robot-exploration-exercise](#/)</center>\n",
    "![FigEx3](http://nalinc.github.io/aima-exercises/Jupyter%20notebook/figures/robotics-pic7.svg)\n",
    "\n",
    "**25.10** \\[robot-exploration-exercise\\]Consider the simplified robot shown in\n",
    "Figure [FigEx3](#FigEx3). Suppose the robot’s Cartesian\n",
    "coordinates are known at all times, as are those of its goal location.\n",
    "However, the locations of the obstacles are unknown. The robot can sense\n",
    "obstacles in its immediate proximity, as illustrated in this figure. For\n",
    "simplicity, let us assume the robot’s motion is noise-free, and the\n",
    "state space is discrete. Figure [FigEx3](#FigEx3) is only one\n",
    "example; in this exercise you are required to address all possible grid\n",
    "worlds with a valid path from the start to the goal location.\n",
    "\n",
    "1.  Design a deliberate controller that guarantees that the robot always\n",
    "    reaches its goal location if at all possible. The deliberate\n",
    "    controller can memorize measurements in the form of a map that is\n",
    "    being acquired as the robot moves. Between individual moves, it may\n",
    "    spend arbitrary time deliberating.\n",
    "\n",
    "2.  Now design a *reactive* controller for the same task.\n",
    "    This controller may not memorize past sensor measurements. (It may\n",
    "    not build a map!) Instead, it has to make all decisions based on the\n",
    "    current measurement, which includes knowledge of its own location\n",
    "    and that of the goal. The time to make a decision must be\n",
    "    independent of the environment size or the number of past\n",
    "    time steps. What is the maximum number of steps that it may take for\n",
    "    your robot to arrive at the goal?\n",
    "\n",
    "3.  How will your controllers from (a) and (b) perform if any of the\n",
    "    following six conditions apply: continuous state space, noise in\n",
    "    perception, noise in motion, noise in both perception and motion,\n",
    "    unknown location of the goal (the goal can be detected only when\n",
    "    within sensor range), or moving obstacles. For each condition and\n",
    "    each controller, give an example of a situation where the robot\n",
    "    fails (or explain why it cannot fail).\n",
    "\n",
    "**25.11** \\[subsumption-exercise\\]In Figure [Fig5](#/)(b) on\n",
    "page [Fig5](#/), we encountered an augmented finite state machine for\n",
    "the control of a single leg of a hexapod robot. In this exercise, the\n",
    "aim is to design an AFSM that, when combined with six copies of the\n",
    "individual leg controllers, results in efficient, stable locomotion. For\n",
    "this purpose, you have to augment the individual leg controller to pass\n",
    "messages to your new AFSM and to wait until other messages arrive. Argue\n",
    "why your controller is efficient, in that it does not unnecessarily\n",
    "waste energy (e.g., by sliding legs), and in that it propels the robot\n",
    "at reasonably high speeds. Prove that your controller satisfies the\n",
    "dynamic stability condition given on page [polygon-stability-condition-page](#/).\n",
    "\n",
    "**25.12** \\[human-robot-exercise\\](This exercise was first devised by Michael\n",
    "Genesereth and Nils Nilsson. It works for first graders through graduate\n",
    "students.) Humans are so adept at basic household tasks that they often\n",
    "forget how complex these tasks are. In this exercise you will discover\n",
    "the complexity and recapitulate the last 30 years of developments in\n",
    "robotics. Consider the task of building an arch out of three blocks.\n",
    "Simulate a robot with four humans as follows:\n",
    "\n",
    "**Brain.** The Brain direct the hands in the execution of a\n",
    "plan to achieve the goal. The Brain receives input from the Eyes, but\n",
    "*cannot see the scene directly*. The brain is the only one\n",
    "who knows what the goal is.\n",
    "\n",
    "**Eyes.** The Eyes report a brief description of the scene\n",
    "to the Brain: “There is a red box standing on top of a green box, which\n",
    "is on its side” Eyes can also answer questions from the Brain such as,\n",
    "“Is there a gap between the Left Hand and the red box?” If you have a\n",
    "video camera, point it at the scene and allow the eyes to look at the\n",
    "viewfinder of the video camera, but not directly at the scene.\n",
    "\n",
    "**Left hand** and **right hand.** One person\n",
    "plays each Hand. The two Hands stand next to each other, each wearing an\n",
    "oven mitt on one hand, Hands execute only simple commands from the\n",
    "Brain—for example, “Left Hand, move two inches forward.” They cannot\n",
    "execute commands other than motions; for example, they cannot be\n",
    "commanded to “Pick up the box.” The Hands must be\n",
    "*blindfolded*. The only sensory capability they have is the\n",
    "ability to tell when their path is blocked by an immovable obstacle such\n",
    "as a table or the other Hand. In such cases, they can beep to inform the\n",
    "Brain of the difficulty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
